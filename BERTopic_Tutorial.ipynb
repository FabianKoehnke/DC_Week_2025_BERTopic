{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic Tutorial\n",
    "\n",
    "This tutorial is a compilation of the BERTopic documetation, the corresponding paper, the SBERT documentation and own code to give an introduction to topic modeling with BERTopic. This should enable you to carry out practical experiments with your own data. ðŸš€\n",
    "\n",
    "## Introduction\n",
    "\n",
    "BERTopic leverages ðŸ¤— transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "\n",
    "We can use topic modeling, e.g., for:\n",
    "\n",
    "- Clustering : Grouping related papers based on their topics\n",
    "- Automatic Summarization : Extracting main topics from a vast number of papers\n",
    "- Research Gap Identification : Detecting underexplored areas by analyzing topic distributions\n",
    "- Interdisciplinary Studies : Finding connections between different research domains\n",
    "- Recommendation Systems â€“ Suggesting relevant papers based on topic similarities\n",
    "\n",
    "## Main Representation of the Algotihm \n",
    "\n",
    "Step 1. Embedding  \n",
    "Step 2. Dimensionality Reduction  \n",
    "Step 3. Clustering  \n",
    "Step 4. Tokenizer  \n",
    "Step 5. Weighting scheme  \n",
    "\n",
    "NOTE: All steps are independent and modulare. E.g., you so can use a variety of clustering models (k-Means, HDBSCAN...)\n",
    "\n",
    "### 1. Embedding \n",
    "\n",
    "Embedding refers to the process of converting high-dimensional data (like words) into a lower-dimensional, dense numerical representation. These representations (vectors), capture meaningful relationships between entities, making it easier for AI models to understand and process data efficiently.\n",
    "\n",
    "With BERTopic and Sentence Transformers we try to capture the meaning of whole sentences or documents. According to the documentation, sentences or entire documents can be used for embedding. We can use multiple pre-trained sentence-transformers. Here is a list:\n",
    "\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "\n",
    "<div style=\"border: 1px solid white; padding: 10px;\">\n",
    "DEGRESSION - Transformers:\n",
    "\n",
    "A Transformer is a deep learning architecture introduced in the paper \"Attention Is All You Need\" by Vaswani et al. (2017). It revolutionized natural language processing (NLP) by replacing older models like RNNs and LSTMs with a more efficient mechanism: self-attention.\n",
    "\n",
    "Self-Attention Mechanism\n",
    "- Each word (or token) in a sentence attends to all other words, learning contextual relationships dynamically.  \n",
    "\n",
    "Positional Encoding\n",
    "- Since Transformers donâ€™t process words sequentially like RNNs, they need a way to understand the order of words.\n",
    "- Positional encoding adds information about word order to the embeddings.  \n",
    "\n",
    "Multi-Head Attention\n",
    "- Instead of just one self-attention mechanism, multiple attention heads allow the model to focus on different parts of a sentence simultaneously.\n",
    "</div>\n",
    "\n",
    "The embedding are primarily used to cluster semantically similar documents and not directly used in generating the topics...\n",
    "\n",
    "### 2. Dimensionality Reduction \n",
    "\n",
    "After having created our numerical representations of the documents we have to reduce the dimensionality of these representations. Cluster models typically have difficulty handling high dimensional data due to the curse of dimensionality. There are great approaches that can reduce dimensionality, such as PCA, but as a default UMAP is selected in BERTopic. It is a technique that can keep some of a dataset's local and global structure when reducing its dimensionality. This structure is important to keep as it contains the information necessary to create clusters of semantically similar documents.\n",
    "\n",
    "### 3. Cluster Documents\n",
    "\n",
    "After having reduced our embeddings, we can start clustering our data. For that, we leverage a density-based clustering technique, HDBSCAN. It can find clusters of different shapes and has the nice feature of identifying outliers where possible. As a result, we do not force documents into a cluster where they might not belong. This will improve the resulting topic representation as there is less noise to draw from.\n",
    "\n",
    "NOTE: Paper of HDBSCAN: Leland McInnes, John Healy, and Steve Astels. 2017. hdbscan: Hierarchical density based clustering. The Journal of Open Source Software, 2(11):205.\n",
    "\n",
    "<div style=\"border: 1px solid white; padding: 10px;\">\n",
    "DEGRESSION - HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise):\n",
    "\n",
    "It works in four main steps:\n",
    "\n",
    "1. Construct Mutual Reachability Graph â€“ This distance metric considers both the core distance (the distance to the k-th nearest neighbor) and the mutual reachability distance between points.\n",
    "2. Generate Minimum Spanning Tree (MST) â€“ Builds a MST from the distance graph, capturing cluster connectivity.\n",
    "3. Hierarchical Clustering â€“ Forms a hierarchy by progressively removing longest edges in the MST.\n",
    "4. Condense and Extract Stable Clusters â€“ instead of manually selecting a clustering level, HDBSCAN automatically determines the most stable clusters by analyzing the persistence of clusters in the hierarchy. Clusters that persist across different levels of granularity are considered meaningful.\n",
    "5. Identifying Noise - HDBSCAN automatically classifies outliers as noise when they do not belong to any stable cluster.\n",
    "\n",
    "</div>\n",
    "\n",
    "### 4. Tokenizer \n",
    "\n",
    "We want a topic representation technique that makes little to no assumption on the expected structure of the clusters. To do this, we first combine all documents in a cluster into a single document. That, very long, document then represents the cluster. Then, we can count how often each word appears in each cluster This generates something called a bag-of-words representation in which the frequency of each word in each cluster can be found. This bag-of-words representation is therefore on a cluster level and not on a document level. This distinction is important as we are interested in words on a topic level (i.e., cluster level). By using a bag-of-words representation, no assumption is made concerning the structure of the clusters. \n",
    "\n",
    "NOTE: detailed informations here: https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "### 5. Weighting scheme  \n",
    "\n",
    "From the generated bag-of-words representation, we want to know what makes one cluster different from another. Which words are typical for cluster 1 and not so much for all other clusters? \n",
    "\n",
    "The topic representations are modeled based on the documents in each cluster where each cluster will\n",
    "be assigned one topic. For each topic, we want to know what makes one topic, based on its cluster-\n",
    "word distribution, different from another? For this purpose, we can modify TF-IDF (Term Frequency-Inverse Document Frequency), a measure for representing the importance of a word to a document, such that it allows for a representation of a termâ€™s importance to a topic instead.\n",
    "\n",
    "The classic TF-IDF procedure combines two statistics, term frequency, and inverse document\n",
    "frequency: \n",
    "\n",
    "$$\n",
    "W_{t,d}=tf_{t,d} \\cdot log(\\frac{N}{df_t})\n",
    "$$\n",
    "\n",
    "Where the term frequency models the frequency of term $t$ in document $d$. The inverse document frequency measures how much information a term provides to a document and is calculated by taking the logarithm of the number of documents in a corpus $N$ divided by the total number of documents that contain $t$.\n",
    "\n",
    "We generalize this procedure to clusters of documents: \n",
    "\n",
    "$$\n",
    "W_{t,c}=tf_{t,c} \\cdot log(1+\\frac{A}{tf_t})\n",
    "$$\n",
    "\n",
    "Where the term frequency models the frequency of term $t$ in a class $c$ or in this instance. Here, the class $c$ is the collection of documents concatenated into a single document for each cluster. Then, the inverse document frequency is replaced by the inverse class frequency to measure how much information a term provides to a class. It is calculated by taking the logarithm of the average number of words per class $A$ divided by the frequency of term $t$ across all classes. To output only positive values, we add one to the division within the logarithm. Thus, this class-based TF-IDF procedure models the importance of words in clusters instead of individual documents. This allows us to generate topic-word distributions for each cluster of documents.\n",
    "\n",
    "In other words, if we extract the most important words per cluster, we get descriptions of topics!\n",
    "\n",
    "### Further Informations \n",
    "\n",
    "- Paper : https://arxiv.org/abs/2203.05794\n",
    "- Project Homepage : https://maartengr.github.io/BERTopic/index.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to ... TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install bertopic\n",
    "!pip install datasets\n",
    "!pip isntall PyPDF2\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HINT: We pobably need to restart the notebook after the installations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bertopic as bt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from hdbscan import HDBSCAN\n",
    "from datasets import load_dataset\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "from umap import UMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef extract_text_from_pdf(pdf_path):\\n    reader = PdfReader(pdf_path)\\n    #text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\\n    text = reader.pages[0].extract_text()\\n\\n    return text\\n\\ndata = []\\npath_data = \"/Users/Fabian/Documents/DataScience/Phd/Disertation/Research/Paper/\" # TODO change to your path\\n\\nfor pdf in os.listdir(path_data):\\n    if pdf[-3:] == \"pdf\":\\n        pdf_text = extract_text_from_pdf(path_data + pdf)\\n        data.append(pdf_text)\\n    else:\\n        print(\"file is not a pdf\")\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = load_dataset(\"newsgroup\", '18828_alt.atheism')[\"train\"][\"text\"]\n",
    "data = load_dataset(\"CShorten/ML-ArXiv-Papers\")[\"train\"][\"abstract\"][0:1500]\n",
    "'''\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    #text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    text = reader.pages[0].extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "data = []\n",
    "path_data = \"/Users/Fabian/Documents/DataScience/Phd/Disertation/Research/Paper/\" # TODO change to your path\n",
    "\n",
    "for pdf in os.listdir(path_data):\n",
    "    if pdf[-3:] == \"pdf\":\n",
    "        pdf_text = extract_text_from_pdf(path_data + pdf)\n",
    "        data.append(pdf_text)\n",
    "    else:\n",
    "        print(\"file is not a pdf\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We can change the embedding model to any other models from the sentence-transformers here:\n",
    "\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 23:39:05,090 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:47<00:00,  1.02s/it]\n",
      "2025-02-23 23:39:54,480 - BERTopic - Embedding - Completed âœ“\n",
      "2025-02-23 23:39:54,481 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-02-23 23:39:56,938 - BERTopic - Dimensionality - Completed âœ“\n",
      "2025-02-23 23:39:56,940 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-02-23 23:39:56,972 - BERTopic - Cluster - Completed âœ“\n",
      "2025-02-23 23:39:56,975 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-02-23 23:40:05,092 - BERTopic - Representation - Completed âœ“\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Extract embeddings\n",
    "embedding_model = \"all-MiniLM-L6-v2\" # all-mpnet-base-v2\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=2, \n",
    "    min_dist=0.0, \n",
    "    metric='cosine'\n",
    "    )\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=10, \n",
    "    metric='euclidean', \n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True\n",
    "    )\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = bt.vectorizers.ClassTfidfTransformer()\n",
    "# Step 6 - (Optional) Fine-tune topic representations with \n",
    "# a `bertopic.representation` model\n",
    "representation_model = bt.representation.KeyBERTInspired()\n",
    "\n",
    "# All steps together\n",
    "topic_model = bt.BERTopic(\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "  representation_model=representation_model, # Step 6 - (Optional) Fine-tune topic representations\n",
    "  verbose=True,\n",
    "  language=\"english\"\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>432</td>\n",
       "      <td>-1_classification_generalization_learning_pred...</td>\n",
       "      <td>[classification, generalization, learning, pre...</td>\n",
       "      <td>[  We investigate fast methods that allow to q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0_kernels_kernel_regularization_classification</td>\n",
       "      <td>[kernels, kernel, regularization, classificati...</td>\n",
       "      <td>[  In this paper, the framework of kernel mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1_reinforcement_learning_planning_reward</td>\n",
       "      <td>[reinforcement, learning, planning, reward, ad...</td>\n",
       "      <td>[  This paper introduces an approach to Reinfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name   \n",
       "0     -1    432  -1_classification_generalization_learning_pred...  \\\n",
       "1      0    132     0_kernels_kernel_regularization_classification   \n",
       "2      1     83           1_reinforcement_learning_planning_reward   \n",
       "\n",
       "                                      Representation   \n",
       "0  [classification, generalization, learning, pre...  \\\n",
       "1  [kernels, kernel, regularization, classificati...   \n",
       "2  [reinforcement, learning, planning, reward, ad...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [  We investigate fast methods that allow to q...  \n",
       "1  [  In this paper, the framework of kernel mach...  \n",
       "2  [  This paper introduces an approach to Reinfo...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info() \n",
    "freq.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HINT: -1 refers to all outliers and should typically be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.42155635356903076,
          0.4273573160171509,
          0.44484782218933105,
          0.48855236172676086,
          0.5491005182266235
         ],
         "xaxis": "x",
         "y": [
          "supervised  ",
          "classification  ",
          "regularization  ",
          "kernel  ",
          "kernels  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.3260829746723175,
          0.34065723419189453,
          0.38264089822769165,
          0.40806707739830017,
          0.4892163872718811
         ],
         "xaxis": "x2",
         "y": [
          "adaptive  ",
          "reward  ",
          "planning  ",
          "learning  ",
          "reinforcement  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.39481106400489807,
          0.5049728155136108,
          0.5627057552337646,
          0.6566301584243774,
          0.6980440616607666
         ],
         "xaxis": "x3",
         "y": [
          "clustered  ",
          "clusters  ",
          "cluster  ",
          "clustering  ",
          "clusterings  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.4053646922111511,
          0.4231785535812378,
          0.5166143178939819,
          0.549309253692627,
          0.5967666506767273
         ],
         "xaxis": "x4",
         "y": [
          "features  ",
          "ensembles  ",
          "classification  ",
          "classifier  ",
          "classifiers  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.34934696555137634,
          0.3721371293067932,
          0.4476954936981201,
          0.5488320589065552,
          0.555300772190094
         ],
         "xaxis": "x5",
         "y": [
          "reward  ",
          "strategy  ",
          "optimal  ",
          "bandits  ",
          "bandit  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.3331869840621948,
          0.3409801125526428,
          0.37458738684654236,
          0.3763282299041748,
          0.3770625591278076
         ],
         "xaxis": "x6",
         "y": [
          "complexity  ",
          "algorithms  ",
          "learning  ",
          "learnable  ",
          "learnability  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.33181318640708923,
          0.35800033807754517,
          0.37310659885406494,
          0.3755280673503876,
          0.4016425907611847
         ],
         "xaxis": "x7",
         "y": [
          "allocation  ",
          "rewards  ",
          "optimal  ",
          "reward  ",
          "bandit  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.4051779508590698,
          0.4163983464241028,
          0.4477332830429077,
          0.4602118134498596,
          0.4829351007938385
         ],
         "xaxis": "x8",
         "y": [
          "semantics  ",
          "labeling  ",
          "semantic  ",
          "classification  ",
          "corpus  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This work reports the most relevant technical aspects in the problem of\nlearning the \\emph{Markov network structure} from data. Such problem has become\nincreasingly important in machine learning, and many other application fields\nof machine learning. Markov networks, together with Bayesian networks, are\nprobabilistic graphical models, a widely used formalism for handling\nprobability distributions in intelligent systems. Learning graphical models\nfrom data have been extensively applied for the case of Bayesian networks, but\nfor Markov networks learning it is not tractable in practice. However, this\nsituation is changing with time, given the exponential growth of computers\ncapacity, the plethora of available digital data, and the researching on new\nlearning technologies. This work stresses on a technology called\nindependence-based learning, which allows the learning of the independence\nstructure of those networks from data in an efficient and sound manner,\nwhenever the dataset is sufficiently large, and data is a representative\nsampling of the target distribution. In the analysis of such technology, this\nwork surveys the current state-of-the-art algorithms for learning Markov\nnetworks structure, discussing its current limitations, and proposing a series\nof open problems where future works may produce some advances in the area in\nterms of quality and efficiency. The paper concludes by opening a discussion\nabout how to develop a general formalism for improving the quality of the\nstructures learned, when data is scarce.\n",
          "  For the universal hypothesis testing problem, where the goal is to decide\nbetween the known null hypothesis distribution and some other unknown\ndistribution, Hoeffding proposed a universal test in the nineteen sixties.\nHoeffding's universal test statistic can be written in terms of\nKullback-Leibler (K-L) divergence between the empirical distribution of the\nobservations and the null hypothesis distribution. In this paper a modification\nof Hoeffding's test is considered based on a relaxation of the K-L divergence\ntest statistic, referred to as the mismatched divergence. The resulting\nmismatched test is shown to be a generalized likelihood-ratio test (GLRT) for\nthe case where the alternate distribution lies in a parametric family of the\ndistributions characterized by a finite dimensional parameter, i.e., it is a\nsolution to the corresponding composite hypothesis testing problem. For certain\nchoices of the alternate distribution, it is shown that both the Hoeffding test\nand the mismatched test have the same asymptotic performance in terms of error\nexponents. A consequence of this result is that the GLRT is optimal in\ndifferentiating a particular distribution from others in an exponential family.\nIt is also shown that the mismatched test has a significant advantage over the\nHoeffding test in terms of finite sample size performance. This advantage is\ndue to the difference in the asymptotic variances of the two test statistics\nunder the null hypothesis. In particular, the variance of the K-L divergence\ngrows linearly with the alphabet size, making the test impractical for\napplications involving large alphabet distributions. The variance of the\nmismatched divergence on the other hand grows linearly with the dimension of\nthe parameter space, and can hence be controlled through a prudent choice of\nthe function class defining the mismatched divergence.\n",
          "  We propose an adaptive diffusion mechanism to optimize a global cost function\nin a distributed manner over a network of nodes. The cost function is assumed\nto consist of a collection of individual components. Diffusion adaptation\nallows the nodes to cooperate and diffuse information in real-time; it also\nhelps alleviate the effects of stochastic gradient noise and measurement noise\nthrough a continuous learning process. We analyze the mean-square-error\nperformance of the algorithm in some detail, including its transient and\nsteady-state behavior. We also apply the diffusion algorithm to two problems:\ndistributed estimation with sparse parameters and distributed localization.\nCompared to well-studied incremental methods, diffusion methods do not require\nthe use of a cyclic path over the nodes and are robust to node and link\nfailure. Diffusion methods also endow networks with adaptation abilities that\nenable the individual nodes to continue learning even when the cost function\nchanges with time. Examples involving such dynamic cost functions with moving\ntargets are common in the context of biological networks.\n",
          "  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers\nfor an offline signature system. From the signature images, global and local\nfeatures are extracted and the signatures are verified with the help of\nGaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.\nSVM is used to fuse matching scores of these matchers. Finally, recognition of\nquery signatures is done by comparing it with all signatures of the database.\nThe proposed system is tested on a signature database contains 5400 offline\nsignatures of 600 individuals and the results are found to be promising.\n",
          "  We introduce a scalable algorithm, MUCCA, for multiclass node classification\nin weighted graphs. Unlike previously proposed methods for the same task, MUCCA\nworks in time linear in the number of nodes. Our approach is based on a\ngame-theoretic formulation of the problem in which the test labels are\nexpressed as a Nash Equilibrium of a certain game. However, in order to achieve\nscalability, we find the equilibrium on a spanning tree of the original graph.\nExperiments on real-world data reveal that MUCCA is much faster than its\ncompetitors while achieving a similar predictive performance.\n",
          "  In this work we investigate the relationship between Bregman distances and\nregularized Logistic Regression model. We present a detailed study of Bregman\nDistance minimization, a family of generalized entropy measures associated with\nconvex functions. We convert the L1-regularized logistic regression into this\nmore general framework and propose a primal-dual method based algorithm for\nlearning the parameters. We pose L1-regularized logistic regression into\nBregman distance minimization and then apply non-linear constrained\noptimization techniques to estimate the parameters of the logistic model.\n",
          "  We consider linear models for stochastic dynamics. To any such model can be\nassociated a network (namely a directed graph) describing which degrees of\nfreedom interact under the dynamics. We tackle the problem of learning such a\nnetwork from observation of the system trajectory over a time interval $T$.\n  We analyze the $\\ell_1$-regularized least squares algorithm and, in the\nsetting in which the underlying network is sparse, we prove performance\nguarantees that are \\emph{uniform in the sampling rate} as long as this is\nsufficiently high. This result substantiates the notion of a well defined `time\ncomplexity' for the network inference problem.\n",
          "  Learning theory has largely focused on two main learning scenarios. The first\nis the classical statistical setting where instances are drawn i.i.d. from a\nfixed distribution and the second scenario is the online learning, completely\nadversarial scenario where adversary at every time step picks the worst\ninstance to provide the learner with. It can be argued that in the real world\nneither of these assumptions are reasonable. It is therefore important to study\nproblems with a range of assumptions on data. Unfortunately, theoretical\nresults in this area are scarce, possibly due to absence of general tools for\nanalysis. Focusing on the regret formulation, we define the minimax value of a\ngame where the adversary is restricted in his moves. The framework captures\nstochastic and non-stochastic assumptions on data. Building on the sequential\nsymmetrization approach, we define a notion of distribution-dependent\nRademacher complexity for the spectrum of problems ranging from i.i.d. to\nworst-case. The bounds let us immediately deduce variation-type bounds. We then\nconsider the i.i.d. adversary and show equivalence of online and batch\nlearnability. In the supervised setting, we consider various hybrid assumptions\non the way that x and y variables are chosen. Finally, we consider smoothed\nlearning problems and show that half-spaces are online learnable in the\nsmoothed model. In fact, exponentially small noise added to adversary's\ndecisions turns this problem with infinite Littlestone's dimension into a\nlearnable problem.\n",
          "  We develop a Bayesian framework for tackling the supervised clustering\nproblem, the generic problem encountered in tasks such as reference matching,\ncoreference resolution, identity uncertainty and record linkage. Our clustering\nmodel is based on the Dirichlet process prior, which enables us to define\ndistributions over the countably infinite sets that naturally arise in this\nproblem. We add supervision to our model by positing the existence of a set of\nunobserved random variables (we call these \"reference types\") that are generic\nacross all clusters. Inference in our framework, which requires integrating\nover infinitely many parameters, is solved using Markov chain Monte Carlo\ntechniques. We present algorithms for both conjugate and non-conjugate priors.\nWe present a simple--but general--parameterization of our model based on a\nGaussian assumption. We evaluate this model on one artificial task and three\nreal-world tasks, comparing it against both unsupervised and state-of-the-art\nsupervised algorithms. Our results show that our model is able to outperform\nother models across a variety of tasks and performance metrics.\n",
          "  This paper describes algorithms for nonnegative matrix factorization (NMF)\nwith the beta-divergence (beta-NMF). The beta-divergence is a family of cost\nfunctions parametrized by a single shape parameter beta that takes the\nEuclidean distance, the Kullback-Leibler divergence and the Itakura-Saito\ndivergence as special cases (beta = 2,1,0, respectively). The proposed\nalgorithms are based on a surrogate auxiliary function (a local majorization of\nthe criterion function). We first describe a majorization-minimization (MM)\nalgorithm that leads to multiplicative updates, which differ from standard\nheuristic multiplicative updates by a beta-dependent power exponent. The\nmonotonicity of the heuristic algorithm can however be proven for beta in (0,1)\nusing the proposed auxiliary function. Then we introduce the concept of\nmajorization-equalization (ME) algorithm which produces updates that move along\nconstant level sets of the auxiliary function and lead to larger steps than MM.\nSimulations on synthetic and real data illustrate the faster convergence of the\nME approach. The paper also describes how the proposed algorithms can be\nadapted to two common variants of NMF : penalized NMF (i.e., when a penalty\nfunction of the factors is added to the criterion function) and convex-NMF\n(when the dictionary is assumed to belong to a known subspace).\n",
          "  Supervised learning is all about the ability to generalize knowledge.\nSpecifically, the goal of the learning is to train a classifier using training\ndata, in such a way that it will be capable of classifying new unseen data\ncorrectly. In order to acheive this goal, it is important to carefully design\nthe learner, so it will not overfit the training data. The later can is done\nusually by adding a regularization term. The statistical learning theory\nexplains the success of this method by claiming that it restricts the\ncomplexity of the learned model. This explanation, however, is rather abstract\nand does not have a geometric intuition. The generalization error of a\nclassifier may be thought of as correlated with its robustness to perturbations\nof the data: a classifier that copes with disturbance is expected to generalize\nwell. Indeed, Xu et al. [2009] have shown that the SVM formulation is\nequivalent to a robust optimization (RO) formulation, in which an adversary\ndisplaces the training and testing points within a ball of pre-determined\nradius. In this work we explore a different kind of robustness, namely changing\neach data point with a Gaussian cloud centered at the sample. Loss is evaluated\nas the expectation of an underlying loss function on the cloud. This setup fits\nthe fact that in many applications, the data is sampled along with noise. We\ndevelop an RO framework, in which the adversary chooses the covariance of the\nnoise. In our algorithm named GURU, the tuning parameter is a spectral bound on\nthe noise, thus it can be estimated using physical or applicative\nconsiderations. Our experiments show that this framework performs as well as\nSVM and even slightly better in some cases. Generalizations for Mercer kernels\nand for the multiclass case are presented as well. We also show that our\nframework may be further generalized, using the technique of convex perspective\nfunctions.\n",
          "  Machine Learning competitions such as the Netflix Prize have proven\nreasonably successful as a method of \"crowdsourcing\" prediction tasks. But\nthese competitions have a number of weaknesses, particularly in the incentive\nstructure they create for the participants. We propose a new approach, called a\nCrowdsourced Learning Mechanism, in which participants collaboratively \"learn\"\na hypothesis for a given prediction task. The approach draws heavily from the\nconcept of a prediction market, where traders bet on the likelihood of a future\nevent. In our framework, the mechanism continues to publish the current\nhypothesis, and participants can modify this hypothesis by wagering on an\nupdate. The critical incentive property is that a participant will profit an\namount that scales according to how much her update improves performance on a\nreleased test set.\n",
          "  In this paper we present a method for learning the parameters of a mixture of\n$k$ identical spherical Gaussians in $n$-dimensional space with an arbitrarily\nsmall separation between the components. Our algorithm is polynomial in all\nparameters other than $k$. The algorithm is based on an appropriate grid search\nover the space of parameters. The theoretical analysis of the algorithm hinges\non a reduction of the problem to 1 dimension and showing that two 1-dimensional\nmixtures whose densities are close in the $L^2$ norm must have similar means\nand mixing coefficients. To produce such a lower bound for the $L^2$ norm in\nterms of the distances between the corresponding means, we analyze the behavior\nof the Fourier transform of a mixture of Gaussians in 1 dimension around the\norigin, which turns out to be closely related to the properties of the\nVandermonde matrix obtained from the component means. Analysis of this matrix\ntogether with basic function approximation results allows us to provide a lower\nbound for the norm of the mixture in the Fourier domain.\n  In recent years much research has been aimed at understanding the\ncomputational aspects of learning parameters of Gaussians mixture distributions\nin high dimension. To the best of our knowledge all existing work on learning\nparameters of Gaussian mixtures assumes minimum separation between components\nof the mixture which is an increasing function of either the dimension of the\nspace $n$ or the number of components $k$. In our paper we prove the first\nresult showing that parameters of a $n$-dimensional Gaussian mixture model with\narbitrarily small component separation can be learned in time polynomial in\n$n$.\n",
          "  The problem is sequence prediction in the following setting. A sequence\n$x_1,...,x_n,...$ of discrete-valued observations is generated according to\nsome unknown probabilistic law (measure) $\\mu$. After observing each outcome,\nit is required to give the conditional probabilities of the next observation.\nThe measure $\\mu$ belongs to an arbitrary but known class $C$ of stochastic\nprocess measures. We are interested in predictors $\\rho$ whose conditional\nprobabilities converge (in some sense) to the \"true\" $\\mu$-conditional\nprobabilities if any $\\mu\\in C$ is chosen to generate the sequence. The\ncontribution of this work is in characterizing the families $C$ for which such\npredictors exist, and in providing a specific and simple form in which to look\nfor a solution. We show that if any predictor works, then there exists a\nBayesian predictor, whose prior is discrete, and which works too. We also find\nseveral sufficient and necessary conditions for the existence of a predictor,\nin terms of topological characterizations of the family $C$, as well as in\nterms of local behaviour of the measures in $C$, which in some cases lead to\nprocedures for constructing such predictors. It should be emphasized that the\nframework is completely general: the stochastic processes considered are not\nrequired to be i.i.d., stationary, or to belong to any parametric or countable\nfamily.\n",
          "  Artificial intelligence offers superior techniques and methods by which\nproblems from diverse domains may find an optimal solution. The Machine\nLearning technologies refer to the domain of artificial intelligence aiming to\ndevelop the techniques allowing the computers to \"learn\". Some systems based on\nMachine Learning technologies tend to eliminate the necessity of the human\nintelligence while the others adopt a man-machine collaborative approach.\n",
          "  Scikit-learn is a Python module integrating a wide range of state-of-the-art\nmachine learning algorithms for medium-scale supervised and unsupervised\nproblems. This package focuses on bringing machine learning to non-specialists\nusing a general-purpose high-level language. Emphasis is put on ease of use,\nperformance, documentation, and API consistency. It has minimal dependencies\nand is distributed under the simplified BSD license, encouraging its use in\nboth academic and commercial settings. Source code, binaries, and documentation\ncan be downloaded from http://scikit-learn.org.\n",
          "  We consider the most common variants of linear regression, including Ridge,\nLasso and Support-vector regression, in a setting where the learner is allowed\nto observe only a fixed number of attributes of each example at training time.\nWe present simple and efficient algorithms for these problems: for Lasso and\nRidge regression they need the same total number of attributes (up to\nconstants) as do full-information algorithms, for reaching a certain accuracy.\nFor Support-vector regression, we require exponentially less attributes\ncompared to the state of the art. By that, we resolve an open problem recently\nposed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to\nbe justified by superior performance compared to the state of the art.\n",
          "  In several online prediction problems of recent interest the comparison class\nis composed of matrices with bounded entries. For example, in the online\nmax-cut problem, the comparison class is matrices which represent cuts of a\ngiven graph and in online gambling the comparison class is matrices which\nrepresent permutations over n teams. Another important example is online\ncollaborative filtering in which a widely used comparison class is the set of\nmatrices with a small trace norm. In this paper we isolate a property of\nmatrices, which we call (beta,tau)-decomposability, and derive an efficient\nonline learning algorithm, that enjoys a regret bound of O*(sqrt(beta tau T))\nfor all problems in which the comparison class is composed of\n(beta,tau)-decomposable matrices. By analyzing the decomposability of cut\nmatrices, triangular matrices, and low trace-norm matrices, we derive near\noptimal regret bounds for online max-cut, online gambling, and online\ncollaborative filtering. In particular, this resolves (in the affirmative) an\nopen problem posed by Abernethy (2010); Kleinberg et al (2010). Finally, we\nderive lower bounds for the three problems and show that our upper bounds are\noptimal up to logarithmic factors. In particular, our lower bound for the\nonline collaborative filtering problem resolves another open problem posed by\nShamir and Srebro (2011).\n",
          "  We consider the problem of identifying patterns in a data set that exhibit\nanomalous behavior, often referred to as anomaly detection. In most anomaly\ndetection algorithms, the dissimilarity between data samples is calculated by a\nsingle criterion, such as Euclidean distance. However, in many cases there may\nnot exist a single dissimilarity measure that captures all possible anomalous\npatterns. In such a case, multiple criteria can be defined, and one can test\nfor anomalies by scalarizing the multiple criteria using a linear combination\nof them. If the importance of the different criteria are not known in advance,\nthe algorithm may need to be executed multiple times with different choices of\nweights in the linear combination. In this paper, we introduce a novel\nnon-parametric multi-criteria anomaly detection method using Pareto depth\nanalysis (PDA). PDA uses the concept of Pareto optimality to detect anomalies\nunder multiple criteria without having to run an algorithm multiple times with\ndifferent choices of weights. The proposed PDA approach scales linearly in the\nnumber of criteria and is provably better than linear combinations of the\ncriteria.\n",
          "  Reservoir computing is a recently introduced, highly efficient bio-inspired\napproach for processing time dependent data. The basic scheme of reservoir\ncomputing consists of a non linear recurrent dynamical system coupled to a\nsingle input layer and a single output layer. Within these constraints many\nimplementations are possible. Here we report an opto-electronic implementation\nof reservoir computing based on a recently proposed architecture consisting of\na single non linear node and a delay line. Our implementation is sufficiently\nfast for real time information processing. We illustrate its performance on\ntasks of practical importance such as nonlinear channel equalization and speech\nrecognition, and obtain results comparable to state of the art digital\nimplementations.\n",
          "  This paper addresses the problem of finding the nearest neighbor (or one of\nthe R-nearest neighbors) of a query object q in a database of n objects. In\ncontrast with most existing approaches, we can only access the ``hidden'' space\nin which the objects live through a similarity oracle. The oracle, given two\nreference objects and a query object, returns the reference object closest to\nthe query object. The oracle attempts to model the behavior of human users,\ncapable of making statements about similarity, but not of assigning meaningful\nnumerical values to distances between objects.\n",
          "  In this article, we derive a new generalization of Chebyshev inequality for\nrandom vectors. We demonstrate that the new generalization is much less\nconservative than the classical generalization.\n",
          "  We tackle the fundamental problem of Bayesian active learning with noise,\nwhere we need to adaptively select from a number of expensive tests in order to\nidentify an unknown hypothesis sampled from a known prior distribution. In the\ncase of noise-free observations, a greedy algorithm called generalized binary\nsearch (GBS) is known to perform near-optimally. We show that if the\nobservations are noisy, perhaps surprisingly, GBS can perform very poorly. We\ndevelop EC2, a novel, greedy active learning algorithm and prove that it is\ncompetitive with the optimal policy, thus obtaining the first competitiveness\nguarantees for Bayesian active learning with noisy observations. Our bounds\nrely on a recently discovered diminishing returns property called adaptive\nsubmodularity, generalizing the classical notion of submodular set functions to\nadaptive policies. Our results hold even if the tests have non-uniform cost and\ntheir noise is correlated. We also propose EffECXtive, a particularly fast\napproximation of EC2, and evaluate it on a Bayesian experimental design problem\ninvolving human subjects, intended to tease apart competing economic theories\nof how people make decisions under uncertainty.\n",
          "  We propose a novel non-parametric adaptive anomaly detection algorithm for\nhigh dimensional data based on score functions derived from nearest neighbor\ngraphs on $n$-point nominal data. Anomalies are declared whenever the score of\na test sample falls below $\\alpha$, which is supposed to be the desired false\nalarm level. The resulting anomaly detector is shown to be asymptotically\noptimal in that it is uniformly most powerful for the specified false alarm\nlevel, $\\alpha$, for the case when the anomaly density is a mixture of the\nnominal and a known density. Our algorithm is computationally efficient, being\nlinear in dimension and quadratic in data size. It does not require choosing\ncomplicated tuning parameters or function approximation classes and it can\nadapt to local structure such as local change in dimensionality. We demonstrate\nthe algorithm on both artificial and real data sets in high dimensional feature\nspaces.\n",
          "  Exponential family extensions of principal component analysis (EPCA) have\nreceived a considerable amount of attention in recent years, demonstrating the\ngrowing need for basic modeling tools that do not assume the squared loss or\nGaussian distribution. We extend the EPCA model toolbox by presenting the first\nexponential family multi-view learning methods of the partial least squares and\ncanonical correlation analysis, based on a unified representation of EPCA as\nmatrix factorization of the natural parameters of exponential family. The\nmodels are based on a new family of priors that are generally usable for all\nsuch factorizations. We also introduce new inference strategies, and\ndemonstrate how the methods outperform earlier ones when the Gaussianity\nassumption does not hold.\n",
          "  Catalogs of periodic variable stars contain large numbers of periodic\nlight-curves (photometric time series data from the astrophysics domain).\nSeparating anomalous objects from well-known classes is an important step\ntowards the discovery of new classes of astronomical objects. Most anomaly\ndetection methods for time series data assume either a single continuous time\nseries or a set of time series whose periods are aligned. Light-curve data\nprecludes the use of these methods as the periods of any given pair of\nlight-curves may be out of sync. One may use an existing anomaly detection\nmethod if, prior to similarity calculation, one performs the costly act of\naligning two light-curves, an operation that scales poorly to massive data\nsets. This paper presents PCAD, an unsupervised anomaly detection method for\nlarge sets of unsynchronized periodic time-series data, that outputs a ranked\nlist of both global and local anomalies. It calculates its anomaly score for\neach light-curve in relation to a set of centroids produced by a modified\nk-means clustering algorithm. Our method is able to scale to large data sets\nthrough the use of sampling. We validate our method on both light-curve data\nand other time series data sets. We demonstrate its effectiveness at finding\nknown anomalies, and discuss the effect of sample size and number of centroids\non our results. We compare our method to naive solutions and existing time\nseries anomaly detection methods for unphased data, and show that PCAD's\nreported anomalies are comparable to or better than all other methods. Finally,\nastrophysicists on our team have verified that PCAD finds true anomalies that\nmight be indicative of novel astrophysical phenomena.\n",
          "  Classification of some objects in classes of concepts is an essential and\neven breathtaking task in many applications. A solution is discussed here based\non Multi-Agent systems. A kernel of some expert agents in several classes is to\nconsult a central agent decide among the classification problem of a certain\nobject. This kernel is moderated with the center agent, trying to manage the\nquerying agents for any decision problem by means of a data-header like feature\nset. Agents have cooperation among concepts related to the classes of this\nclassification decision-making; and may affect on each others' results on a\ncertain query object in a multi-agent learning approach. This leads to an\nonline feature learning via the consulting trend. The performance is discussed\nto be much better in comparison to some other prior trends while system's\nmessage passing overload is decreased to less agents and the expertism helps\nthe performance and operability of system win the comparison.\n",
          "  The use of computational intelligence techniques for classification has been\nused in numerous applications. This paper compares the use of a Multi Layer\nPerceptron Neural Network and a new Relational Network on classifying the HIV\nstatus of women at ante-natal clinics. The paper discusses the architecture of\nthe relational network and its merits compared to a neural network and most\nother computational intelligence classifiers. Results gathered from the study\nindicate comparable classification accuracies as well as revealed relationships\nbetween data features in the classification data. Much higher classification\naccuracies are recommended for future research in the area of HIV\nclassification as well as missing data estimation.\n",
          "  In this paper we consider the task of estimating the non-zero pattern of the\nsparse inverse covariance matrix of a zero-mean Gaussian random vector from a\nset of iid samples. Note that this is also equivalent to recovering the\nunderlying graph structure of a sparse Gaussian Markov Random Field (GMRF). We\npresent two novel greedy approaches to solving this problem. The first\nestimates the non-zero covariates of the overall inverse covariance matrix\nusing a series of global forward and backward greedy steps. The second\nestimates the neighborhood of each node in the graph separately, again using\ngreedy forward and backward steps, and combines the intermediate neighborhoods\nto form an overall estimate. The principal contribution of this paper is a\nrigorous analysis of the sparsistency, or consistency in recovering the\nsparsity pattern of the inverse covariance matrix. Surprisingly, we show that\nboth the local and global greedy methods learn the full structure of the model\nwith high probability given just $O(d\\log(p))$ samples, which is a\n\\emph{significant} improvement over state of the art $\\ell_1$-regularized\nGaussian MLE (Graphical Lasso) that requires $O(d^2\\log(p))$ samples. Moreover,\nthe restricted eigenvalue and smoothness conditions imposed by our greedy\nmethods are much weaker than the strong irrepresentable conditions required by\nthe $\\ell_1$-regularization based methods. We corroborate our results with\nextensive simulations and examples, comparing our local and global greedy\nmethods to the $\\ell_1$-regularized Gaussian MLE as well as the Neighborhood\nGreedy method to that of nodewise $\\ell_1$-regularized linear regression\n(Neighborhood Lasso).\n",
          "  A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension.\n",
          "  Hierarchical statistical models are widely employed in information science\nand data engineering. The models consist of two types of variables: observable\nvariables that represent the given data and latent variables for the\nunobservable labels. An asymptotic analysis of the models plays an important\nrole in evaluating the learning process; the result of the analysis is applied\nnot only to theoretical but also to practical situations, such as optimal model\nselection and active learning. There are many studies of generalization errors,\nwhich measure the prediction accuracy of the observable variables. However, the\naccuracy of estimating the latent variables has not yet been elucidated. For a\nquantitative evaluation of this, the present paper formulates\ndistribution-based functions for the errors in the estimation of the latent\nvariables. The asymptotic behavior is analyzed for both the maximum likelihood\nand the Bayes methods.\n",
          "  Sparse methods for supervised learning aim at finding good linear predictors\nfrom as few variables as possible, i.e., with small cardinality of their\nsupports. This combinatorial selection problem is often turned into a convex\noptimization problem by replacing the cardinality function by its convex\nenvelope (tightest convex lower bound), in this case the L1-norm. In this\npaper, we investigate more general set-functions than the cardinality, that may\nincorporate prior knowledge or structural constraints which are common in many\napplications: namely, we show that for nondecreasing submodular set-functions,\nthe corresponding convex envelope can be obtained from its \\lova extension, a\ncommon tool in submodular analysis. This defines a family of polyhedral norms,\nfor which we provide generic algorithmic tools (subgradients and proximal\noperators) and theoretical results (conditions for support recovery or\nhigh-dimensional inference). By selecting specific submodular functions, we can\ngive a new interpretation to known norms, such as those based on\nrank-statistics or grouped norms with potentially overlapping groups; we also\ndefine new norms, in particular ones that can be used as non-factorial priors\nfor supervised learning.\n",
          "  This encyclopedic article gives a mini-introduction into the theory of\nuniversal learning, founded by Ray Solomonoff in the 1960s and significantly\ndeveloped and extended in the last decade. It explains the spirit of universal\nlearning, but necessarily glosses over technical subtleties.\n",
          "  This paper proposes to use a rather new modelling approach in the realm of\nsolar radiation forecasting. In this work, two forecasting models:\nAutoregressive Moving Average (ARMA) and Neural Network (NN) models are\ncombined to form a model committee. The Bayesian inference is used to affect a\nprobability to each model in the committee. Hence, each model's predictions are\nweighted by their respective probability. The models are fitted to one year of\nhourly Global Horizontal Irradiance (GHI) measurements. Another year (the test\nset) is used for making genuine one hour ahead (h+1) out-of-sample forecast\ncomparisons. The proposed approach is benchmarked against the persistence\nmodel. The very first results show an improvement brought by this approach.\n",
          "  The Border algorithm and the iPred algorithm find the Hasse diagrams of FCA\nlattices. We show that they can be generalized to arbitrary lattices. In the\ncase of iPred, this requires the identification of a join-semilattice\nhomomorphism into a distributive lattice.\n",
          "  The growing number of dimensionality reduction methods available for data\nvisualization has recently inspired the development of quality assessment\nmeasures, in order to evaluate the resulting low-dimensional representation\nindependently from a methods' inherent criteria. Several (existing) quality\nmeasures can be (re)formulated based on the so-called co-ranking matrix, which\nsubsumes all rank errors (i.e. differences between the ranking of distances\nfrom every point to all others, comparing the low-dimensional representation to\nthe original data). The measures are often based on the partioning of the\nco-ranking matrix into 4 submatrices, divided at the K-th row and column,\ncalculating a weighted combination of the sums of each submatrix. Hence, the\nevaluation process typically involves plotting a graph over several (or even\nall possible) settings of the parameter K. Considering simple artificial\nexamples, we argue that this parameter controls two notions at once, that need\nnot necessarily be combined, and that the rectangular shape of submatrices is\ndisadvantageous for an intuitive interpretation of the parameter. We debate\nthat quality measures, as general and flexible evaluation tools, should have\nparameters with a direct and intuitive interpretation as to which specific\nerror types are tolerated or penalized. Therefore, we propose to replace K with\ntwo parameters to control these notions separately, and introduce a differently\nshaped weighting on the co-ranking matrix. The two new parameters can then\ndirectly be interpreted as a threshold up to which rank errors are tolerated,\nand a threshold up to which the rank-distances are significant for the\nevaluation. Moreover, we propose a color representation of local quality to\nvisually support the evaluation process for a given mapping, where every point\nin the mapping is colored according to its local contribution to the overall\nquality.\n",
          "  The problem of \"approximating the crowd\" is that of estimating the crowd's\nmajority opinion by querying only a subset of it. Algorithms that approximate\nthe crowd can intelligently stretch a limited budget for a crowdsourcing task.\nWe present an algorithm, \"CrowdSense,\" that works in an online fashion to\ndynamically sample subsets of labelers based on an exploration/exploitation\ncriterion. The algorithm produces a weighted combination of a subset of the\nlabelers' votes that approximates the crowd's opinion.\n",
          "  Mappings to structured output spaces (strings, trees, partitions, etc.) are\ntypically learned using extensions of classification algorithms to simple\ngraphical structures (eg., linear chains) in which search and parameter\nestimation can be performed exactly. Unfortunately, in many complex problems,\nit is rare that exact search or parameter estimation is tractable. Instead of\nlearning exact models and searching via heuristic means, we embrace this\ndifficulty and treat the structured output problem in terms of approximate\nsearch. We present a framework for learning as search optimization, and two\nparameter updates with convergence theorems and bounds. Empirical evidence\nshows that our integrated approach to learning and decoding can outperform\nexact models at smaller computational cost.\n",
          "  There has been a tremendous growth in publicly available digital video\nfootage over the past decade. This has necessitated the development of new\ntechniques in computer vision geared towards efficient analysis, storage and\nretrieval of such data. Many mid-level computer vision tasks such as\nsegmentation, object detection, tracking, etc. involve an inference problem\nbased on the video data available. Video data has a high degree of spatial and\ntemporal coherence. The property must be intelligently leveraged in order to\nobtain better results.\n  Graphical models, such as Markov Random Fields, have emerged as a powerful\ntool for such inference problems. They are naturally suited for expressing the\nspatial dependencies present in video data, It is however, not clear, how to\nextend the existing techniques for the problem of inference over time. This\nthesis explores the Path Probability Method, a variational technique in\nstatistical mechanics, in the context of graphical models and approximate\ninference problems. It extends the method to a general framework for problems\ninvolving inference in time, resulting in an algorithm, \\emph{DynBP}. We\nexplore the relation of the algorithm with existing techniques, and find the\nalgorithm competitive with existing approaches.\n  The main contribution of this thesis are the extended GBP algorithm, the\nextension of Path Probability Methods to the DynBP algorithm and the\nrelationship between them. We have also explored some applications in computer\nvision involving temporal evolution with promising results.\n",
          "  Multi-class classification is one of the most important tasks in machine\nlearning. In this paper we consider two online multi-class classification\nproblems: classification by a linear model and by a kernelized model. The\nquality of predictions is measured by the Brier loss function. We suggest two\ncomputationally efficient algorithms to work with these problems and prove\ntheoretical guarantees on their losses. We kernelize one of the algorithms and\nprove theoretical guarantees on its loss. We perform experiments and compare\nour algorithms with logistic regression.\n",
          "  Teaching is one of the most important factors affecting any education system.\nMany research efforts have been conducted to facilitate the presentation modes\nused by instructors in classrooms as well as provide means for students to\nreview lectures through web browsers. Other studies have been made to provide\nacoustical design recommendations for classrooms like room size and\nreverberation times. However, using acoustical features of classrooms as a way\nto provide education systems with feedback about the learning process was not\nthoroughly investigated in any of these studies. We propose a system that\nextracts different sound features of students and instructors, and then uses\nmachine learning techniques to evaluate the acoustical quality of any learning\nenvironment. We infer conclusions about the students' satisfaction with the\nquality of lectures. Using classifiers instead of surveys and other subjective\nways of measures can facilitate and speed such experiments which enables us to\nperform them continuously. We believe our system enables education systems to\ncontinuously review and improve their teaching strategies and acoustical\nquality of classrooms.\n",
          "  We propose a novel problem formulation of learning a single task when the\ndata are provided in different feature spaces. Each such space is called an\noutlook, and is assumed to contain both labeled and unlabeled data. The\nobjective is to take advantage of the data from all the outlooks to better\nclassify each of the outlooks. We devise an algorithm that computes optimal\naffine mappings from different outlooks to a target outlook by matching moments\nof the empirical distributions. We further derive a probabilistic\ninterpretation of the resulting algorithm and a sample complexity bound\nindicating how many samples are needed to adequately find the mapping. We\nreport the results of extensive experiments on activity recognition tasks that\nshow the value of the proposed approach in boosting performance.\n",
          "  The question of polynomial learnability of probability distributions,\nparticularly Gaussian mixture distributions, has recently received significant\nattention in theoretical computer science and machine learning. However,\ndespite major progress, the general question of polynomial learnability of\nGaussian mixture distributions still remained open. The current work resolves\nthe question of polynomial learnability for Gaussian mixtures in high dimension\nwith an arbitrary fixed number of components. The result on learning Gaussian\nmixtures relies on an analysis of distributions belonging to what we call\n\"polynomial families\" in low dimension. These families are characterized by\ntheir moments being polynomial in parameters and include almost all common\nprobability distributions as well as their mixtures and products. Using tools\nfrom real algebraic geometry, we show that parameters of any distribution\nbelonging to such a family can be learned in polynomial time and using a\npolynomial number of sample points. The result on learning polynomial families\nis quite general and is of independent interest. To estimate parameters of a\nGaussian mixture distribution in high dimensions, we provide a deterministic\nalgorithm for dimensionality reduction. This allows us to reduce learning a\nhigh-dimensional mixture to a polynomial number of parameter estimations in low\ndimension. Combining this reduction with the results on polynomial families\nyields our result on learning arbitrary Gaussian mixtures in high dimensions.\n",
          "  This article describes a new type of artificial neuron, called the authors\n\"cyberneuron\". Unlike classical models of artificial neurons, this type of\nneuron used table substitution instead of the operation of multiplication of\ninput values for the weights. This allowed to significantly increase the\ninformation capacity of a single neuron, but also greatly simplify the process\nof learning. Considered an example of the use of \"cyberneuron\" with the task of\ndetecting computer viruses.\n",
          "  Learning machines which have hierarchical structures or hidden variables are\nsingular statistical models because they are nonidentifiable and their Fisher\ninformation matrices are singular. In singular statistical models, neither the\nBayes a posteriori distribution converges to the normal distribution nor the\nmaximum likelihood estimator satisfies asymptotic normality. This is the main\nreason why it has been difficult to predict their generalization performances\nfrom trained states. In this paper, we study four errors, (1) Bayes\ngeneralization error, (2) Bayes training error, (3) Gibbs generalization error,\nand (4) Gibbs training error, and prove that there are mathematical relations\namong these errors. The formulas proved in this paper are equations of states\nin statistical estimation because they hold for any true distribution, any\nparametric model, and any a priori distribution. Also we show that Bayes and\nGibbs generalization errors are estimated by Bayes and Gibbs training errors,\nand propose widely applicable information criteria which can be applied to both\nregular and singular statistical models.\n",
          "  We present a method to stop the evaluation of a decision making process when\nthe result of the full evaluation is obvious. This trait is highly desirable\nfor online margin-based machine learning algorithms where a classifier\ntraditionally evaluates all the features for every example. We observe that\nsome examples are easier to classify than others, a phenomenon which is\ncharacterized by the event when most of the features agree on the class of an\nexample. By stopping the feature evaluation when encountering an easy to\nclassify example, the learning algorithm can achieve substantial gains in\ncomputation. Our method provides a natural attention mechanism for learning\nalgorithms. By modifying Pegasos, a margin-based online learning algorithm, to\ninclude our attentive method we lower the number of attributes computed from\n$n$ to an average of $O(\\sqrt{n})$ features without loss in prediction\naccuracy. We demonstrate the effectiveness of Attentive Pegasos on MNIST data.\n",
          "  In this paper, we propose a unified algorithmic framework for solving many\nknown variants of \\mds. Our algorithm is a simple iterative scheme with\nguaranteed convergence, and is \\emph{modular}; by changing the internals of a\nsingle subroutine in the algorithm, we can switch cost functions and target\nspaces easily. In addition to the formal guarantees of convergence, our\nalgorithms are accurate; in most cases, they converge to better quality\nsolutions than existing methods, in comparable time. We expect that this\nframework will be useful for a number of \\mds variants that have not yet been\nstudied.\n  Our framework extends to embedding high-dimensional points lying on a sphere\nto points on a lower dimensional sphere, preserving geodesic distances. As a\ncompliment to this result, we also extend the Johnson-Lindenstrauss Lemma to\nthis spherical setting, where projecting to a random $O((1/\\eps^2) \\log\nn)$-dimensional sphere causes $\\eps$-distortion.\n",
          "  We consider the problem of building high-level, class-specific feature\ndetectors from only unlabeled data. For example, is it possible to learn a face\ndetector using only unlabeled images? To answer this, we train a 9-layered\nlocally connected sparse autoencoder with pooling and local contrast\nnormalization on a large dataset of images (the model has 1 billion\nconnections, the dataset has 10 million 200x200 pixel images downloaded from\nthe Internet). We train this network using model parallelism and asynchronous\nSGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to\nwhat appears to be a widely-held intuition, our experimental results reveal\nthat it is possible to train a face detector without having to label images as\ncontaining a face or not. Control experiments show that this feature detector\nis robust not only to translation but also to scaling and out-of-plane\nrotation. We also find that the same network is sensitive to other high-level\nconcepts such as cat faces and human bodies. Starting with these learned\nfeatures, we trained our network to obtain 15.8% accuracy in recognizing 20,000\nobject categories from ImageNet, a leap of 70% relative improvement over the\nprevious state-of-the-art.\n",
          "  We provide rigorous guarantees on learning with the weighted trace-norm under\narbitrary sampling distributions. We show that the standard weighted trace-norm\nmight fail when the sampling distribution is not a product distribution (i.e.\nwhen row and column indexes are not selected independently), present a\ncorrected variant for which we establish strong learning guarantees, and\ndemonstrate that it works better in practice. We provide guarantees when\nweighting by either the true or empirical sampling distribution, and suggest\nthat even if the true distribution is known (or is uniform), weighting by the\nempirical distribution may be beneficial.\n",
          "  In many fields observations are performed irregularly along time, due to\neither measurement limitations or lack of a constant immanent rate. While\ndiscrete-time Markov models (as Dynamic Bayesian Networks) introduce either\ninefficient computation or an information loss to reasoning about such\nprocesses, continuous-time Markov models assume either a discrete state space\n(as Continuous-Time Bayesian Networks), or a flat continuous state space (as\nstochastic differential equations). To address these problems, we present a new\nmodeling class called Irregular-Time Bayesian Networks (ITBNs), generalizing\nDynamic Bayesian Networks, allowing substantially more compact representations,\nand increasing the expressivity of the temporal dynamics. In addition, a\nglobally optimal solution is guaranteed when learning temporal systems,\nprovided that they are fully observed at the same irregularly spaced\ntime-points, and a semiparametric subclass of ITBNs is introduced to allow\nfurther adaptation to the irregular nature of the available data.\n",
          "  We consider a living organism as an observer of the evolution of its\nenvironment recording sensory information about the state space X of the\nenvironment in real time. Sensory information is sampled and then processed on\ntwo levels. On the biological level, the organism serves as an evaluation\nmechanism of the subjective relevance of the incoming data to the observer: the\nobserver assigns excitation values to events in X it could recognize using its\nsensory equipment. On the algorithmic level, sensory input is used for updating\na database, the memory of the observer whose purpose is to serve as a\ngeometric/combinatorial model of X, whose nodes are weighted by the excitation\nvalues produced by the evaluation mechanism. These values serve as a guidance\nsystem for deciding how the database should transform as observation data\nmounts. We define a searching problem for the proposed model and discuss the\nmodel's flexibility and its computational efficiency, as well as the\npossibility of implementing it as a dynamic network of neuron-like units. We\nshow how various easily observable properties of the human memory and thought\nprocess can be explained within the framework of this model. These include:\nreasoning (with efficiency bounds), errors, temporary and permanent loss of\ninformation. We are also able to define general learning problems in terms of\nthe new model, such as the language acquisition problem.\n",
          "  We consider decentralized restless multi-armed bandit problems with unknown\ndynamics and multiple players. The reward state of each arm transits according\nto an unknown Markovian rule when it is played and evolves according to an\narbitrary unknown random process when it is passive. Players activating the\nsame arm at the same time collide and suffer from reward loss. The objective is\nto maximize the long-term reward by designing a decentralized arm selection\npolicy to address unknown reward models and collisions among players. A\ndecentralized policy is constructed that achieves a regret with logarithmic\norder when an arbitrary nontrivial bound on certain system parameters is known.\nWhen no knowledge about the system is available, we extend the policy to\nachieve a regret arbitrarily close to the logarithmic order. The result finds\napplications in communication networks, financial investment, and industrial\nengineering.\n",
          "  Different features have different relevance to a particular learning problem.\nSome features are less relevant; while some very important. Instead of\nselecting the most relevant features using feature selection, an algorithm can\nbe given this knowledge of feature importance based on expert opinion or prior\nlearning. Learning can be faster and more accurate if learners take feature\nimportance into account. Correlation aided Neural Networks (CANN) is presented\nwhich is such an algorithm. CANN treats feature importance as the correlation\ncoefficient between the target attribute and the features. CANN modifies normal\nfeed-forward Neural Network to fit both correlation values and training data.\nEmpirical evaluation shows that CANN is faster and more accurate than applying\nthe two step approach of feature selection and then using normal learning\nalgorithms.\n",
          "  Information theoretic active learning has been widely studied for\nprobabilistic models. For simple regression an optimal myopic policy is easily\ntractable. However, for other tasks and with more complex models, such as\nclassification with nonparametric models, the optimal solution is harder to\ncompute. Current approaches make approximations to achieve tractability. We\npropose an approach that expresses information gain in terms of predictive\nentropies, and apply this method to the Gaussian Process Classifier (GPC). Our\napproach makes minimal approximations to the full information theoretic\nobjective. Our experimental performance compares favourably to many popular\nactive learning algorithms, and has equal or lower computational complexity. We\ncompare well to decision theoretic approaches also, which are privy to more\ninformation and require much more computational time. Secondly, by developing\nfurther a reformulation of binary preference learning to a classification\nproblem, we extend our algorithm to Gaussian Process preference learning.\n",
          "  This paper provides a theoretical support for clustering aspect of the\nnonnegative matrix factorization (NMF). By utilizing the Karush-Kuhn-Tucker\noptimality conditions, we show that NMF objective is equivalent to graph\nclustering objective, so clustering aspect of the NMF has a solid\njustification. Different from previous approaches which usually discard the\nnonnegativity constraints, our approach guarantees the stationary point being\nused in deriving the equivalence is located on the feasible region in the\nnonnegative orthant. Additionally, since clustering capability of a matrix\ndecomposition technique can sometimes imply its latent semantic indexing (LSI)\naspect, we will also evaluate LSI aspect of the NMF by showing its capability\nin solving the synonymy and polysemy problems in synthetic datasets. And more\nextensive evaluation will be conducted by comparing LSI performances of the NMF\nand the singular value decomposition (SVD), the standard LSI method, using some\nstandard datasets.\n",
          "  In this paper we consider the problem of learning the optimal policy for\nuncontrolled restless bandit problems. In an uncontrolled restless bandit\nproblem, there is a finite set of arms, each of which when pulled yields a\npositive reward. There is a player who sequentially selects one of the arms at\neach time step. The goal of the player is to maximize its undiscounted reward\nover a time horizon T. The reward process of each arm is a finite state Markov\nchain, whose transition probabilities are unknown by the player. State\ntransitions of each arm is independent of the selection of the player. We\npropose a learning algorithm with logarithmic regret uniformly over time with\nrespect to the optimal finite horizon policy. Our results extend the optimal\nadaptive learning of MDPs to POMDPs.\n",
          "  We study the problem of learning Bayesian network structures from data. We\ndevelop an algorithm for finding the k-best Bayesian network structures. We\npropose to compute the posterior probabilities of hypotheses of interest by\nBayesian model averaging over the k-best Bayesian networks. We present\nempirical results on structural discovery over several real and synthetic data\nsets and show that the method outperforms the model selection method and the\nstate of-the-art MCMC methods.\n",
          "  A problem posed by Freund is how to efficiently track a small pool of experts\nout of a much larger set. This problem was solved when Bousquet and Warmuth\nintroduced their mixing past posteriors (MPP) algorithm in 2001.\n  In Freund's problem the experts would normally be considered black boxes.\nHowever, in this paper we re-examine Freund's problem in case the experts have\ninternal structure that enables them to learn. In this case the problem has two\npossible interpretations: should the experts learn from all data or only from\nthe subsequence on which they are being tracked? The MPP algorithm solves the\nfirst case. Our contribution is to generalise MPP to address the second option.\nThe results we obtain apply to any expert structure that can be formalised\nusing (expert) hidden Markov models. Curiously enough, for our interpretation\nthere are \\emph{two} natural reference schemes: freezing and sleeping. For each\nscheme, we provide an efficient prediction strategy and prove the relevant loss\nbound.\n",
          "  Several variants of a stochastic local search process for constructing the\nsynaptic weights of an Ising perceptron are studied. In this process, binary\npatterns are sequentially presented to the Ising perceptron and are then\nlearned as the synaptic weight configuration is modified through a chain of\nsingle- or double-weight flips within the compatible weight configuration space\nof the earlier learned patterns. This process is able to reach a storage\ncapacity of $\\alpha \\approx 0.63$ for pattern length N = 101 and $\\alpha\n\\approx 0.41$ for N = 1001. If in addition a relearning process is exploited,\nthe learning performance is further improved to a storage capacity of $\\alpha\n\\approx 0.80$ for N = 101 and $\\alpha \\approx 0.42$ for N=1001. We found that,\nfor a given learning task, the solutions constructed by the random walk\nlearning process are separated by a typical Hamming distance, which decreases\nwith the constraint density $\\alpha$ of the learning task; at a fixed value of\n$\\alpha$, the width of the Hamming distance distributions decreases with $N$.\n",
          "  Observations consisting of measurements on relationships for pairs of objects\narise in many settings, such as protein interaction and gene regulatory\nnetworks, collections of author-recipient email, and social networks. Analyzing\nsuch data with probabilisic models can be delicate because the simple\nexchangeability assumptions underlying many boilerplate models no longer hold.\nIn this paper, we describe a latent variable model of such data called the\nmixed membership stochastic blockmodel. This model extends blockmodels for\nrelational data to ones which capture mixed membership latent relational\nstructure, thus providing an object-specific low-dimensional representation. We\ndevelop a general variational inference algorithm for fast approximate\nposterior inference. We explore applications to social and protein interaction\nnetworks.\n",
          "  This paper addresses the estimation of parameters of a Bayesian network from\nincomplete data. The task is usually tackled by running the\nExpectation-Maximization (EM) algorithm several times in order to obtain a high\nlog-likelihood estimate. We argue that choosing the maximum log-likelihood\nestimate (as well as the maximum penalized log-likelihood and the maximum a\nposteriori estimate) has severe drawbacks, being affected both by overfitting\nand model uncertainty. Two ideas are discussed to overcome these issues: a\nmaximum entropy approach and a Bayesian model averaging approach. Both ideas\ncan be easily applied on top of EM, while the entropy idea can be also\nimplemented in a more sophisticated way, through a dedicated non-linear solver.\nA vast set of experiments shows that these ideas produce significantly better\nestimates and inferences than the traditional and widely used maximum\n(penalized) log-likelihood and maximum a posteriori estimates. In particular,\nif EM is adopted as optimization engine, the model averaging approach is the\nbest performing one; its performance is matched by the entropy approach when\nimplemented using the non-linear solver. The results suggest that the\napplicability of these ideas is immediate (they are easy to implement and to\nintegrate in currently available inference engines) and that they constitute a\nbetter way to learn Bayesian network parameters.\n",
          "  In this paper we consider general l0-norm minimization problems, that is, the\nproblems with l0-norm appearing in either objective function or constraint. In\nparticular, we first reformulate the l0-norm constrained problem as an\nequivalent rank minimization problem and then apply the penalty decomposition\n(PD) method proposed in [33] to solve the latter problem. By utilizing the\nspecial structures, we then transform all matrix operations of this method to\nvector operations and obtain a PD method that only involves vector operations.\nUnder some suitable assumptions, we establish that any accumulation point of\nthe sequence generated by the PD method satisfies a first-order optimality\ncondition that is generally stronger than one natural optimality condition. We\nfurther extend the PD method to solve the problem with the l0-norm appearing in\nobjective function. Finally, we test the performance of our PD methods by\napplying them to compressed sensing, sparse logistic regression and sparse\ninverse covariance selection. The computational results demonstrate that our\nmethods generally outperform the existing methods in terms of solution quality\nand/or speed.\n",
          "  Many combinatorial problems arising in machine learning can be reduced to the\nproblem of minimizing a submodular function. Submodular functions are a natural\ndiscrete analog of convex functions, and can be minimized in strongly\npolynomial time. Unfortunately, state-of-the-art algorithms for general\nsubmodular minimization are intractable for larger problems. In this paper, we\nintroduce a novel subclass of submodular minimization problems that we call\ndecomposable. Decomposable submodular functions are those that can be\nrepresented as sums of concave functions applied to modular functions. We\ndevelop an algorithm, SLG, that can efficiently minimize decomposable\nsubmodular functions with tens of thousands of variables. Our algorithm\nexploits recent results in smoothed convex minimization. We apply SLG to\nsynthetic benchmarks and a joint classification-and-segmentation task, and show\nthat it outperforms the state-of-the-art general purpose submodular\nminimization algorithms by several orders of magnitude.\n",
          "  Most traditional online learning algorithms are based on variants of mirror\ndescent or follow-the-leader. In this paper, we present an online algorithm\nbased on a completely different approach, tailored for transductive settings,\nwhich combines \"random playout\" and randomized rounding of loss subgradients.\nAs an application of our approach, we present the first computationally\nefficient online algorithm for collaborative filtering with trace-norm\nconstrained matrices. As a second application, we solve an open question\nlinking batch learning and transductive online learning\n",
          "  Recurrent neural networks (RNNs) in combination with a pooling operator and\nthe neighbourhood components analysis (NCA) objective function are able to\ndetect the characterizing dynamics of sequences and embed them into a\nfixed-length vector space of arbitrary dimensionality. Subsequently, the\nresulting features are meaningful and can be used for visualization or nearest\nneighbour classification in linear time. This kind of metric learning for\nsequential data enables the use of algorithms tailored towards fixed length\nvector spaces such as R^n.\n",
          "  We show that the existence of a computationally efficient calibration\nalgorithm, with a low weak calibration rate, would imply the existence of an\nefficient algorithm for computing approximate Nash equilibria - thus implying\nthe unlikely conclusion that every problem in PPAD is solvable in polynomial\ntime.\n",
          "  The term \"nexting\" has been used by psychologists to refer to the propensity\nof people and many other animals to continually predict what will happen next\nin an immediate, local, and personal sense. The ability to \"next\" constitutes a\nbasic kind of awareness and knowledge of one's environment. In this paper we\npresent results with a robot that learns to next in real time, predicting\nthousands of features of the world's state, including all sensory inputs, at\ntimescales from 0.1 to 8 seconds. This was achieved by treating each state\nfeature as a reward-like target and applying temporal-difference methods to\nlearn a corresponding value function with a discount rate corresponding to the\ntimescale. We show that two thousand predictions, each dependent on six\nthousand state features, can be learned and updated online at better than 10Hz\non a laptop computer, using the standard TD(lambda) algorithm with linear\nfunction approximation. We show that this approach is efficient enough to be\npractical, with most of the learning complete within 30 minutes. We also show\nthat a single tile-coded feature representation suffices to accurately predict\nmany different signals at a significant range of timescales. Finally, we show\nthat the accuracy of our learned predictions compares favorably with the\noptimal off-line solution.\n",
          "  This paper has been retracted.\n",
          "  We propose a novel feature selection strategy to discover\nlanguage-independent acoustic features that tend to be responsible for emotions\nregardless of languages, linguistics and other factors. Experimental results\nsuggest that the language-independent feature subset discovered yields the\nperformance comparable to the full feature set on various emotional speech\ncorpora.\n",
          "  Mirror descent with an entropic regularizer is known to achieve shifting\nregret bounds that are logarithmic in the dimension. This is done using either\na carefully designed projection or by a weight sharing technique. Via a novel\nunified analysis, we show that these two approaches deliver essentially\nequivalent bounds on a notion of regret generalizing shifting, adaptive,\ndiscounted, and other related regrets. Our analysis also captures and extends\nthe generalized weight sharing technique of Bousquet and Warmuth, and can be\nrefined in several ways, including improvements for small losses and adaptive\ntuning of parameters.\n",
          "  We analyze the convergence behaviour of a recently proposed algorithm for\nregularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is\nbased on a new interpretation of DAL as a proximal minimization algorithm. We\ntheoretically show under some conditions that DAL converges super-linearly in a\nnon-asymptotic and global sense. Due to a special modelling of sparse\nestimation problems in the context of machine learning, the assumptions we make\nare milder and more natural than those made in conventional analysis of\naugmented Lagrangian algorithms. In addition, the new interpretation enables us\nto generalize DAL to wide varieties of sparse estimation problems. We\nexperimentally confirm our analysis in a large scale $\\ell_1$-regularized\nlogistic regression problem and extensively compare the efficiency of DAL\nalgorithm to previously proposed algorithms on both synthetic and benchmark\ndatasets.\n",
          "  Statistical learning theory chiefly studies restricted hypothesis classes,\nparticularly those with finite Vapnik-Chervonenkis (VC) dimension. The\nfundamental quantity of interest is the sample complexity: the number of\nsamples required to learn to a specified level of accuracy. Here we consider\nlearning over the set of all computable labeling functions. Since the\nVC-dimension is infinite and a priori (uniform) bounds on the number of samples\nare impossible, we let the learning algorithm decide when it has seen\nsufficient samples to have learned. We first show that learning in this setting\nis indeed possible, and develop a learning algorithm. We then show, however,\nthat bounding sample complexity independently of the distribution is\nimpossible. Notably, this impossibility is entirely due to the requirement that\nthe learning algorithm be computable, and not due to the statistical nature of\nthe problem.\n",
          "  This paper studies the MINLIP estimator for the identification of Wiener\nsystems consisting of a sequence of a linear FIR dynamical model, and a\nmonotonically increasing (or decreasing) static function. Given $T$\nobservations, this algorithm boils down to solving a convex quadratic program\nwith $O(T)$ variables and inequality constraints, implementing an inference\ntechnique which is based entirely on model complexity control. The resulting\nestimates of the linear submodel are found to be almost consistent when no\nnoise is present in the data, under a condition of smoothness of the true\nnonlinearity and local Persistency of Excitation (local PE) of the data. This\nresult is novel as it does not rely on classical tools as a 'linearization'\nusing a Taylor decomposition, nor exploits stochastic properties of the data.\nIt is indicated how to extend the method to cope with noisy data, and empirical\nevidence contrasts performance of the estimator against other recently proposed\ntechniques.\n",
          "  We consider the celebrated Blackwell Approachability Theorem for two-player\ngames with vector payoffs. We show that Blackwell's result is equivalent, via\nefficient reductions, to the existence of \"no-regret\" algorithms for Online\nLinear Optimization. Indeed, we show that any algorithm for one such problem\ncan be efficiently converted into an algorithm for the other. We provide a\nuseful application of this reduction: the first efficient algorithm for\ncalibrated forecasting.\n",
          "  Machine Learning (ML) techniques are indispensable in a wide range of fields.\nUnfortunately, the exponential increase of dataset sizes are rapidly extending\nthe runtime of sequential algorithms and threatening to slow future progress in\nML. With the promise of affordable large-scale parallel computing, Cloud\nsystems offer a viable platform to resolve the computational challenges in ML.\nHowever, designing and implementing efficient, provably correct distributed ML\nalgorithms is often prohibitively challenging. To enable ML researchers to\neasily and efficiently use parallel systems, we introduced the GraphLab\nabstraction which is designed to represent the computational patterns in ML\nalgorithms while permitting efficient parallel and distributed implementations.\nIn this paper we provide a formal description of the GraphLab parallel\nabstraction and present an efficient distributed implementation. We conduct a\ncomprehensive evaluation of GraphLab on three state-of-the-art ML algorithms\nusing real large-scale data and a 64 node EC2 cluster of 512 processors. We\nfind that GraphLab achieves orders of magnitude performance gains over Hadoop\nwhile performing comparably or superior to hand-tuned MPI implementations.\n",
          "  The $\\ell$-1 norm based optimization is widely used in signal processing,\nespecially in recent compressed sensing theory. This paper studies the solution\npath of the $\\ell$-1 norm penalized least-square problem, whose constrained\nform is known as Least Absolute Shrinkage and Selection Operator (LASSO). A\nsolution path is the set of all the optimizers with respect to the evolution of\nthe hyperparameter (Lagrange multiplier). The study of the solution path is of\ngreat significance in viewing and understanding the profile of the tradeoff\nbetween the approximation and regularization terms. If the solution path of a\ngiven problem is known, it can help us to find the optimal hyperparameter under\na given criterion such as the Akaike Information Criterion. In this paper we\npresent a sufficient condition on $\\ell$-1 norm penalized least-square problem.\nUnder this sufficient condition, the number of nonzero entries in the optimizer\nor solution vector increases monotonically when the hyperparameter decreases.\nWe also generalize the result to the often used total variation case, where the\n$\\ell$-1 norm is taken over the first order derivative of the solution vector.\nWe prove that the proposed condition has intrinsic connections with the\ncondition given by Donoho, et al \\cite{Donoho08} and the positive cone\ncondition by Efron {\\it el al} \\cite{Efron04}. However, the proposed condition\ndoes not need to assume the sparsity level of the signal as required by Donoho\net al's condition, and is easier to verify than Efron, et al's positive cone\ncondition when being used for practical applications.\n",
          "  We describe a novel approach to statistical learning from particles tracked\nwhile moving in a random environment. The problem consists in inferring\nproperties of the environment from recorded snapshots. We consider here the\ncase of a fluid seeded with identical passive particles that diffuse and are\nadvected by a flow. Our approach rests on efficient algorithms to estimate the\nweighted number of possible matchings among particles in two consecutive\nsnapshots, the partition function of the underlying graphical model. The\npartition function is then maximized over the model parameters, namely\ndiffusivity and velocity gradient. A Belief Propagation (BP) scheme is the\nbackbone of our algorithm, providing accurate results for the flow parameters\nwe want to learn. The BP estimate is additionally improved by incorporating\nLoop Series (LS) contributions. For the weighted matching problem, LS is\ncompactly expressed as a Cauchy integral, accurately estimated by a saddle\npoint approximation. Numerical experiments show that the quality of our\nimproved BP algorithm is comparable to the one of a fully polynomial randomized\napproximation scheme, based on the Markov Chain Monte Carlo (MCMC) method,\nwhile the BP-based scheme is substantially faster than the MCMC scheme.\n",
          "  This paper proposes a novel latent semantic learning method for extracting\nhigh-level features (i.e. latent semantics) from a large vocabulary of abundant\nmid-level features (i.e. visual keywords) with structured sparse\nrepresentation, which can help to bridge the semantic gap in the challenging\ntask of human action recognition. To discover the manifold structure of\nmidlevel features, we develop a spectral embedding approach to latent semantic\nlearning based on L1-graph, without the need to tune any parameter for graph\nconstruction as a key step of manifold learning. More importantly, we construct\nthe L1-graph with structured sparse representation, which can be obtained by\nstructured sparse coding with its structured sparsity ensured by novel L1-norm\nhypergraph regularization over mid-level features. In the new embedding space,\nwe learn latent semantics automatically from abundant mid-level features\nthrough spectral clustering. The learnt latent semantics can be readily used\nfor human action recognition with SVM by defining a histogram intersection\nkernel. Different from the traditional latent semantic analysis based on topic\nmodels, our latent semantic learning method can explore the manifold structure\nof mid-level features in both L1-graph construction and spectral embedding,\nwhich results in compact but discriminative high-level features. The\nexperimental results on the commonly used KTH action dataset and unconstrained\nYouTube action dataset show the superior performance of our method.\n",
          "  Several technologies are emerging that provide new ways to capture, store,\npresent and use knowledge. This book is the first to provide a comprehensive\nintroduction to five of the most important of these technologies: Knowledge\nEngineering, Knowledge Based Engineering, Knowledge Webs, Ontologies and\nSemantic Webs. For each of these, answers are given to a number of key\nquestions (What is it? How does it operate? How is a system developed? What can\nit be used for? What tools are available? What are the main issues?). The book\nis aimed at students, researchers and practitioners interested in Knowledge\nManagement, Artificial Intelligence, Design Engineering and Web Technologies.\n  During the 1990s, Nick worked at the University of Nottingham on the\napplication of AI techniques to knowledge management and on various knowledge\nacquisition projects to develop expert systems for military applications. In\n1999, he joined Epistemics where he worked on numerous knowledge projects and\nhelped establish knowledge management programmes at large organisations in the\nengineering, technology and legal sectors. He is author of the book \"Knowledge\nAcquisition in Practice\", which describes a step-by-step procedure for\nacquiring and implementing expertise. He maintains strong links with leading\nresearch organisations working on knowledge technologies, such as\nknowledge-based engineering, ontologies and semantic technologies.\n",
          "  This paper has been withdrawn by the author. This draft is withdrawn for its\npoor quality in english, unfortunately produced by the author when he was just\nstarting his science route. Look at the ICML version instead:\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\n",
          "  This article presents a survey of work on lifted graphical models. We review\na general form for a lifted graphical model, a par-factor graph, and show how a\nnumber of existing statistical relational representations map to this\nformalism. We discuss inference algorithms, including lifted inference\nalgorithms, that efficiently compute the answers to probabilistic queries. We\nalso review work in learning lifted graphical models from data. It is our\nbelief that the need for statistical relational models (whether it goes by that\nname or another) will grow in the coming decades, as we are inundated with data\nwhich is a mix of structured and unstructured, with entities and relations\nextracted in a noisy manner from text, and with the need to reason effectively\nwith this data. We hope that this synthesis of ideas from many different\nresearch groups will provide an accessible starting point for new researchers\nin this expanding field.\n",
          "  Most enterprise data is distributed in multiple relational databases with\nexpert-designed schema. Using traditional single-table machine learning\ntechniques over such data not only incur a computational penalty for converting\nto a 'flat' form (mega-join), even the human-specified semantic information\npresent in the relations is lost. In this paper, we present a practical,\ntwo-phase hierarchical meta-classification algorithm for relational databases\nwith a semantic divide and conquer approach. We propose a recursive, prediction\naggregation technique over heterogeneous classifiers applied on individual\ndatabase tables. The proposed algorithm was evaluated on three diverse\ndatasets, namely TPCH, PKDD and UCI benchmarks and showed considerable\nreduction in classification time without any loss of prediction accuracy.\n",
          "  Consider the problem of learning the drift coefficient of a stochastic\ndifferential equation from a sample path. In this paper, we assume that the\ndrift is parametrized by a high dimensional vector. We address the question of\nhow long the system needs to be observed in order to learn this vector of\nparameters. We prove a general lower bound on this time complexity by using a\ncharacterization of mutual information as time integral of conditional\nvariance, due to Kadota, Zakai, and Ziv. This general lower bound is applied to\nspecific classes of linear and non-linear stochastic differential equations. In\nthe linear case, the problem under consideration is the one of learning a\nmatrix of interaction coefficients. We evaluate our lower bound for ensembles\nof sparse and dense random matrices. The resulting estimates match the\nqualitative behavior of upper bounds achieved by computationally efficient\nprocedures.\n",
          "  We give sublinear-time approximation algorithms for some optimization\nproblems arising in machine learning, such as training linear classifiers and\nfinding minimum enclosing balls. Our algorithms can be extended to some\nkernelized versions of these problems, such as SVDD, hard margin SVM, and\nL2-SVM, for which sublinear-time algorithms were not known before. These new\nalgorithms use a combination of a novel sampling techniques and a new\nmultiplicative update algorithm. We give lower bounds which show the running\ntimes of many of our algorithms to be nearly best possible in the unit-cost RAM\nmodel. We also give implementations of our algorithms in the semi-streaming\nsetting, obtaining the first low pass polylogarithmic space and sublinear time\nalgorithms achieving arbitrary approximation factor.\n",
          "  In regular statistical models, the leave-one-out cross-validation is\nasymptotically equivalent to the Akaike information criterion. However, since\nmany learning machines are singular statistical models, the asymptotic behavior\nof the cross-validation remains unknown. In previous studies, we established\nthe singular learning theory and proposed a widely applicable information\ncriterion, the expectation value of which is asymptotically equal to the\naverage Bayes generalization loss. In the present paper, we theoretically\ncompare the Bayes cross-validation loss and the widely applicable information\ncriterion and prove two theorems. First, the Bayes cross-validation loss is\nasymptotically equivalent to the widely applicable information criterion as a\nrandom variable. Therefore, model selection and hyperparameter optimization\nusing these two values are asymptotically equivalent. Second, the sum of the\nBayes generalization error and the Bayes cross-validation error is\nasymptotically equal to $2\\lambda/n$, where $\\lambda$ is the real log canonical\nthreshold and $n$ is the number of training samples. Therefore the relation\nbetween the cross-validation error and the generalization error is determined\nby the algebraic geometrical structure of a learning machine. We also clarify\nthat the deviance information criteria are different from the Bayes\ncross-validation and the widely applicable information criterion.\n",
          "  We consider the two problems of predicting links in a dynamic graph sequence\nand predicting functions defined at each node of the graph. In many\napplications, the solution of one problem is useful for solving the other.\nIndeed, if these functions reflect node features, then they are related through\nthe graph structure. In this paper, we formulate a hybrid approach that\nsimultaneously learns the structure of the graph and predicts the values of the\nnode-related functions. Our approach is based on the optimization of a joint\nregularization objective. We empirically test the benefits of the proposed\nmethod with both synthetic and real data. The results indicate that joint\nregularization improves prediction performance over the graph evolution and the\nnode features.\n",
          "  We consider a collection of prediction experiments, which are clustered in\nthe sense that groups of experiments ex- hibit similar relationship between the\npredictor and response variables. The experiment clusters as well as the\nregres- sion relationships are unknown. The regression relation- ships define\nthe experiment clusters, and in general, the predictor and response variables\nmay not exhibit any clus- tering. We call this prediction problem clustered\nregres- sion with unknown clusters (CRUC) and in this paper we focus on linear\nregression. We study and compare several methods for CRUC, demonstrate their\napplicability to the Yahoo Learning-to-rank Challenge (YLRC) dataset, and in-\nvestigate an associated mathematical model. CRUC is at the crossroads of many\nprior works and we study several prediction algorithms with diverse origins: an\nadaptation of the expectation-maximization algorithm, an approach in- spired by\nK-means clustering, the singular value threshold- ing approach to matrix rank\nminimization under quadratic constraints, an adaptation of the Curds and Whey\nmethod in multiple regression, and a local regression (LoR) scheme reminiscent\nof neighborhood methods in collaborative filter- ing. Based on empirical\nevaluation on the YLRC dataset as well as simulated data, we identify the LoR\nmethod as a good practical choice: it yields best or near-best prediction\nperformance at a reasonable computational load, and it is less sensitive to the\nchoice of the algorithm parameter. We also provide some analysis of the LoR\nmethod for an asso- ciated mathematical model, which sheds light on optimal\nparameter choice and prediction performance.\n",
          "  The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.\n",
          "  In many real-world networks, nodes have class labels, attributes, or\nvariables that affect the network's topology. If the topology of the network is\nknown but the labels of the nodes are hidden, we would like to select a small\nsubset of nodes such that, if we knew their labels, we could accurately predict\nthe labels of all the other nodes. We develop an active learning algorithm for\nthis problem which uses information-theoretic techniques to choose which nodes\nto explore. We test our algorithm on networks from three different domains: a\nsocial network, a network of English words that appear adjacently in a novel,\nand a marine food web. Our algorithm makes no initial assumptions about how the\ngroups connect, and performs well even when faced with quite general types of\nnetwork structure. In particular, we do not assume that nodes of the same class\nare more likely to be connected to each other---only that they connect to the\nrest of the network in similar ways.\n",
          "  This paper applies machine learning techniques to student modeling. It\npresents a method for discovering high-level student behaviors from a very\nlarge set of low-level traces corresponding to problem-solving actions in a\nlearning environment. Basic actions are encoded into sets of domain-dependent\nattribute-value patterns called cases. Then a domain-independent hierarchical\nclustering identifies what we call general attitudes, yielding automatic\ndiagnosis expressed in natural language, addressed in principle to teachers.\nThe method can be applied to individual students or to entire groups, like a\nclass. We exhibit examples of this system applied to thousands of students'\nactions in the domain of algebraic transformations.\n",
          "  The paper describes a neural approach for modelling and control of a\nturbocharged Diesel engine. A neural model, whose structure is mainly based on\nsome physical equations describing the engine behaviour, is built for the\nrotation speed and the exhaust gas opacity. The model is composed of three\ninterconnected neural submodels, each of them constituting a nonlinear\nmulti-input single-output error model. The structural identification and the\nparameter estimation from data gathered on a real engine are described. The\nneural direct model is then used to determine a neural controller of the\nengine, in a specialized training scheme minimising a multivariable criterion.\nSimulations show the effect of the pollution constraint weighting on a\ntrajectory tracking of the engine speed. Neural networks, which are flexible\nand parsimonious nonlinear black-box models, with universal approximation\ncapabilities, can accurately describe or control complex nonlinear systems,\nwith little a priori theoretical knowledge. The presented work extends optimal\nneuro-control to the multivariable case and shows the flexibility of neural\noptimisers. Considering the preliminary results, it appears that neural\nnetworks can be used as embedded models for engine control, to satisfy the more\nand more restricting pollutant emission legislation. Particularly, they are\nable to model nonlinear dynamics and outperform during transients the control\nschemes based on static mappings.\n",
          "  The use of image transformations is essential for efficient modeling and\nlearning of visual data. But the class of relevant transformations is large:\naffine transformations, projective transformations, elastic deformations, ...\nthe list goes on. Therefore, learning these transformations, rather than hand\ncoding them, is of great conceptual interest. To the best of our knowledge, all\nthe related work so far has been concerned with either supervised or weakly\nsupervised learning (from correlated sequences, video streams, or\nimage-transform pairs). In this paper, on the contrary, we present a simple\nmethod for learning affine and elastic transformations when no examples of\nthese transformations are explicitly given, and no prior knowledge of space\n(such as ordering of pixels) is included either. The system has only access to\na moderately large database of natural images arranged in no particular order.\n",
          "  We consider a class of sparsity-inducing regularization terms based on\nsubmodular functions. While previous work has focused on non-decreasing\nfunctions, we explore symmetric submodular functions and their \\lova\nextensions. We show that the Lovasz extension may be seen as the convex\nenvelope of a function that depends on level sets (i.e., the set of indices\nwhose corresponding components of the underlying predictor are greater than a\ngiven constant): this leads to a class of convex structured regularization\nterms that impose prior knowledge on the level sets, and not only on the\nsupports of the underlying predictors. We provide a unified set of optimization\nalgorithms, such as proximal operators, and theoretical guarantees (allowed\nlevel sets and recovery conditions). By selecting specific submodular\nfunctions, we give a new interpretation to known norms, such as the total\nvariation; we also define new norms, in particular ones that are based on order\nstatistics with application to clustering and outlier detection, and on noisy\ncuts in graphs with application to change point detection in the presence of\noutliers.\n",
          "  Motivation: Several different threads of research have been proposed for\nmodeling and mining temporal data. On the one hand, approaches such as dynamic\nBayesian networks (DBNs) provide a formal probabilistic basis to model\nrelationships between time-indexed random variables but these models are\nintractable to learn in the general case. On the other, algorithms such as\nfrequent episode mining are scalable to large datasets but do not exhibit the\nrigorous probabilistic interpretations that are the mainstay of the graphical\nmodels literature.\n  Results: We present a unification of these two seemingly diverse threads of\nresearch, by demonstrating how dynamic (discrete) Bayesian networks can be\ninferred from the results of frequent episode mining. This helps bridge the\nmodeling emphasis of the former with the counting emphasis of the latter.\nFirst, we show how, under reasonable assumptions on data characteristics and on\ninfluences of random variables, the optimal DBN structure can be computed using\na greedy, local, algorithm. Next, we connect the optimality of the DBN\nstructure with the notion of fixed-delay episodes and their counts of distinct\noccurrences. Finally, to demonstrate the practical feasibility of our approach,\nwe focus on a specific (but broadly applicable) class of networks, called\nexcitatory networks, and show how the search for the optimal DBN structure can\nbe conducted using just information from frequent episodes. Application on\ndatasets gathered from mathematical models of spiking neurons as well as real\nneuroscience datasets are presented.\n  Availability: Algorithmic implementations, simulator codebases, and datasets\nare available from our website at http://neural-code.cs.vt.edu/dbn\n",
          "  While statistics focusses on hypothesis testing and on estimating (properties\nof) the true sampling distribution, in machine learning the performance of\nlearning algorithms on future data is the primary issue. In this paper we\nbridge the gap with a general principle (PHI) that identifies hypotheses with\nbest predictive performance. This includes predictive point and interval\nestimation, simple and composite hypothesis testing, (mixture) model selection,\nand others as special cases. For concrete instantiations we will recover\nwell-known methods, variations thereof, and new ones. PHI nicely justifies,\nreconciles, and blends (a reparametrization invariant variation of) MAP, ML,\nMDL, and moment estimation. One particular feature of PHI is that it can\ngenuinely deal with nested hypotheses.\n",
          "  Statistically resolving the underlying haplotype pair for a genotype\nmeasurement is an important intermediate step in gene mapping studies, and has\nreceived much attention recently. Consequently, a variety of methods for this\nproblem have been developed. Different methods employ different statistical\nmodels, and thus implicitly encode different assumptions about the nature of\nthe underlying haplotype structure. Depending on the population sample in\nquestion, their relative performance can vary greatly, and it is unclear which\nmethod to choose for a particular sample. Instead of choosing a single method,\nwe explore combining predictions returned by different methods in a principled\nway, and thereby circumvent the problem of method selection.\n  We propose several techniques for combining haplotype reconstructions and\nanalyze their computational properties. In an experimental study on real-world\nhaplotype data we show that such techniques can provide more accurate and\nrobust reconstructions, and are useful for outlier detection. Typically, the\ncombined prediction is at least as accurate as or even more accurate than the\nbest individual method, effectively circumventing the method selection problem.\n",
          "  Cooperative decision making is a vision of future network management and\ncontrol. Distributed connection preemption is an important example where nodes\ncan make intelligent decisions on allocating resources and controlling traffic\nflows for multi-class service networks. A challenge is that nodal decisions are\nspatially dependent as traffic flows trespass multiple nodes in a network.\nHence the performance-complexity trade-off becomes important, i.e., how\naccurate decisions are versus how much information is exchanged among nodes.\nConnection preemption is known to be NP-complete. Centralized preemption is\noptimal but computationally intractable. Decentralized preemption is\ncomputationally efficient but may result in a poor performance. This work\ninvestigates distributed preemption where nodes decide whether and which flows\nto preempt using only local information exchange with neighbors. We develop,\nbased on the probabilistic graphical models, a near-optimal distributed\nalgorithm. The algorithm is used by each node to make collectively near-optimal\npreemption decisions. We study trade-offs between near-optimal performance and\ncomplexity that corresponds to the amount of information-exchange of the\ndistributed algorithm. The algorithm is validated by both analysis and\nsimulation.\n",
          "  Knowing the largest rate at which data can be sent on an end-to-end path such\nthat the egress rate is equal to the ingress rate with high probability can be\nvery practical when choosing transmission rates in video streaming or selecting\npeers in peer-to-peer applications. We introduce probabilistic available\nbandwidth, which is defined in terms of ingress rates and egress rates of\ntraffic on a path, rather than in terms of capacity and utilization of the\nconstituent links of the path like the standard available bandwidth metric. In\nthis paper, we describe a distributed algorithm, based on a probabilistic\ngraphical model and Bayesian active learning, for simultaneously estimating the\nprobabilistic available bandwidth of multiple paths through a network. Our\nprocedure exploits the fact that each packet train provides information not\nonly about the path it traverses, but also about any path that shares a link\nwith the monitored path. Simulations and PlanetLab experiments indicate that\nthis process can dramatically reduce the number of probes required to generate\naccurate estimates.\n",
          "  We use co-evolutionary genetic algorithms to model the players' learning\nprocess in several Cournot models, and evaluate them in terms of their\nconvergence to the Nash Equilibrium. The \"social-learning\" versions of the two\nco-evolutionary algorithms we introduce, establish Nash Equilibrium in those\nmodels, in contrast to the \"individual learning\" versions which, as we see\nhere, do not imply the convergence of the players' strategies to the Nash\noutcome. When players use \"canonical co-evolutionary genetic algorithms\" as\nlearning algorithms, the process of the game is an ergodic Markov Chain, and\ntherefore we analyze simulation results using both the relevant methodology and\nmore general statistical tests, to find that in the \"social\" case, states\nleading to NE play are highly frequent at the stationary distribution of the\nchain, in contrast to the \"individual learning\" case, when NE is not reached at\nall in our simulations; to find that the expected Hamming distance of the\nstates at the limiting distribution from the \"NE state\" is significantly\nsmaller in the \"social\" than in the \"individual learning case\"; to estimate the\nexpected time that the \"social\" algorithms need to get to the \"NE state\" and\nverify their robustness and finally to show that a large fraction of the games\nplayed are indeed at the Nash Equilibrium.\n",
          "  Learning Classifier Systems (LCS) are population-based reinforcement learners\nused in a wide variety of applications. This paper presents a LCS where each\ntraditional rule is represented by a spiking neural network, a type of network\nwith dynamic internal state. We employ a constructivist model of growth of both\nneurons and dendrites that realise flexible learning by evolving structures of\nsufficient complexity to solve a well-known problem involving continuous,\nreal-valued inputs. Additionally, we extend the system to enable temporal state\ndecomposition. By allowing our LCS to chain together sequences of heterogeneous\nactions into macro-actions, it is shown to perform optimally in a problem where\ntraditional methods can fail to find a solution in a reasonable amount of time.\nOur final system is tested on a simulated robotics platform.\n",
          "  We study upper and lower bounds on the sample-complexity of learning\nnear-optimal behaviour in finite-state discounted Markov Decision Processes\n(MDPs). For the upper bound we make the assumption that each action leads to at\nmost two possible next-states and prove a new bound for a UCRL-style algorithm\non the number of time-steps when it is not Probably Approximately Correct\n(PAC). The new lower bound strengthens previous work by being both more general\n(it applies to all policies) and tighter. The upper and lower bounds match up\nto logarithmic factors.\n",
          "  Submodular functions are relevant to machine learning for at least two\nreasons: (1) some problems may be expressed directly as the optimization of\nsubmodular functions and (2) the lovasz extension of submodular functions\nprovides a useful set of regularization functions for supervised and\nunsupervised learning. In this monograph, we present the theory of submodular\nfunctions from a convex analysis perspective, presenting tight links between\ncertain polyhedra, combinatorial optimization and convex optimization problems.\nIn particular, we show how submodular function minimization is equivalent to\nsolving a wide variety of convex optimization problems. This allows the\nderivation of new efficient algorithms for approximate and exact submodular\nfunction minimization with theoretical guarantees and good practical\nperformance. By listing many examples of submodular functions, we review\nvarious applications to machine learning, such as clustering, experimental\ndesign, sensor placement, graphical model structure learning or subset\nselection, as well as a family of structured sparsity-inducing norms that can\nbe derived and used from submodular functions.\n",
          "  We introduce a procedure to infer the interactions among a set of binary\nvariables, based on their sampled frequencies and pairwise correlations. The\nalgorithm builds the clusters of variables contributing most to the entropy of\nthe inferred Ising model, and rejects the small contributions due to the\nsampling noise. Our procedure successfully recovers benchmark Ising models even\nat criticality and in the low temperature phase, and is applied to\nneurobiological data.\n",
          "  We investigate and extend the conformal prediction method due to\nVovk,Gammerman and Shafer (2005) to construct nonparametric prediction regions.\nThese regions have guaranteed distribution free, finite sample coverage,\nwithout any assumptions on the distribution or the bandwidth. Explicit\nconvergence rates of the loss function are established for such regions under\nstandard regularity conditions. Approximations for simplifying implementation\nand data driven bandwidth selection methods are also discussed. The theoretical\nproperties of our method are demonstrated through simulations.\n",
          "  We will establish that the VC dimension of the class of d-dimensional\nellipsoids is (d^2+3d)/2, and that maximum likelihood estimate with N-component\nd-dimensional Gaussian mixture models induces a geometric class having VC\ndimension at least N(d^2+3d)/2.\n  Keywords: VC dimension; finite dimensional ellipsoid; Gaussian mixture model\n",
          "  In density estimation task, maximum entropy model (Maxent) can effectively\nuse reliable prior information via certain constraints, i.e., linear\nconstraints without empirical parameters. However, reliable prior information\nis often insufficient, and the selection of uncertain constraints becomes\nnecessary but poses considerable implementation complexity. Improper setting of\nuncertain constraints can result in overfitting or underfitting. To solve this\nproblem, a generalization of Maxent, under Tsallis entropy framework, is\nproposed. The proposed method introduces a convex quadratic constraint for the\ncorrection of (expected) Tsallis entropy bias (TEB). Specifically, we\ndemonstrate that the expected Tsallis entropy of sampling distributions is\nsmaller than the Tsallis entropy of the underlying real distribution. This\nexpected entropy reduction is exactly the (expected) TEB, which can be\nexpressed by a closed-form formula and act as a consistent and unbiased\ncorrection. TEB indicates that the entropy of a specific sampling distribution\nshould be increased accordingly. This entails a quantitative re-interpretation\nof the Maxent principle. By compensating TEB and meanwhile forcing the\nresulting distribution to be close to the sampling distribution, our\ngeneralized TEBC Maxent can be expected to alleviate the overfitting and\nunderfitting. We also present a connection between TEB and Lidstone estimator.\nAs a result, TEB-Lidstone estimator is developed by analytically identifying\nthe rate of probability correction in Lidstone. Extensive empirical evaluation\nshows promising performance of both TEBC Maxent and TEB-Lidstone in comparison\nwith various state-of-the-art density estimation methods.\n",
          "  Given $n$ points in a $d$ dimensional Euclidean space, the Minimum Enclosing\nBall (MEB) problem is to find the ball with the smallest radius which contains\nall $n$ points. We give a $O(nd\\Qcal/\\sqrt{\\epsilon})$ approximation algorithm\nfor producing an enclosing ball whose radius is at most $\\epsilon$ away from\nthe optimum (where $\\Qcal$ is an upper bound on the norm of the points). This\nimproves existing results using \\emph{coresets}, which yield a $O(nd/\\epsilon)$\ngreedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a\nrelated problem wherein a convex polytope of a fixed shape is given and the aim\nis to find the smallest magnification of the polytope which encloses the given\npoints. For this problem we present a $O(mnd\\Qcal/\\epsilon)$ approximation\nalgorithm, where $m$ is the number of faces of the polytope. Our algorithms\nborrow heavily from convex duality and recently developed techniques in\nnon-smooth optimization, and are in contrast with existing methods which rely\non geometric arguments. In particular, we specialize the excessive gap\nframework of \\citet{Nesterov05a} to obtain our results.\n",
          "  In many large scale distributed systems and on the web, agents need to\ninteract with other unknown agents to carry out some tasks or transactions. The\nability to reason about and assess the potential risks in carrying out such\ntransactions is essential for providing a safe and reliable environment. A\ntraditional approach to reason about the trustworthiness of a transaction is to\ndetermine the trustworthiness of the specific agent involved, derived from the\nhistory of its behavior. As a departure from such traditional trust models, we\npropose a generic, machine learning approach based trust framework where an\nagent uses its own previous transactions (with other agents) to build a\nknowledge base, and utilize this to assess the trustworthiness of a transaction\nbased on associated features, which are capable of distinguishing successful\ntransactions from unsuccessful ones. These features are harnessed using\nappropriate machine learning algorithms to extract relationships between the\npotential transaction and previous transactions. The trace driven experiments\nusing real auction dataset show that this approach provides good accuracy and\nis highly efficient compared to other trust mechanisms, especially when\nhistorical information of the specific agent is rare, incomplete or inaccurate.\n",
          "  In this paper we consider the problem of reconstructing a hidden weighted\nhypergraph of constant rank using additive queries. We prove the following: Let\n$G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$\nhyperedges. For any $m$ there exists a non-adaptive algorithm that finds the\nedges of the graph and their weights using $$ O(\\frac{m\\log n}{\\log m}) $$\nadditive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal\nQuery Complexity Bounds for Finding Graphs. {\\em STOC}, 749--758,~2008].\n  When the weights of the hypergraph are integers that are less than\n$O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for\nunweighted hypergraphs) there exists a non-adaptive algorithm that finds the\nedges of the graph and their weights using $$ O(\\frac{m\\log \\frac{n^d}{m}}{\\log\nm}). $$ additive queries.\n  Using the information theoretic bound the above query complexities are tight.\n",
          "  Determinantal point processes (DPPs), which arise in random matrix theory and\nquantum physics, are natural models for subset selection problems where\ndiversity is preferred. Among many remarkable properties, DPPs offer tractable\nalgorithms for exact inference, including computing marginal probabilities and\nsampling; however, an important open question has been how to learn a DPP from\nlabeled training data. In this paper we propose a natural feature-based\nparameterization of conditional DPPs, and show how it leads to a convex and\nefficient learning formulation. We analyze the relationship between our model\nand binary Markov random fields with repulsive potentials, which are\nqualitatively similar but computationally intractable. Finally, we apply our\napproach to the task of extractive summarization, where the goal is to choose a\nsmall subset of sentences conveying the most important information from a set\nof documents. In this task there is a fundamental tradeoff between sentences\nthat are highly relevant to the collection as a whole, and sentences that are\ndiverse and not repetitive. Our parameterization allows us to naturally balance\nthese two characteristics. We evaluate our system on data from the DUC 2003/04\nmulti-document summarization task, achieving state-of-the-art results.\n",
          "  The elastic net was introduced as a heuristic algorithm for combinatorial\noptimisation and has been applied, among other problems, to biological\nmodelling. It has an energy function which trades off a fitness term against a\ntension term. In the original formulation of the algorithm the tension term was\nimplicitly based on a first-order derivative. In this paper we generalise the\nelastic net model to an arbitrary quadratic tension term, e.g. derived from a\ndiscretised differential operator, and give an efficient learning algorithm. We\nrefer to these as generalised elastic nets (GENs). We give a theoretical\nanalysis of the tension term for 1D nets with periodic boundary conditions, and\nshow that the model is sensitive to the choice of finite difference scheme that\nrepresents the discretised derivative. We illustrate some of these issues in\nthe context of cortical map models, by relating the choice of tension term to a\ncortical interaction function. In particular, we prove that this interaction\ntakes the form of a Mexican hat for the original elastic net, and of\nprogressively more oscillatory Mexican hats for higher-order derivatives. The\nresults apply not only to generalised elastic nets but also to other methods\nusing discrete differential penalties, and are expected to be useful in other\nareas, such as data analysis, computer graphics and optimisation problems.\n",
          "  Non-negative matrix factorization (NMF) has previously been shown to be a\nuseful decomposition for multivariate data. We interpret the factorization in a\nnew way and use it to generate missing attributes from test data. We provide a\njoint optimization scheme for the missing attributes as well as the NMF\nfactors. We prove the monotonic convergence of our algorithms. We present\nclassification results for cases with missing attributes.\n",
          "  Zoonosis refers to the transmission of infectious diseases from animal to\nhuman. The increasing number of zoonosis incidence makes the great losses to\nlives, including humans and animals, and also the impact in social economic. It\nmotivates development of a system that can predict the future number of\nzoonosis occurrences in human. This paper analyses and presents the use of\nSeasonal Autoregressive Integrated Moving Average (SARIMA) method for\ndeveloping a forecasting model that able to support and provide prediction\nnumber of zoonosis human incidence. The dataset for model development was\ncollected on a time series data of human tuberculosis occurrences in United\nStates which comprises of fourteen years of monthly data obtained from a study\npublished by Centers for Disease Control and Prevention (CDC). Several trial\nmodels of SARIMA were compared to obtain the most appropriate model. Then,\ndiagnostic tests were used to determine model validity. The result showed that\nthe SARIMA(9,0,14)(12,1,24)12 is the fittest model. While in the measure of\naccuracy, the selected model achieved 0.062 of Theils U value. It implied that\nthe model was highly accurate and a close fit. It was also indicated the\ncapability of final model to closely represent and made prediction based on the\ntuberculosis historical dataset.\n",
          "  We motivate and analyse a new Tree Search algorithm, GPTS, based on recent\ntheoretical advances in the use of Gaussian Processes for Bandit problems. We\nconsider tree paths as arms and we assume the target/reward function is drawn\nfrom a GP distribution. The posterior mean and variance, after observing data,\nare used to define confidence intervals for the function values, and we\nsequentially play arms with highest upper confidence bounds. We give an\nefficient implementation of GPTS and we adapt previous regret bounds by\ndetermining the decay rate of the eigenvalues of the kernel matrix on the whole\nset of tree paths. We consider two kernels in the feature space of binary\nvectors indexed by the nodes of the tree: linear and Gaussian. The regret grows\nin square root of the number of iterations T, up to a logarithmic factor, with\na constant that improves with bigger Gaussian kernel widths. We focus on\npractical values of T, smaller than the number of arms. Finally, we apply GPTS\nto Open Loop Planning in discounted Markov Decision Processes by modelling the\nreward as a discounted sum of independent Gaussian Processes. We report similar\nregret bounds to those of the OLOP algorithm.\n",
          "  We consider a hidden Markov model with multiple observation processes, one of\nwhich is chosen at each point in time by a policy---a deterministic function of\nthe information state---and attempt to determine which policy minimises the\nlimiting expected entropy of the information state. Focusing on a special case,\nwe prove analytically that the information state always converges in\ndistribution, and derive a formula for the limiting entropy which can be used\nfor calculations with high precision. Using this fomula, we find\ncomputationally that the optimal policy is always a threshold policy, allowing\nit to be easily found. We also find that the greedy policy is almost optimal.\n",
          "  We study the task of cleaning scanned text documents that are strongly\ncorrupted by dirt such as manual line strokes, spilled ink etc. We aim at\nautonomously removing dirt from a single letter-size page based only on the\ninformation the page contains. Our approach, therefore, has to learn character\nrepresentations without supervision and requires a mechanism to distinguish\nlearned representations from irregular patterns. To learn character\nrepresentations, we use a probabilistic generative model parameterizing pattern\nfeatures, feature variances, the features' planar arrangements, and pattern\nfrequencies. The latent variables of the model describe pattern class, pattern\nposition, and the presence or absence of individual pattern features. The model\nparameters are optimized using a novel variational EM approximation. After\nlearning, the parameters represent, independently of their absolute position,\nplanar feature arrangements and their variances. A quality measure defined\nbased on the learned representation then allows for an autonomous\ndiscrimination between regular character patterns and the irregular patterns\nmaking up the dirt. The irregular patterns can thus be removed to clean the\ndocument. For a full Latin alphabet we found that a single page does not\ncontain sufficiently many character examples. However, even if heavily\ncorrupted by dirt, we show that a page containing a lower number of character\ntypes can efficiently and autonomously be cleaned solely based on the\nstructural regularity of the characters it contains. In different examples\nusing characters from different alphabets, we demonstrate generality of the\napproach and discuss its implications for future developments.\n",
          "  Recent reports have described that the equivalent sample size (ESS) in a\nDirichlet prior plays an important role in learning Bayesian networks. This\npaper provides an asymptotic analysis of the marginal likelihood score for a\nBayesian network. Results show that the ratio of the ESS and sample size\ndetermine the penalty of adding arcs in learning Bayesian networks. The number\nof arcs increases monotonically as the ESS increases; the number of arcs\nmonotonically decreases as the ESS decreases. Furthermore, the marginal\nlikelihood score provides a unified expression of various score metrics by\nchanging prior knowledge.\n",
          "  We consider the problem of online linear regression on individual sequences.\nThe goal in this paper is for the forecaster to output sequential predictions\nwhich are, after $T$ time rounds, almost as good as the ones output by the best\nlinear predictor in a given $\\ell^1$-ball in $\\\\R^d$. We consider both the\ncases where the dimension~$d$ is small and large relative to the time horizon\n$T$. We first present regret bounds with optimal dependencies on $d$, $T$, and\non the sizes $U$, $X$ and $Y$ of the $\\ell^1$-ball, the input data and the\nobservations. The minimax regret is shown to exhibit a regime transition around\nthe point $d = \\sqrt{T} U X / (2 Y)$. Furthermore, we present efficient\nalgorithms that are adaptive, \\ie, that do not require the knowledge of $U$,\n$X$, $Y$, and $T$, but still achieve nearly optimal regret bounds.\n",
          "  Recursive Neural Networks are non-linear adaptive models that are able to\nlearn deep structured information. However, these models have not yet been\nbroadly accepted. This fact is mainly due to its inherent complexity. In\nparticular, not only for being extremely complex information processing models,\nbut also because of a computational expensive learning phase. The most popular\ntraining method for these models is back-propagation through the structure.\nThis algorithm has been revealed not to be the most appropriate for structured\nprocessing due to problems of convergence, while more sophisticated training\nmethods enhance the speed of convergence at the expense of increasing\nsignificantly the computational cost. In this paper, we firstly perform an\nanalysis of the underlying principles behind these models aimed at\nunderstanding their computational power. Secondly, we propose an approximate\nsecond order stochastic learning algorithm. The proposed algorithm dynamically\nadapts the learning rate throughout the training phase of the network without\nincurring excessively expensive computational effort. The algorithm operates in\nboth on-line and batch modes. Furthermore, the resulting learning scheme is\nrobust against the vanishing gradients problem. The advantages of the proposed\nalgorithm are demonstrated with a real-world application example.\n",
          "  We consider the problem of learning the structure of Ising models (pairwise\nbinary Markov random fields) from i.i.d. samples. While several methods have\nbeen proposed to accomplish this task, their relative merits and limitations\nremain somewhat obscure. By analyzing a number of concrete examples, we show\nthat low-complexity algorithms systematically fail when the Markov random field\ndevelops long-range correlations. More precisely, this phenomenon appears to be\nrelated to the Ising model phase transition (although it does not coincide with\nit).\n",
          "  Many applications require optimizing an unknown, noisy function that is\nexpensive to evaluate. We formalize this task as a multi-armed bandit problem,\nwhere the payoff function is either sampled from a Gaussian process (GP) or has\nlow RKHS norm. We resolve the important open problem of deriving regret bounds\nfor this setting, which imply novel convergence rates for GP optimization. We\nanalyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its\ncumulative regret in terms of maximal information gain, establishing a novel\nconnection between GP optimization and experimental design. Moreover, by\nbounding the latter in terms of operator spectra, we obtain explicit sublinear\nregret bounds for many commonly used covariance functions. In some important\ncases, our bounds have surprisingly weak dependence on the dimensionality. In\nour experiments on real sensor data, GP-UCB compares favorably with other\nheuristical GP optimization approaches.\n",
          "  We propose an alternative approach to construct an artificial learning\nsystem, which naturally learns in an unsupervised manner. Its mathematical\nprototype is a dynamical system, which automatically shapes its vector field in\nresponse to the input signal. The vector field converges to a gradient of a\nmulti-dimensional probability density distribution of the input process, taken\nwith negative sign. The most probable patterns are represented by the stable\nfixed points, whose basins of attraction are formed automatically. The\nperformance of this system is illustrated with musical signals.\n",
          "  Sequential prediction problems such as imitation learning, where future\nobservations depend on previous predictions (actions), violate the common\ni.i.d. assumptions made in statistical learning. This leads to poor performance\nin theory and often in practice. Some recent approaches provide stronger\nguarantees in this setting, but remain somewhat unsatisfactory as they train\neither non-stationary or stochastic policies and require a large number of\niterations. In this paper, we propose a new iterative algorithm, which trains a\nstationary deterministic policy, that can be seen as a no regret algorithm in\nan online learning setting. We show that any such no regret algorithm, combined\nwith additional reduction assumptions, must find a policy with good performance\nunder the distribution of observations it induces in such sequential settings.\nWe demonstrate that this new approach outperforms previous approaches on two\nchallenging imitation learning problems and a benchmark sequence labeling\nproblem.\n",
          "  We show how to control the generalization error of time series models wherein\npast values of the outcome are used to predict future values. The results are\nbased on a generalization of standard i.i.d. concentration inequalities to\ndependent data without the mixing assumptions common in the time series\nsetting. Our proof and the result are simpler than previous analyses with\ndependent data or stochastic adversaries which use sequential Rademacher\ncomplexities rather than the expected Rademacher complexity for i.i.d.\nprocesses. We also derive empirical Rademacher results without mixing\nassumptions resulting in fully calculable upper bounds.\n",
          "  The Web has enabled the availability of a huge amount of useful information,\nbut has also eased the ability to spread false information and rumors across\nmultiple sources, making it hard to distinguish between what is true and what\nis not. Recent examples include the premature Steve Jobs obituary, the second\nbankruptcy of United airlines, the creation of Black Holes by the operation of\nthe Large Hadron Collider, etc. Since it is important to permit the expression\nof dissenting and conflicting opinions, it would be a fallacy to try to ensure\nthat the Web provides only consistent information. However, to help in\nseparating the wheat from the chaff, it is essential to be able to determine\ndependence between sources. Given the huge number of data sources and the vast\nvolume of conflicting data available on the Web, doing so in a scalable manner\nis extremely challenging and has not been addressed by existing work yet.\n  In this paper, we present a set of research problems and propose some\npreliminary solutions on the issues involved in discovering dependence between\nsources. We also discuss how this knowledge can benefit a variety of\ntechnologies, such as data integration and Web 2.0, that help users manage and\naccess the totality of the available information from various sources.\n",
          "  Interactive applications incorporating high-data rate sensing and computer\nvision are becoming possible due to novel runtime systems and the use of\nparallel computation resources. To allow interactive use, such applications\nrequire careful tuning of multiple application parameters to meet required\nfidelity and latency bounds. This is a nontrivial task, often requiring expert\nknowledge, which becomes intractable as resources and application load\ncharacteristics change. This paper describes a method for automatic performance\ntuning that learns application characteristics and effects of tunable\nparameters online, and constructs models that are used to maximize fidelity for\na given latency constraint. The paper shows that accurate latency models can be\nlearned online, knowledge of application structure can be used to reduce the\ncomplexity of the learning task, and operating points can be found that achieve\n90% of the optimal fidelity by exploring the parameter space only 3% of the\ntime.\n",
          "  We introduce a class of neural networks derived from probabilistic models in\nthe form of Bayesian networks. By imposing additional assumptions about the\nnature of the probabilistic models represented in the networks, we derive\nneural networks with standard dynamics that require no training to determine\nthe synaptic weights, that perform accurate calculation of the mean values of\nthe random variables, that can pool multiple sources of evidence, and that deal\ncleanly and consistently with inconsistent or contradictory evidence. The\npresented neural networks capture many properties of Bayesian networks,\nproviding distributed versions of probabilistic models.\n",
          "  Recently Kutin and Niyogi investigated several notions of algorithmic\nstability--a property of a learning map conceptually similar to\ncontinuity--showing that training-stability is sufficient for consistency of\nEmpirical Risk Minimization while distribution-free CV-stability is necessary\nand sufficient for having finite VC-dimension. This paper concerns a phase\ntransition in the training stability of ERM, conjectured by the same authors.\nKutin and Niyogi proved that ERM on finite hypothesis spaces containing a\nunique risk minimizer has training stability that scales exponentially with\nsample size, and conjectured that the existence of multiple risk minimizers\nprevents even super-quadratic convergence. We prove this result for the\nstrictly weaker notion of CV-stability, positively resolving the conjecture.\n",
          "  Automatic image annotation (AIA) raises tremendous challenges to machine\nlearning as it requires modeling of data that are both ambiguous in input and\noutput, e.g., images containing multiple objects and labeled with multiple\nsemantic tags. Even more challenging is that the number of candidate tags is\nusually huge (as large as the vocabulary size) yet each image is only related\nto a few of them. This paper presents a hybrid generative-discriminative\nclassifier to simultaneously address the extreme data-ambiguity and\noverfitting-vulnerability issues in tasks such as AIA. Particularly: (1) an\nExponential-Multinomial Mixture (EMM) model is established to capture both the\ninput and output ambiguity and in the meanwhile to encourage prediction\nsparsity; and (2) the prediction ability of the EMM model is explicitly\nmaximized through discriminative learning that integrates variational inference\nof graphical models and the pairwise formulation of ordinal regression.\nExperiments show that our approach achieves both superior annotation\nperformance and better tag scalability.\n",
          "  We present IBSEAD or distributed autonomous entity systems based Interaction\n- a learning algorithm for the computer to self-evolve in a self-obsessed\nmanner. This learning algorithm will present the computer to look at the\ninternal and external environment in series of independent entities, which will\ninteract with each other, with and/or without knowledge of the computer's\nbrain. When a learning algorithm interacts, it does so by detecting and\nunderstanding the entities in the human algorithm. However, the problem with\nthis approach is that the algorithm does not consider the interaction of the\nthird party or unknown entities, which may be interacting with each other.\nThese unknown entities in their interaction with the non-computer entities make\nan effect in the environment that influences the information and the behaviour\nof the computer brain. Such details and the ability to process the dynamic and\nunsettling nature of these interactions are absent in the current learning\nalgorithm such as the decision tree learning algorithm. IBSEAD is able to\nevaluate and consider such algorithms and thus give us a better accuracy in\nsimulation of the highly evolved nature of the human brain. Processes such as\ndreams, imagination and novelty, that exist in humans are not fully simulated\nby the existing learning algorithms. Also, Hidden Markov models (HMM) are\nuseful in finding \"hidden\" entities, which may be known or unknown. However,\nthis model fails to consider the case of unknown entities which maybe unclear\nor unknown. IBSEAD is better because it considers three types of entities-\nknown, unknown and invisible. We present our case with a comparison of existing\nalgorithms in known environments and cases and present the results of the\nexperiments using dry run of the simulated runs of the existing machine\nlearning algorithms versus IBSEAD.\n",
          "  In this paper, we study the risk bounds for samples independently drawn from\nan infinitely divisible (ID) distribution. In particular, based on a martingale\nmethod, we develop two deviation inequalities for a sequence of random\nvariables of an ID distribution with zero Gaussian component. By applying the\ndeviation inequalities, we obtain the risk bounds based on the covering number\nfor the ID distribution. Finally, we analyze the asymptotic convergence of the\nrisk bound derived from one of the two deviation inequalities and show that the\nconvergence rate of the bound is faster than the result for the generic i.i.d.\nempirical process (Mendelson, 2003).\n",
          "  Recently, new approaches to adaptive control have sought to reformulate the\nproblem as a minimization of a relative entropy criterion to obtain tractable\nsolutions. In particular, it has been shown that minimizing the expected\ndeviation from the causal input-output dependencies of the true plant leads to\na new promising stochastic control rule called the Bayesian control rule. This\nwork proves the convergence of the Bayesian control rule under two sufficient\nassumptions: boundedness, which is an ergodicity condition; and consistency,\nwhich is an instantiation of the sure-thing principle.\n",
          "  Combinatorial network optimization algorithms that compute optimal structures\ntaking into account edge weights form the foundation for many network\nprotocols. Examples include shortest path routing, minimal spanning tree\ncomputation, maximum weighted matching on bipartite graphs, etc. We present\nCLRMR, the first online learning algorithm that efficiently solves the\nstochastic version of these problems where the underlying edge weights vary as\nindependent Markov chains with unknown dynamics.\n  The performance of an online learning algorithm is characterized in terms of\nregret, defined as the cumulative difference in rewards between a\nsuitably-defined genie, and that obtained by the given algorithm. We prove\nthat, compared to a genie that knows the Markov transition matrices and uses\nthe single-best structure at all times, CLRMR yields regret that is polynomial\nin the number of edges and nearly-logarithmic in time.\n",
          "  In many recent applications, data is plentiful. By now, we have a rather\nclear understanding of how more data can be used to improve the accuracy of\nlearning algorithms. Recently, there has been a growing interest in\nunderstanding how more data can be leveraged to reduce the required training\nruntime. In this paper, we study the runtime of learning as a function of the\nnumber of available training examples, and underscore the main high-level\ntechniques. We provide some initial positive results showing that the runtime\ncan decrease exponentially while only requiring a polynomial growth of the\nnumber of examples, and spell-out several interesting open problems.\n",
          "  This work gives a simultaneous analysis of both the ordinary least squares\nestimator and the ridge regression estimator in the random design setting under\nmild assumptions on the covariate/response distributions. In particular, the\nanalysis provides sharp results on the ``out-of-sample'' prediction error, as\nopposed to the ``in-sample'' (fixed design) error. The analysis also reveals\nthe effect of errors in the estimated covariance structure, as well as the\neffect of modeling errors, neither of which effects are present in the fixed\ndesign setting. The proofs of the main results are based on a simple\ndecomposition lemma combined with concentration inequalities for random vectors\nand matrices.\n",
          "  We give a characterization of Maximum Entropy/Minimum Relative Entropy\ninference by providing two `strong entropy concentration' theorems. These\ntheorems unify and generalize Jaynes' `concentration phenomenon' and Van\nCampenhout and Cover's `conditional limit theorem'. The theorems characterize\nexactly in what sense a prior distribution Q conditioned on a given constraint,\nand the distribution P, minimizing the relative entropy D(P ||Q) over all\ndistributions satisfying the constraint, are `close' to each other. We then\napply our theorems to establish the relationship between entropy concentration\nand a game-theoretic characterization of Maximum Entropy Inference due to\nTopsoe and others.\n",
          "  As a fundamental problem in pattern recognition, graph matching has\napplications in a variety of fields, from computer vision to computational\nbiology. In graph matching, patterns are modeled as graphs and pattern\nrecognition amounts to finding a correspondence between the nodes of different\ngraphs. Many formulations of this problem can be cast in general as a quadratic\nassignment problem, where a linear term in the objective function encodes node\ncompatibility and a quadratic term encodes edge compatibility. The main\nresearch focus in this theme is about designing efficient algorithms for\napproximately solving the quadratic assignment problem, since it is NP-hard. In\nthis paper we turn our attention to a different question: how to estimate\ncompatibility functions such that the solution of the resulting graph matching\nproblem best matches the expected solution that a human would manually provide.\nWe present a method for learning graph matching: the training examples are\npairs of graphs and the `labels' are matches between them. Our experimental\nresults reveal that learning can substantially improve the performance of\nstandard graph matching algorithms. In particular, we find that simple linear\nassignment with such a learning scheme outperforms Graduated Assignment with\nbistochastic normalisation, a state-of-the-art quadratic assignment relaxation\nalgorithm.\n",
          "  We present a novel graphical framework for modeling non-negative sequential\ndata with hierarchical structure. Our model corresponds to a network of coupled\nnon-negative matrix factorization (NMF) modules, which we refer to as a\npositive factor network (PFN). The data model is linear, subject to\nnon-negativity constraints, so that observation data consisting of an additive\ncombination of individually representable observations is also representable by\nthe network. This is a desirable property for modeling problems in\ncomputational auditory scene analysis, since distinct sound sources in the\nenvironment are often well-modeled as combining additively in the corresponding\nmagnitude spectrogram. We propose inference and learning algorithms that\nleverage existing NMF algorithms and that are straightforward to implement. We\npresent a target tracking example and provide results for synthetic observation\ndata which serve to illustrate the interesting properties of PFNs and motivate\ntheir potential usefulness in applications such as music transcription, source\nseparation, and speech recognition. We show how a target process characterized\nby a hierarchical state transition model can be represented as a PFN. Our\nresults illustrate that a PFN which is defined in terms of a single target\nobservation can then be used to effectively track the states of multiple\nsimultaneous targets. Our results show that the quality of the inferred target\nstates degrades gradually as the observation noise is increased. We also\npresent results for an example in which meaningful hierarchical features are\nextracted from a spectrogram. Such a hierarchical representation could be\nuseful for music transcription and source separation applications. We also\npropose a network for language modeling.\n",
          "  Kolmogorov-Smirnov (K-S) test-a non-parametric method to measure the goodness\nof fit, is applied for automatic modulation classification (AMC) in this paper.\nThe basic procedure involves computing the empirical cumulative distribution\nfunction (ECDF) of some decision statistic derived from the received signal,\nand comparing it with the CDFs of the signal under each candidate modulation\nformat. The K-S-based modulation classifier is first developed for AWGN\nchannel, then it is applied to OFDM-SDMA systems to cancel multiuser\ninterference. Regarding the complexity issue of K-S modulation classification,\nwe propose a low-complexity method based on the robustness of the K-S\nclassifier. Extensive simulation results demonstrate that compared with the\ntraditional cumulant-based classifiers, the proposed K-S classifier offers\nsuperior classification performance and requires less number of signal samples\n(thus is fast).\n",
          "  We derive exponential tail inequalities for sums of random matrices with no\ndependence on the explicit matrix dimensions. These are similar to the matrix\nversions of the Chernoff bound and Bernstein inequality except with the\nexplicit matrix dimensions replaced by a trace quantity that can be small even\nwhen the dimension is large or infinite. Some applications to principal\ncomponent analysis and approximate matrix multiplication are given to\nillustrate the utility of the new bounds.\n",
          "  Recent results in Compressive Sensing have shown that, under certain\nconditions, the solution to an underdetermined system of linear equations with\nsparsity-based regularization can be accurately recovered by solving convex\nrelaxations of the original problem. In this work, we present a novel\nprimal-dual analysis on a class of sparsity minimization problems. We show that\nthe Lagrangian bidual (i.e., the Lagrangian dual of the Lagrangian dual) of the\nsparsity minimization problems can be used to derive interesting convex\nrelaxations: the bidual of the $\\ell_0$-minimization problem is the\n$\\ell_1$-minimization problem; and the bidual of the $\\ell_{0,1}$-minimization\nproblem for enforcing group sparsity on structured data is the\n$\\ell_{1,\\infty}$-minimization problem. The analysis provides a means to\ncompute per-instance non-trivial lower bounds on the (group) sparsity of the\ndesired solutions. In a real-world application, the bidual relaxation improves\nthe performance of a sparsity-based classification framework applied to robust\nface recognition.\n",
          "  We show that the problem of finding an optimal stochastic 'blind' controller\nin a Markov decision process is an NP-hard problem. The corresponding decision\nproblem is NP-hard, in PSPACE, and SQRT-SUM-hard, hence placing it in NP would\nimply breakthroughs in long-standing open problems in computer science. Our\nresult establishes that the more general problem of stochastic controller\noptimization in POMDPs is also NP-hard. Nonetheless, we outline a special case\nthat is convex and admits efficient global solutions.\n",
          "  On-line learning of a hierarchical learning model is studied by a method from\nstatistical mechanics. In our model a student of a simple perceptron learns\nfrom not a true teacher directly, but ensemble teachers who learn from the true\nteacher with a perceptron learning rule. Since the true teacher and the\nensemble teachers are expressed as non-monotonic perceptron and simple ones,\nrespectively, the ensemble teachers go around the unlearnable true teacher with\nthe distance between them fixed in an asymptotic steady state. The\ngeneralization performance of the student is shown to exceed that of the\nensemble teachers in a transient state, as was shown in similar\nensemble-teachers models. Further, it is found that moving the ensemble\nteachers even in the steady state, in contrast to the fixed ensemble teachers,\nis efficient for the performance of the student.\n",
          "  Tree reconstruction methods are often judged by their accuracy, measured by\nhow close they get to the true tree. Yet most reconstruction methods like ML do\nnot explicitly maximize this accuracy. To address this problem, we propose a\nBayesian solution. Given tree samples, we propose finding the tree estimate\nwhich is closest on average to the samples. This ``median'' tree is known as\nthe Bayes estimator (BE). The BE literally maximizes posterior expected\naccuracy, measured in terms of closeness (distance) to the true tree. We\ndiscuss a unified framework of BE trees, focusing especially on tree distances\nwhich are expressible as squared euclidean distances. Notable examples include\nRobinson--Foulds distance, quartet distance, and squared path difference. Using\nsimulated data, we show Bayes estimators can be efficiently computed in\npractice by hill climbing. We also show that Bayes estimators achieve higher\naccuracy, compared to maximum likelihood and neighbor joining.\n",
          "  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers\nfor an offline signature system. From the signature images, global and local\nfeatures are extracted and the signatures are verified with the help of\nGaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.\nSVM is used to fuse matching scores of these matchers. Finally, recognition of\nquery signatures is done by comparing it with all signatures of the database.\nThe proposed system is tested on a signature database contains 5400 offline\nsignatures of 600 individuals and the results are found to be promising.\n",
          "  Classifiers are often used to detect miscreant activities. We study how an\nadversary can systematically query a classifier to elicit information that\nallows the adversary to evade detection while incurring a near-minimal cost of\nmodifying their intended malfeasance. We generalize the theory of Lowd and Meek\n(2005) to the family of convex-inducing classifiers that partition input space\ninto two sets one of which is convex. We present query algorithms for this\nfamily that construct undetected instances of approximately minimal cost using\nonly polynomially-many queries in the dimension of the space and in the level\nof approximation. Our results demonstrate that near-optimal evasion can be\naccomplished without reverse-engineering the classifier's decision boundary. We\nalso consider general lp costs and show that near-optimal evasion on the family\nof convex-inducing classifiers is generally efficient for both positive and\nnegative convexity for all levels of approximation if p=1.\n",
          "  In nonlinear latent variable models or dynamic models, if we consider the\nlatent variables as confounders (common causes), the noise dependencies imply\nfurther relations between the observed variables. Such models are then closely\nrelated to causal discovery in the presence of nonlinear confounders, which is\na challenging problem. However, generally in such models the observation noise\nis assumed to be independent across data dimensions, and consequently the noise\ndependencies are ignored. In this paper we focus on the Gaussian process latent\nvariable model (GPLVM), from which we develop an extended model called\ninvariant GPLVM (IGPLVM), which can adapt to arbitrary noise covariances. With\nthe Gaussian process prior put on a particular transformation of the latent\nnonlinear functions, instead of the original ones, the algorithm for IGPLVM\ninvolves almost the same computational loads as that for the original GPLVM.\nBesides its potential application in causal discovery, IGPLVM has the advantage\nthat its estimated latent nonlinear manifold is invariant to any nonsingular\nlinear transformation of the data. Experimental results on both synthetic and\nrealworld data show its encouraging performance in nonlinear manifold learning\nand causal discovery.\n",
          "  We consider finite horizon Markov decision processes under performance\nmeasures that involve both the mean and the variance of the cumulative reward.\nWe show that either randomized or history-based policies can improve\nperformance. We prove that the complexity of computing a policy that maximizes\nthe mean reward under a variance constraint is NP-hard for some cases, and\nstrongly NP-hard for others. We finally offer pseudopolynomial exact and\napproximation algorithms.\n",
          "  We present a framework for performing efficient regression in general metric\nspaces. Roughly speaking, our regressor predicts the value at a new point by\ncomputing a Lipschitz extension --- the smoothest function consistent with the\nobserved data --- after performing structural risk minimization to avoid\noverfitting. We obtain finite-sample risk bounds with minimal structural and\nnoise assumptions, and a natural speed-precision tradeoff. The offline\n(learning) and online (prediction) stages can be solved by convex programming,\nbut this naive approach has runtime complexity $O(n^3)$, which is prohibitive\nfor large datasets. We design instead a regression algorithm whose speed and\ngeneralization performance depend on the intrinsic dimension of the data, to\nwhich the algorithm adapts. While our main innovation is algorithmic, the\nstatistical results may also be of independent interest.\n",
          "  Ordinal regression is an important type of learning, which has properties of\nboth classification and regression. Here we describe a simple and effective\napproach to adapt a traditional neural network to learn ordinal categories. Our\napproach is a generalization of the perceptron method for ordinal regression.\nOn several benchmark datasets, our method (NNRank) outperforms a neural network\nclassification method. Compared with the ordinal regression methods using\nGaussian processes and support vector machines, NNRank achieves comparable\nperformance. Moreover, NNRank has the advantages of traditional neural\nnetworks: learning in both online and batch modes, handling very large training\ndatasets, and making rapid predictions. These features make NNRank a useful and\ncomplementary tool for large-scale data processing tasks such as information\nretrieval, web page ranking, collaborative filtering, and protein ranking in\nBioinformatics.\n",
          "  Many common probability distributions in statistics like the Gaussian,\nmultinomial, Beta or Gamma distributions can be studied under the unified\nframework of exponential families. In this paper, we prove that both R\\'enyi\nand Tsallis divergences of distributions belonging to the same exponential\nfamily admit a generic closed form expression. Furthermore, we show that\nR\\'enyi and Tsallis entropies can also be calculated in closed-form for\nsub-families including the Gaussian or exponential distributions, among others.\n",
          "  Hybrid learning methods use theoretical knowledge of a domain and a set of\nclassified examples to develop a method for classification. Methods that use\ndomain knowledge have been shown to perform better than inductive learners.\nHowever, there is no general method to include domain knowledge into all\ninductive learning algorithms as all hybrid methods are highly specialized for\na particular algorithm. We present an algorithm that will take domain knowledge\nin the form of propositional rules, generate artificial examples from the rules\nand also remove instances likely to be flawed. This enriched dataset then can\nbe used by any learning algorithm. Experimental results of different scenarios\nare shown that demonstrate this method to be more effective than simple\ninductive learning.\n",
          "  In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are\n$N$ arms, with rewards on all arms evolving at each time as Markov chains with\nknown parameters. A player seeks to activate $K \\geq 1$ arms at each time in\norder to maximize the expected total reward obtained over multiple plays. RMAB\nis a challenging problem that is known to be PSPACE-hard in general. We\nconsider in this work the even harder non-Bayesian RMAB, in which the\nparameters of the Markov chain are assumed to be unknown \\emph{a priori}. We\ndevelop an original approach to this problem that is applicable when the\ncorresponding Bayesian problem has the structure that, depending on the known\nparameter values, the optimal solution is one of a prescribed finite set of\npolicies. In such settings, we propose to learn the optimal policy for the\nnon-Bayesian RMAB by employing a suitable meta-policy which treats each policy\nfrom this finite set as an arm in a different non-Bayesian multi-armed bandit\nproblem for which a single-arm selection policy is optimal. We demonstrate this\napproach by developing a novel sensing policy for opportunistic spectrum access\nover unknown dynamic channels. We prove that our policy achieves\nnear-logarithmic regret (the difference in expected reward compared to a\nmodel-aware genie), which leads to the same average reward that can be achieved\nby the optimal policy under a known model. This is the first such result in the\nliterature for a non-Bayesian RMAB.\n",
          "  We first present our work in machine translation, during which we used\naligned sentences to train a neural network to embed n-grams of different\nlanguages into an $d$-dimensional space, such that n-grams that are the\ntranslation of each other are close with respect to some metric. Good n-grams\nto n-grams translation results were achieved, but full sentences translation is\nstill problematic. We realized that learning semantics of sentences and\ndocuments was the key for solving a lot of natural language processing\nproblems, and thus moved to the second part of our work: sentence compression.\nWe introduce a flexible neural network architecture for learning embeddings of\nwords and sentences that extract their semantics, propose an efficient\nimplementation in the Torch framework and present embedding results comparable\nto the ones obtained with classical neural language models, while being more\npowerful.\n",
          "  This paper considers a dynamic game with transferable utilities (TU), where\nthe characteristic function is a continuous-time bounded mean ergodic process.\nA central planner interacts continuously over time with the players by choosing\nthe instantaneous allocations subject to budget constraints. Before the game\nstarts, the central planner knows the nature of the process (bounded mean\nergodic), the bounded set from which the coalitions' values are sampled, and\nthe long run average coalitions' values. On the other hand, he has no knowledge\nof the underlying probability function generating the coalitions' values. Our\ngoal is to find allocation rules that use a measure of the extra reward that a\ncoalition has received up to the current time by re-distributing the budget\namong the players. The objective is two-fold: i) guaranteeing convergence of\nthe average allocations to the core (or a specific point in the core) of the\naverage game, ii) driving the coalitions' excesses to an a priori given cone.\nThe resulting allocation rules are robust as they guarantee the aforementioned\nconvergence properties despite the uncertain and time-varying nature of the\ncoaltions' values. We highlight three main contributions. First, we design an\nallocation rule based on full observation of the extra reward so that the\naverage allocation approaches a specific point in the core of the average game,\nwhile the coalitions' excesses converge to an a priori given direction. Second,\nwe design a new allocation rule based on partial observation on the extra\nreward so that the average allocation converges to the core of the average\ngame, while the coalitions' excesses converge to an a priori given cone. And\nthird, we establish connections to approachability theory and attainability\ntheory.\n",
          "  Motivated by problems of anomaly detection, this paper implements the\nNeyman-Pearson paradigm to deal with asymmetric errors in binary classification\nwith a convex loss. Given a finite collection of classifiers, we combine them\nand obtain a new classifier that satisfies simultaneously the two following\nproperties with high probability: (i) its probability of type I error is below\na pre-specified level and (ii), it has probability of type II error close to\nthe minimum possible. The proposed classifier is obtained by solving an\noptimization problem with an empirical objective and an empirical constraint.\nNew techniques to handle such problems are developed and have consequences on\nchance constrained programming.\n",
          "  Back-propagation with gradient method is the most popular learning algorithm\nfor feed-forward neural networks. However, it is critical to determine a proper\nfixed learning rate for the algorithm. In this paper, an optimized recursive\nalgorithm is presented for online learning based on matrix operation and\noptimization methods analytically, which can avoid the trouble to select a\nproper learning rate for the gradient method. The proof of weak convergence of\nthe proposed algorithm also is given. Although this approach is proposed for\nthree-layer, feed-forward neural networks, it could be extended to multiple\nlayer feed-forward neural networks. The effectiveness of the proposed\nalgorithms applied to the identification of behavior of a two-input and\ntwo-output non-linear dynamic system is demonstrated by simulation experiments.\n",
          "  We develop a novel method, based on the statistical concept of the\nVapnik-Chervonenkis dimension, to evaluate the selectivity (output cardinality)\nof SQL queries - a crucial step in optimizing the execution of large scale\ndatabase and data-mining operations. The major theoretical contribution of this\nwork, which is of independent interest, is an explicit bound to the\nVC-dimension of a range space defined by all possible outcomes of a collection\n(class) of queries. We prove that the VC-dimension is a function of the maximum\nnumber of Boolean operations in the selection predicate and of the maximum\nnumber of select and join operations in any individual query in the collection,\nbut it is neither a function of the number of queries in the collection nor of\nthe size (number of tuples) of the database. We leverage on this result and\ndevelop a method that, given a class of queries, builds a concise random sample\nof a database, such that with high probability the execution of any query in\nthe class on the sample provides an accurate estimate for the selectivity of\nthe query on the original large database. The error probability holds\nsimultaneously for the selectivity estimates of all queries in the collection,\nthus the same sample can be used to evaluate the selectivity of multiple\nqueries, and the sample needs to be refreshed only following major changes in\nthe database. The sample representation computed by our method is typically\nsufficiently small to be stored in main memory. We present extensive\nexperimental results, validating our theoretical analysis and demonstrating the\nadvantage of our technique when compared to complex selectivity estimation\ntechniques used in PostgreSQL and the Microsoft SQL Server.\n",
          "  Solving stochastic optimization problems under partial observability, where\none needs to adaptively make decisions with uncertain outcomes, is a\nfundamental but notoriously difficult challenge. In this paper, we introduce\nthe concept of adaptive submodularity, generalizing submodular set functions to\nadaptive policies. We prove that if a problem satisfies this property, a simple\nadaptive greedy algorithm is guaranteed to be competitive with the optimal\npolicy. In addition to providing performance guarantees for both stochastic\nmaximization and coverage, adaptive submodularity can be exploited to\ndrastically speed up the greedy algorithm by using lazy evaluations. We\nillustrate the usefulness of the concept by giving several examples of adaptive\nsubmodular objectives arising in diverse applications including sensor\nplacement, viral marketing and active learning. Proving adaptive submodularity\nfor these problems allows us to recover existing results in these applications\nas special cases, improve approximation guarantees and handle natural\ngeneralizations.\n",
          "  Conditional random field (CRF) and Structural Support Vector Machine\n(Structural SVM) are two state-of-the-art methods for structured prediction\nwhich captures the interdependencies among output variables. The success of\nthese methods is attributed to the fact that their discriminative models are\nable to account for overlapping features on the whole input observations. These\nfeatures are usually generated by applying a given set of templates on labeled\ndata, but improper templates may lead to degraded performance. To alleviate\nthis issue, in this paper, we propose a novel multiple template learning\nparadigm to learn structured prediction and the importance of each template\nsimultaneously, so that hundreds of arbitrary templates could be added into the\nlearning model without caution. This paradigm can be formulated as a special\nmultiple kernel learning problem with exponential number of constraints. Then\nwe introduce an efficient cutting plane algorithm to solve this problem in the\nprimal, and its convergence is presented. We also evaluate the proposed\nlearning paradigm on two widely-studied structured prediction tasks,\n\\emph{i.e.} sequence labeling and dependency parsing. Extensive experimental\nresults show that the proposed method outperforms CRFs and Structural SVMs due\nto exploiting the importance of each template. Our complexity analysis and\nempirical results also show that our proposed method is more efficient than\nOnlineMKL on very sparse and high-dimensional data. We further extend this\nparadigm for structured prediction using generalized $p$-block norm\nregularization with $p>1$, and experiments show competitive performances when\n$p \\in [1,2)$.\n",
          "  Given a set of data, biclustering aims at finding simultaneous partitions in\nbiclusters of its samples and of the features which are used for representing\nthe samples. Consistent biclusterings allow to obtain correct classifications\nof the samples from the known classification of the features, and vice versa,\nand they are very useful for performing supervised classifications. The problem\nof finding consistent biclusterings can be seen as a feature selection problem,\nwhere the features that are not relevant for classification purposes are\nremoved from the set of data, while the total number of features is maximized\nin order to preserve information. This feature selection problem can be\nformulated as a linear fractional 0-1 optimization problem. We propose a\nreformulation of this problem as a bilevel optimization problem, and we present\na heuristic algorithm for an efficient solution of the reformulated problem.\nComputational experiments show that the presented algorithm is able to find\nbetter solutions with respect to the ones obtained by employing previously\npresented heuristic algorithms.\n",
          "  This paper introduces and motivates the use of hybrid robust feature\nextraction technique for spoken language identification (LID) system. The\nspeech recognizers use a parametric form of a signal to get the most important\ndistinguishable features of speech signal for recognition task. In this paper\nMel-frequency cepstral coefficients (MFCC), Perceptual linear prediction\ncoefficients (PLP) along with two hybrid features are used for language\nIdentification. Two hybrid features, Bark Frequency Cepstral Coefficients\n(BFCC) and Revised Perceptual Linear Prediction Coefficients (RPLP) were\nobtained from combination of MFCC and PLP. Two different classifiers, Vector\nQuantization (VQ) with Dynamic Time Warping (DTW) and Gaussian Mixture Model\n(GMM) were used for classification. The experiment shows better identification\nrate using hybrid feature extraction techniques compared to conventional\nfeature extraction methods.BFCC has shown better performance than MFCC with\nboth classifiers. RPLP along with GMM has shown best identification performance\namong all feature extraction techniques.\n",
          "  This paper proposes uni-orthogonal and bi-orthogonal nonnegative matrix\nfactorization algorithms with robust convergence proofs. We design the\nalgorithms based on the work of Lee and Seung [1], and derive the converged\nversions by utilizing ideas from the work of Lin [2]. The experimental results\nconfirm the theoretical guarantees of the convergences.\n",
          "  We report a new optimal resolution for the statistical stratification problem\nunder proportional sampling allocation among strata. Consider a finite\npopulation of N units, a random sample of n units selected from this population\nand a number L of strata. Thus, we have to define which units belong to each\nstratum so as to minimize the variance of a total estimator for one desired\nvariable of interest in each stratum,and consequently reduce the overall\nvariance for such quantity. In order to solve this problem, an exact algorithm\nbased on the concept of minimal path in a graph is proposed and assessed.\nComputational results using real data from IBGE (Brazilian Central Statistical\nOffice) are provided.\n",
          "  We introduce a new graphical model for tracking radio-tagged animals and\nlearning their movement patterns. The model provides a principled way to\ncombine radio telemetry data with an arbitrary set of userdefined, spatial\nfeatures. We describe an efficient stochastic gradient algorithm for fitting\nmodel parameters to data and demonstrate its effectiveness via asymptotic\nanalysis and synthetic experiments. We also apply our model to real datasets,\nand show that it outperforms the most popular radio telemetry software package\nused in ecology. We conclude that integration of different data sources under a\nsingle statistical framework, coupled with appropriate parameter and state\nestimation procedures, produces both accurate location estimates and an\ninterpretable statistical model of animal movement.\n",
          "  Given i.i.d. data from an unknown distribution, we consider the problem of\npredicting future items. An adaptive way to estimate the probability density is\nto recursively subdivide the domain to an appropriate data-dependent\ngranularity. A Bayesian would assign a data-independent prior probability to\n\"subdivide\", which leads to a prior over infinite(ly many) trees. We derive an\nexact, fast, and simple inference algorithm for such a prior, for the data\nevidence, the predictive distribution, the effective model dimension, moments,\nand other quantities. We prove asymptotic convergence and consistency results,\nand illustrate the behavior of our model on some prototypical functions.\n",
          "  Sparse estimation methods are aimed at using or obtaining parsimonious\nrepresentations of data or models. While naturally cast as a combinatorial\noptimization problem, variable or feature selection admits a convex relaxation\nthrough the regularization by the $\\ell_1$-norm. In this paper, we consider\nsituations where we are not only interested in sparsity, but where some\nstructural prior knowledge is available as well. We show that the $\\ell_1$-norm\ncan then be extended to structured norms built on either disjoint or\noverlapping groups of variables, leading to a flexible framework that can deal\nwith various structures. We present applications to unsupervised learning, for\nstructured sparse principal component analysis and hierarchical dictionary\nlearning, and to supervised learning in the context of non-linear variable\nselection.\n",
          "  Fisher score is one of the most widely used supervised feature selection\nmethods. However, it selects each feature independently according to their\nscores under the Fisher criterion, which leads to a suboptimal subset of\nfeatures. In this paper, we present a generalized Fisher score to jointly\nselect features. It aims at finding an subset of features, which maximize the\nlower bound of traditional Fisher score. The resulting feature selection\nproblem is a mixed integer programming, which can be reformulated as a\nquadratically constrained linear programming (QCLP). It is solved by cutting\nplane algorithm, in each iteration of which a multiple kernel learning problem\nis solved alternatively by multivariate ridge regression and projected gradient\ndescent. Experiments on benchmark data sets indicate that the proposed method\noutperforms Fisher score as well as many other state-of-the-art feature\nselection methods.\n",
          "  Understanding inductive reasoning is a problem that has engaged mankind for\nthousands of years. This problem is relevant to a wide range of fields and is\nintegral to the philosophy of science. It has been tackled by many great minds\nranging from philosophers to scientists to mathematicians, and more recently\ncomputer scientists. In this article we argue the case for Solomonoff\nInduction, a formal inductive framework which combines algorithmic information\ntheory with the Bayesian framework. Although it achieves excellent theoretical\nresults and is based on solid philosophical foundations, the requisite\ntechnical knowledge necessary for understanding this framework has caused it to\nremain largely unknown and unappreciated in the wider scientific community. The\nmain contribution of this article is to convey Solomonoff induction and its\nrelated concepts in a generally accessible form with the aim of bridging this\ncurrent technical gap. In the process we examine the major historical\ncontributions that have led to the formulation of Solomonoff Induction as well\nas criticisms of Solomonoff and induction in general. In particular we examine\nhow Solomonoff induction addresses many issues that have plagued other\ninductive systems, such as the black ravens paradox and the confirmation\nproblem, and compare this approach with other recent approaches.\n",
          "  This paper uses the notion of algorithmic stability to derive novel\ngeneralization bounds for several families of transductive regression\nalgorithms, both by using convexity and closed-form solutions. Our analysis\nhelps compare the stability of these algorithms. It also shows that a number of\nwidely used transductive regression algorithms are in fact unstable. Finally,\nit reports the results of experiments with local transductive regression\ndemonstrating the benefit of our stability bounds for model selection, for one\nof the algorithms, in particular for determining the radius of the local\nneighborhood used by the algorithm.\n",
          "  Improving the energy-efficiency of heating, ventilation, and air-conditioning\n(HVAC) systems has the potential to realize large economic and societal\nbenefits. This paper concerns the system identification of a hybrid system\nmodel of a building-wide HVAC system and its subsequent control using a hybrid\nsystem formulation of learning-based model predictive control (LBMPC). Here,\nthe learning refers to model updates to the hybrid system model that\nincorporate the heating effects due to occupancy, solar effects, outside air\ntemperature (OAT), and equipment, in addition to integrator dynamics inherently\npresent in low-level control. Though we make significant modeling\nsimplifications, our corresponding controller that uses this model is able to\nexperimentally achieve a large reduction in energy usage without any\ndegradations in occupant comfort. It is in this way that we justify the\nmodeling simplifications that we have made. We conclude by presenting results\nfrom experiments on our building HVAC testbed, which show an average of 1.5MWh\nof energy savings per day (p = 0.002) with a 95% confidence interval of 1.0MWh\nto 2.1MWh of energy savings.\n",
          "  The Bayesian framework is a well-studied and successful framework for\ninductive reasoning, which includes hypothesis testing and confirmation,\nparameter estimation, sequence prediction, classification, and regression. But\nstandard statistical guidelines for choosing the model class and prior are not\nalways available or fail, in particular in complex situations. Solomonoff\ncompleted the Bayesian framework by providing a rigorous, unique, formal, and\nuniversal choice for the model class and the prior. We discuss in breadth how\nand in which sense universal (non-i.i.d.) sequence prediction solves various\n(philosophical) problems of traditional Bayesian sequence prediction. We show\nthat Solomonoff's model possesses many desirable properties: Strong total and\nweak instantaneous bounds, and in contrast to most classical continuous prior\ndensities has no zero p(oste)rior problem, i.e. can confirm universal\nhypotheses, is reparametrization and regrouping invariant, and avoids the\nold-evidence and updating problem. It even performs well (actually better) in\nnon-computable environments.\n",
          "  The main objective of higher education is to provide quality education to\nstudents. One way to achieve highest level of quality in higher education\nsystem is by discovering knowledge for prediction regarding enrolment of\nstudents in a course. This paper presents a data mining project to generate\npredictive models for student retention management. Given new records of\nincoming students, these predictive models can produce short accurate\nprediction lists identifying students who tend to need the support from the\nstudent retention program most. This paper examines the quality of the\npredictive models generated by the machine learning algorithms. The results\nshow that some of the machines learning algorithms are able to establish\neffective predictive models from the existing student retention data.\n",
          "  We address the sparse signal recovery problem in the context of multiple\nmeasurement vectors (MMV) when elements in each nonzero row of the solution\nmatrix are temporally correlated. Existing algorithms do not consider such\ntemporal correlations and thus their performance degrades significantly with\nthe correlations. In this work, we propose a block sparse Bayesian learning\nframework which models the temporal correlations. In this framework we derive\ntwo sparse Bayesian learning (SBL) algorithms, which have superior recovery\nperformance compared to existing algorithms, especially in the presence of high\ntemporal correlations. Furthermore, our algorithms are better at handling\nhighly underdetermined problems and require less row-sparsity on the solution\nmatrix. We also provide analysis of the global and local minima of their cost\nfunction, and show that the SBL cost function has the very desirable property\nthat the global minimum is at the sparsest solution to the MMV problem.\nExtensive experiments also provide some interesting results that motivate\nfuture theoretical research on the MMV model.\n",
          "  Since Estimation of Distribution Algorithms (EDA) were proposed, many\nattempts have been made to improve EDAs' performance in the context of global\noptimization. So far, the studies or applications of multivariate probabilistic\nmodel based continuous EDAs are still restricted to rather low dimensional\nproblems (smaller than 100D). Traditional EDAs have difficulties in solving\nhigher dimensional problems because of the curse of dimensionality and their\nrapidly increasing computational cost. However, scaling up continuous EDAs for\nhigher dimensional optimization is still necessary, which is supported by the\ndistinctive feature of EDAs: Because a probabilistic model is explicitly\nestimated, from the learnt model one can discover useful properties or features\nof the problem. Besides obtaining a good solution, understanding of the problem\nstructure can be of great benefit, especially for black box optimization. We\npropose a novel EDA framework with Model Complexity Control (EDA-MCC) to scale\nup EDAs. By using Weakly dependent variable Identification (WI) and Subspace\nModeling (SM), EDA-MCC shows significantly better performance than traditional\nEDAs on high dimensional problems. Moreover, the computational cost and the\nrequirement of large population sizes can be reduced in EDA-MCC. In addition to\nbeing able to find a good solution, EDA-MCC can also produce a useful problem\nstructure characterization. EDA-MCC is the first successful instance of\nmultivariate model based EDAs that can be effectively applied a general class\nof up to 500D problems. It also outperforms some newly developed algorithms\ndesigned specifically for large scale optimization. In order to understand the\nstrength and weakness of EDA-MCC, we have carried out extensive computational\nstudies of EDA-MCC. Our results have revealed when EDA-MCC is likely to\noutperform others on what kind of benchmark functions.\n",
          "  We introduce a framework for filtering features that employs the\nHilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence\nbetween the features and the labels. The key idea is that good features should\nmaximise such dependence. Feature selection for various supervised learning\nproblems (including classification and regression) is unified under this\nframework, and the solutions can be approximated using a backward-elimination\nalgorithm. We demonstrate the usefulness of our method on both artificial and\nreal world datasets.\n",
          "  We propose a novel model for nonlinear dimension reduction motivated by the\nprobabilistic formulation of principal component analysis. Nonlinearity is\nachieved by specifying different transformation matrices at different locations\nof the latent space and smoothing the transformation using a Markov random\nfield type prior. The computation is made feasible by the recent advances in\nsampling from von Mises-Fisher distributions.\n",
          "  In practical data integration systems, it is common for the data sources\nbeing integrated to provide conflicting information about the same entity.\nConsequently, a major challenge for data integration is to derive the most\ncomplete and accurate integrated records from diverse and sometimes conflicting\nsources. We term this challenge the truth finding problem. We observe that some\nsources are generally more reliable than others, and therefore a good model of\nsource quality is the key to solving the truth finding problem. In this work,\nwe propose a probabilistic graphical model that can automatically infer true\nrecords and source quality without any supervision. In contrast to previous\nmethods, our principled approach leverages a generative process of two types of\nerrors (false positive and false negative) by modeling two different aspects of\nsource quality. In so doing, ours is also the first approach designed to merge\nmulti-valued attribute types. Our method is scalable, due to an efficient\nsampling-based inference algorithm that needs very few iterations in practice\nand enjoys linear time complexity, with an even faster incremental variant.\nExperiments on two real world datasets show that our new method outperforms\nexisting state-of-the-art approaches to the truth finding problem.\n",
          "  Set-functions appear in many areas of computer science and applied\nmathematics, such as machine learning, computer vision, operations research or\nelectrical networks. Among these set-functions, submodular functions play an\nimportant role, similar to convex functions on vector spaces. In this tutorial,\nthe theory of submodular functions is presented, in a self-contained way, with\nall results shown from first principles. A good knowledge of convex analysis is\nassumed.\n",
          "  We propose a compression-based version of the empirical entropy of a finite\nstring over a finite alphabet. Whereas previously one considers the naked\nentropy of (possibly higher order) Markov processes, we consider the sum of the\ndescription of the random variable involved plus the entropy it induces. We\nassume only that the distribution involved is computable. To test the new\nnotion we compare the Normalized Information Distance (the similarity metric)\nwith a related measure based on Mutual Information in Shannon's framework. This\nway the similarities and differences of the last two concepts are exposed.\n",
          "  We present Searn, an algorithm for integrating search and learning to solve\ncomplex structured prediction problems such as those that occur in natural\nlanguage, speech, computational biology, and vision. Searn is a meta-algorithm\nthat transforms these complex problems into simple classification problems to\nwhich any binary classifier may be applied. Unlike current algorithms for\nstructured learning that require decomposition of both the loss function and\nthe feature functions over the predicted structure, Searn is able to learn\nprediction functions for any loss function and any class of features. Moreover,\nSearn comes with a strong, natural theoretical guarantee: good performance on\nthe derived classification problems implies good performance on the structured\nprediction problem.\n",
          "  To understand the structural dynamics of a large-scale social, biological or\ntechnological network, it may be useful to discover behavioral roles\nrepresenting the main connectivity patterns present over time. In this paper,\nwe propose a scalable non-parametric approach to automatically learn the\nstructural dynamics of the network and individual nodes. Roles may represent\nstructural or behavioral patterns such as the center of a star, peripheral\nnodes, or bridge nodes that connect different communities. Our novel approach\nlearns the appropriate structural role dynamics for any arbitrary network and\ntracks the changes over time. In particular, we uncover the specific global\nnetwork dynamics and the local node dynamics of a technological, communication,\nand social network. We identify interesting node and network patterns such as\nstationary and non-stationary roles, spikes/steps in role-memberships (perhaps\nindicating anomalies), increasing/decreasing role trends, among many others.\nOur results indicate that the nodes in each of these networks have distinct\nconnectivity patterns that are non-stationary and evolve considerably over\ntime. Overall, the experiments demonstrate the effectiveness of our approach\nfor fast mining and tracking of the dynamics in large networks. Furthermore,\nthe dynamic structural representation provides a basis for building more\nsophisticated models and tools that are fast for exploring large dynamic\nnetworks.\n",
          "  Ensemble learning aims to improve generalization ability by using multiple\nbase learners. It is well-known that to construct a good ensemble, the base\nlearners should be accurate as well as diverse. In this paper, unlabeled data\nis exploited to facilitate ensemble learning by helping augment the diversity\namong the base learners. Specifically, a semi-supervised ensemble method named\nUDEED is proposed. Unlike existing semi-supervised ensemble methods where\nerror-prone pseudo-labels are estimated for unlabeled data to enlarge the\nlabeled data to improve accuracy, UDEED works by maximizing accuracies of base\nlearners on labeled data while maximizing diversity among them on unlabeled\ndata. Experiments show that UDEED can effectively utilize unlabeled data for\nensemble learning and is highly competitive to well-established semi-supervised\nensemble methods.\n",
          "  Let us assume that $f$ is a continuous function defined on the unit ball of\n$\\mathbb R^d$, of the form $f(x) = g (A x)$, where $A$ is a $k \\times d$ matrix\nand $g$ is a function of $k$ variables for $k \\ll d$. We are given a budget $m\n\\in \\mathbb N$ of possible point evaluations $f(x_i)$, $i=1,...,m$, of $f$,\nwhich we are allowed to query in order to construct a uniform approximating\nfunction. Under certain smoothness and variation assumptions on the function\n$g$, and an {\\it arbitrary} choice of the matrix $A$, we present in this paper\n  1. a sampling choice of the points $\\{x_i\\}$ drawn at random for each\nfunction approximation;\n  2. algorithms (Algorithm 1 and Algorithm 2) for computing the approximating\nfunction, whose complexity is at most polynomial in the dimension $d$ and in\nthe number $m$ of points.\n  Due to the arbitrariness of $A$, the choice of the sampling points will be\naccording to suitable random distributions and our results hold with\noverwhelming probability. Our approach uses tools taken from the {\\it\ncompressed sensing} framework, recent Chernoff bounds for sums of\npositive-semidefinite matrices, and classical stability bounds for invariant\nsubspaces of singular value decompositions.\n",
          "  Many learning machines that have hierarchical structure or hidden variables\nare now being used in information science, artificial intelligence, and\nbioinformatics. However, several learning machines used in such fields are not\nregular but singular statistical models, hence their generalization performance\nis still left unknown. To overcome these problems, in the previous papers, we\nproved new equations in statistical learning, by which we can estimate the\nBayes generalization loss from the Bayes training loss and the functional\nvariance, on the condition that the true distribution is a singularity\ncontained in a learning machine. In this paper, we prove that the same\nequations hold even if a true distribution is not contained in a parametric\nmodel. Also we prove that, the proposed equations in a regular case are\nasymptotically equivalent to the Takeuchi information criterion. Therefore, the\nproposed equations are always applicable without any condition on the unknown\ntrue distribution.\n",
          "  Given a time series of multicomponent measurements x(t), the usual objective\nof nonlinear blind source separation (BSS) is to find a \"source\" time series\ns(t), comprised of statistically independent combinations of the measured\ncomponents. In this paper, the source time series is required to have a density\nfunction in (s,ds/dt)-space that is equal to the product of density functions\nof individual components. This formulation of the BSS problem has a solution\nthat is unique, up to permutations and component-wise transformations.\nSeparability is shown to impose constraints on certain locally invariant\n(scalar) functions of x, which are derived from local higher-order correlations\nof the data's velocity dx/dt. The data are separable if and only if they\nsatisfy these constraints, and, if the constraints are satisfied, the sources\ncan be explicitly constructed from the data. The method is illustrated by using\nit to separate two speech-like sounds recorded with a single microphone.\n",
          "  mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.\n",
          "  Recent theoretical and empirical work in statistical machine learning has\ndemonstrated the importance of learning algorithms for deep architectures,\ni.e., function classes obtained by composing multiple non-linear\ntransformations. Self-taught learning (exploiting unlabeled examples or\nexamples from other distributions) has already been applied to deep learners,\nbut mostly to show the advantage of unlabeled examples. Here we explore the\nadvantage brought by {\\em out-of-distribution examples}. For this purpose we\ndeveloped a powerful generator of stochastic variations and noise processes for\ncharacter images, including not only affine transformations but also slant,\nlocal elastic deformations, changes in thickness, background images, grey level\nchanges, contrast, occlusion, and various types of noise. The\nout-of-distribution examples are obtained from these highly distorted images or\nby including examples of object classes different from those in the target test\nset. We show that {\\em deep learners benefit more from out-of-distribution\nexamples than a corresponding shallow learner}, at least in the area of\nhandwritten character recognition. In fact, we show that they beat previously\npublished results and reach human-level performance on both handwritten digit\nclassification and 62-class handwritten character recognition.\n",
          "  Astronomy is increasingly encountering two fundamental truths: (1) The field\nis faced with the task of extracting useful information from extremely large,\ncomplex, and high dimensional datasets; (2) The techniques of astroinformatics\nand astrostatistics are the only way to make this tractable, and bring the\nrequired level of sophistication to the analysis. Thus, an approach which\nprovides these tools in a way that scales to these datasets is not just\ndesirable, it is vital. The expertise required spans not just astronomy, but\nalso computer science, statistics, and informatics. As a computer scientist and\nexpert in machine learning, Alex's contribution of expertise and a large number\nof fast algorithms designed to scale to large datasets, is extremely welcome.\nWe focus in this discussion on the questions raised by the practical\napplication of these algorithms to real astronomical datasets. That is, what is\nneeded to maximally leverage their potential to improve the science return?\nThis is not a trivial task. While computing and statistical expertise are\nrequired, so is astronomical expertise. Precedent has shown that, to-date, the\ncollaborations most productive in producing astronomical science results (e.g,\nthe Sloan Digital Sky Survey), have either involved astronomers expert in\ncomputer science and/or statistics, or astronomers involved in close, long-term\ncollaborations with experts in those fields. This does not mean that the\nastronomers are giving the most important input, but simply that their input is\ncrucial in guiding the effort in the most fruitful directions, and coping with\nthe issues raised by real data. Thus, the tools must be useable and\nunderstandable by those whose primary expertise is not computing or statistics,\neven though they may have quite extensive knowledge of those fields.\n",
          "  Gaussian graphical models are of great interest in statistical learning.\nBecause the conditional independencies between different nodes correspond to\nzero entries in the inverse covariance matrix of the Gaussian distribution, one\ncan learn the structure of the graph by estimating a sparse inverse covariance\nmatrix from sample data, by solving a convex maximum likelihood problem with an\n$\\ell_1$-regularization term. In this paper, we propose a first-order method\nbased on an alternating linearization technique that exploits the problem's\nspecial structure; in particular, the subproblems solved in each iteration have\nclosed-form solutions. Moreover, our algorithm obtains an $\\epsilon$-optimal\nsolution in $O(1/\\epsilon)$ iterations. Numerical experiments on both synthetic\nand real data from gene association networks show that a practical version of\nthis algorithm outperforms other competitive algorithms.\n",
          "  In this work, we propose a PAC-Bayes bound for the generalization risk of the\nGibbs classifier in the multi-class classification framework. The novelty of\nour work is the critical use of the confusion matrix of a classifier as an\nerror measure; this puts our contribution in the line of work aiming at dealing\nwith performance measure that are richer than mere scalar criterion such as the\nmisclassification rate. Thanks to very recent and beautiful results on matrix\nconcentration inequalities, we derive two bounds showing that the true\nconfusion risk of the Gibbs classifier is upper-bounded by its empirical risk\nplus a term depending on the number of training examples in each class. To the\nbest of our knowledge, this is the first PAC-Bayes bounds based on confusion\nmatrices.\n",
          "  We consider the problem of covariance matrix estimation in the presence of\nlatent variables. Under suitable conditions, it is possible to learn the\nmarginal covariance matrix of the observed variables via a tractable convex\nprogram, where the concentration matrix of the observed variables is decomposed\ninto a sparse matrix (representing the graphical structure of the observed\nvariables) and a low rank matrix (representing the marginalization effect of\nlatent variables). We present an efficient first-order method based on split\nBregman to solve the convex problem. The algorithm is guaranteed to converge\nunder mild conditions. We show that our algorithm is significantly faster than\nthe state-of-the-art algorithm on both artificial and real-world data. Applying\nthe algorithm to a gene expression data involving thousands of genes, we show\nthat most of the correlation between observed variables can be explained by\nonly a few dozen latent factors.\n",
          "  We present a method for learning max-weight matching predictors in bipartite\ngraphs. The method consists of performing maximum a posteriori estimation in\nexponential families with sufficient statistics that encode permutations and\ndata features. Although inference is in general hard, we show that for one very\nrelevant application - web page ranking - exact inference is efficient. For\ngeneral model instances, an appropriate sampler is readily available. Contrary\nto existing max-margin matching models, our approach is statistically\nconsistent and, in addition, experiments with increasing sample sizes indicate\nsuperior improvement over such models. We apply the method to graph matching in\ncomputer vision as well as to a standard benchmark dataset for learning web\npage ranking, in which we obtain state-of-the-art results, in particular\nimproving on max-margin variants. The drawback of this method with respect to\nmax-margin alternatives is its runtime for large graphs, which is comparatively\nhigh.\n",
          "  Induction is the process by which we obtain predictive laws or theories or\nmodels of the world. We consider the structural aspect of induction. We answer\nthe question as to whether we can find a finite and minmalistic set of\noperations on structural elements in terms of which any theory can be\nexpressed. We identify abstraction (grouping similar entities) and\nsuper-structuring (combining topologically e.g., spatio-temporally close\nentities) as the essential structural operations in the induction process. We\nshow that only two more structural operations, namely, reverse abstraction and\nreverse super-structuring (the duals of abstraction and super-structuring\nrespectively) suffice in order to exploit the full power of Turing-equivalent\ngenerative grammars in induction. We explore the implications of this theorem\nwith respect to the nature of hidden variables, radical positivism and the\n2-century old claim of David Hume about the principles of connexion among\nideas.\n",
          "  For the additive white Gaussian noise channel with average codeword power\nconstraint, new coding methods are devised in which the codewords are sparse\nsuperpositions, that is, linear combinations of subsets of vectors from a given\ndesign, with the possible messages indexed by the choice of subset. Decoding is\nby least squares, tailored to the assumed form of linear combination.\nCommunication is shown to be reliable with error probability exponentially\nsmall for all rates up to the Shannon capacity.\n",
          "  Machine learning over fully distributed data poses an important problem in\npeer-to-peer (P2P) applications. In this model we have one data record at each\nnetwork node, but without the possibility to move raw data due to privacy\nconsiderations. For example, user profiles, ratings, history, or sensor\nreadings can represent this case. This problem is difficult, because there is\nno possibility to learn local models, the system model offers almost no\nguarantees for reliability, yet the communication cost needs to be kept low.\nHere we propose gossip learning, a generic approach that is based on multiple\nmodels taking random walks over the network in parallel, while applying an\nonline learning algorithm to improve themselves, and getting combined via\nensemble learning methods. We present an instantiation of this approach for the\ncase of classification with linear models. Our main contribution is an ensemble\nlearning method which---through the continuous combination of the models in the\nnetwork---implements a virtual weighted voting mechanism over an exponential\nnumber of models at practically no extra cost as compared to independent random\nwalks. We prove the convergence of the method theoretically, and perform\nextensive experiments on benchmark datasets. Our experimental analysis\ndemonstrates the performance and robustness of the proposed approach.\n",
          "  We consider the problem of joint universal variable-rate lossy coding and\nidentification for parametric classes of stationary $\\beta$-mixing sources with\ngeneral (Polish) alphabets. Compression performance is measured in terms of\nLagrangians, while identification performance is measured by the variational\ndistance between the true source and the estimated source. Provided that the\nsources are mixing at a sufficiently fast rate and satisfy certain smoothness\nand Vapnik-Chervonenkis learnability conditions, it is shown that, for bounded\nmetric distortions, there exist universal schemes for joint lossy compression\nand identification whose Lagrangian redundancies converge to zero as $\\sqrt{V_n\n\\log n /n}$ as the block length $n$ tends to infinity, where $V_n$ is the\nVapnik-Chervonenkis dimension of a certain class of decision regions defined by\nthe $n$-dimensional marginal distributions of the sources; furthermore, for\neach $n$, the decoder can identify $n$-dimensional marginal of the active\nsource up to a ball of radius $O(\\sqrt{V_n\\log n/n})$ in variational distance,\neventually with probability one. The results are supplemented by several\nexamples of parametric sources satisfying the regularity conditions.\n",
          "  Learning latent structure in complex networks has become an important problem\nfueled by many types of networked data originating from practically all fields\nof science. In this paper, we propose a new non-parametric Bayesian\nmultiple-membership latent feature model for networks. Contrary to existing\nmultiple-membership models that scale quadratically in the number of vertices\nthe proposed model scales linearly in the number of links admitting\nmultiple-membership analysis in large scale networks. We demonstrate a\nconnection between the single membership relational model and multiple\nmembership models and show on \"real\" size benchmark network data that\naccounting for multiple memberships improves the learning of latent structure\nas measured by link prediction while explicitly accounting for multiple\nmembership result in a more compact representation of the latent structure of\nnetworks.\n",
          "  Detection of rare variants by resequencing is important for the\nidentification of individuals carrying disease variants. Rapid sequencing by\nnew technologies enables low-cost resequencing of target regions, although it\nis still prohibitive to test more than a few individuals. In order to improve\ncost trade-offs, it has recently been suggested to apply pooling designs which\nenable the detection of carriers of rare alleles in groups of individuals.\nHowever, this was shown to hold only for a relatively low number of individuals\nin a pool, and requires the design of pooling schemes for particular cases.\n  We propose a novel pooling design, based on a compressed sensing approach,\nwhich is both general, simple and efficient. We model the experimental\nprocedure and show via computer simulations that it enables the recovery of\nrare allele carriers out of larger groups than were possible before, especially\nin situations where high coverage is obtained for each individual.\n  Our approach can also be combined with barcoding techniques to enhance\nperformance and provide a feasible solution based on current resequencing\ncosts. For example, when targeting a small enough genomic region (~100\nbase-pairs) and using only ~10 sequencing lanes and ~10 distinct barcodes, one\ncan recover the identity of 4 rare allele carriers out of a population of over\n4000 individuals.\n",
          "  Given a sample covariance matrix, we examine the problem of maximizing the\nvariance explained by a linear combination of the input variables while\nconstraining the number of nonzero coefficients in this combination. This is\nknown as sparse principal component analysis and has a wide array of\napplications in machine learning and engineering. We formulate a new\nsemidefinite relaxation to this problem and derive a greedy algorithm that\ncomputes a full set of good solutions for all target numbers of non zero\ncoefficients, with total complexity O(n^3), where n is the number of variables.\nWe then use the same relaxation to derive sufficient conditions for global\noptimality of a solution, which can be tested in O(n^3) per pattern. We discuss\napplications in subset selection and sparse recovery and show on artificial\nexamples and biological data that our algorithm does provide globally optimal\nsolutions in many cases.\n",
          "  A learning algorithm based on primary school teaching and learning is\npresented. The methodology is to continuously evaluate a student and to give\nthem training on the examples for which they repeatedly fail, until, they can\ncorrectly answer all types of questions. This incremental learning procedure\nproduces better learning curves by demanding the student to optimally dedicate\ntheir learning time on the failed examples. When used in machine learning, the\nalgorithm is found to train a machine on a data with maximum variance in the\nfeature space so that the generalization ability of the network improves. The\nalgorithm has interesting applications in data mining, model evaluations and\nrare objects discovery.\n",
          "  We face network data from various sources, such as protein interactions and\nonline social networks. A critical problem is to model network interactions and\nidentify latent groups of network nodes. This problem is challenging due to\nmany reasons. For example, the network nodes are interdependent instead of\nindependent of each other, and the data are known to be very noisy (e.g.,\nmissing edges). To address these challenges, we propose a new relational model\nfor network data, Sparse Matrix-variate Gaussian process Blockmodel (SMGB). Our\nmodel generalizes popular bilinear generative models and captures nonlinear\nnetwork interactions using a matrix-variate Gaussian process with latent\nmembership variables. We also assign sparse prior distributions on the latent\nmembership variables to learn sparse group assignments for individual network\nnodes. To estimate the latent variables efficiently from data, we develop an\nefficient variational expectation maximization method. We compared our\napproaches with several state-of-the-art network models on both synthetic and\nreal-world network datasets. Experimental results demonstrate SMGBs outperform\nthe alternative approaches in terms of discovering latent classes or predicting\nunknown interactions.\n",
          "  We study learning in a noisy bisection model: specifically, Bayesian\nalgorithms to learn a target value V given access only to noisy realizations of\nwhether V is less than or greater than a threshold theta. At step t = 0, 1, 2,\n..., the learner sets threshold theta t and observes a noisy realization of\nsign(V - theta t). After T steps, the goal is to output an estimate V^ which is\nwithin an eta-tolerance of V . This problem has been studied, predominantly in\nenvironments with a fixed error probability q < 1/2 for the noisy realization\nof sign(V - theta t). In practice, it is often the case that q can approach\n1/2, especially as theta -> V, and there is little known when this happens. We\ngive a pseudo-Bayesian algorithm which provably converges to V. When the true\nprior matches our algorithm's Gaussian prior, we show near-optimal expected\nperformance. Our methods extend to the general multiple-threshold setting where\nthe observation noisily indicates which of k >= 2 regions V belongs to.\n",
          "  Crowdsourcing systems, in which numerous tasks are electronically distributed\nto numerous \"information piece-workers\", have emerged as an effective paradigm\nfor human-powered solving of large scale problems in domains such as image\nclassification, data entry, optical character recognition, recommendation, and\nproofreading. Because these low-paid workers can be unreliable, nearly all such\nsystems must devise schemes to increase confidence in their answers, typically\nby assigning each task multiple times and combining the answers in an\nappropriate manner, e.g. majority voting.\n  In this paper, we consider a general model of such crowdsourcing tasks and\npose the problem of minimizing the total price (i.e., number of task\nassignments) that must be paid to achieve a target overall reliability. We give\na new algorithm for deciding which tasks to assign to which workers and for\ninferring correct answers from the workers' answers. We show that our\nalgorithm, inspired by belief propagation and low-rank matrix approximation,\nsignificantly outperforms majority voting and, in fact, is optimal through\ncomparison to an oracle that knows the reliability of every worker. Further, we\ncompare our approach with a more general class of algorithms which can\ndynamically assign tasks. By adaptively deciding which questions to ask to the\nnext arriving worker, one might hope to reduce uncertainty more efficiently. We\nshow that, perhaps surprisingly, the minimum price necessary to achieve a\ntarget reliability scales in the same manner under both adaptive and\nnon-adaptive scenarios. Hence, our non-adaptive approach is order-optimal under\nboth scenarios. This strongly relies on the fact that workers are fleeting and\ncan not be exploited. Therefore, architecturally, our results suggest that\nbuilding a reliable worker-reputation system is essential to fully harnessing\nthe potential of adaptive designs.\n",
          "  This paper proposes an efficient technique for partitioning large biometric\ndatabase during identification. In this technique feature vector which\ncomprises of global and local descriptors extracted from offline signature are\nused by fuzzy clustering technique to partition the database. As biometric\nfeatures posses no natural order of sorting, thus it is difficult to index them\nalphabetically or numerically. Hence, some supervised criteria is required to\npartition the search space. At the time of identification the fuzziness\ncriterion is introduced to find the nearest clusters for declaring the identity\nof query sample. The system is tested using bin-miss rate and performs better\nin comparison to traditional k-means approach.\n",
          "  We propose a method for the problem of real time chord accompaniment of\nimprovised music. Our implementation can learn an underlying structure of the\nmusical performance and predict next chord. The system uses Hidden Markov Model\nto find the most probable chord sequence for the played melody and then a\nVariable Order Markov Model is used to a) learn the structure (if any) and b)\npredict next chord. We implemented our system in Java and MAX/Msp and compared\nand evaluated using objective (prediction accuracy) and subjective\n(questionnaire) evaluation methods.\n",
          "  This document describes concisely the ubiquitous class of exponential family\ndistributions met in statistics. The first part recalls definitions and\nsummarizes main properties and duality with Bregman divergences (all proofs are\nskipped). The second part lists decompositions and related formula of common\nexponential family distributions. We recall the Fisher-Rao-Riemannian\ngeometries and the dual affine connection information geometries of statistical\nmanifolds. It is intended to maintain and update this document and catalog by\nadding new distribution items.\n",
          "  This paper aims at the problem of link pattern prediction in collections of\nobjects connected by multiple relation types, where each type may play a\ndistinct role. While common link analysis models are limited to single-type\nlink prediction, we attempt here to capture the correlations among different\nrelation types and reveal the impact of various relation types on performance\nquality. For that, we define the overall relations between object pairs as a\n\\textit{link pattern} which consists in interaction pattern and connection\nstructure in the network, and then use tensor formalization to jointly model\nand predict the link patterns, which we refer to as \\textit{Link Pattern\nPrediction} (LPP) problem. To address the issue, we propose a Probabilistic\nLatent Tensor Factorization (PLTF) model by introducing another latent factor\nfor multiple relation types and furnish the Hierarchical Bayesian treatment of\nthe proposed probabilistic model to avoid overfitting for solving the LPP\nproblem. To learn the proposed model we develop an efficient Markov Chain Monte\nCarlo sampling method. Extensive experiments are conducted on several real\nworld datasets and demonstrate significant improvements over several existing\nstate-of-the-art methods.\n",
          "  Many learning tasks can be viewed as sequence prediction problems. For\nexample, online classification can be converted to sequence prediction with the\nsequence being pairs of input/target data and where the goal is to correctly\npredict the target data given input data and previous input/target pairs.\nSolomonoff induction is known to solve the general sequence prediction problem,\nbut only if the entire sequence is sampled from a computable distribution. In\nthe case of classification and discriminative learning though, only the targets\nneed be structured (given the inputs). We show that the normalised version of\nSolomonoff induction can still be used in this case, and more generally that it\ncan detect any recursive sub-pattern (regularity) within an otherwise\ncompletely unstructured sequence. It is also shown that the unnormalised\nversion can fail to predict very simple recursive sub-patterns.\n",
          "  We consider the problem of identifying the sparse principal component of a\nrank-deficient matrix. We introduce auxiliary spherical variables and prove\nthat there exists a set of candidate index-sets (that is, sets of indices to\nthe nonzero elements of the vector argument) whose size is polynomially\nbounded, in terms of rank, and contains the optimal index-set, i.e. the\nindex-set of the nonzero elements of the optimal solution. Finally, we develop\nan algorithm that computes the optimal sparse principal component in polynomial\ntime for any sparsity degree.\n",
          "  In conventional target tracking systems, human operators use the estimated\ntarget tracks to make higher level inference of the target behaviour/intent.\nThis paper develops syntactic filtering algorithms that assist human operators\nby extracting spatial patterns from target tracks to identify\nsuspicious/anomalous spatial trajectories. The targets' spatial trajectories\nare modeled by a stochastic context free grammar (SCFG) and a switched mode\nstate space model. Bayesian filtering algorithms for stochastic context free\ngrammars are presented for extracting the syntactic structure and illustrated\nfor a ground moving target indicator (GMTI) radar example. The performance of\nthe algorithms is tested with the experimental data collected using DRDC\nOttawa's X-band Wideband Experimental Airborne Radar (XWEAR).\n",
          "  In the study of computer codes, filling space as uniformly as possible is\nimportant to describe the complexity of the investigated phenomenon. However,\nthis property is not conserved by reducing the dimension. Some numeric\nexperiment designs are conceived in this sense as Latin hypercubes or\northogonal arrays, but they consider only the projections onto the axes or the\ncoordinate planes. In this article we introduce a statistic which allows\nstudying the good distribution of points according to all 1-dimensional\nprojections. By angularly scanning the domain, we obtain a radar type\nrepresentation, allowing the uniformity defects of a design to be identified\nwith respect to its projections onto straight lines. The advantages of this new\ntool are demonstrated on usual examples of space-filling designs (SFD) and a\nglobal statistic independent of the angle of rotation is studied.\n",
          "  In Part I of this two-part paper [1], we proposed a new game, called Chinese\nrestaurant game, to analyze the social learning problem with negative network\nexternality. The best responses of agents in the Chinese restaurant game with\nimperfect signals are constructed through a recursive method, and the influence\nof both learning and network externality on the utilities of agents is studied.\nIn Part II of this two-part paper, we illustrate three applications of Chinese\nrestaurant game in wireless networking, cloud computing, and online social\nnetworking. For each application, we formulate the corresponding problem as a\nChinese restaurant game and analyze how agents learn and make strategic\ndecisions in the problem. The proposed method is compared with four\ncommon-sense methods in terms of agents' utilities and the overall system\nperformance through simulations. We find that the proposed Chinese restaurant\ngame theoretic approach indeed helps agents make better decisions and improves\nthe overall system performance. Furthermore, agents with different decision\norders have different advantages in terms of their utilities, which also\nverifies the conclusions drawn in Part I of this two-part paper.\n",
          "  Recent reports have described that learning Bayesian networks are highly\nsensitive to the chosen equivalent sample size (ESS) in the Bayesian Dirichlet\nequivalence uniform (BDeu). This sensitivity often engenders some unstable or\nundesirable results. This paper describes some asymptotic analyses of BDeu to\nexplain the reasons for the sensitivity and its effects. Furthermore, this\npaper presents a proposal for a robust learning score for ESS by eliminating\nthe sensitive factors from the approximation of log-BDeu.\n",
          "  In this paper we explore noise tolerant learning of classifiers. We formulate\nthe problem as follows. We assume that there is an ${\\bf unobservable}$\ntraining set which is noise-free. The actual training set given to the learning\nalgorithm is obtained from this ideal data set by corrupting the class label of\neach example. The probability that the class label of an example is corrupted\nis a function of the feature vector of the example. This would account for most\nkinds of noisy data one encounters in practice. We say that a learning method\nis noise tolerant if the classifiers learnt with the ideal noise-free data and\nwith noisy data, both have the same classification accuracy on the noise-free\ndata. In this paper we analyze the noise tolerance properties of risk\nminimization (under different loss functions), which is a generic method for\nlearning classifiers. We show that risk minimization under 0-1 loss function\nhas impressive noise tolerance properties and that under squared error loss is\ntolerant only to uniform noise; risk minimization under other loss functions is\nnot noise tolerant. We conclude the paper with some discussion on implications\nof these theoretical results.\n",
          "  Monte-Carlo Tree Search (MCTS) methods are drawing great interest after\nyielding breakthrough results in computer Go. This paper proposes a Bayesian\napproach to MCTS that is inspired by distributionfree approaches such as UCT\n[13], yet significantly differs in important respects. The Bayesian framework\nallows potentially much more accurate (Bayes-optimal) estimation of node values\nand node uncertainties from a limited number of simulation trials. We further\npropose propagating inference in the tree via fast analytic Gaussian\napproximation methods: this can make the overhead of Bayesian inference\nmanageable in domains such as Go, while preserving high accuracy of\nexpected-value estimates. We find substantial empirical outperformance of UCT\nin an idealized bandit-tree test environment, where we can obtain valuable\ninsights by comparing with known ground truth. Additionally we rigorously prove\non-policy and off-policy convergence of the proposed methods.\n",
          "  Structured output prediction is an important machine learning problem both in\ntheory and practice, and the max-margin Markov network (\\mcn) is an effective\napproach. All state-of-the-art algorithms for optimizing \\mcn\\ objectives take\nat least $O(1/\\epsilon)$ number of iterations to find an $\\epsilon$ accurate\nsolution. Recent results in structured optimization suggest that faster rates\nare possible by exploiting the structure of the objective function. Towards\nthis end \\citet{Nesterov05} proposed an excessive gap reduction technique based\non Euclidean projections which converges in $O(1/\\sqrt{\\epsilon})$ iterations\non strongly convex functions. Unfortunately when applied to \\mcn s, this\napproach does not admit graphical model factorization which, as in many\nexisting algorithms, is crucial for keeping the cost per iteration tractable.\nIn this paper, we present a new excessive gap reduction technique based on\nBregman projections which admits graphical model factorization naturally, and\nconverges in $O(1/\\sqrt{\\epsilon})$ iterations. Compared with existing\nalgorithms, the convergence rate of our method has better dependence on\n$\\epsilon$ and other parameters of the problem, and can be easily kernelized.\n",
          "  Conformal prediction uses past experience to determine precise levels of\nconfidence in new predictions. Given an error probability $\\epsilon$, together\nwith a method that makes a prediction $\\hat{y}$ of a label $y$, it produces a\nset of labels, typically containing $\\hat{y}$, that also contains $y$ with\nprobability $1-\\epsilon$. Conformal prediction can be applied to any method for\nproducing $\\hat{y}$: a nearest-neighbor method, a support-vector machine, ridge\nregression, etc.\n  Conformal prediction is designed for an on-line setting in which labels are\npredicted successively, each one being revealed before the next is predicted.\nThe most novel and valuable feature of conformal prediction is that if the\nsuccessive examples are sampled independently from the same distribution, then\nthe successive predictions will be right $1-\\epsilon$ of the time, even though\nthey are based on an accumulating dataset rather than on independent datasets.\n  In addition to the model under which successive examples are sampled\nindependently, other on-line compression models can also use conformal\nprediction. The widely used Gaussian linear model is one of these.\n  This tutorial presents a self-contained account of the theory of conformal\nprediction and works through several numerical examples. A more comprehensive\ntreatment of the topic is provided in \"Algorithmic Learning in a Random World\",\nby Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005).\n",
          "  We present several theoretical contributions which allow Lie groups to be fit\nto high dimensional datasets. Transformation operators are represented in their\neigen-basis, reducing the computational complexity of parameter estimation to\nthat of training a linear transformation model. A transformation specific\n\"blurring\" operator is introduced that allows inference to escape local minima\nvia a smoothing of the transformation space. A penalty on traversed manifold\ndistance is added which encourages the discovery of sparse, minimal distance,\ntransformations between states. Both learning and inference are demonstrated\nusing these methods for the full set of affine transformations on natural image\npatches. Transformation operators are then trained on natural video sequences.\nIt is shown that the learned video transformations provide a better description\nof inter-frame differences than the standard motion model based on rigid\ntranslation.\n",
          "  Which ads should we display in sponsored search in order to maximize our\nrevenue? How should we dynamically rank information sources to maximize value\nof information? These applications exhibit strong diminishing returns:\nSelection of redundant ads and information sources decreases their marginal\nutility. We show that these and other problems can be formalized as repeatedly\nselecting an assignment of items to positions to maximize a sequence of\nmonotone submodular functions that arrive one by one. We present an efficient\nalgorithm for this general problem and analyze it in the no-regret model. Our\nalgorithm possesses strong theoretical guarantees, such as a performance ratio\nthat converges to the optimal constant of 1-1/e. We empirically evaluate our\nalgorithm on two real-world online optimization problems on the web: ad\nallocation with submodular utilities, and dynamically ranking blogs to detect\ninformation cascades.\n",
          "  This paper is devoted to the problem of sampling Gaussian fields in high\ndimension. Solutions exist for two specific structures of inverse covariance :\nsparse and circulant. The proposed approach is valid in a more general case and\nespecially as it emerges in inverse problems. It relies on a\nperturbation-optimization principle: adequate stochastic perturbation of a\ncriterion and optimization of the perturbed criterion. It is shown that the\ncriterion minimizer is a sample of the target density. The motivation in\ninverse problems is related to general (non-convolutive) linear observation\nmodels and their resolution in a Bayesian framework implemented through\nsampling algorithms when existing samplers are not feasible. It finds a direct\napplication in myopic and/or unsupervised inversion as well as in some\nnon-Gaussian inversion. An illustration focused on hyperparameter estimation\nfor super-resolution problems assesses the effectiveness of the proposed\napproach.\n",
          "  To improve the performance of speaker identification systems, an effective\nand robust method is proposed to extract speech features, capable of operating\nin noisy environment. Based on the time-frequency multi-resolution property of\nwavelet transform, the input speech signal is decomposed into various frequency\nchannels. For capturing the characteristic of the signal, the Mel-Frequency\nCepstral Coefficients (MFCCs) of the wavelet channels are calculated. Hidden\nMarkov Models (HMMs) were used for the recognition stage as they give better\nrecognition for the speaker's features than Dynamic Time Warping (DTW).\nComparison of the proposed approach with the MFCCs conventional feature\nextraction method shows that the proposed method not only effectively reduces\nthe influence of noise, but also improves recognition. A recognition rate of\n99.3% was obtained using the proposed feature extraction technique compared to\n98.7% using the MFCCs. When the test patterns were corrupted by additive white\nGaussian noise with 20 dB S/N ratio, the recognition rate was 97.3% using the\nproposed method compared to 93.3% using the MFCCs.\n",
          "  We consider the problem of analyzing the heterogeneity of clustering\ndistributions for multiple groups of observed data, each of which is indexed by\na covariate value, and inferring global clusters arising from observations\naggregated over the covariate domain. We propose a novel Bayesian nonparametric\nmethod reposing on the formalism of spatial modeling and a nested hierarchy of\nDirichlet processes. We provide an analysis of the model properties, relating\nand contrasting the notions of local and global clusters. We also provide an\nefficient inference algorithm, and demonstrate the utility of our method in\nseveral data examples, including the problem of object tracking and a global\nclustering analysis of functional data where the functional identity\ninformation is not available.\n",
          "  The No Free Lunch theorems are often used to argue that domain specific\nknowledge is required to design successful algorithms. We use algorithmic\ninformation theory to argue the case for a universal bias allowing an algorithm\nto succeed in all interesting problem domains. Additionally, we give a new\nalgorithm for off-line classification, inspired by Solomonoff induction, with\ngood performance on all structured problems under reasonable assumptions. This\nincludes a proof of the efficacy of the well-known heuristic of randomly\nselecting training data in the hope of reducing misclassification rates.\n",
          "  Speech recognition and speaker identification are important for\nauthentication and verification in security purpose, but they are difficult to\nachieve. Speaker identification methods can be divided into text-independent\nand text-dependent. This paper presents a technique of text-dependent speaker\nidentification using MFCC-domain support vector machine (SVM). In this work,\nmelfrequency cepstrum coefficients (MFCCs) and their statistical distribution\nproperties are used as features, which will be inputs to the neural network.\nThis work firstly used sequential minimum optimization (SMO) learning technique\nfor SVM that improve performance over traditional techniques Chunking, Osuna.\nThe cepstrum coefficients representing the speaker characteristics of a speech\nsegment are computed by nonlinear filter bank analysis and discrete cosine\ntransform. The speaker identification ability and convergence speed of the SVMs\nare investigated for different combinations of features. Extensive experimental\nresults on several samples show the effectiveness of the proposed approach.\n",
          "  Driven by a large number of potential applications in areas like\nbioinformatics, information retrieval and social network analysis, the problem\nsetting of inferring relations between pairs of data objects has recently been\ninvestigated quite intensively in the machine learning community. To this end,\ncurrent approaches typically consider datasets containing crisp relations, so\nthat standard classification methods can be adopted. However, relations between\nobjects like similarities and preferences are often expressed in a graded\nmanner in real-world applications. A general kernel-based framework for\nlearning relations from data is introduced here. It extends existing approaches\nbecause both crisp and graded relations are considered, and it unifies existing\napproaches because different types of graded relations can be modeled,\nincluding symmetric and reciprocal relations. This framework establishes\nimportant links between recent developments in fuzzy set theory and machine\nlearning. Its usefulness is demonstrated through various experiments on\nsynthetic and real-world data.\n",
          "  We study the tracking problem, namely, estimating the hidden state of an\nobject over time, from unreliable and noisy measurements. The standard\nframework for the tracking problem is the generative framework, which is the\nbasis of solutions such as the Bayesian algorithm and its approximation, the\nparticle filters. However, these solutions can be very sensitive to model\nmismatches. In this paper, motivated by online learning, we introduce a new\nframework for tracking. We provide an efficient tracking algorithm for this\nframework. We provide experimental results comparing our algorithm to the\nBayesian algorithm on simulated data. Our experiments show that when there are\nslight model mismatches, our algorithm outperforms the Bayesian algorithm.\n",
          "  In this paper, we have established a unified framework of multistage\nparameter estimation. We demonstrate that a wide variety of statistical\nproblems such as fixed-sample-size interval estimation, point estimation with\nerror control, bounded-width confidence intervals, interval estimation\nfollowing hypothesis testing, construction of confidence sequences, can be cast\ninto the general framework of constructing sequential random intervals with\nprescribed coverage probabilities. We have developed exact methods for the\nconstruction of such sequential random intervals in the context of multistage\nsampling. In particular, we have established inclusion principle and coverage\ntuning techniques to control and adjust the coverage probabilities of\nsequential random intervals. We have obtained concrete sampling schemes which\nare unprecedentedly efficient in terms of sampling effort as compared to\nexisting procedures.\n",
          "  This paper investigates how neurons can use metabolic cost to facilitate\nlearning at a population level. Although decision-making by individual neurons\nhas been extensively studied, questions regarding how neurons should behave to\ncooperate effectively remain largely unaddressed. Under assumptions that\ncapture a few basic features of cortical neurons, we show that constraining\nreward maximization by metabolic cost aligns the information content of actions\nwith their expected reward. Thus, metabolic cost provides a mechanism whereby\nneurons encode expected reward into their outputs. Further, aside from reducing\nenergy expenditures, imposing a tight metabolic constraint also increases the\naccuracy of empirical estimates of rewards, increasing the robustness of\ndistributed learning. Finally, we present two implementations of metabolically\nconstrained learning that confirm our theoretical finding. These results\nsuggest that metabolic cost may be an organizing principle underlying the\nneural code, and may also provide a useful guide to the design and analysis of\nother cooperating populations.\n",
          "  We consider an original problem that arises from the issue of security\nanalysis of a power system and that we name optimal discovery with\nprobabilistic expert advice. We address it with an algorithm based on the\noptimistic paradigm and the Good-Turing missing mass estimator. We show that\nthis strategy uniformly attains the optimal discovery rate in a macroscopic\nlimit sense, under some assumptions on the probabilistic experts. We also\nprovide numerical experiments suggesting that this optimal behavior may still\nhold under weaker assumptions.\n",
          "  We investigate unsupervised pre-training of deep architectures as feature\ngenerators for \"shallow\" classifiers. Stacked Denoising Autoencoders (SdA),\nwhen used as feature pre-processing tools for SVM classification, can lead to\nsignificant improvements in accuracy - however, at the price of a substantial\nincrease in computational cost. In this paper we create a simple algorithm\nwhich mimics the layer by layer training of SdAs. However, in contrast to SdAs,\nour algorithm requires no training through gradient descent as the parameters\ncan be computed in closed-form. It can be implemented in less than 20 lines of\nMATLABTMand reduces the computation time from several hours to mere seconds. We\nshow that our feature transformation reliably improves the results of SVM\nclassification significantly on all our data sets - often outperforming SdAs\nand even deep neural networks in three out of four deep learning benchmarks.\n",
          "  In a social network, agents are intelligent and have the capability to make\ndecisions to maximize their utilities. They can either make wise decisions by\ntaking advantages of other agents' experiences through learning, or make\ndecisions earlier to avoid competitions from huge crowds. Both these two\neffects, social learning and negative network externality, play important roles\nin the decision process of an agent. While there are existing works on either\nsocial learning or negative network externality, a general study on considering\nboth these two contradictory effects is still limited. We find that the Chinese\nrestaurant process, a popular random process, provides a well-defined structure\nto model the decision process of an agent under these two effects. By\nintroducing the strategic behavior into the non-strategic Chinese restaurant\nprocess, in Part I of this two-part paper, we propose a new game, called\nChinese Restaurant Game, to formulate the social learning problem with negative\nnetwork externality. Through analyzing the proposed Chinese restaurant game, we\nderive the optimal strategy of each agent and provide a recursive method to\nachieve the optimal strategy. How social learning and negative network\nexternality influence each other under various settings is also studied through\nsimulations.\n",
          "  This paper analyses the problem of Gaussian process (GP) bandits with\ndeterministic observations. The analysis uses a branch and bound algorithm that\nis related to the UCB algorithm of (Srinivas et al., 2010). For GPs with\nGaussian observation noise, with variance strictly greater than zero, (Srinivas\net al., 2010) proved that the regret vanishes at the approximate rate of\n$O(\\frac{1}{\\sqrt{t}})$, where t is the number of observations. To complement\ntheir result, we attack the deterministic case and attain a much faster\nexponential convergence rate. Under some regularity assumptions, we show that\nthe regret decreases asymptotically according to $O(e^{-\\frac{\\tau t}{(\\ln\nt)^{d/4}}})$ with high probability. Here, d is the dimension of the search\nspace and $\\tau$ is a constant that depends on the behaviour of the objective\nfunction near its global maximum.\n",
          "  This paper considers the problem of learning, from samples, the dependency\nstructure of a system of linear stochastic differential equations, when some of\nthe variables are latent. In particular, we observe the time evolution of some\nvariables, and never observe other variables; from this, we would like to find\nthe dependency structure between the observed variables - separating out the\nspurious interactions caused by the (marginalizing out of the) latent\nvariables' time series. We develop a new method, based on convex optimization,\nto do so in the case when the number of latent variables is smaller than the\nnumber of observed ones. For the case when the dependency structure between the\nobserved variables is sparse, we theoretically establish a high-dimensional\nscaling result for structure recovery. We verify our theoretical result with\nboth synthetic and real data (from the stock market).\n",
          "  A key issue in statistics and machine learning is to automatically select the\n\"right\" model complexity, e.g., the number of neighbors to be averaged over in\nk nearest neighbor (kNN) regression or the polynomial degree in regression with\npolynomials. We suggest a novel principle - the Loss Rank Principle (LoRP) -\nfor model selection in regression and classification. It is based on the loss\nrank, which counts how many other (fictitious) data would be fitted better.\nLoRP selects the model that has minimal loss rank. Unlike most penalized\nmaximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the\nregression functions and the loss function. It works without a stochastic noise\nmodel, and is directly applicable to any non-parametric regressor, like kNN.\n",
          "  Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide\npowerful generalizations of linear regression, where the target variable is\nassumed to be a (possibly unknown) 1-dimensional function of a linear\npredictor. In general, these problems entail non-convex estimation procedures,\nand, in practice, iterative local search heuristics are often used. Kalai and\nSastry (2009) recently provided the first provably efficient method for\nlearning SIMs and GLMs, under the assumptions that the data are in fact\ngenerated under a GLM and under certain monotonicity and Lipschitz constraints.\nHowever, to obtain provable performance, the method requires a fresh sample\nevery iteration. In this paper, we provide algorithms for learning GLMs and\nSIMs, which are both computationally and statistically efficient. We also\nprovide an empirical study, demonstrating their feasibility in practice.\n",
          "  Modern data acquisition routinely produces massive amounts of network data.\nThough many methods and models have been proposed to analyze such data, the\nresearch of network data is largely disconnected with the classical theory of\nstatistical learning and signal processing. In this paper, we present a new\nframework for modeling network data, which connects two seemingly different\nareas: network data analysis and compressed sensing. From a nonparametric\nperspective, we model an observed network using a large dictionary. In\nparticular, we consider the network clique detection problem and show\nconnections between our formulation with a new algebraic tool, namely Randon\nbasis pursuit in homogeneous spaces. Such a connection allows us to identify\nrigorous recovery conditions for clique detection problems. Though this paper\nis mainly conceptual, we also develop practical approximation algorithms for\nsolving empirical problems and demonstrate their usefulness on real-world\ndatasets.\n",
          "  We propose to model the text classification process as a sequential decision\nprocess. In this process, an agent learns to classify documents into topics\nwhile reading the document sentences sequentially and learns to stop as soon as\nenough information was read for deciding. The proposed algorithm is based on a\nmodelisation of Text Classification as a Markov Decision Process and learns by\nusing Reinforcement Learning. Experiments on four different classical\nmono-label corpora show that the proposed approach performs comparably to\nclassical SVM approaches for large training sets, and better for small training\nsets. In addition, the model automatically adapts its reading process to the\nquantity of training information provided.\n",
          "  In this paper we shall review the common problems associated with Piecewise\nLinear Separation incremental algorithms. This kind of neural models yield poor\nperformances when dealing with some classification problems, due to the\nevolving schemes used to construct the resulting networks. So as to avoid this\nundesirable behavior we shall propose a modification criterion. It is based\nupon the definition of a function which will provide information about the\nquality of the network growth process during the learning phase. This function\nis evaluated periodically as the network structure evolves, and will permit, as\nwe shall show through exhaustive benchmarks, to considerably improve the\nperformance(measured in terms of network complexity and generalization\ncapabilities) offered by the networks generated by these incremental models.\n",
          "  We prove that mutual information is actually negative copula entropy, based\non which a method for mutual information estimation is proposed.\n",
          "  We study the worst case error of kernel density estimates via subset\napproximation. A kernel density estimate of a distribution is the convolution\nof that distribution with a fixed kernel (e.g. Gaussian kernel). Given a subset\n(i.e. a point set) of the input distribution, we can compare the kernel density\nestimates of the input distribution with that of the subset and bound the worst\ncase error. If the maximum error is eps, then this subset can be thought of as\nan eps-sample (aka an eps-approximation) of the range space defined with the\ninput distribution as the ground set and the fixed kernel representing the\nfamily of ranges. Interestingly, in this case the ranges are not binary, but\nhave a continuous range (for simplicity we focus on kernels with range of\n[0,1]); these allow for smoother notions of range spaces.\n  It turns out, the use of this smoother family of range spaces has an added\nbenefit of greatly decreasing the size required for eps-samples. For instance,\nin the plane the size is O((1/eps^{4/3}) log^{2/3}(1/eps)) for disks (based on\nVC-dimension arguments) but is only O((1/eps) sqrt{log (1/eps)}) for Gaussian\nkernels and for kernels with bounded slope that only affect a bounded domain.\nThese bounds are accomplished by studying the discrepancy of these \"kernel\"\nrange spaces, and here the improvement in bounds are even more pronounced. In\nthe plane, we show the discrepancy is O(sqrt{log n}) for these kernels, whereas\nfor balls there is a lower bound of Omega(n^{1/4}).\n",
          "  We propose a theory that relates difficulty of learning in deep architectures\nto culture and language. It is articulated around the following hypotheses: (1)\nlearning in an individual human brain is hampered by the presence of effective\nlocal minima; (2) this optimization difficulty is particularly important when\nit comes to learning higher-level abstractions, i.e., concepts that cover a\nvast and highly-nonlinear span of sensory configurations; (3) such high-level\nabstractions are best represented in brains by the composition of many levels\nof representation, i.e., by deep architectures; (4) a human brain can learn\nsuch high-level abstractions if guided by the signals produced by other humans,\nwhich act as hints or indirect supervision for these high-level abstractions;\nand (5), language and the recombination and optimization of mental concepts\nprovide an efficient evolutionary recombination operator, and this gives rise\nto rapid search in the space of communicable ideas that help humans build up\nbetter high-level internal representations of their world. These hypotheses put\ntogether imply that human culture and the evolution of ideas have been crucial\nto counter an optimization difficulty: this optimization difficulty would\notherwise make it very difficult for human brains to capture high-level\nknowledge of the world. The theory is grounded in experimental observations of\nthe difficulties of training deep artificial neural networks. Plausible\nconsequences of this theory for the efficiency of cultural evolutions are\nsketched.\n",
          "  Nonnegative Matrix Factorization (NMF) is a widely used technique in many\napplications such as face recognition, motion segmentation, etc. It\napproximates the nonnegative data in an original high dimensional space with a\nlinear representation in a low dimensional space by using the product of two\nnonnegative matrices. In many applications data are often partially corrupted\nwith large additive noise. When the positions of noise are known, some existing\nvariants of NMF can be applied by treating these corrupted entries as missing\nvalues. However, the positions are often unknown in many real world\napplications, which prevents the usage of traditional NMF or other existing\nvariants of NMF. This paper proposes a Robust Nonnegative Matrix Factorization\n(RobustNMF) algorithm that explicitly models the partial corruption as large\nadditive noise without requiring the information of positions of noise. In\npractice, large additive noise can be used to model outliers. In particular,\nthe proposed method jointly approximates the clean data matrix with the product\nof two nonnegative matrices and estimates the positions and values of\noutliers/noise. An efficient iterative optimization algorithm with a solid\ntheoretical justification has been proposed to learn the desired matrix\nfactorization. Experimental results demonstrate the advantages of the proposed\nalgorithm.\n",
          "  In multi-task learning several related tasks are considered simultaneously,\nwith the hope that by an appropriate sharing of information across tasks, each\ntask may benefit from the others. In the context of learning linear functions\nfor supervised classification or regression, this can be achieved by including\na priori information about the weight vectors associated with the tasks, and\nhow they are expected to be related to each other. In this paper, we assume\nthat tasks are clustered into groups, which are unknown beforehand, and that\ntasks within a group have similar weight vectors. We design a new spectral norm\nthat encodes this a priori assumption, without the prior knowledge of the\npartition of tasks into groups, resulting in a new convex optimization\nformulation for multi-task learning. We show in simulations on synthetic\nexamples and on the IEDB MHC-I binding dataset, that our approach outperforms\nwell-known convex methods for multi-task learning, as well as related non\nconvex methods dedicated to the same problem.\n",
          "  This paper presents a forecasting model designed using WSNs (Wireless Sensor\nNetworks) to predict flood in rivers using simple and fast calculations to\nprovide real-time results and save the lives of people who may be affected by\nthe flood. Our prediction model uses multiple variable robust linear regression\nwhich is easy to understand and simple and cost effective in implementation, is\nspeed efficient, but has low resource utilization and yet provides real time\npredictions with reliable accuracy, thus having features which are desirable in\nany real world algorithm. Our prediction model is independent of the number of\nparameters, i.e. any number of parameters may be added or removed based on the\non-site requirements. When the water level rises, we represent it using a\npolynomial whose nature is used to determine if the water level may exceed the\nflood line in the near future. We compare our work with a contemporary\nalgorithm to demonstrate our improvements over it. Then we present our\nsimulation results for the predicted water level compared to the actual water\nlevel.\n",
          "  Detecting outliers which are grossly different from or inconsistent with the\nremaining dataset is a major challenge in real-world KDD applications. Existing\noutlier detection methods are ineffective on scattered real-world datasets due\nto implicit data patterns and parameter setting issues. We define a novel\n\"Local Distance-based Outlier Factor\" (LDOF) to measure the {outlier-ness} of\nobjects in scattered datasets which addresses these issues. LDOF uses the\nrelative location of an object to its neighbours to determine the degree to\nwhich the object deviates from its neighbourhood. Properties of LDOF are\ntheoretically analysed including LDOF's lower bound and its false-detection\nprobability, as well as parameter settings. In order to facilitate parameter\nsettings in real-world applications, we employ a top-n technique in our outlier\ndetection approach, where only the objects with the highest LDOF values are\nregarded as outliers. Compared to conventional approaches (such as top-n KNN\nand top-n LOF), our method top-n LDOF is more effective at detecting outliers\nin scattered data. It is also easier to set parameters, since its performance\nis relatively stable over a large range of parameter values, as illustrated by\nexperimental results on both real-world and synthetic datasets.\n",
          "  We study distribution free, nonparametric prediction bands with a special\nfocus on their finite sample behavior. First we investigate and develop\ndifferent notions of finite sample coverage guarantees. Then we give a new\nprediction band estimator by combining the idea of \"conformal prediction\" (Vovk\net al. 2009) with nonparametric conditional density estimation. The proposed\nestimator, called COPS (Conformal Optimized Prediction Set), always has finite\nsample guarantee in a stronger sense than the original conformal prediction\nestimator. Under regularity conditions the estimator converges to an oracle\nband at a minimax optimal rate. A fast approximation algorithm and a data\ndriven method for selecting the bandwidth are developed. The method is\nillustrated first in simulated data. Then, an application shows that the\nproposed method gives desirable prediction intervals in an automatic way, as\ncompared to the classical linear regression modeling.\n",
          "  We show that for many classes of symmetric two-player games, the simple\ndecision rule \"imitate-the-best\" can hardly be beaten by any other decision\nrule. We provide necessary and sufficient conditions for imitation to be\nunbeatable and show that it can only be beaten by much in games that are of the\nrock-scissors-paper variety. Thus, in many interesting examples, like 2x2\ngames, Cournot duopoly, price competition, rent seeking, public goods games,\ncommon pool resource games, minimum effort coordination games, arms race,\nsearch, bargaining, etc., imitation cannot be beaten by much even by a very\nclever opponent.\n",
          "  This paper addresses the general problem of domain adaptation which arises in\na variety of applications where the distribution of the labeled sample\navailable somewhat differs from that of the test data. Building on previous\nwork by Ben-David et al. (2007), we introduce a novel distance between\ndistributions, discrepancy distance, that is tailored to adaptation problems\nwith arbitrary loss functions. We give Rademacher complexity bounds for\nestimating the discrepancy distance from finite samples for different loss\nfunctions. Using this distance, we derive novel generalization bounds for\ndomain adaptation for a wide family of loss functions. We also present a series\nof novel adaptation bounds for large classes of regularization-based\nalgorithms, including support vector machines and kernel ridge regression based\non the empirical discrepancy. This motivates our analysis of the problem of\nminimizing the empirical discrepancy for various loss functions for which we\nalso give novel algorithms. We report the results of preliminary experiments\nthat demonstrate the benefits of our discrepancy minimization algorithms for\ndomain adaptation.\n",
          "  In distributed learning, the goal is to perform a learning task over data\ndistributed across multiple nodes with minimal (expensive) communication. Prior\nwork (Daume III et al., 2012) proposes a general model that bounds the\ncommunication required for learning classifiers while allowing for $\\eps$\ntraining error on linearly separable data adversarially distributed across\nnodes.\n  In this work, we develop key improvements and extensions to this basic model.\nOur first result is a two-party multiplicative-weight-update based protocol\nthat uses $O(d^2 \\log{1/\\eps})$ words of communication to classify distributed\ndata in arbitrary dimension $d$, $\\eps$-optimally. This readily extends to\nclassification over $k$ nodes with $O(kd^2 \\log{1/\\eps})$ words of\ncommunication. Our proposed protocol is simple to implement and is considerably\nmore efficient than baselines compared, as demonstrated by our empirical\nresults.\n  In addition, we illustrate general algorithm design paradigms for doing\nefficient learning over distributed data. We show how to solve\nfixed-dimensional and high dimensional linear programming efficiently in a\ndistributed setting where constraints may be distributed across nodes. Since\nmany learning problems can be viewed as convex optimization problems where\nconstraints are generated by individual points, this models many typical\ndistributed learning scenarios. Our techniques make use of a novel connection\nfrom multipass streaming, as well as adapting the multiplicative-weight-update\nframework more generally to a distributed setting. As a consequence, our\nmethods extend to the wide range of problems solvable using these techniques.\n",
          "  Kolmogorov argued that the concept of information exists also in problems\nwith no underlying stochastic model (as Shannon's information representation)\nfor instance, the information contained in an algorithm or in the genome. He\nintroduced a combinatorial notion of entropy and information $I(x:\\sy)$\nconveyed by a binary string $x$ about the unknown value of a variable $\\sy$.\nThe current paper poses the following questions: what is the relationship\nbetween the information conveyed by $x$ about $\\sy$ to the description\ncomplexity of $x$ ? is there a notion of cost of information ? are there limits\non how efficient $x$ conveys information ?\n  To answer these questions Kolmogorov's definition is extended and a new\nconcept termed {\\em information width} which is similar to $n$-widths in\napproximation theory is introduced. Information of any input source, e.g.,\nsample-based, general side-information or a hybrid of both can be evaluated by\na single common formula. An application to the space of binary functions is\nconsidered.\n",
          "  We derive generalization error bounds for stationary univariate\nautoregressive (AR) models. We show that imposing stationarity is enough to\ncontrol the Gaussian complexity without further regularization. This lets us\nuse structural risk minimization for model selection. We demonstrate our\nmethods by predicting interest rate movements.\n",
          "  We consider the problem of estimating the inverse covariance matrix by\nmaximizing the likelihood function with a penalty added to encourage the\nsparsity of the resulting matrix. We propose a new approach based on the split\nBregman method to solve the regularized maximum likelihood estimation problem.\nWe show that our method is significantly faster than the widely used graphical\nlasso method, which is based on blockwise coordinate descent, on both\nartificial and real-world data. More importantly, different from the graphical\nlasso, the split Bregman based method is much more general, and can be applied\nto a class of regularization terms other than the $\\ell_1$ norm\n",
          "  We introduce a theory of sequential causal inference in which learners in a\nchain estimate a structural model from their upstream teacher and then pass\nsamples from the model to their downstream student. It extends the population\ndynamics of genetic drift, recasting Kimura's selectively neutral theory as a\nspecial case of a generalized drift process using structured populations with\nmemory. We examine the diffusion and fixation properties of several drift\nprocesses and propose applications to learning, inference, and evolution. We\nalso demonstrate how the organization of drift process space controls fidelity,\nfacilitates innovations, and leads to information loss in sequential learning\nwith and without memory.\n",
          "  We investigate the problem of learning XML queries, path queries and tree\npattern queries, from examples given by the user. A learning algorithm takes on\nthe input a set of XML documents with nodes annotated by the user and returns a\nquery that selects the nodes in a manner consistent with the annotation. We\nstudy two learning settings that differ with the types of annotations. In the\nfirst setting the user may only indicate required nodes that the query must\nreturn. In the second, more general, setting, the user may also indicate\nforbidden nodes that the query must not return. The query may or may not return\nany node with no annotation. We formalize what it means for a class of queries\nto be \\emph{learnable}. One requirement is the existence of a learning\nalgorithm that is sound i.e., always returns a query consistent with the\nexamples given by the user. Furthermore, the learning algorithm should be\ncomplete i.e., able to produce every query with a sufficiently rich example.\nOther requirements involve tractability of learning and its robustness to\nnonessential examples. We show that the classes of simple path queries and\npath-subsumption-free tree queries are learnable from positive examples. The\nlearnability of the full class of tree pattern queries (and the full class of\npath queries) remains an open question. We show also that adding negative\nexamples to the picture renders the learning unfeasible.\n  Published in ICDT 2012, Berlin.\n",
          "  A generalized-statistics variational principle for source separation is\nformulated by recourse to Tsallis' entropy subjected to the additive duality\nand employing constraints described by normal averages. The variational\nprinciple is amalgamated with Hopfield-like learning rules resulting in an\nunsupervised learning model. The update rules are formulated with the aid of\nq-deformed calculus. Numerical examples exemplify the efficacy of this model.\n",
          "  We consider the problem of minimal correction of the training set to make it\nconsistent with monotonic constraints. This problem arises during analysis of\ndata sets via techniques that require monotone data. We show that this problem\nis NP-hard in general and is equivalent to finding a maximal independent set in\nspecial orgraphs. Practically important cases of that problem considered in\ndetail. These are the cases when a partial order given on the replies set is a\ntotal order or has a dimension 2. We show that the second case can be reduced\nto maximization of a quadratic convex function on a convex set. For this case\nwe construct an approximate polynomial algorithm based on convex optimization.\n",
          "  We consider the problem of learning the structure of Ising models (pairwise\nbinary Markov random fields) from i.i.d. samples. While several methods have\nbeen proposed to accomplish this task, their relative merits and limitations\nremain somewhat obscure. By analyzing a number of concrete examples, we show\nthat low-complexity algorithms often fail when the Markov random field develops\nlong-range correlations. More precisely, this phenomenon appears to be related\nto the Ising model phase transition (although it does not coincide with it).\n",
          "  We consider the problem of learning a linear factor model. We propose a\nregularized form of principal component analysis (PCA) and demonstrate through\nexperiments with synthetic and real data the superiority of resulting estimates\nto those produced by pre-existing factor analysis approaches. We also establish\ntheoretical results that explain how our algorithm corrects the biases induced\nby conventional approaches. An important feature of our algorithm is that its\ncomputational requirements are similar to those of PCA, which enjoys wide use\nin large part due to its efficiency.\n",
          "  We provide a variant of Azuma's concentration inequality for martingales, in\nwhich the standard boundedness requirement is replaced by the milder\nrequirement of a subgaussian tail.\n",
          "  PAQ8 is an open source lossless data compression algorithm that currently\nachieves the best compression rates on many benchmarks. This report presents a\ndetailed description of PAQ8 from a statistical machine learning perspective.\nIt shows that it is possible to understand some of the modules of PAQ8 and use\nthis understanding to improve the method. However, intuitive statistical\nexplanations of the behavior of other modules remain elusive. We hope the\ndescription in this report will be a starting point for discussions that will\nincrease our understanding, lead to improvements to PAQ8, and facilitate a\ntransfer of knowledge from PAQ8 to other machine learning methods, such a\nrecurrent neural networks and stochastic memoizers. Finally, the report\npresents a broad range of new applications of PAQ to machine learning tasks\nincluding language modeling and adaptive text prediction, adaptive game\nplaying, classification, and compression using features from the field of deep\nlearning.\n",
          "  KNN is one of the most popular classification methods, but it often fails to\nwork well with inappropriate choice of distance metric or due to the presence\nof numerous class-irrelevant features. Linear feature transformation methods\nhave been widely applied to extract class-relevant information to improve kNN\nclassification, which is very limited in many applications. Kernels have been\nused to learn powerful non-linear feature transformations, but these methods\nfail to scale to large datasets. In this paper, we present a scalable\nnon-linear feature mapping method based on a deep neural network pretrained\nwith restricted boltzmann machines for improving kNN classification in a\nlarge-margin framework, which we call DNet-kNN. DNet-kNN can be used for both\nclassification and for supervised dimensionality reduction. The experimental\nresults on two benchmark handwritten digit datasets show that DNet-kNN has much\nbetter performance than large-margin kNN using a linear mapping and kNN based\non a deep autoencoder pretrained with retricted boltzmann machines.\n",
          "  In the Nonnegative Matrix Factorization (NMF) problem we are given an $n\n\\times m$ nonnegative matrix $M$ and an integer $r > 0$. Our goal is to express\n$M$ as $A W$ where $A$ and $W$ are nonnegative matrices of size $n \\times r$\nand $r \\times m$ respectively. In some applications, it makes sense to ask\ninstead for the product $AW$ to approximate $M$ -- i.e. (approximately)\nminimize $\\norm{M - AW}_F$ where $\\norm{}_F$ denotes the Frobenius norm; we\nrefer to this as Approximate NMF. This problem has a rich history spanning\nquantum mechanics, probability theory, data analysis, polyhedral combinatorics,\ncommunication complexity, demography, chemometrics, etc. In the past decade NMF\nhas become enormously popular in machine learning, where $A$ and $W$ are\ncomputed using a variety of local search heuristics. Vavasis proved that this\nproblem is NP-complete. We initiate a study of when this problem is solvable in\npolynomial time:\n  1. We give a polynomial-time algorithm for exact and approximate NMF for\nevery constant $r$. Indeed NMF is most interesting in applications precisely\nwhen $r$ is small.\n  2. We complement this with a hardness result, that if exact NMF can be solved\nin time $(nm)^{o(r)}$, 3-SAT has a sub-exponential time algorithm. This rules\nout substantial improvements to the above algorithm.\n  3. We give an algorithm that runs in time polynomial in $n$, $m$ and $r$\nunder the separablity condition identified by Donoho and Stodden in 2003. The\nalgorithm may be practical since it is simple and noise tolerant (under benign\nassumptions). Separability is believed to hold in many practical settings.\n  To the best of our knowledge, this last result is the first example of a\npolynomial-time algorithm that provably works under a non-trivial condition on\nthe input and we believe that this will be an interesting and important\ndirection for future work.\n",
          "  The performance in higher secondary school education in India is a turning\npoint in the academic lives of all students. As this academic performance is\ninfluenced by many factors, it is essential to develop predictive data mining\nmodel for students' performance so as to identify the slow learners and study\nthe influence of the dominant factors on their academic performance. In the\npresent investigation, a survey cum experimental methodology was adopted to\ngenerate a database and it was constructed from a primary and a secondary\nsource. While the primary data was collected from the regular students, the\nsecondary data was gathered from the school and office of the Chief Educational\nOfficer (CEO). A total of 1000 datasets of the year 2006 from five different\nschools in three different districts of Tamilnadu were collected. The raw data\nwas preprocessed in terms of filling up missing values, transforming values in\none form into another and relevant attribute/ variable selection. As a result,\nwe had 772 student records, which were used for CHAID prediction model\nconstruction. A set of prediction rules were extracted from CHIAD prediction\nmodel and the efficiency of the generated CHIAD prediction model was found. The\naccuracy of the present model was compared with other model and it has been\nfound to be satisfactory.\n",
          "  A nonlinear channel estimator using complex Least Square Support Vector\nMachines (LS-SVM) is proposed for pilot-aided OFDM system and applied to Long\nTerm Evolution (LTE) downlink under high mobility conditions. The estimation\nalgorithm makes use of the reference signals to estimate the total frequency\nresponse of the highly selective multipath channel in the presence of\nnon-Gaussian impulse noise interfering with pilot signals. Thus, the algorithm\nmaps trained data into a high dimensional feature space and uses the structural\nrisk minimization (SRM) principle to carry out the regression estimation for\nthe frequency response function of the highly selective channel. The\nsimulations show the effectiveness of the proposed method which has good\nperformance and high precision to track the variations of the fading channels\ncompared to the conventional LS method and it is robust at high speed mobility.\n",
          "  The two parameter Poisson-Dirichlet Process (PDP), a generalisation of the\nDirichlet Process, is increasingly being used for probabilistic modelling in\ndiscrete areas such as language technology, bioinformatics, and image analysis.\nThere is a rich literature about the PDP and its derivative distributions such\nas the Chinese Restaurant Process (CRP). This article reviews some of the basic\ntheory and then the major results needed for Bayesian modelling of discrete\nproblems including details of priors, posteriors and computation.\n  The PDP allows one to build distributions over countable partitions. The PDP\nhas two other remarkable properties: first it is partially conjugate to itself,\nwhich allows one to build hierarchies of PDPs, and second using a marginalised\nrelative the CRP, one gets fragmentation and clustering properties that lets\none layer partitions to build trees. This article presents the basic theory for\nunderstanding the notion of partitions and distributions over them, the PDP and\nthe CRP, and the important properties of conjugacy, fragmentation and\nclustering, as well as some key related properties such as consistency and\nconvergence. This article also presents a Bayesian interpretation of the\nPoisson-Dirichlet process based on an improper and infinite dimensional\nDirichlet distribution. This means we can understand the process as just\nanother Dirichlet and thus all its sampling properties emerge naturally.\n  The theory of PDPs is usually presented for continuous distributions (more\ngenerally referred to as non-atomic distributions), however, when applied to\ndiscrete distributions its remarkable conjugacy property emerges. This context\nand basic results are also presented, as well as techniques for computing the\nsecond order Stirling numbers that occur in the posteriors for discrete\ndistributions.\n",
          "  Tensor decomposition is a powerful computational tool for multiway data\nanalysis. Many popular tensor decomposition approaches---such as the Tucker\ndecomposition and CANDECOMP/PARAFAC (CP)---amount to multi-linear\nfactorization. They are insufficient to model (i) complex interactions between\ndata entities, (ii) various data types (e.g. missing data and binary data), and\n(iii) noisy observations and outliers. To address these issues, we propose\ntensor-variate latent nonparametric Bayesian models, coupled with efficient\ninference methods, for multiway data analysis. We name these models InfTucker.\nUsing these InfTucker, we conduct Tucker decomposition in an infinite feature\nspace. Unlike classical tensor decomposition models, our new approaches handle\nboth continuous and binary data in a probabilistic framework. Unlike previous\nBayesian models on matrices and tensors, our models are based on latent\nGaussian or $t$ processes with nonlinear covariance functions. To efficiently\nlearn the InfTucker from data, we develop a variational inference technique on\ntensors. Compared with classical implementation, the new technique reduces both\ntime and space complexities by several orders of magnitude. Our experimental\nresults on chemometrics and social network datasets demonstrate that our new\nmodels achieved significantly higher prediction accuracy than the most\nstate-of-art tensor decomposition\n",
          "  Machine learning approaches to multi-label document classification have to\ndate largely relied on discriminative modeling techniques such as support\nvector machines. A drawback of these approaches is that performance rapidly\ndrops off as the total number of labels and the number of labels per document\nincrease. This problem is amplified when the label frequencies exhibit the type\nof highly skewed distributions that are often observed in real-world datasets.\nIn this paper we investigate a class of generative statistical topic models for\nmulti-label documents that associate individual word tokens with different\nlabels. We investigate the advantages of this approach relative to\ndiscriminative models, particularly with respect to classification problems\ninvolving large numbers of relatively rare labels. We compare the performance\nof generative and discriminative approaches on document labeling tasks ranging\nfrom datasets with several thousand labels to datasets with tens of labels. The\nexperimental results indicate that probabilistic generative models can achieve\ncompetitive multi-label classification performance compared to discriminative\nmethods, and have advantages for datasets with many labels and skewed label\nfrequencies.\n",
          "  For the additive Gaussian noise channel with average codeword power\nconstraint, sparse superposition codes and adaptive successive decoding is\ndeveloped. Codewords are linear combinations of subsets of vectors, with the\nmessage indexed by the choice of subset. A feasible decoding algorithm is\npresented. Communication is reliable with error probability exponentially small\nfor all rates below the Shannon capacity.\n",
          "  This paper concerns the construction of tests for universal hypothesis\ntesting problems, in which the alternate hypothesis is poorly modeled and the\nobservation space is large. The mismatched universal test is a feature-based\ntechnique for this purpose. In prior work it is shown that its\nfinite-observation performance can be much better than the (optimal) Hoeffding\ntest, and good performance depends crucially on the choice of features. The\ncontributions of this paper include: 1) We obtain bounds on the number of\n\\epsilon distinguishable distributions in an exponential family. 2) This\nmotivates a new framework for feature extraction, cast as a rank-constrained\noptimization problem. 3) We obtain a gradient-based algorithm to solve the\nrank-constrained optimization problem and prove its local convergence.\n",
          "  The ability to monitor the progress of students academic performance is a\ncritical issue to the academic community of higher learning. A system for\nanalyzing students results based on cluster analysis and uses standard\nstatistical algorithms to arrange their scores data according to the level of\ntheir performance is described. In this paper, we also implemented k mean\nclustering algorithm for analyzing students result data. The model was combined\nwith the deterministic model to analyze the students results of a private\nInstitution in Nigeria which is a good benchmark to monitor the progression of\nacademic performance of students in higher Institution for the purpose of\nmaking an effective decision by the academic planners.\n",
          "  We classify digits of real-world house numbers using convolutional neural\nnetworks (ConvNets). ConvNets are hierarchical feature learning neural networks\nwhose structure is biologically inspired. Unlike many popular vision approaches\nthat are hand-designed, ConvNets can automatically learn a unique set of\nfeatures optimized for a given task. We augmented the traditional ConvNet\narchitecture by learning multi-stage features and by using Lp pooling and\nestablish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2%\nerror improvement). Furthermore, we analyze the benefits of different pooling\nmethods and multi-stage features in ConvNets. The source code and a tutorial\nare available at eblearn.sf.net.\n",
          "  We learn multiple hypotheses for related tasks under a latent hierarchical\nrelationship between tasks. We exploit the intuition that for domain\nadaptation, we wish to share classifier structure, but for multitask learning,\nwe wish to share covariance structure. Our hierarchical model is seen to\nsubsume several previously proposed multitask learning models and performs well\non three distinct real-world data sets.\n",
          "  The ability to detect weak distributed activation patterns in networks is\ncritical to several applications, such as identifying the onset of anomalous\nactivity or incipient congestion in the Internet, or faint traces of a\nbiochemical spread by a sensor network. This is a challenging problem since\nweak distributed patterns can be invisible in per node statistics as well as a\nglobal network-wide aggregate. Most prior work considers situations in which\nthe activation/non-activation of each node is statistically independent, but\nthis is unrealistic in many problems. In this paper, we consider structured\npatterns arising from statistical dependencies in the activation process. Our\ncontributions are three-fold. First, we propose a sparsifying transform that\nsuccinctly represents structured activation patterns that conform to a\nhierarchical dependency graph. Second, we establish that the proposed transform\nfacilitates detection of very weak activation patterns that cannot be detected\nwith existing methods. Third, we show that the structure of the hierarchical\ndependency graph governing the activation process, and hence the network\ntransform, can be learnt from very few (logarithmic in network size)\nindependent snapshots of network activity.\n",
          "  Gaussian belief propagation (GaBP) is an iterative message-passing algorithm\nfor inference in Gaussian graphical models. It is known that when GaBP\nconverges it converges to the correct MAP estimate of the Gaussian random\nvector and simple sufficient conditions for its convergence have been\nestablished. In this paper we develop a double-loop algorithm for forcing\nconvergence of GaBP. Our method computes the correct MAP estimate even in cases\nwhere standard GaBP would not have converged. We further extend this\nconstruction to compute least-squares solutions of over-constrained linear\nsystems. We believe that our construction has numerous applications, since the\nGaBP algorithm is linked to solution of linear systems of equations, which is a\nfundamental problem in computer science and engineering. As a case study, we\ndiscuss the linear detection problem. We show that using our new construction,\nwe are able to force convergence of Montanari's linear detection algorithm, in\ncases where it would originally fail. As a consequence, we are able to increase\nsignificantly the number of users that can transmit concurrently.\n",
          "  We study the tracking problem, namely, estimating the hidden state of an\nobject over time, from unreliable and noisy measurements. The standard\nframework for the tracking problem is the generative framework, which is the\nbasis of solutions such as the Bayesian algorithm and its approximation, the\nparticle filters. However, the problem with these solutions is that they are\nvery sensitive to model mismatches. In this paper, motivated by online\nlearning, we introduce a new framework -- an {\\em explanatory} framework -- for\ntracking. We provide an efficient tracking algorithm for this framework. We\nprovide experimental results comparing our algorithm to the Bayesian algorithm\non simulated data. Our experiments show that when there are slight model\nmismatches, our algorithm vastly outperforms the Bayesian algorithm.\n",
          "  The purpose of this note is to show how the method of maximum entropy in the\nmean (MEM) may be used to improve parametric estimation when the measurements\nare corrupted by large level of noise. The method is developed in the context\non a concrete example: that of estimation of the parameter in an exponential\ndistribution. We compare the performance of our method with the bayesian and\nmaximum likelihood approaches.\n",
          "  We introduce an algorithm that, given n objects, learns a similarity matrix\nover all n^2 pairs, from crowdsourced data alone. The algorithm samples\nresponses to adaptively chosen triplet-based relative-similarity queries. Each\nquery has the form \"is object 'a' more similar to 'b' or to 'c'?\" and is chosen\nto be maximally informative given the preceding responses. The output is an\nembedding of the objects into Euclidean space (like MDS); we refer to this as\nthe \"crowd kernel.\" SVMs reveal that the crowd kernel captures prominent and\nsubtle features across a number of domains, such as \"is striped\" among neckties\nand \"vowel vs. consonant\" among letters.\n",
          "  We tackle the problem of multi-class relational sequence learning using\nrelevant patterns discovered from a set of labelled sequences. To deal with\nthis problem, firstly each relational sequence is mapped into a feature vector\nusing the result of a feature construction method. Since, the efficacy of\nsequence learning algorithms strongly depends on the features used to represent\nthe sequences, the second step is to find an optimal subset of the constructed\nfeatures leading to high classification accuracy. This feature selection task\nhas been solved adopting a wrapper approach that uses a stochastic local search\nalgorithm embedding a naive Bayes classifier. The performance of the proposed\nmethod applied to a real-world dataset shows an improvement when compared to\nother established methods, such as hidden Markov models, Fisher kernels and\nconditional random fields for relational sequences.\n",
          "  We prove existence and uniqueness of the minimizer for the average geodesic\ndistance to the points of a geodesically convex set on the sphere. This implies\na corresponding existence and uniqueness result for an optimal algorithm for\nhalfspace learning, when data and target functions are drawn from the uniform\ndistribution.\n",
          "  Bayesian structure learning is the NP-hard problem of discovering a Bayesian\nnetwork that optimally represents a given set of training data. In this paper\nwe study the computational worst-case complexity of exact Bayesian structure\nlearning under graph theoretic restrictions on the super-structure. The\nsuper-structure (a concept introduced by Perrier, Imoto, and Miyano, JMLR 2008)\nis an undirected graph that contains as subgraphs the skeletons of solution\nnetworks. Our results apply to several variants of score-based Bayesian\nstructure learning where the score of a network decomposes into local scores of\nits nodes. Results: We show that exact Bayesian structure learning can be\ncarried out in non-uniform polynomial time if the super-structure has bounded\ntreewidth and in linear time if in addition the super-structure has bounded\nmaximum degree. We complement this with a number of hardness results. We show\nthat both restrictions (treewidth and degree) are essential and cannot be\ndropped without loosing uniform polynomial time tractability (subject to a\ncomplexity-theoretic assumption). Furthermore, we show that the restrictions\nremain essential if we do not search for a globally optimal network but we aim\nto improve a given network by means of at most k arc additions, arc deletions,\nor arc reversals (k-neighborhood local search).\n",
          "  We consider the problem of optimizing the sum of a smooth convex function and\na non-smooth convex function using proximal-gradient methods, where an error is\npresent in the calculation of the gradient of the smooth term or in the\nproximity operator with respect to the non-smooth term. We show that both the\nbasic proximal-gradient method and the accelerated proximal-gradient method\nachieve the same convergence rate as in the error-free case, provided that the\nerrors decrease at appropriate rates.Using these rates, we perform as well as\nor better than a carefully chosen fixed error level on a set of structured\nsparsity problems.\n",
          "  India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved.\n",
          "  Most generalization bounds in learning theory are based on some measure of\nthe complexity of the hypothesis class used, independently of any algorithm. In\ncontrast, the notion of algorithmic stability can be used to derive tight\ngeneralization bounds that are tailored to specific learning algorithms by\nexploiting their particular properties. However, as in much of learning theory,\nexisting stability analyses and bounds apply only in the scenario where the\nsamples are independently and identically distributed. In many machine learning\napplications, however, this assumption does not hold. The observations received\nby the learning algorithm often have some inherent temporal dependence.\n  This paper studies the scenario where the observations are drawn from a\nstationary phi-mixing or beta-mixing sequence, a widely adopted assumption in\nthe study of non-i.i.d. processes that implies a dependence between\nobservations weakening over time. We prove novel and distinct stability-based\ngeneralization bounds for stationary phi-mixing and beta-mixing sequences.\nThese bounds strictly generalize the bounds given in the i.i.d. case and apply\nto all stable learning algorithms, thereby extending the use of\nstability-bounds to non-i.i.d. scenarios.\n  We also illustrate the application of our phi-mixing generalization bounds to\ngeneral classes of learning algorithms, including Support Vector Regression,\nKernel Ridge Regression, and Support Vector Machines, and many other kernel\nregularization-based and relative entropy-based regularization algorithms.\nThese novel bounds can thus be viewed as the first theoretical basis for the\nuse of these algorithms in non-i.i.d. scenarios.\n",
          "  The decision boundaries of Bayes classifier are optimal because they lead to\nmaximum probability of correct decision. It means if we knew the prior\nprobabilities and the class-conditional densities, we could design a classifier\nwhich gives the lowest probability of error. However, in classification based\non nonparametric density estimation methods such as Parzen windows, the\ndecision regions depend on the choice of parameters such as window width.\nMoreover, these methods suffer from curse of dimensionality of the feature\nspace and small sample size problem which severely restricts their practical\napplications. In this paper, we address these problems by introducing a novel\ndimension reduction and classification method based on local component\nanalysis. In this method, by adopting an iterative cross-validation algorithm,\nwe simultaneously estimate the optimal transformation matrices (for dimension\nreduction) and classifier parameters based on local information. The proposed\nmethod can classify the data with complicated boundary and also alleviate the\ncourse of dimensionality dilemma. Experiments on real data show the superiority\nof the proposed algorithm in term of classification accuracies for pattern\nclassification applications like age, facial expression and character\nrecognition. Keywords: Bayes classifier, curse of dimensionality dilemma,\nParzen window, pattern classification, subspace learning.\n",
          "  We give polynomial-time algorithms for the exact computation of lowest-energy\n(ground) states, worst margin violators, log partition functions, and marginal\nedge probabilities in certain binary undirected graphical models. Our approach\nprovides an interesting alternative to the well-known graph cut paradigm in\nthat it does not impose any submodularity constraints; instead we require\nplanarity to establish a correspondence with perfect matchings (dimer\ncoverings) in an expanded dual graph. We implement a unified framework while\ndelegating complex but well-understood subproblems (planar embedding,\nmaximum-weight perfect matching) to established algorithms for which efficient\nimplementations are freely available. Unlike graph cut methods, we can perform\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\nthe associated conditional random fields (CRFs), and employ marginal posterior\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\nMaximum-margin CRF parameter estimation on image denoising and segmentation\nproblems shows our approach to be efficient and effective. A C++ implementation\nis available from http://nic.schraudolph.org/isinf/\n",
          "  Networks are ubiquitous in science and have become a focal point for\ndiscussion in everyday life. Formal statistical models for the analysis of\nnetwork data have emerged as a major topic of interest in diverse areas of\nstudy, and most of these involve a form of graphical representation.\nProbability models on graphs date back to 1959. Along with empirical studies in\nsocial psychology and sociology from the 1960s, these early works generated an\nactive network community and a substantial literature in the 1970s. This effort\nmoved into the statistical literature in the late 1970s and 1980s, and the past\ndecade has seen a burgeoning network literature in statistical physics and\ncomputer science. The growth of the World Wide Web and the emergence of online\nnetworking communities such as Facebook, MySpace, and LinkedIn, and a host of\nmore specialized professional network communities has intensified interest in\nthe study of networks and network data. Our goal in this review is to provide\nthe reader with an entry point to this burgeoning literature. We begin with an\noverview of the historical development of statistical network modeling and then\nwe introduce a number of examples that have been studied in the network\nliterature. Our subsequent discussion focuses on a number of prominent static\nand dynamic network models and their interconnections. We emphasize formal\nmodel descriptions, and pay special attention to the interpretation of\nparameters and their estimation. We end with a description of some open\nproblems and challenges for machine learning and statistics.\n",
          "  We introduce algorithmic information theory, also known as the theory of\nKolmogorov complexity. We explain the main concepts of this quantitative\napproach to defining `information'. We discuss the extent to which Kolmogorov's\nand Shannon's information theory have a common purpose, and where they are\nfundamentally different. We indicate how recent developments within the theory\nallow one to formally distinguish between `structural' (meaningful) and\n`random' information as measured by the Kolmogorov structure function, which\nleads to a mathematical formalization of Occam's razor in inductive inference.\nWe end by discussing some of the philosophical implications of the theory.\n",
          "  We present a method for estimating pose information from a single depth image\ngiven an arbitrary kinematic structure without prior training. For an arbitrary\nskeleton and depth image, an evolutionary algorithm is used to find the optimal\nkinematic configuration to explain the observed image. Results show that our\napproach can correctly estimate poses of 39 and 78 degree-of-freedom models\nfrom a single depth image, even in cases of significant self-occlusion.\n",
          "  The recent increase in dimensionality of data has thrown a great challenge to\nthe existing dimensionality reduction methods in terms of their effectiveness.\nDimensionality reduction has emerged as one of the significant preprocessing\nsteps in machine learning applications and has been effective in removing\ninappropriate data, increasing learning accuracy, and improving\ncomprehensibility. Feature redundancy exercises great influence on the\nperformance of classification process. Towards the better classification\nperformance, this paper addresses the usefulness of truncating the highly\ncorrelated and redundant attributes. Here, an effort has been made to verify\nthe utility of dimensionality reduction by applying LVQ (Learning Vector\nQuantization) method on two Benchmark datasets of 'Pima Indian Diabetic\npatients' and 'Lung cancer patients'.\n",
          "  Distributions over rankings are used to model data in various settings such\nas preference analysis and political elections. The factorial size of the space\nof rankings, however, typically forces one to make structural assumptions, such\nas smoothness, sparsity, or probabilistic independence about these underlying\ndistributions. We approach the modeling problem from the computational\nprinciple that one should make structural assumptions which allow for efficient\ncalculation of typical probabilistic queries. For ranking models, \"typical\"\nqueries predominantly take the form of partial ranking queries (e.g., given a\nuser's top-k favorite movies, what are his preferences over remaining movies?).\nIn this paper, we argue that riffled independence factorizations proposed in\nrecent literature [7, 8] are a natural structural assumption for ranking\ndistributions, allowing for particularly efficient processing of partial\nranking queries.\n",
          "  We show how rate-distortion theory provides a mechanism for automated theory\nbuilding by naturally distinguishing between regularity and randomness. We\nstart from the simple principle that model variables should, as much as\npossible, render the future and past conditionally independent. From this, we\nconstruct an objective function for model making whose extrema embody the\ntrade-off between a model's structural complexity and its predictive power. The\nsolutions correspond to a hierarchy of models that, at each level of\ncomplexity, achieve optimal predictive power at minimal cost. In the limit of\nmaximal prediction the resulting optimal model identifies a process's intrinsic\norganization by extracting the underlying causal states. In this limit, the\nmodel's complexity is given by the statistical complexity, which is known to be\nminimal for achieving maximum prediction. Examples show how theory building can\nprofit from analyzing a process's causal compressibility, which is reflected in\nthe optimal models' rate-distortion curve--the process's characteristic for\noptimally balancing structure and noise at different levels of representation.\n",
          "  Calibrated strategies can be obtained by performing strategies that have no\ninternal regret in some auxiliary game. Such strategies can be constructed\nexplicitly with the use of Blackwell's approachability theorem, in an other\nauxiliary game. We establish the converse: a strategy that approaches a convex\n$B$-set can be derived from the construction of a calibrated strategy. We\ndevelop these tools in the framework of a game with partial monitoring, where\nplayers do not observe the actions of their opponents but receive random\nsignals, to define a notion of internal regret and construct strategies that\nhave no such regret.\n",
          "  For classification problems, feature extraction is a crucial process which\naims to find a suitable data representation that increases the performance of\nthe machine learning algorithm. According to the curse of dimensionality\ntheorem, the number of samples needed for a classification task increases\nexponentially as the number of dimensions (variables, features) increases. On\nthe other hand, it is costly to collect, store and process data. Moreover,\nirrelevant and redundant features might hinder classifier performance. In\nexploratory analysis settings, high dimensionality prevents the users from\nexploring the data visually. Feature extraction is a two-step process: feature\nconstruction and feature selection. Feature construction creates new features\nbased on the original features and feature selection is the process of\nselecting the best features as in filter, wrapper and embedded methods.\n  In this work, we focus on feature construction methods that aim to decrease\ndata dimensionality for visualization tasks. Various linear (such as principal\ncomponents analysis (PCA), multiple discriminants analysis (MDA), exploratory\nprojection pursuit) and non-linear (such as multidimensional scaling (MDS),\nmanifold learning, kernel PCA/LDA, evolutionary constructive induction)\ntechniques have been proposed for dimensionality reduction. Our algorithm is an\nadaptive feature extraction method which consists of evolutionary constructive\ninduction for feature construction and a hybrid filter/wrapper method for\nfeature selection.\n",
          "  The problem of content search through comparisons has recently received\nconsiderable attention. In short, a user searching for a target object\nnavigates through a database in the following manner: the user is asked to\nselect the object most similar to her target from a small list of objects. A\nnew object list is then presented to the user based on her earlier selection.\nThis process is repeated until the target is included in the list presented, at\nwhich point the search terminates. This problem is known to be strongly related\nto the small-world network design problem.\n  However, contrary to prior work, which focuses on cases where objects in the\ndatabase are equally popular, we consider here the case where the demand for\nobjects may be heterogeneous. We show that, under heterogeneous demand, the\nsmall-world network design problem is NP-hard. Given the above negative result,\nwe propose a novel mechanism for small-world design and provide an upper bound\non its performance under heterogeneous demand. The above mechanism has a\nnatural equivalent in the context of content search through comparisons, and we\nestablish both an upper bound and a lower bound for the performance of this\nmechanism. These bounds are intuitively appealing, as they depend on the\nentropy of the demand as well as its doubling constant, a quantity capturing\nthe topology of the set of target objects. They also illustrate interesting\nconnections between comparison-based search to classic results from information\ntheory. Finally, we propose an adaptive learning algorithm for content search\nthat meets the performance guarantees achieved by the above mechanisms.\n",
          "  In this paper, we have established a new framework of truncated inverse\nsampling for estimating mean values of non-negative random variables such as\nbinomial, Poisson, hyper-geometrical, and bounded variables. We have derived\nexplicit formulas and computational methods for designing sampling schemes to\nensure prescribed levels of precision and confidence for point estimators.\nMoreover, we have developed interval estimation methods.\n",
          "  We consider the problem of learning classifiers for labeled data that has\nbeen distributed across several nodes. Our goal is to find a single classifier,\nwith small approximation error, across all datasets while minimizing the\ncommunication between nodes. This setting models real-world communication\nbottlenecks in the processing of massive distributed datasets. We present\nseveral very general sampling-based solutions as well as some two-way protocols\nwhich have a provable exponential speed-up over any one-way protocol. We focus\non core problems for noiseless data distributed across two or more nodes. The\ntechniques we introduce are reminiscent of active learning, but rather than\nactively probing labels, nodes actively communicate with each other, each node\nsimultaneously learning the important data from another node.\n",
          "  Causality is a non-obvious concept that is often considered to be related to\ntemporality. In this paper we present a number of past and present approaches\nto the definition of temporality and causality from philosophical, physical,\nand computational points of view. We note that time is an important ingredient\nin many relationships and phenomena. The topic is then divided into the two\nmain areas of temporal discovery, which is concerned with finding relations\nthat are stretched over time, and causal discovery, where a claim is made as to\nthe causal influence of certain events on others. We present a number of\ncomputational tools used for attempting to automatically discover temporal and\ncausal relations in data.\n",
          "  We consider regularized support vector machines (SVMs) and show that they are\nprecisely equivalent to a new robust optimization formulation. We show that\nthis equivalence of robust optimization and regularization has implications for\nboth algorithms, and analysis. In terms of algorithms, the equivalence suggests\nmore general SVM-like algorithms for classification that explicitly build in\nprotection to noise, and at the same time control overfitting. On the analysis\nfront, the equivalence of robustness and regularization, provides a robust\noptimization interpretation for the success of regularized SVMs. We use the\nthis new robustness interpretation of SVMs to give a new proof of consistency\nof (kernelized) SVMs, thus establishing robustness as the reason regularized\nSVMs generalize well.\n",
          "  In the supervised learning setting termed Multiple-Instance Learning (MIL),\nthe examples are bags of instances, and the bag label is a function of the\nlabels of its instances. Typically, this function is the Boolean OR. The\nlearner observes a sample of bags and the bag labels, but not the instance\nlabels that determine the bag labels. The learner is then required to emit a\nclassification rule for bags based on the sample. MIL has numerous\napplications, and many heuristic algorithms have been used successfully on this\nproblem, each adapted to specific settings or applications. In this work we\nprovide a unified theoretical analysis for MIL, which holds for any underlying\nhypothesis class, regardless of a specific application or problem domain. We\nshow that the sample complexity of MIL is only poly-logarithmically dependent\non the size of the bag, for any underlying hypothesis class. In addition, we\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\ncan be generated from any efficient non-MIL supervised learning algorithm that\nhandles one-sided error. The computational complexity of the resulting\nalgorithm is only polynomially dependent on the bag size.\n",
          "  We propose a unified framework for deriving and studying soft-in-soft-out\n(SISO) detection in interference channels using the concept of variational\ninference. The proposed framework may be used in multiple-access interference\n(MAI), inter-symbol interference (ISI), and multiple-input multiple-outpu\n(MIMO) channels. Without loss of generality, we will focus our attention on\nturbo multiuser detection, to facilitate a more concrete discussion. It is\nshown that, with some loss of optimality, variational inference avoids the\nexponential complexity of a posteriori probability (APP) detection by\noptimizing a closely-related, but much more manageable, objective function\ncalled variational free energy. In addition to its systematic appeal, there are\nseveral other advantages to this viewpoint. First of all, it provides unified\nand rigorous justifications for numerous detectors that were proposed on\nradically different grounds, and facilitates convenient joint detection and\ndecoding (utilizing the turbo principle) when error-control codes are\nincorporated. Secondly, efficient joint parameter estimation and data detection\nis possible via the variational expectation maximization (EM) algorithm, such\nthat the detrimental effect of inaccurate channel knowledge at the receiver may\nbe dealt with systematically. We are also able to extend BPSK-based SISO\ndetection schemes to arbitrary square QAM constellations in a rigorous manner\nusing a variational argument.\n",
          "  Sequence optimization, where the items in a list are ordered to maximize some\nreward has many applications such as web advertisement placement, search, and\ncontrol libraries in robotics. Previous work in sequence optimization produces\na static ordering that does not take any features of the item or context of the\nproblem into account. In this work, we propose a general approach to order the\nitems within the sequence based on the context (e.g., perceptual information,\nenvironment description, and goals). We take a simple, efficient,\nreduction-based approach where the choice and order of the items is established\nby repeatedly learning simple classifiers or regressors for each \"slot\" in the\nsequence. Our approach leverages recent work on submodular function\nmaximization to provide a formal regret reduction from submodular sequence\noptimization to simple cost-sensitive prediction. We apply our contextual\nsequence prediction algorithm to optimize control libraries and demonstrate\nresults on two robotics problems: manipulator trajectory prediction and mobile\nrobot path planning.\n",
          "  This paper introduces the Furthest Hyperplane Problem (FHP), which is an\nunsupervised counterpart of Support Vector Machines. Given a set of n points in\nRd, the objective is to produce the hyperplane (passing through the origin)\nwhich maximizes the separation margin, that is, the minimal distance between\nthe hyperplane and any input point. To the best of our knowledge, this is the\nfirst paper achieving provable results regarding FHP. We provide both lower and\nupper bounds to this NP-hard problem. First, we give a simple randomized\nalgorithm whose running time is n^O(1/{\\theta}^2) where {\\theta} is the optimal\nseparation margin. We show that its exponential dependency on 1/{\\theta}^2 is\ntight, up to sub-polynomial factors, assuming SAT cannot be solved in\nsub-exponential time. Next, we give an efficient approxima- tion algorithm. For\nany {\\alpha} \\in [0, 1], the algorithm produces a hyperplane whose distance\nfrom at least 1 - 5{\\alpha} fraction of the points is at least {\\alpha} times\nthe optimal separation margin. Finally, we show that FHP does not admit a PTAS\nby presenting a gap preserving reduction from a particular version of the PCP\ntheorem.\n",
          "  Given a random binary sequence $X^{(n)}$ of random variables, $X_{t},$\n$t=1,2,...,n$, for instance, one that is generated by a Markov source (teacher)\nof order $k^{*}$ (each state represented by $k^{*}$ bits). Assume that the\nprobability of the event $X_{t}=1$ is constant and denote it by $\\beta$.\nConsider a learner which is based on a parametric model, for instance a Markov\nmodel of order $k$, who trains on a sequence $x^{(m)}$ which is randomly drawn\nby the teacher. Test the learner's performance by giving it a sequence\n$x^{(n)}$ (generated by the teacher) and check its predictions on every bit of\n$x^{(n)}.$ An error occurs at time $t$ if the learner's prediction $Y_{t}$\ndiffers from the true bit value $X_{t}$. Denote by $\\xi^{(n)}$ the sequence of\nerrors where the error bit $\\xi_{t}$ at time $t$ equals 1 or 0 according to\nwhether the event of an error occurs or not, respectively. Consider the\nsubsequence $\\xi^{(\\nu)}$ of $\\xi^{(n)}$ which corresponds to the errors of\npredicting a 0, i.e., $\\xi^{(\\nu)}$ consists of the bits of $\\xi^{(n)}$ only at\ntimes $t$ such that $Y_{t}=0.$ In this paper we compute an estimate on the\ndeviation of the frequency of 1s of $\\xi^{(\\nu)}$ from $\\beta$. The result\nshows that the level of randomness of $\\xi^{(\\nu)}$ decreases relative to an\nincrease in the complexity of the learner.\n",
          "  This paper is withdrawn due to some errors, which are corrected in\narXiv:0912.0071v4 [cs.LG].\n",
          "  Regularized risk minimization with the binary hinge loss and its variants\nlies at the heart of many machine learning problems. Bundle methods for\nregularized risk minimization (BMRM) and the closely related SVMStruct are\nconsidered the best general purpose solvers to tackle this problem. It was\nrecently shown that BMRM requires $O(1/\\epsilon)$ iterations to converge to an\n$\\epsilon$ accurate solution. In the first part of the paper we use the\nHadamard matrix to construct a regularized risk minimization problem and show\nthat these rates cannot be improved. We then show how one can exploit the\nstructure of the objective function to devise an algorithm for the binary hinge\nloss which converges to an $\\epsilon$ accurate solution in\n$O(1/\\sqrt{\\epsilon})$ iterations.\n",
          "  Learning structured representations has emerged as an important problem in\nmany domains, including document and Web data mining, bioinformatics, and image\nanalysis. One approach to learning complex structures is to integrate many\nsmaller, incomplete and noisy structure fragments. In this work, we present an\nunsupervised probabilistic approach that extends affinity propagation to\ncombine the small ontological fragments into a collection of integrated,\nconsistent, and larger folksonomies. This is a challenging task because the\nmethod must aggregate similar structures while avoiding structural\ninconsistencies and handling noise. We validate the approach on a real-world\nsocial media dataset, comprised of shallow personal hierarchies specified by\nmany individual users, collected from the photosharing website Flickr. Our\nempirical results show that our proposed approach is able to construct deeper\nand denser structures, compared to an approach using only the standard affinity\npropagation algorithm. Additionally, the approach yields better overall\nintegration quality than a state-of-the-art approach based on incremental\nrelational clustering.\n",
          "  Motivated by the amount of code that goes unidentified on the web, we\nintroduce a practical method for algorithmically identifying the programming\nlanguage of source code. Our work is based on supervised learning and\nintelligent statistical features. We also explored, but abandoned, a\ngrammatical approach. In testing, our implementation greatly outperforms that\nof an existing tool that relies on a Bayesian classifier. Code is written in\nPython and available under an MIT license.\n",
          "  Separation of the sources and analysis of their connectivity have been an\nimportant topic in EEG/MEG analysis. To solve this problem in an automatic\nmanner, we propose a two-layer model, in which the sources are conditionally\nuncorrelated from each other, but not independent; the dependence is caused by\nthe causality in their time-varying variances (envelopes). The model is\nidentified in two steps. We first propose a new source separation technique\nwhich takes into account the autocorrelations (which may be time-varying) and\ntime-varying variances of the sources. The causality in the envelopes is then\ndiscovered by exploiting a special kind of multivariate GARCH (generalized\nautoregressive conditional heteroscedasticity) model. The resulting causal\ndiagram gives the effective connectivity between the separated sources; in our\nexperimental results on MEG data, sources with similar functions are grouped\ntogether, with negative influences between groups, and the groups are connected\nvia some interesting sources.\n",
          "  This paper develops generalizations of empowerment to continuous states.\nEmpowerment is a recently introduced information-theoretic quantity motivated\nby hypotheses about the efficiency of the sensorimotor loop in biological\norganisms, but also from considerations stemming from curiosity-driven\nlearning. Empowemerment measures, for agent-environment systems with stochastic\ntransitions, how much influence an agent has on its environment, but only that\ninfluence that can be sensed by the agent sensors. It is an\ninformation-theoretic generalization of joint controllability (influence on\nenvironment) and observability (measurement by sensors) of the environment by\nthe agent, both controllability and observability being usually defined in\ncontrol theory as the dimensionality of the control/observation spaces. Earlier\nwork has shown that empowerment has various interesting and relevant\nproperties, e.g., it allows us to identify salient states using only the\ndynamics, and it can act as intrinsic reward without requiring an external\nreward. However, in this previous work empowerment was limited to the case of\nsmall-scale and discrete domains and furthermore state transition probabilities\nwere assumed to be known. The goal of this paper is to extend empowerment to\nthe significantly more important and relevant case of continuous vector-valued\nstate spaces and initially unknown state transition probabilities. The\ncontinuous state space is addressed by Monte-Carlo approximation; the unknown\ntransitions are addressed by model learning and prediction for which we apply\nGaussian processes regression with iterated forecasting. In a number of\nwell-known continuous control tasks we examine the dynamics induced by\nempowerment and include an application to exploration and online model\nlearning.\n",
          "  Contextual bandit algorithms have become popular for online recommendation\nsystems such as Digg, Yahoo! Buzz, and news recommendation in general.\n\\emph{Offline} evaluation of the effectiveness of new algorithms in these\napplications is critical for protecting online user experiences but very\nchallenging due to their \"partial-label\" nature. Common practice is to create a\nsimulator which simulates the online environment for the problem at hand and\nthen run an algorithm against this simulator. However, creating simulator\nitself is often difficult and modeling bias is usually unavoidably introduced.\nIn this paper, we introduce a \\emph{replay} methodology for contextual bandit\nalgorithm evaluation. Different from simulator-based approaches, our method is\ncompletely data-driven and very easy to adapt to different applications. More\nimportantly, our method can provide provably unbiased evaluations. Our\nempirical results on a large-scale news article recommendation dataset\ncollected from Yahoo! Front Page conform well with our theoretical results.\nFurthermore, comparisons between our offline replay and online bucket\nevaluation of several contextual bandit algorithms show accuracy and\neffectiveness of our offline evaluation method.\n",
          "  We consider multi-label prediction problems with large output spaces under\nthe assumption of output sparsity -- that the target (label) vectors have small\nsupport. We develop a general theory for a variant of the popular error\ncorrecting output code scheme, using ideas from compressed sensing for\nexploiting this sparsity. The method can be regarded as a simple reduction from\nmulti-label regression problems to binary regression problems. We show that the\nnumber of subproblems need only be logarithmic in the total number of possible\nlabels, making this approach radically more efficient than others. We also\nstate and prove robustness guarantees for this method in the form of regret\ntransform bounds (in general), and also provide a more detailed analysis for\nthe linear prediction setting.\n",
          "  In this paper we address an issue that has been brought to the attention of\nthe database community with the advent of the Semantic Web, i.e. the issue of\nhow ontologies (and semantics conveyed by them) can help solving typical\ndatabase problems, through a better understanding of KR aspects related to\ndatabases. In particular, we investigate this issue from the ILP perspective by\nconsidering two database problems, (i) the definition of views and (ii) the\ndefinition of constraints, for a database whose schema is represented also by\nmeans of an ontology. Both can be reformulated as ILP problems and can benefit\nfrom the expressive and deductive power of the KR framework DL+log. We\nillustrate the application scenarios by means of examples. Keywords: Inductive\nLogic Programming, Relational Databases, Ontologies, Description Logics, Hybrid\nKnowledge Representation and Reasoning Systems. Note: To appear in Theory and\nPractice of Logic Programming (TPLP).\n",
          "  This paper has been withdrawn due to an error found by Dana Angluin and Lev\nReyzin.\n",
          "  This paper describes a methodology for detecting anomalies from sequentially\nobserved and potentially noisy data. The proposed approach consists of two main\nelements: (1) {\\em filtering}, or assigning a belief or likelihood to each\nsuccessive measurement based upon our ability to predict it from previous noisy\nobservations, and (2) {\\em hedging}, or flagging potential anomalies by\ncomparing the current belief against a time-varying and data-adaptive\nthreshold. The threshold is adjusted based on the available feedback from an\nend user. Our algorithms, which combine universal prediction with recent work\non online convex programming, do not require computing posterior distributions\ngiven all current observations and involve simple primal-dual parameter\nupdates. At the heart of the proposed approach lie exponential-family models\nwhich can be used in a wide variety of contexts and applications, and which\nyield methods that achieve sublinear per-round regret against both static and\nslowly varying product distributions with marginals drawn from the same\nexponential family. Moreover, the regret against static distributions coincides\nwith the minimax value of the corresponding online strongly convex game. We\nalso prove bounds on the number of mistakes made during the hedging step\nrelative to the best offline choice of the threshold with access to all\nestimated beliefs and feedback signals. We validate the theory on synthetic\ndata drawn from a time-varying distribution over binary vectors of high\ndimensionality, as well as on the Enron email dataset.\n",
          "  In the current competitive world, industrial companies seek to manufacture\nproducts of higher quality which can be achieved by increasing reliability,\nmaintainability and thus the availability of products. On the other hand,\nimprovement in products lifecycle is necessary for achieving high reliability.\nTypically, maintenance activities are aimed to reduce failures of industrial\nmachinery and minimize the consequences of such failures. So the industrial\ncompanies try to improve their efficiency by using different fault detection\ntechniques. One strategy is to process and analyze previous generated data to\npredict future failures. The purpose of this paper is to detect wasted parts\nusing different data mining algorithms and compare the accuracy of these\nalgorithms. A combination of thermal and physical characteristics has been used\nand the algorithms were implemented on Ahanpishegan's current data to estimate\nthe availability of its produced parts.\n  Keywords: Data Mining, Fault Detection, Availability, Prediction Algorithms.\n",
          "  In this paper, we show a connection between a certain online low-congestion\nrouting problem and an online prediction of graph labeling. More specifically,\nwe prove that if there exists a routing scheme that guarantees a congestion of\n$\\alpha$ on any edge, there exists an online prediction algorithm with mistake\nbound $\\alpha$ times the cut size, which is the size of the cut induced by the\nlabel partitioning of graph vertices. With previous known bound of $O(\\log n)$\nfor $\\alpha$ for the routing problem on trees with $n$ vertices, we obtain an\nimproved prediction algorithm for graphs with high effective resistance.\n  In contrast to previous approaches that move the graph problem into problems\nin vector space using graph Laplacian and rely on the analysis of the\nperceptron algorithm, our proof are purely combinatorial. Further more, our\napproach directly generalizes to the case where labels are not binary.\n",
          "  The ability of a classifier to take on new information and classes by\nevolving the classifier without it having to be fully retrained is known as\nincremental learning. Incremental learning has been successfully applied to\nmany classification problems, where the data is changing and is not all\navailable at once. In this paper there is a comparison between Learn++, which\nis one of the most recent incremental learning algorithms, and the new proposed\nmethod of Incremental Learning Using Genetic Algorithm (ILUGA). Learn++ has\nshown good incremental learning capabilities on benchmark datasets on which the\nnew ILUGA method has been tested. ILUGA has also shown good incremental\nlearning ability using only a few classifiers and does not suffer from\ncatastrophic forgetting. The results obtained for ILUGA on the Optical\nCharacter Recognition (OCR) and Wine datasets are good, with an overall\naccuracy of 93% and 94% respectively showing a 4% improvement over Learn++.MT\nfor the difficult multi-class OCR dataset.\n",
          "  Personalized web services strive to adapt their services (advertisements,\nnews articles, etc) to individual users by making use of both content and user\ninformation. Despite a few recent advances, this problem remains challenging\nfor at least two reasons. First, web service is featured with dynamically\nchanging pools of content, rendering traditional collaborative filtering\nmethods inapplicable. Second, the scale of most web services of practical\ninterest calls for solutions that are both fast in learning and computation.\n  In this work, we model personalized recommendation of news articles as a\ncontextual bandit problem, a principled approach in which a learning algorithm\nsequentially selects articles to serve users based on contextual information\nabout the users and articles, while simultaneously adapting its\narticle-selection strategy based on user-click feedback to maximize total user\nclicks.\n  The contributions of this work are three-fold. First, we propose a new,\ngeneral contextual bandit algorithm that is computationally efficient and well\nmotivated from learning theory. Second, we argue that any bandit algorithm can\nbe reliably evaluated offline using previously recorded random traffic.\nFinally, using this offline evaluation method, we successfully applied our new\nalgorithm to a Yahoo! Front Page Today Module dataset containing over 33\nmillion events. Results showed a 12.5% click lift compared to a standard\ncontext-free bandit algorithm, and the advantage becomes even greater when data\ngets more scarce.\n",
          "  Recognition systems are commonly designed to authenticate users at the access\ncontrol levels of a system. A number of voice recognition methods have been\ndeveloped using a pitch estimation process which are very vulnerable in low\nSignal to Noise Ratio (SNR) environments thus, these programs fail to provide\nthe desired level of accuracy and robustness. Also, most text independent\nspeaker recognition programs are incapable of coping with unauthorized attempts\nto gain access by tampering with the samples or reference database. The\nproposed text-independent voice recognition system makes use of multilevel\ncryptography to preserve data integrity while in transit or storage. Encryption\nand decryption follow a transform based approach layered with pseudorandom\nnoise addition whereas for pitch detection, a modified version of the\nautocorrelation pitch extraction algorithm is used. The experimental results\nshow that the proposed algorithm can decrypt the signal under test with\nexponentially reducing Mean Square Error over an increasing range of SNR.\nFurther, it outperforms the conventional algorithms in actual identification\ntasks even in noisy environments. The recognition rate thus obtained using the\nproposed method is compared with other conventional methods used for speaker\nidentification.\n",
          "  This paper addresses the pattern classification problem arising when\navailable target data include some uncertainty information. Target data\nconsidered here is either qualitative (a class label) or quantitative (an\nestimation of the posterior probability). Our main contribution is a SVM\ninspired formulation of this problem allowing to take into account class label\nthrough a hinge loss as well as probability estimates using epsilon-insensitive\ncost function together with a minimum norm (maximum margin) objective. This\nformulation shows a dual form leading to a quadratic problem and allows the use\nof a representer theorem and associated kernel. The solution provided can be\nused for both decision and posterior probability estimation. Based on empirical\nevidence our method outperforms regular SVM in terms of probability predictions\nand classification performances.\n",
          "  Although the Music Sight Reading process has been studied from the cognitive\npsychology view points, but the computational learning methods like the\nReinforcement Learning have not yet been used to modeling of such processes. In\nthis paper, with regards to essential properties of our specific problem, we\nconsider the value function concept and will indicate that the optimum policy\ncan be obtained by the method we offer without to be getting involved with\ncomputing of the complex value functions. Also, we will offer a normative\nbehavioral model for the interaction of the agent with the musical pitch\nenvironment and by using a slightly different version of Partially observable\nMarkov decision processes we will show that our method helps for faster\nlearning of state-action pairs in our implemented agents.\n",
          "  We study the empirical meaning of randomness with respect to a family of\nprobability distributions $P_\\theta$, where $\\theta$ is a real parameter, using\nalgorithmic randomness theory. In the case when for a computable probability\ndistribution $P_\\theta$ an effectively strongly consistent estimate exists, we\nshow that the Levin's a priory semicomputable semimeasure of the set of all\n$P_\\theta$-random sequences is positive if and only if the parameter $\\theta$\nis a computable real number. The different methods for generating\n``meaningful'' $P_\\theta$-random sequences with noncomputable $\\theta$ are\ndiscussed.\n",
          "  Least squares (LS) fitting is one of the most fundamental techniques in\nscience and engineering. It is used to estimate parameters from multiple noisy\nobservations. In many problems the parameters are known a-priori to be bounded\ninteger valued, or they come from a finite set of values on an arbitrary finite\nlattice. In this case finding the closest vector becomes NP-Hard problem. In\nthis paper we propose a novel algorithm, the Tomographic Least Squares Decoder\n(TLSD), that not only solves the ILS problem, better than other sub-optimal\ntechniques, but also is capable of providing the a-posteriori probability\ndistribution for each element in the solution vector. The algorithm is based on\nreconstruction of the vector from multiple two-dimensional projections. The\nprojections are carefully chosen to provide low computational complexity.\nUnlike other iterative techniques, such as the belief propagation, the proposed\nalgorithm has ensured convergence. We also provide simulated experiments\ncomparing the algorithm to other sub-optimal algorithms.\n",
          "  The goal of machine learning is to provide solutions which are trained by\ndata or by experience coming from the environment. Many training algorithms\nexist and some brilliant successes were achieved. But even in structured\nenvironments for machine learning (e.g. data mining or board games), most\napplications beyond the level of toy problems need careful hand-tuning or human\ningenuity (i.e. detection of interesting patterns) or both. We discuss several\naspects how self-configuration can help to alleviate these problems. One aspect\nis the self-configuration by tuning of algorithms, where recent advances have\nbeen made in the area of SPO (Sequen- tial Parameter Optimization). Another\naspect is the self-configuration by pattern detection or feature construction.\nForming multiple features (e.g. random boolean functions) and using algorithms\n(e.g. random forests) which easily digest many fea- tures can largely increase\nlearning speed. However, a full-fledged theory of feature construction is not\nyet available and forms a current barrier in machine learning. We discuss\nseveral ideas for systematic inclusion of feature construction. This may lead\nto partly self-configuring machine learning solutions which show robustness,\nflexibility, and fast learning in potentially changing environments.\n",
          "  Smart premise selection is essential when using automated reasoning as a tool\nfor large-theory formal proof development. A good method for premise selection\nin complex mathematical libraries is the application of machine learning to\nlarge corpora of proofs. This work develops learning-based premise selection in\ntwo ways. First, a newly available minimal dependency analysis of existing\nhigh-level formal mathematical proofs is used to build a large knowledge base\nof proof dependencies, providing precise data for ATP-based re-verification and\nfor training premise selection algorithms. Second, a new machine learning\nalgorithm for premise selection based on kernel methods is proposed and\nimplemented. To evaluate the impact of both techniques, a benchmark consisting\nof 2078 large-theory mathematical problems is constructed,extending the older\nMPTP Challenge benchmark. The combined effect of the techniques results in a\n50% improvement on the benchmark over the Vampire/SInE state-of-the-art system\nfor automated reasoning in large theories.\n",
          "  In this paper, we have established a general framework of multistage\nhypothesis tests which applies to arbitrarily many mutually exclusive and\nexhaustive composite hypotheses. Within the new framework, we have constructed\nspecific multistage tests which rigorously control the risk of committing\ndecision errors and are more efficient than previous tests in terms of average\nsample number and the number of sampling operations. Without truncation, the\nsample numbers of our testing plans are absolutely bounded.\n",
          "  The issue of discrete probability estimation for samples of small size is\naddressed in this study. The maximum likelihood method often suffers\nover-fitting when insufficient data is available. Although the Bayesian\napproach can avoid over-fitting by using prior distributions, it still has\nproblems with objective analysis. In response to these drawbacks, a new\ntheoretical framework based on thermodynamics, where energy and temperature are\nintroduced, was developed. Entropy and likelihood are placed at the center of\nthis method. The key principle of inference for probability mass functions is\nthe minimum free energy, which is shown to unify the two principles of maximum\nlikelihood and maximum entropy. Our method can robustly estimate probability\nfunctions from small size data.\n",
          "  The versatility of exponential families, along with their attendant convexity\nproperties, make them a popular and effective statistical model. A central\nissue is learning these models in high-dimensions, such as when there is some\nsparsity pattern of the optimal parameter. This work characterizes a certain\nstrong convexity property of general exponential families, which allow their\ngeneralization ability to be quantified. In particular, we show how this\nproperty can be used to analyze generic exponential families under L_1\nregularization.\n",
          "  The structure representation of data distribution plays an important role in\nunderstanding the underlying mechanism of generating data. In this paper, we\npropose nearest prime simplicial complex approaches (NSC) by utilizing\npersistent homology to capture such structures. Assuming that each class is\nrepresented with a prime simplicial complex, we classify unlabeled samples\nbased on the nearest projection distances from the samples to the simplicial\ncomplexes. We also extend the extrapolation ability of these complexes with a\nprojection constraint term. Experiments in simulated and practical datasets\nindicate that compared with several published algorithms, the proposed NSC\napproaches achieve promising performance without losing the structure\nrepresentation.\n",
          "  We show that learning a convex body in $\\RR^d$, given random samples from the\nbody, requires $2^{\\Omega(\\sqrt{d/\\eps})}$ samples. By learning a convex body\nwe mean finding a set having at most $\\eps$ relative symmetric difference with\nthe input body. To prove the lower bound we construct a hard to learn family of\nconvex bodies. Our construction of this family is very simple and based on\nerror correcting codes.\n",
          "  We analyse the prequential plug-in codes relative to one-parameter\nexponential families M. We show that if data are sampled i.i.d. from some\ndistribution outside M, then the redundancy of any plug-in prequential code\ngrows at rate larger than 1/2 ln(n) in the worst case. This means that plug-in\ncodes, such as the Rissanen-Dawid ML code, may behave inferior to other\nimportant universal codes such as the 2-part MDL, Shtarkov and Bayes codes, for\nwhich the redundancy is always 1/2 ln(n) + O(1). However, we also show that a\nslight modification of the ML plug-in code, \"almost\" in the model, does achieve\nthe optimal redundancy even if the the true distribution is outside M.\n",
          "  This preprint has been withdrawn by the author for revision\n",
          "  Pac-Bayes bounds are among the most accurate generalization bounds for\nclassifiers learned from independently and identically distributed (IID) data,\nand it is particularly so for margin classifiers: there have been recent\ncontributions showing how practical these bounds can be either to perform model\nselection (Ambroladze et al., 2007) or even to directly guide the learning of\nlinear classifiers (Germain et al., 2009). However, there are many practical\nsituations where the training data show some dependencies and where the\ntraditional IID assumption does not hold. Stating generalization bounds for\nsuch frameworks is therefore of the utmost interest, both from theoretical and\npractical standpoints. In this work, we propose the first - to the best of our\nknowledge - Pac-Bayes generalization bounds for classifiers trained on data\nexhibiting interdependencies. The approach undertaken to establish our results\nis based on the decomposition of a so-called dependency graph that encodes the\ndependencies within the data, in sets of independent data, thanks to graph\nfractional covers. Our bounds are very general, since being able to find an\nupper bound on the fractional chromatic number of the dependency graph is\nsufficient to get new Pac-Bayes bounds for specific settings. We show how our\nresults can be used to derive bounds for ranking statistics (such as Auc) and\nclassifiers trained on data distributed according to a stationary {\\ss}-mixing\nprocess. In the way, we show how our approach seemlessly allows us to deal with\nU-processes. As a side note, we also provide a Pac-Bayes generalization bound\nfor classifiers learned on data from stationary $\\varphi$-mixing distributions.\n",
          "  In many networks, vertices have hidden attributes, or types, that are\ncorrelated with the networks topology. If the topology is known but these\nattributes are not, and if learning the attributes is costly, we need a method\nfor choosing which vertex to query in order to learn as much as possible about\nthe attributes of the other vertices. We assume the network is generated by a\nstochastic block model, but we make no assumptions about its assortativity or\ndisassortativity. We choose which vertex to query using two methods: 1)\nmaximizing the mutual information between its attributes and those of the\nothers (a well-known approach in active learning) and 2) maximizing the average\nagreement between two independent samples of the conditional Gibbs\ndistribution. Experimental results show that both these methods do much better\nthan simple heuristics. They also consistently identify certain vertices as\nimportant by querying them early on.\n",
          "  Specialized intelligent systems can be found everywhere: finger print,\nhandwriting, speech, and face recognition, spam filtering, chess and other game\nprograms, robots, et al. This decade the first presumably complete mathematical\ntheory of artificial intelligence based on universal\ninduction-prediction-decision-action has been proposed. This\ninformation-theoretic approach solidifies the foundations of inductive\ninference and artificial intelligence. Getting the foundations right usually\nmarks a significant progress and maturing of a field. The theory provides a\ngold standard and guidance for researchers working on intelligent algorithms.\nThe roots of universal induction have been laid exactly half-a-century ago and\nthe roots of universal intelligence exactly one decade ago. So it is timely to\ntake stock of what has been achieved and what remains to be done. Since there\nare already good recent surveys, I describe the state-of-the-art only in\npassing and refer the reader to the literature. This article concentrates on\nthe open problems in universal induction and its extension to universal\nintelligence.\n",
          "  Grammar inference deals with determining (preferable simple) models/grammars\nconsistent with a set of observations. There is a large body of research on\ngrammar inference within the theory of formal languages. However, there is\nsurprisingly little known on grammar inference for graph grammars. In this\npaper we take a further step in this direction and work within the framework of\nnode label controlled (NLC) graph grammars. Specifically, we characterize,\ngiven a set of disjoint and isomorphic subgraphs of a graph $G$, whether or not\nthere is a NLC graph grammar rule which can generate these subgraphs to obtain\n$G$. This generalizes previous results by assuming that the set of isomorphic\nsubgraphs is disjoint instead of non-touching. This leads naturally to consider\nthe more involved ``non-confluent'' graph grammar rules.\n",
          "  Nowadays, computer scientists have shown the interest in the study of social\ninsect's behaviour in neural networks area for solving different combinatorial\nand statistical problems. Chief among these is the Artificial Bee Colony (ABC)\nalgorithm. This paper investigates the use of ABC algorithm that simulates the\nintelligent foraging behaviour of a honey bee swarm. Multilayer Perceptron\n(MLP) trained with the standard back propagation algorithm normally utilises\ncomputationally intensive training algorithms. One of the crucial problems with\nthe backpropagation (BP) algorithm is that it can sometimes yield the networks\nwith suboptimal weights because of the presence of many local optima in the\nsolution space. To overcome ABC algorithm used in this work to train MLP\nlearning the complex behaviour of earthquake time series data trained by BP,\nthe performance of MLP-ABC is benchmarked against MLP training with the\nstandard BP. The experimental result shows that MLP-ABC performance is better\nthan MLP-BP for time series data.\n",
          "  We extend the Chow-Liu algorithm for general random variables while the\nprevious versions only considered finite cases. In particular, this paper\napplies the generalization to Suzuki's learning algorithm that generates from\ndata forests rather than trees based on the minimum description length by\nbalancing the fitness of the data to the forest and the simplicity of the\nforest. As a result, we successfully obtain an algorithm when both of the\nGaussian and finite random variables are present.\n",
          "  Markov jump processes and continuous time Bayesian networks are important\nclasses of continuous time dynamical systems. In this paper, we tackle the\nproblem of inferring unobserved paths in these models by introducing a fast\nauxiliary variable Gibbs sampler. Our approach is based on the idea of\nuniformization, and sets up a Markov chain over paths by sampling a finite set\nof virtual jump times and then running a standard hidden Markov model forward\nfiltering-backward sampling algorithm over states at the set of extant and\nvirtual jump times. We demonstrate significant computational benefits over a\nstate-of-the-art Gibbs sampler on a number of continuous time Bayesian\nnetworks.\n",
          "  Using virtual stock markets with artificial interacting software investors,\naka agent-based models (ABMs), we present a method to reverse engineer\nreal-world financial time series. We model financial markets as made of a large\nnumber of interacting boundedly rational agents. By optimizing the similarity\nbetween the actual data and that generated by the reconstructed virtual stock\nmarket, we obtain parameters and strategies, which reveal some of the inner\nworkings of the target stock market. We validate our approach by out-of-sample\npredictions of directional moves of the Nasdaq Composite Index.\n",
          "  Recovering the 3D structure of the scene from images yields useful\ninformation for tasks such as shape and scene recognition, object detection, or\nmotion planning and object grasping in robotics. In this thesis, we introduce a\ngeneral machine learning approach called unsupervised CRF learning based on\nmaximizing the conditional likelihood. We apply our approach to computer vision\nsystems that recover the 3-D scene geometry from images. We focus on recovering\n3D geometry from single images, stereo pairs and video sequences. Building\nthese systems requires algorithms for doing inference as well as learning the\nparameters of conditional Markov random fields (MRF). Our system is trained\nunsupervisedly without using ground-truth labeled data. We employ a\nslanted-plane stereo vision model in which we use a fixed over-segmentation to\nsegment the left image into coherent regions called superpixels, then assign a\ndisparity plane for each superpixel. Plane parameters are estimated by solving\nan MRF labelling problem, through minimizing an energy fuction. We demonstrate\nthe use of our unsupervised CRF learning algorithm for a parameterized\nslanted-plane stereo vision model involving shape from texture cues. Our stereo\nmodel with texture cues, only by unsupervised training, outperforms the results\nin related work on the same stereo dataset. In this thesis, we also formulate\nstructure and motion estimation as an energy minimization problem, in which the\nmodel is an extension of our slanted-plane stereo vision model that also\nhandles surface velocity. Velocity estimation is achieved by solving an MRF\nlabeling problem using Loopy BP. Performance analysis is done using our novel\nevaluation metrics based on the notion of view prediction error. Experiments on\nroad-driving stereo sequences show encouraging results.\n",
          "  We study sparse principal components analysis in the high-dimensional\nsetting, where $p$ (the number of variables) can be much larger than $n$ (the\nnumber of observations). We prove optimal, non-asymptotic lower and upper\nbounds on the minimax estimation error for the leading eigenvector when it\nbelongs to an $\\ell_q$ ball for $q \\in [0,1]$. Our bounds are sharp in $p$ and\n$n$ for all $q \\in [0, 1]$ over a wide class of distributions. The upper bound\nis obtained by analyzing the performance of $\\ell_q$-constrained PCA. In\nparticular, our results provide convergence rates for $\\ell_1$-constrained PCA.\n",
          "  An importance weight quantifies the relative importance of one example over\nanother, coming up in applications of boosting, asymmetric classification\ncosts, reductions, and active learning. The standard approach for dealing with\nimportance weights in gradient descent is via multiplication of the gradient.\nWe first demonstrate the problems of this approach when importance weights are\nlarge, and argue in favor of more sophisticated ways for dealing with them. We\nthen develop an approach which enjoys an invariance property: that updating\ntwice with importance weight $h$ is equivalent to updating once with importance\nweight $2h$. For many important losses this has a closed form update which\nsatisfies standard regret guarantees when all examples have $h=1$. We also\nbriefly discuss two other reasonable approaches for handling large importance\nweights. Empirically, these approaches yield substantially superior prediction\nwith similar computational performance while reducing the sensitivity of the\nalgorithm to the exact setting of the learning rate. We apply these to online\nactive learning yielding an extraordinarily fast active learning algorithm that\nworks even in the presence of adversarial noise.\n",
          "  In this short note we prove a maximal concentration lemma for sub-Gaussian\nrandom variables stating that for independent sub-Gaussian random variables we\nhave \\[P<(\\max_{1\\le i\\le N}S_{i}>\\epsilon>)\n\\le\\exp<(-\\frac{1}{N^2}\\sum_{i=1}^{N}\\frac{\\epsilon^{2}}{2\\sigma_{i}^{2}}>), \\]\nwhere $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random\nvariables and $\\sigma_i$ is the variance of the $i$th random variable.\n",
          "  We define and study the link prediction problem in bipartite networks,\nspecializing general link prediction algorithms to the bipartite case. In a\ngraph, a link prediction function of two vertices denotes the similarity or\nproximity of the vertices. Common link prediction functions for general graphs\nare defined using paths of length two between two nodes. Since in a bipartite\ngraph adjacency vertices can only be connected by paths of odd lengths, these\nfunctions do not apply to bipartite graphs. Instead, a certain class of graph\nkernels (spectral transformation kernels) can be generalized to bipartite\ngraphs when the positive-semidefinite kernel constraint is relaxed. This\ngeneralization is realized by the odd component of the underlying spectral\ntransformation. This construction leads to several new link prediction\npseudokernels such as the matrix hyperbolic sine, which we examine for rating\ngraphs, authorship graphs, folksonomies, document--feature networks and other\ntypes of bipartite networks.\n",
          "  Building biological models by inferring functional dependencies from\nexperimental data is an im- portant issue in Molecular Biology. To relieve the\nbiologist from this traditionally manual process, various approaches have been\nproposed to increase the degree of automation. However, available ap- proaches\noften yield a single model only, rely on specific assumptions, and/or use\ndedicated, heuris- tic algorithms that are intolerant to changing circumstances\nor requirements in the view of the rapid progress made in Biotechnology. Our\naim is to provide a declarative solution to the problem by ap- peal to Answer\nSet Programming (ASP) overcoming these difficulties. We build upon an existing\napproach to Automatic Network Reconstruction proposed by part of the authors.\nThis approach has firm mathematical foundations and is well suited for ASP due\nto its combinatorial flavor providing a characterization of all models\nexplaining a set of experiments. The usage of ASP has several ben- efits over\nthe existing heuristic algorithms. First, it is declarative and thus\ntransparent for biological experts. Second, it is elaboration tolerant and thus\nallows for an easy exploration and incorporation of biological constraints.\nThird, it allows for exploring the entire space of possible models. Finally,\nour approach offers an excellent performance, matching existing,\nspecial-purpose systems.\n",
          "  Following a review of metric, ultrametric and generalized ultrametric, we\nreview their application in data analysis. We show how they allow us to explore\nboth geometry and topology of information, starting with measured data. Some\nthemes are then developed based on the use of metric, ultrametric and\ngeneralized ultrametric in logic. In particular we study approximation chains\nin an ultrametric or generalized ultrametric context. Our aim in this work is\nto extend the scope of data analysis by facilitating reasoning based on the\ndata analysis; and to show how quantitative and qualitative data analysis can\nbe incorporated into logic programming.\n",
          "  In this paper we adapt online estimation strategies to perform model-based\nclustering on large networks. Our work focuses on two algorithms, the first\nbased on the SAEM algorithm, and the second on variational methods. These two\nstrategies are compared with existing approaches on simulated and real data. We\nuse the method to decipher the connexion structure of the political websphere\nduring the US political campaign in 2008. We show that our online EM-based\nalgorithms offer a good trade-off between precision and speed, when estimating\nparameters for mixture distributions in the context of random graphs.\n",
          "  Submodular functions are discrete functions that model laws of diminishing\nreturns and enjoy numerous algorithmic applications. They have been used in\nmany areas, including combinatorial optimization, machine learning, and\neconomics. In this work we study submodular functions from a learning theoretic\nangle. We provide algorithms for learning submodular functions, as well as\nlower bounds on their learnability. In doing so, we uncover several novel\nstructural results revealing ways in which submodular functions can be both\nsurprisingly structured and surprisingly unstructured. We provide several\nconcrete implications of our work in other domains including algorithmic game\ntheory and combinatorial optimization.\n  At a technical level, this research combines ideas from many areas, including\nlearning theory (distributional learning and PAC-style analyses), combinatorics\nand optimization (matroids and submodular functions), and pseudorandomness\n(lossless expander graphs).\n",
          "  Fuzzy inference systems always suffer from the lack of efficient structures\nor platforms for their hardware implementation. In this paper, we tried to\novercome this problem by proposing new method for the implementation of those\nfuzzy inference systems which use fuzzy rule base to make inference. To achieve\nthis goal, we have designed a multi-layer neuro-fuzzy computing system based on\nthe memristor crossbar structure by introducing some new concepts like fuzzy\nminterms. Although many applications can be realized through the use of our\nproposed system, in this study we show how the fuzzy XOR function can be\nconstructed and how it can be used to extract edges from grayscale images. Our\nmemristive fuzzy edge detector (implemented in analog form) compared with other\ncommon edge detectors has this advantage that it can extract edges of any given\nimage all at once in real-time.\n",
          "  Given a finite family of functions, the goal of model selection aggregation\nis to construct a procedure that mimics the function from this family that is\nthe closest to an unknown regression function. More precisely, we consider a\ngeneral regression model with fixed design and measure the distance between\nfunctions by the mean squared error at the design points. While procedures\nbased on exponential weights are known to solve the problem of model selection\naggregation in expectation, they are, surprisingly, sub-optimal in deviation.\nWe propose a new formulation called Q-aggregation that addresses this\nlimitation; namely, its solution leads to sharp oracle inequalities that are\noptimal in a minimax sense. Moreover, based on the new formulation, we design\ngreedy Q-aggregation procedures that produce sparse aggregation models\nachieving the optimal rate. The convergence and performance of these greedy\nprocedures are illustrated and compared with other standard methods on\nsimulated examples.\n",
          "  We prove an exponential probability tail inequality for positive semidefinite\nquadratic forms in a subgaussian random vector. The bound is analogous to one\nthat holds when the vector has independent Gaussian entries.\n",
          "  Designing and implementing efficient, provably correct parallel machine\nlearning (ML) algorithms is challenging. Existing high-level parallel\nabstractions like MapReduce are insufficiently expressive while low-level tools\nlike MPI and Pthreads leave ML experts repeatedly solving the same design\nchallenges. By targeting common patterns in ML, we developed GraphLab, which\nimproves upon abstractions like MapReduce by compactly expressing asynchronous\niterative algorithms with sparse computational dependencies while ensuring data\nconsistency and achieving a high degree of parallel performance. We demonstrate\nthe expressiveness of the GraphLab framework by designing and implementing\nparallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and\nCompressed Sensing. We show that using GraphLab we can achieve excellent\nparallel performance on large scale real-world problems.\n",
          "  Information theory is widely accepted as a powerful tool for analyzing\ncomplex systems and it has been applied in many disciplines. Recently, some\ncentral components of information theory - multivariate information measures -\nhave found expanded use in the study of several phenomena. These information\nmeasures differ in subtle yet significant ways. Here, we will review the\ninformation theory behind each measure, as well as examine the differences\nbetween these measures by applying them to several simple model systems. In\naddition to these systems, we will illustrate the usefulness of the information\nmeasures by analyzing neural spiking data from a dissociated culture through\nearly stages of its development. We hope that this work will aid other\nresearchers as they seek the best multivariate information measure for their\nspecific research goals and system. Finally, we have made software available\nonline which allows the user to calculate all of the information measures\ndiscussed within this paper.\n",
          "  We live in a computerized and networked society where many of our actions\nleave a digital trace and affect other people's actions. This has lead to the\nemergence of a new data-driven research field: mathematical methods of computer\nscience, statistical physics and sociometry provide insights on a wide range of\ndisciplines ranging from social science to human mobility. A recent important\ndiscovery is that query volumes (i.e., the number of requests submitted by\nusers to search engines on the www) can be used to track and, in some cases, to\nanticipate the dynamics of social phenomena. Successful exemples include\nunemployment levels, car and home sales, and epidemics spreading. Few recent\nworks applied this approach to stock prices and market sentiment. However, it\nremains unclear if trends in financial markets can be anticipated by the\ncollective wisdom of on-line users on the web. Here we show that trading\nvolumes of stocks traded in NASDAQ-100 are correlated with the volumes of\nqueries related to the same stocks. In particular, query volumes anticipate in\nmany cases peaks of trading by one day or more. Our analysis is carried out on\na unique dataset of queries, submitted to an important web search engine, which\nenable us to investigate also the user behavior. We show that the query volume\ndynamics emerges from the collective but seemingly uncoordinated activity of\nmany users. These findings contribute to the debate on the identification of\nearly warnings of financial systemic risk, based on the activity of users of\nthe www.\n",
          "  In this work, decision tree learning algorithms and fuzzy inferencing systems\nare applied for galaxy morphology classification. In particular, the CART, the\nC4.5, the Random Forest and fuzzy logic algorithms are studied and reliable\nclassifiers are developed to distinguish between spiral galaxies, elliptical\ngalaxies or star/unknown galactic objects. Morphology information for the\ntraining and testing datasets is obtained from the Galaxy Zoo project while the\ncorresponding photometric and spectra parameters are downloaded from the SDSS\nDR7 catalogue.\n",
          "  In machine learning, distance-based algorithms, and other approaches, use\ninformation that is represented by propositional data. However, this kind of\nrepresentation can be quite restrictive and, in many cases, it requires more\ncomplex structures in order to represent data in a more natural way. Terms are\nthe basis for functional and logic programming representation. Distances\nbetween terms are a useful tool not only to compare terms, but also to\ndetermine the search space in many of these applications. This dissertation\napplies distances between terms, exploiting the features of each distance and\nthe possibility to compare from propositional data types to hierarchical\nrepresentations. The distances between terms are applied through the k-NN\n(k-nearest neighbor) classification algorithm using XML as a common language\nrepresentation. To be able to represent these data in an XML structure and to\ntake advantage of the benefits of distance between terms, it is necessary to\napply some transformations. These transformations allow the conversion of flat\ndata into hierarchical data represented in XML, using some techniques based on\nintuitive associations between the names and values of variables and\nassociations based on attribute similarity.\n  Several experiments with the distances between terms of Nienhuys-Cheng and\nEstruch et al. were performed. In the case of originally propositional data,\nthese distances are compared to the Euclidean distance. In all cases, the\nexperiments were performed with the distance-weighted k-nearest neighbor\nalgorithm, using several exponents for the attraction function (weighted\ndistance). It can be seen that in some cases, the term distances can\nsignificantly improve the results on approaches applied to flat\nrepresentations.\n",
          "  While high-level data parallel frameworks, like MapReduce, simplify the\ndesign and implementation of large-scale data processing systems, they do not\nnaturally or efficiently support many important data mining and machine\nlearning algorithms and can lead to inefficient learning systems. To help fill\nthis critical void, we introduced the GraphLab abstraction which naturally\nexpresses asynchronous, dynamic, graph-parallel computation while ensuring data\nconsistency and achieving a high degree of parallel performance in the\nshared-memory setting. In this paper, we extend the GraphLab framework to the\nsubstantially more challenging distributed setting while preserving strong data\nconsistency guarantees. We develop graph based extensions to pipelined locking\nand data versioning to reduce network congestion and mitigate the effect of\nnetwork latency. We also introduce fault tolerance to the GraphLab abstraction\nusing the classic Chandy-Lamport snapshot algorithm and demonstrate how it can\nbe easily implemented by exploiting the GraphLab abstraction itself. Finally,\nwe evaluate our distributed implementation of the GraphLab abstraction on a\nlarge Amazon EC2 deployment and show 1-2 orders of magnitude performance gains\nover Hadoop-based implementations.\n",
          "  This paper presents the formulation of a combinatorial optimization problem\nwith the following characteristics: i.the search space is the power set of a\nfinite set structured as a Boolean lattice; ii.the cost function forms a\nU-shaped curve when applied to any lattice chain. This formulation applies for\nfeature selection in the context of pattern recognition. The known approaches\nfor this problem are branch-and-bound algorithms and heuristics, that explore\npartially the search space. Branch-and-bound algorithms are equivalent to the\nfull search, while heuristics are not. This paper presents a branch-and-bound\nalgorithm that differs from the others known by exploring the lattice structure\nand the U-shaped chain curves of the search space. The main contribution of\nthis paper is the architecture of this algorithm that is based on the\nrepresentation and exploration of the search space by new lattice properties\nproven here. Several experiments, with well known public data, indicate the\nsuperiority of the proposed method to SFFS, which is a popular heuristic that\ngives good results in very short computational time. In all experiments, the\nproposed method got better or equal results in similar or even smaller\ncomputational time.\n",
          "  We study the problem of decision-theoretic online learning (DTOL). Motivated\nby practical applications, we focus on DTOL when the number of actions is very\nlarge. Previous algorithms for learning in this framework have a tunable\nlearning rate parameter, and a barrier to using online-learning in practical\napplications is that it is not understood how to set this parameter optimally,\nparticularly when the number of actions is large.\n  In this paper, we offer a clean solution by proposing a novel and completely\nparameter-free algorithm for DTOL. We introduce a new notion of regret, which\nis more natural for applications with a large number of actions. We show that\nour algorithm achieves good performance with respect to this new notion of\nregret; in addition, it also achieves performance close to that of the best\nbounds achieved by previous algorithms with optimally-tuned parameters,\naccording to previous notions of regret.\n",
          "  Most of the non-asymptotic theoretical work in regression is carried out for\nthe square loss, where estimators can be obtained through closed-form\nexpressions. In this paper, we use and extend tools from the convex\noptimization literature, namely self-concordant functions, to provide simple\nextensions of theoretical results for the square loss to the logistic loss. We\napply the extension techniques to logistic regression with regularization by\nthe $\\ell_2$-norm and regularization by the $\\ell_1$-norm, showing that new\nresults for binary classification through logistic regression can be easily\nderived from corresponding results for least-squares regression.\n",
          "  Traffic forecasting from past observed traffic data with small calculation\ncomplexity is one of important problems for planning of servers and networks.\nFocusing on World Wide Web (WWW) traffic as fundamental investigation, this\npaper would deal with Bayesian forecasting of network traffic on the time\nvarying Poisson model from a viewpoint from statistical decision theory. Under\nthis model, we would show that the estimated forecasting value is obtained by\nsimple arithmetic calculation and expresses real WWW traffic well from both\ntheoretical and empirical points of view.\n",
          "  In certain applications it is useful to fit multinomial distributions to\nobserved data with a penalty term that encourages sparsity. For example, in\nprobabilistic latent audio source decomposition one may wish to encode the\nassumption that only a few latent sources are active at any given time. The\nstandard heuristic of applying an L1 penalty is not an option when fitting the\nparameters to a multinomial distribution, which are constrained to sum to 1. An\nalternative is to use a penalty term that encourages low-entropy solutions,\nwhich corresponds to maximum a posteriori (MAP) parameter estimation with an\nentropic prior. The lack of conjugacy between the entropic prior and the\nmultinomial distribution complicates this approach. In this report I propose a\nsimple iterative algorithm for MAP estimation of multinomial distributions with\nsparsity-inducing entropic priors.\n",
          "  Music Sight Reading is a complex process in which when it is occurred in the\nbrain some learning attributes would be emerged. Besides giving a model based\non actor-critic method in the Reinforcement Learning, the agent is considered\nto have a neural network structure. We studied on where the sight reading\nprocess is happened and also a serious problem which is how the synaptic\nweights would be adjusted through the learning process. The model we offer here\nis a computational model on which an updated weights equation to fix the\nweights is accompanied too.\n",
          "  This paper formalises the concept of learning symbolic rules from multisource\ndata in a cardiac monitoring context. Our sources, electrocardiograms and\narterial blood pressure measures, describe cardiac behaviours from different\nviewpoints. To learn interpretable rules, we use an Inductive Logic Programming\n(ILP) method. We develop an original strategy to cope with the dimensionality\nissues caused by using this ILP technique on a rich multisource language. The\nresults show that our method greatly improves the feasibility and the\nefficiency of the process while staying accurate. They also confirm the\nbenefits of using multiple sources to improve the diagnosis of cardiac\narrhythmias.\n",
          "  Recently, applying the novel data mining techniques for evaluating enterprise\nfinancial distress has received much research alternation. Support Vector\nMachine (SVM) and back propagation neural (BPN) network has been applied\nsuccessfully in many areas with excellent generalization results, such as rule\nextraction, classification and evaluation. In this paper, a model based on SVM\nwith Gaussian RBF kernel is proposed here for enterprise financial distress\nevaluation. BPN network is considered one of the simplest and are most general\nmethods used for supervised training of multilayered neural network. The\ncomparative results show that through the difference between the performance\nmeasures is marginal; SVM gives higher precision and lower error rates.\n",
          "  In this paper, we present the case for a declarative foundation for\ndata-intensive machine learning systems. Instead of creating a new system for\neach specific flavor of machine learning task, or hardcoding new optimizations,\nwe argue for the use of recursive queries to program a variety of machine\nlearning systems. By taking this approach, database query optimization\ntechniques can be utilized to identify effective execution plans, and the\nresulting runtime plans can be executed on a single unified data-parallel query\nprocessing engine. As a proof of concept, we consider two programming\nmodels--Pregel and Iterative Map-Reduce-Update---from the machine learning\ndomain, and show how they can be captured in Datalog, tuned for a specific\ntask, and then compiled into an optimized physical plan. Experiments performed\non a large computing cluster with real data demonstrate that this declarative\napproach can provide very good performance while offering both increased\ngenerality and programming ease.\n",
          "  This paper describes an effective unsupervised speaker indexing approach. We\nsuggest a two stage algorithm to speed-up the state-of-the-art algorithm based\non the Bayesian Information Criterion (BIC). In the first stage of the merging\nprocess a computationally cheap method based on the vector quantization (VQ) is\nused. Then in the second stage a more computational expensive technique based\non the BIC is applied. In the speaker indexing task a turning parameter or a\nthreshold is used. We suggest an on-line procedure to define the value of a\nturning parameter without using development data. The results are evaluated\nusing 10 hours of audio data.\n",
          "  To attain the best learning accuracy, people move on with difficulties and\nfrustrations. Though one can optimize the empirical objective using a given set\nof samples, its generalization ability to the entire sample distribution\nremains questionable. Even if a fair generalization guarantee is offered, one\nstill wants to know what is to happen if the regularizer is removed, and/or how\nwell the artificial loss (like the hinge loss) relates to the accuracy.\n  For such reason, this report surveys four different trials towards the\nlearning accuracy, embracing the major advances in supervised learning theory\nin the past four years. Starting from the generic setting of learning, the\nfirst two trials introduce the best optimization and generalization bounds for\nconvex learning, and the third trial gets rid of the regularizer. As an\ninnovative attempt, the fourth trial studies the optimization when the\nobjective is exactly the accuracy, in the special case of binary\nclassification. This report also analyzes the last trial through experiments.\n",
          "  This manuscript investigates the relationship between Blackwell\nApproachability, a stochastic vector-valued repeated game, and minimax theory,\na single-play scalar-valued scenario. First, it is established in a general\nsetting --- one not permitting invocation of minimax theory --- that\nBlackwell's Approachability Theorem and its generalization due to Hou are still\nvalid. Second, minimax structure grants a result in the spirit of Blackwell's\nweak-approachability conjecture, later resolved by Vieille, that any set is\neither approachable by one player, or avoidable by the opponent. This analysis\nalso reveals a strategy for the opponent.\n",
          "  In this paper, we propose the MIML (Multi-Instance Multi-Label learning)\nframework where an example is described by multiple instances and associated\nwith multiple class labels. Compared to traditional learning frameworks, the\nMIML framework is more convenient and natural for representing complicated\nobjects which have multiple semantic meanings. To learn from MIML examples, we\npropose the MimlBoost and MimlSvm algorithms based on a simple degeneration\nstrategy, and experiments show that solving problems involving complicated\nobjects with multiple semantic meanings in the MIML framework can lead to good\nperformance. Considering that the degeneration process may lose information, we\npropose the D-MimlSvm algorithm which tackles MIML problems directly in a\nregularization framework. Moreover, we show that even when we do not have\naccess to the real objects and thus cannot capture more information from real\nobjects by using the MIML representation, MIML is still useful. We propose the\nInsDif and SubCod algorithms. InsDif works by transforming single-instances\ninto the MIML representation for learning, while SubCod works by transforming\nsingle-label examples into the MIML representation for learning. Experiments\nshow that in some tasks they are able to achieve better performance than\nlearning the single-instances or single-label examples directly.\n",
          "  In this paper we address the problem of modeling relational data, which\nappear in many applications such as social network analysis, recommender\nsystems and bioinformatics. Previous studies either consider latent feature\nbased models but disregarding local structure in the network, or focus\nexclusively on capturing local structure of objects based on latent blockmodels\nwithout coupling with latent characteristics of objects. To combine the\nbenefits of the previous work, we propose a novel model that can simultaneously\nincorporate the effect of latent features and covariates if any, as well as the\neffect of latent structure that may exist in the data. To achieve this, we\nmodel the relation graph as a function of both latent feature factors and\nlatent cluster memberships of objects to collectively discover globally\npredictive intrinsic properties of objects and capture latent block structure\nin the network to improve prediction performance. We also develop an\noptimization transfer algorithm based on the generalized EM-style strategy to\nlearn the latent factors. We prove the efficacy of our proposed model through\nthe link prediction task and cluster analysis task, and extensive experiments\non the synthetic data and several real world datasets suggest that our proposed\nLFBM model outperforms the other state of the art approaches in the evaluated\ntasks.\n",
          "  We describe an adaptive context tree weighting (ACTW) algorithm, as an\nextension to the standard context tree weighting (CTW) algorithm. Unlike the\nstandard CTW algorithm, which weights all observations equally regardless of\nthe depth, ACTW gives increasing weight to more recent observations, aiming to\nimprove performance in cases where the input sequence is from a non-stationary\ndistribution. Data compression results show ACTW variants improving over CTW on\nmerged files from standard compression benchmark tests while never being\nsignificantly worse on any individual file.\n",
          "  This paper provides a theoretical explanation on the clustering aspect of\nnonnegative matrix factorization (NMF). We prove that even without imposing\northogonality nor sparsity constraint on the basis and/or coefficient matrix,\nNMF still can give clustering results, thus providing a theoretical support for\nmany works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority\nof the standard NMF as a clustering method.\n",
          "  We describe and analyze a new algorithm for agnostically learning\nkernel-based halfspaces with respect to the \\emph{zero-one} loss function.\nUnlike most previous formulations which rely on surrogate convex loss functions\n(e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finite\ntime/sample guarantees with respect to the more natural zero-one loss function.\nThe proposed algorithm can learn kernel-based halfspaces in worst-case time\n$\\poly(\\exp(L\\log(L/\\epsilon)))$, for $\\emph{any}$ distribution, where $L$ is a\nLipschitz constant (which can be thought of as the reciprocal of the margin),\nand the learned classifier is worse than the optimal halfspace by at most\n$\\epsilon$. We also prove a hardness result, showing that under a certain\ncryptographic assumption, no algorithm can learn kernel-based halfspaces in\ntime polynomial in $L$.\n",
          "  Post-genomic research deals with challenging problems in screening genomes of\norganisms for particular functions or potential for being the targets of\ngenetic engineering for desirable biological features. 'Phenotyping' of wild\ntype and mutants is a time-consuming and costly effort by many individuals.\nThis article is a preliminary progress report in research on large-scale\nautomation of phenotyping steps (imaging, informatics and data analysis) needed\nto study plant gene-proteins networks that influence growth and development of\nplants. Our results undermine the significance of phenotypic traits that are\nimplicit in patterns of dynamics in plant root response to sudden changes of\nits environmental conditions, such as sudden re-orientation of the root tip\nagainst the gravity vector. Including dynamic features besides the common\nmorphological ones has paid off in design of robust and accurate machine\nlearning methods to automate a typical phenotyping scenario, i.e. to\ndistinguish the wild type from the mutants.\n",
          "  This paper describes the winning entry to the IJCNN 2011 Social Network\nChallenge run by Kaggle.com. The goal of the contest was to promote research on\nreal-world link prediction, and the dataset was a graph obtained by crawling\nthe popular Flickr social photo sharing website, with user identities scrubbed.\nBy de-anonymizing much of the competition test set using our own Flickr crawl,\nwe were able to effectively game the competition. Our attack represents a new\napplication of de-anonymization to gaming machine learning contests, suggesting\nchanges in how future competitions should be run.\n  We introduce a new simulated annealing-based weighted graph matching\nalgorithm for the seeding step of de-anonymization. We also show how to combine\nde-anonymization with link prediction---the latter is required to achieve good\nperformance on the portion of the test set not de-anonymized---for example by\ntraining the predictor on the de-anonymized portion of the test set, and\ncombining probabilistic predictions from de-anonymization and link prediction.\n",
          "  In this paper, we present a new multiple instance learning (MIL) method,\ncalled MIS-Boost, which learns discriminative instance prototypes by explicit\ninstance selection in a boosting framework. Unlike previous instance selection\nbased MIL methods, we do not restrict the prototypes to a discrete set of\ntraining instances but allow them to take arbitrary values in the instance\nfeature space. We also do not restrict the total number of prototypes and the\nnumber of selected-instances per bag; these quantities are completely\ndata-driven. We show that MIS-Boost outperforms state-of-the-art MIL methods on\na number of benchmark datasets. We also apply MIS-Boost to large-scale image\nclassification, where we show that the automatically selected prototypes map to\nvisually meaningful image regions.\n",
          "  We investigate fast methods that allow to quickly eliminate variables\n(features) in supervised learning problems involving a convex loss function and\na $l_1$-norm penalty, leading to a potentially substantial reduction in the\nnumber of variables prior to running the supervised learning algorithm. The\nmethods are not heuristic: they only eliminate features that are {\\em\nguaranteed} to be absent after solving the learning problem. Our framework\napplies to a large class of problems, including support vector machine\nclassification, logistic regression and least-squares.\n  The complexity of the feature elimination step is negligible compared to the\ntypical computational effort involved in the sparse supervised learning\nproblem: it grows linearly with the number of features times the number of\nexamples, with much better count if data is sparse. We apply our method to data\nsets arising in text classification and observe a dramatic reduction of the\ndimensionality, hence in computational effort required to solve the learning\nproblem, especially when very sparse classifiers are sought. Our method allows\nto immediately extend the scope of existing algorithms, allowing us to run them\non data sets of sizes that were out of their reach before.\n",
          "  We present a Dirichlet process mixture model over discrete incomplete\nrankings and study two Gibbs sampling inference techniques for estimating\nposterior clusterings. The first approach uses a slice sampling subcomponent\nfor estimating cluster parameters. The second approach marginalizes out several\ncluster parameters by taking advantage of approximations to the conditional\nposteriors. We empirically demonstrate (1) the effectiveness of this\napproximation for improving convergence, (2) the benefits of the Dirichlet\nprocess model over alternative clustering techniques for ranked data, and (3)\nthe applicability of the approach to exploring large realworld ranking\ndatasets.\n",
          "  We present BayeSum (for ``Bayesian summarization''), a model for sentence\nextraction in query-focused summarization. BayeSum leverages the common case in\nwhich multiple documents are relevant to a single query. Using these documents\nas reinforcement for query terms, BayeSum is not afflicted by the paucity of\ninformation in short queries. We show that approximate inference in BayeSum is\npossible on large data sets and results in a state-of-the-art summarization\nsystem. Furthermore, we show how BayeSum can be understood as a justified query\nexpansion technique in the language modeling for IR framework.\n",
          "  We present an asymptotically exact analysis of the problem of detecting\ncommunities in sparse random networks. Our results are also applicable to\ndetection of functional modules, partitions, and colorings in noisy planted\nmodels. Using a cavity method analysis, we unveil a phase transition from a\nregion where the original group assignment is undetectable to one where\ndetection is possible. In some cases, the detectable region splits into an\nalgorithmically hard region and an easy one. Our approach naturally translates\ninto a practical algorithm for detecting modules in sparse networks, and\nlearning the parameters of the underlying model.\n",
          "  Many open-source projects land security fixes in public repositories before\nshipping these patches to users. This paper presents attacks on such projects -\ntaking Firefox as a case-study - that exploit patch metadata to efficiently\nsearch for security patches prior to shipping. Using access-restricted bug\nreports linked from patch descriptions, security patches can be immediately\nidentified for 260 out of 300 days of Firefox 3 development. In response to\nMozilla obfuscating descriptions, we show that machine learning can exploit\nmetadata such as patch author to search for security patches, extending the\ntotal window of vulnerability by 5 months in an 8 month period when examining\nup to two patches daily. Finally we present strong evidence that further\nmetadata obfuscation is unlikely to prevent information leaks, and we argue\nthat open-source projects instead ought to keep security patches secret until\nthey are ready to be released.\n",
          "  After building a classifier with modern tools of machine learning we\ntypically have a black box at hand that is able to predict well for unseen\ndata. Thus, we get an answer to the question what is the most likely label of a\ngiven unseen data point. However, most methods will provide no answer why the\nmodel predicted the particular label for a single instance and what features\nwere most influential for that particular instance. The only method that is\ncurrently able to provide such explanations are decision trees. This paper\nproposes a procedure which (based on a set of assumptions) allows to explain\nthe decisions of any classification method.\n",
          "  We introduce a new family of estimators for unnormalized statistical models.\nOur family of estimators is parameterized by two nonlinear functions and uses a\nsingle sample from an auxiliary distribution, generalizing Maximum Likelihood\nMonte Carlo estimation of Geyer and Thompson (1992). The family is such that we\ncan estimate the partition function like any other parameter in the model. The\nestimation is done by optimizing an algebraically simple, well defined\nobjective function, which allows for the use of dedicated optimization methods.\nWe establish consistency of the estimator family and give an expression for the\nasymptotic covariance matrix, which enables us to further analyze the influence\nof the nonlinearities and the auxiliary density on estimation performance. Some\nestimators in our family are particularly stable for a wide range of auxiliary\ndensities. Interestingly, a specific choice of the nonlinearity establishes a\nconnection between density estimation and classification by nonlinear logistic\nregression. Finally, the optimal amount of auxiliary samples relative to the\ngiven amount of the data is considered from the perspective of computational\nefficiency.\n",
          "  Growing neuropsychological and neurophysiological evidence suggests that the\nvisual cortex uses parts-based representations to encode, store and retrieve\nrelevant objects. In such a scheme, objects are represented as a set of\nspatially distributed local features, or parts, arranged in stereotypical\nfashion. To encode the local appearance and to represent the relations between\nthe constituent parts, there has to be an appropriate memory structure formed\nby previous experience with visual objects. Here, we propose a model how a\nhierarchical memory structure supporting efficient storage and rapid recall of\nparts-based representations can be established by an experience-driven process\nof self-organization. The process is based on the collaboration of slow\nbidirectional synaptic plasticity and homeostatic unit activity regulation,\nboth running at the top of fast activity dynamics with winner-take-all\ncharacter modulated by an oscillatory rhythm. These neural mechanisms lay down\nthe basis for cooperation and competition between the distributed units and\ntheir synaptic connections. Choosing human face recognition as a test task, we\nshow that, under the condition of open-ended, unsupervised incremental\nlearning, the system is able to form memory traces for individual faces in a\nparts-based fashion. On a lower memory layer the synaptic structure is\ndeveloped to represent local facial features and their interrelations, while\nthe identities of different persons are captured explicitly on a higher layer.\nAn additional property of the resulting representations is the sparseness of\nboth the activity during the recall and the synaptic patterns comprising the\nmemory traces.\n",
          "  We present a new application and covering number bound for the framework of\n\"Machine Learning with Operational Costs (MLOC),\" which is an exploratory form\nof decision theory. The MLOC framework incorporates knowledge about how a\npredictive model will be used for a subsequent task, thus combining machine\nlearning with the decision that is made afterwards. In this work, we use the\nMLOC framework to study a problem that has implications for power grid\nreliability and maintenance, called the Machine Learning and Traveling\nRepairman Problem ML&TRP. The goal of the ML&TRP is to determine a route for a\n\"repair crew,\" which repairs nodes on a graph. The repair crew aims to minimize\nthe cost of failures at the nodes, but as in many real situations, the failure\nprobabilities are not known and must be estimated. The MLOC framework allows us\nto understand how this uncertainty influences the repair route. We also present\nnew covering number generalization bounds for the MLOC framework.\n",
          "  The paper proposes a new message passing algorithm for cycle-free factor\ngraphs. The proposed \"entropy message passing\" (EMP) algorithm may be viewed as\nsum-product message passing over the entropy semiring, which has previously\nappeared in automata theory. The primary use of EMP is to compute the entropy\nof a model. However, EMP can also be used to compute expressions that appear in\nexpectation maximization and in gradient descent algorithms.\n",
          "  We describe and analyze efficient algorithms for learning a linear predictor\nfrom examples when the learner can only view a few attributes of each training\nexample. This is the case, for instance, in medical research, where each\npatient participating in the experiment is only willing to go through a small\nnumber of tests. Our analysis bounds the number of additional examples\nsufficient to compensate for the lack of full information on each training\nexample. We demonstrate the efficiency of our algorithms by showing that when\nrunning on digit recognition data, they obtain a high prediction accuracy even\nwhen the learner gets to see only four pixels of each image.\n",
          "  In this paper, we formulate a novel problem for finding blackhole and volcano\npatterns in a large directed graph. Specifically, a blackhole pattern is a\ngroup which is made of a set of nodes in a way such that there are only inlinks\nto this group from the rest nodes in the graph. In contrast, a volcano pattern\nis a group which only has outlinks to the rest nodes in the graph. Both\npatterns can be observed in real world. For instance, in a trading network, a\nblackhole pattern may represent a group of traders who are manipulating the\nmarket. In the paper, we first prove that the blackhole mining problem is a\ndual problem of finding volcanoes. Therefore, we focus on finding the blackhole\npatterns. Along this line, we design two pruning schemes to guide the blackhole\nfinding process. In the first pruning scheme, we strategically prune the search\nspace based on a set of pattern-size-independent pruning rules and develop an\niBlackhole algorithm. The second pruning scheme follows a divide-and-conquer\nstrategy to further exploit the pruning results from the first pruning scheme.\nIndeed, a target directed graphs can be divided into several disconnected\nsubgraphs by the first pruning scheme, and thus the blackhole finding can be\nconducted in each disconnected subgraph rather than in a large graph. Based on\nthese two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally,\nexperimental results on real-world data show that the iBlackhole-DC algorithm\ncan be several orders of magnitude faster than the iBlackhole algorithm, which\nhas a huge computational advantage over a brute-force method.\n",
          "  Linear principal component analysis (PCA) can be extended to a nonlinear PCA\nby using artificial neural networks. But the benefit of curved components\nrequires a careful control of the model complexity. Moreover, standard\ntechniques for model selection, including cross-validation and more generally\nthe use of an independent test set, fail when applied to nonlinear PCA because\nof its inherent unsupervised characteristics. This paper presents a new\napproach for validating the complexity of nonlinear PCA models by using the\nerror in missing data estimation as a criterion for model selection. It is\nmotivated by the idea that only the model of optimal complexity is able to\npredict missing values with the highest accuracy. While standard test set\nvalidation usually favours over-fitted nonlinear PCA models, the proposed model\nvalidation approach correctly selects the optimal model complexity.\n",
          "  In this paper, we consider the nonasymptotic sequential estimation of means\nof random variables bounded in between zero and one. We have rigorously\ndemonstrated that, in order to guarantee prescribed relative precision and\nconfidence level, it suffices to continue sampling until the sample sum is no\nless than a certain bound and then take the average of samples as an estimate\nfor the mean of the bounded random variable. We have developed an explicit\nformula and a bisection search method for the determination of such bound of\nsample sum, without any knowledge of the bounded variable. Moreover, we have\nderived bounds for the distribution of sample size. In the special case of\nBernoulli random variables, we have established analytical and numerical\nmethods to further reduce the bound of sample sum and thus improve the\nefficiency of sampling. Furthermore, the fallacy of existing results are\ndetected and analyzed.\n",
          "  Speaker identification is a powerful, non-invasive and in-expensive biometric\ntechnique. The recognition accuracy, however, deteriorates when noise levels\naffect a specific band of frequency. In this paper, we present a sub-band based\nspeaker identification that intends to improve the live testing performance.\nEach frequency sub-band is processed and classified independently. We also\ncompare the linear and non-linear merging techniques for the sub-bands\nrecognizer. Support vector machines and Gaussian Mixture models are the\nnon-linear merging techniques that are investigated. Results showed that the\nsub-band based method used with linear merging techniques enormously improved\nthe performance of the speaker identification over the performance of wide-band\nrecognizers when tested live. A live testing improvement of 9.78% was achieved\n",
          "  We introduce the graphlet decomposition of a weighted network, which encodes\na notion of social information based on social structure. We develop a scalable\ninference algorithm, which combines EM with Bron-Kerbosch in a novel fashion,\nfor estimating the parameters of the model underlying graphlets using one\nnetwork sample. We explore some theoretical properties of the graphlet\ndecomposition, including computational complexity, redundancy and expected\naccuracy. We demonstrate graphlets on synthetic and real data. We analyze\nmessaging patterns on Facebook and criminal associations in the 19th century.\n",
          "  Online learning has become increasingly popular on handling massive data. The\nsequential nature of online learning, however, requires a centralized learner\nto store data and update parameters. In this paper, we consider online learning\nwith {\\em distributed} data sources. The autonomous learners update local\nparameters based on local data sources and periodically exchange information\nwith a small subset of neighbors in a communication network. We derive the\nregret bound for strongly convex functions that generalizes the work by Ram et\nal. (2010) for convex functions. Most importantly, we show that our algorithm\nhas \\emph{intrinsic} privacy-preserving properties, and we prove the sufficient\nand necessary conditions for privacy preservation in the network. These\nconditions imply that for networks with greater-than-one connectivity, a\nmalicious learner cannot reconstruct the subgradients (and sensitive raw data)\nof other learners, which makes our algorithm appealing in privacy sensitive\napplications.\n",
          "  Current methods for determining whether a time series exhibits fractal\nstructure (FS) rely on subjective assessments on estimators of the Hurst\nexponent (H). Here, I introduce the Bayesian Assessment of Scaling, an\nanalytical framework for drawing objective and accurate inferences on the FS of\ntime series. The technique exploits the scaling property of the diffusion\nassociated to a time series. The resulting criterion is simple to compute and\nrepresents an accurate characterization of the evidence supporting different\nhypotheses on the scaling regime of a time series. Additionally, a closed-form\nMaximum Likelihood estimator of H is derived from the criterion, and this\nestimator outperforms the best available estimators.\n",
          "  We describe an adaptation and application of a search-based structured\nprediction algorithm \"Searn\" to unsupervised learning problems. We show that it\nis possible to reduce unsupervised learning to supervised learning and\ndemonstrate a high-quality unsupervised shift-reduce parsing model. We\nadditionally show a close connection between unsupervised Searn and expectation\nmaximization. Finally, we demonstrate the efficacy of a semi-supervised\nextension. The key idea that enables this is an application of the predict-self\nidea for unsupervised learning.\n",
          "  This paper describes two applications of conditional restricted Boltzmann\nmachines (CRBMs) to the task of autotagging music. The first consists of\ntraining a CRBM to predict tags that a user would apply to a clip of a song\nbased on tags already applied by other users. By learning the relationships\nbetween tags, this model is able to pre-process training data to significantly\nimprove the performance of a support vector machine (SVM) autotagging. The\nsecond is the use of a discriminative RBM, a type of CRBM, to autotag music. By\nsimultaneously exploiting the relationships among tags and between tags and\naudio-based features, this model is able to significantly outperform SVMs,\nlogistic regression, and multi-layer perceptrons. In order to be applied to\nthis problem, the discriminative RBM was generalized to the multi-label setting\nand four different learning algorithms for it were evaluated, the first such\nin-depth analysis of which we are aware.\n",
          "  Jerry Fodor argues that Darwin was wrong about \"natural selection\" because\n(1) it is only a tautology rather than a scientific law that can support\ncounterfactuals (\"If X had happened, Y would have happened\") and because (2)\nonly minds can select. Hence Darwin's analogy with \"artificial selection\" by\nanimal breeders was misleading and evolutionary explanation is nothing but\npost-hoc historical narrative. I argue that Darwin was right on all counts.\n",
          "  The paper studies the asymptotic behavior of Random Algebraic Riccati\nEquations (RARE) arising in Kalman filtering when the arrival of the\nobservations is described by a Bernoulli i.i.d. process. We model the RARE as\nan order-preserving, strongly sublinear random dynamical system (RDS). Under a\nsufficient condition, stochastic boundedness, and using a limit-set dichotomy\nresult for order-preserving, strongly sublinear RDS, we establish the\nasymptotic properties of the RARE: the sequence of random prediction error\ncovariance matrices converges weakly to a unique invariant distribution, whose\nsupport exhibits fractal behavior. In particular, this weak convergence holds\nunder broad conditions and even when the observations arrival rate is below the\ncritical probability for mean stability. We apply the weak-Feller property of\nthe Markov process governing the RARE to characterize the support of the\nlimiting invariant distribution as the topological closure of a countable set\nof points, which, in general, is not dense in the set of positive semi-definite\nmatrices. We use the explicit characterization of the support of the invariant\ndistribution and the almost sure ergodicity of the sample paths to easily\ncompute the moments of the invariant distribution. A one dimensional example\nillustrates that the support is a fractured subset of the non-negative reals\nwith self-similarity properties.\n",
          "  Given the ever increasing bandwidth of the visual information available to\nmany intelligent systems, it is becoming essential to endow them with a sense\nof what is worthwhile their attention and what can be safely disregarded. This\narticle presents a general mathematical framework to efficiently allocate the\navailable computational resources to process the parts of the input that are\nrelevant to solve a given perceptual problem. By this we mean to find the\nhypothesis H (i.e., the state of the world) that maximizes a function L(H),\nrepresenting how well each hypothesis \"explains\" the input. Given the large\nbandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is\ncomputationally infeasible (e.g., because it would imply checking a large\nnumber of pixels). To address this problem we propose a mathematical framework\nwith two key ingredients. The first one is a Bounding Mechanism (BM) to compute\nlower and upper bounds of L(H), for a given computational budget. These bounds\nare much cheaper to compute than L(H) itself, can be refined at any time by\nincreasing the budget allocated to a hypothesis, and are frequently enough to\ndiscard a hypothesis. To compute these bounds, we develop a novel theory of\nshapes and shape priors. The second ingredient is a Focus of Attention\nMechanism (FoAM) to select which hypothesis' bounds should be refined next,\nwith the goal of discarding non-optimal hypotheses with the least amount of\ncomputation. The proposed framework: 1) is very efficient since most hypotheses\nare discarded with minimal computation; 2) is parallelizable; 3) is guaranteed\nto find the globally optimal hypothesis; and 4) its running time depends on the\nproblem at hand, not on the bandwidth of the input. We instantiate the proposed\nframework for the problem of simultaneously estimating the class, pose, and a\nnoiseless version of a 2D shape in a 2D image.\n",
          "  Bayesian model averaging, model selection and its approximations such as BIC\nare generally statistically consistent, but sometimes achieve slower rates og\nconvergence than other methods such as AIC and leave-one-out cross-validation.\nOn the other hand, these other methods can br inconsistent. We identify the\n\"catch-up phenomenon\" as a novel explanation for the slow convergence of\nBayesian methods. Based on this analysis we define the switch distribution, a\nmodification of the Bayesian marginal distribution. We show that, under broad\nconditions,model selection and prediction based on the switch distribution is\nboth consistent and achieves optimal convergence rates, thereby resolving the\nAIC-BIC dilemma. The method is practical; we give an efficient implementation.\nThe switch distribution has a data compression interpretation, and can thus be\nviewed as a \"prequential\" or MDL method; yet it is different from the MDL\nmethods that are usually considered in the literature. We compare the switch\ndistribution to Bayes factor model selection and leave-one-out\ncross-validation.\n",
          "  We address the problem of learning in an online setting where the learner\nrepeatedly observes features, selects among a set of actions, and receives\nreward for the action taken. We provide the first efficient algorithm with an\noptimal regret. Our algorithm uses a cost sensitive classification learner as\nan oracle and has a running time $\\mathrm{polylog}(N)$, where $N$ is the number\nof classification rules among which the oracle might choose. This is\nexponentially faster than all previous algorithms that achieve optimal regret\nin this setting. Our formulation also enables us to create an algorithm with\nregret that is additive rather than multiplicative in feedback delay as in all\nprevious work.\n",
          "  Next to the shortest path distance, the second most popular distance function\nbetween vertices in a graph is the commute distance (resistance distance). For\ntwo vertices u and v, the hitting time H_{uv} is the expected time it takes a\nrandom walk to travel from u to v. The commute time is its symmetrized version\nC_{uv} = H_{uv} + H_{vu}. In our paper we study the behavior of hitting times\nand commute distances when the number n of vertices in the graph is very large.\nWe prove that as n converges to infinty, hitting times and commute distances\nconverge to expressions that do not take into account the global structure of\nthe graph at all. Namely, the hitting time H_{uv} converges to 1/d_v and the\ncommute time to 1/d_u + 1/d_v where d_u and d_v denote the degrees of vertices\nu and v. In these cases, the hitting and commute times are misleading in the\nsense that they do not provide information about the structure of the graph. We\nfocus on two major classes of random graphs: random geometric graphs (k-nearest\nneighbor graphs, epsilon-graphs, Gaussian similarity graphs) and random graphs\nwith given expected degrees (in particular, Erdos-Renyi graphs with and without\nplanted partitions)\n",
          "  We present a class of models that, via a simple construction, enables exact,\nincremental, non-parametric, polynomial-time, Bayesian inference of conditional\nmeasures. The approach relies upon creating a sequence of covers on the\nconditioning variable and maintaining a different model for each set within a\ncover. Inference remains tractable by specifying the probabilistic model in\nterms of a random walk within the sequence of covers. We demonstrate the\napproach on problems of conditional density estimation, which, to our knowledge\nis the first closed-form, non-parametric Bayesian approach to this problem.\n",
          "  We study probability distributions over free algebras of trees. Probability\ndistributions can be seen as particular (formal power) tree series [Berstel et\nal 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely\nstudied class of tree series is the class of rational (or recognizable) tree\nseries which can be defined either in an algebraic way or by means of\nmultiplicity tree automata. We argue that the algebraic representation is very\nconvenient to model probability distributions over a free algebra of trees.\nFirst, as in the string case, the algebraic representation allows to design\nlearning algorithms for the whole class of probability distributions defined by\nrational tree series. Note that learning algorithms for rational tree series\ncorrespond to learning algorithms for weighted tree automata where both the\nstructure and the weights are learned. Second, the algebraic representation can\nbe easily extended to deal with unranked trees (like XML trees where a symbol\nmay have an unbounded number of children). Both properties are particularly\nrelevant for applications: nondeterministic automata are required for the\ninference problem to be relevant (recall that Hidden Markov Models are\nequivalent to nondeterministic string automata); nowadays applications for Web\nInformation Extraction, Web Services and document processing consider unranked\ntrees.\n",
          "  We show that all non-negative submodular functions have high {\\em\nnoise-stability}. As a consequence, we obtain a polynomial-time learning\nalgorithm for this class with respect to any product distribution on\n$\\{-1,1\\}^n$ (for any constant accuracy parameter $\\epsilon$). Our algorithm\nalso succeeds in the agnostic setting. Previous work on learning submodular\nfunctions required either query access or strong assumptions about the types of\nsubmodular functions to be learned (and did not hold in the agnostic setting).\n",
          "  It is well known that text compression can be achieved by predicting the next\nsymbol in the stream of text data based on the history seen up to the current\nsymbol. The better the prediction the more skewed the conditional probability\ndistribution of the next symbol and the shorter the codeword that needs to be\nassigned to represent this next symbol. What about the opposite direction ?\nsuppose we have a black box that can compress text stream. Can it be used to\npredict the next symbol in the stream ? We introduce a criterion based on the\nlength of the compressed data and use it to predict the next symbol. We examine\nempirically the prediction error rate and its dependency on some compression\nparameters.\n",
          "  In this paper, we present a supervised learning approach to training\nsubmodular scoring functions for extractive multi-document summarization. By\ntaking a structured predicition approach, we provide a large-margin method that\ndirectly optimizes a convex relaxation of the desired performance measure. The\nlearning method applies to all submodular summarization methods, and we\ndemonstrate its effectiveness for both pairwise as well as coverage-based\nscoring functions on multiple datasets. Compared to state-of-the-art functions\nthat were tuned manually, our method significantly improves performance and\nenables high-fidelity models with numbers of parameters well beyond what could\nreasonbly be tuned by hand.\n",
          "  Graph-based representations of images have recently acquired an important\nrole for classification purposes within the context of machine learning\napproaches. The underlying idea is to consider that relevant information of an\nimage is implicitly encoded into the relationships between more basic entities\nthat compose by themselves the whole image. The classification problem is then\nreformulated in terms of an optimization problem usually solved by a\ngradient-based search procedure. Vario-eta through structure is an approximate\nsecond order stochastic optimization technique that achieves a good trade-off\nbetween speed of convergence and the computational effort required. However,\nthe robustness of this technique for large scale problems has not been yet\nassessed. In this paper we firstly provide a theoretical justification of the\nassumptions made by this optimization procedure. Secondly, a complexity\nanalysis of the algorithm is performed to prove its suitability for large scale\nlearning problems.\n",
          "  This paper discusses the knowledge integration of clinical information\nextracted from distributed medical ontology in order to ameliorate a machine\nlearning-based multi-label coding assignment system. The proposed approach is\nimplemented using a decision tree based cascade hierarchical technique on the\nuniversity hospital data for patients with Coronary Heart Disease (CHD). The\npreliminary results obtained show a satisfactory finding.\n",
          "  Classifiers are often used to detect miscreant activities. We study how an\nadversary can efficiently query a classifier to elicit information that allows\nthe adversary to evade detection at near-minimal cost. We generalize results of\nLowd and Meek (2005) to convex-inducing classifiers. We present algorithms that\nconstruct undetected instances of near-minimal cost using only polynomially\nmany queries in the dimension of the space and without reverse engineering the\ndecision boundary.\n",
          "  In statistical problems, a set of parameterized probability distributions is\nused to estimate the true probability distribution. If Fisher information\nmatrix at the true distribution is singular, then it has been left unknown what\nwe can estimate about the true distribution from random samples. In this paper,\nwe study a singular regression problem and prove a limit theorem which shows\nthe relation between the singular regression problem and two birational\ninvariants, a real log canonical threshold and a singular fluctuation. The\nobtained theorem has an important application to statistics, because it enables\nus to estimate the generalization error from the training error without any\nknowledge of the true probability distribution.\n",
          "  We study (constrained) least-squares regression as well as multiple response\nleast-squares regression and ask the question of whether a subset of the data,\na coreset, suffices to compute a good approximate solution to the regression.\nWe give deterministic, low order polynomial-time algorithms to construct such\ncoresets with approximation guarantees, together with lower bounds indicating\nthat there is not much room for improvement upon our results.\n",
          "  The literature on statistical learning for time series assumes the asymptotic\nindependence or ``mixing' of the data-generating process. These mixing\nassumptions are never tested, nor are there methods for estimating mixing rates\nfrom data. We give an estimator for the $\\beta$-mixing rate based on a single\nstationary sample path and show it is $L_1$-risk consistent.\n",
          "  We consider unsupervised crowdsourcing performance based on the model wherein\nthe responses of end-users are essentially rated according to how their\nresponses correlate with the majority of other responses to the same\nsubtasks/questions. In one setting, we consider an independent sequence of\nidentically distributed crowdsourcing assignments (meta-tasks), while in the\nother we consider a single assignment with a large number of component\nsubtasks. Both problems yield intuitive results in which the overall\nreliability of the crowd is a factor.\n",
          "  We analyze the generalization performance of a student in a model composed of\nnonlinear perceptrons: a true teacher, ensemble teachers, and the student. We\ncalculate the generalization error of the student analytically or numerically\nusing statistical mechanics in the framework of on-line learning. We treat two\nwell-known learning rules: Hebbian learning and perceptron learning. As a\nresult, it is proven that the nonlinear model shows qualitatively different\nbehaviors from the linear model. Moreover, it is clarified that Hebbian\nlearning and perceptron learning show qualitatively different behaviors from\neach other. In Hebbian learning, we can analytically obtain the solutions. In\nthis case, the generalization error monotonically decreases. The steady value\nof the generalization error is independent of the learning rate. The larger the\nnumber of teachers is and the more variety the ensemble teachers have, the\nsmaller the generalization error is. In perceptron learning, we have to\nnumerically obtain the solutions. In this case, the dynamical behaviors of the\ngeneralization error are non-monotonic. The smaller the learning rate is, the\nlarger the number of teachers is; and the more variety the ensemble teachers\nhave, the smaller the minimum value of the generalization error is.\n",
          "  Artificial Neural Network is among the most popular algorithm for supervised\nlearning. However, Neural Networks have a well-known drawback of being a \"Black\nBox\" learner that is not comprehensible to the Users. This lack of transparency\nmakes it unsuitable for many high risk tasks such as medical diagnosis that\nrequires a rational justification for making a decision. Rule Extraction\nmethods attempt to curb this limitation by extracting comprehensible rules from\na trained Network. Many such extraction algorithms have been developed over the\nyears with their respective strengths and weaknesses. They have been broadly\ncategorized into three types based on their approach to use internal model of\nthe Network. Eclectic Methods are hybrid algorithms that combine the other\napproaches to attain more performance. In this paper, we present an Eclectic\nmethod called HERETIC. Our algorithm uses Inductive Decision Tree learning\ncombined with information of the neural network structure for extracting\nlogical rules. Experiments and theoretical analysis show HERETIC to be better\nin terms of speed and performance.\n",
          "  We consider the restless multi-armed bandit (RMAB) problem with unknown\ndynamics in which a player chooses M out of N arms to play at each time. The\nreward state of each arm transits according to an unknown Markovian rule when\nit is played and evolves according to an arbitrary unknown random process when\nit is passive. The performance of an arm selection policy is measured by\nregret, defined as the reward loss with respect to the case where the player\nknows which M arms are the most rewarding and always plays the M best arms. We\nconstruct a policy with an interleaving exploration and exploitation epoch\nstructure that achieves a regret with logarithmic order when arbitrary (but\nnontrivial) bounds on certain system parameters are known. When no knowledge\nabout the system is available, we show that the proposed policy achieves a\nregret arbitrarily close to the logarithmic order. We further extend the\nproblem to a decentralized setting where multiple distributed players share the\narms without information exchange. Under both an exogenous restless model and\nan endogenous restless model, we show that a decentralized extension of the\nproposed policy preserves the logarithmic regret order as in the centralized\nsetting. The results apply to adaptive learning in various dynamic systems and\ncommunication networks, as well as financial investment.\n",
          "  In this paper, I expand Shannon's definition of entropy into a new form of\nentropy that allows integration of information from different random events.\nShannon's notion of entropy is a special case of my more general definition of\nentropy. I define probability using a so-called performance function, which is\nde facto an exponential distribution. Assuming that my general notion of\nentropy reflects the true uncertainty about a probabilistic event, I understand\nthat our perceived uncertainty differs. I claim that our perception is the\nresult of two opposing forces similar to the two famous antagonists in Chinese\nphilosophy: Yin and Yang. Based on this idea, I show that our perceived\nuncertainty matches the true uncertainty in points determined by the golden\nratio. I demonstrate that the well-known sigmoid function, which we typically\nemploy in artificial neural networks as a non-linear threshold function,\ndescribes the actual performance. Furthermore, I provide a motivation for the\ntime dilation in Einstein's Special Relativity, basically claiming that\nalthough time dilation conforms with our perception, it does not correspond to\nreality. At the end of the paper, I show how to apply this theoretical\nframework to practical applications. I present recognition rates for a pattern\nrecognition problem, and also propose a network architecture that can take\nadvantage of general entropy to solve complex decision problems.\n",
          "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n",
          "  This paper focuses on analyzing the free-riding behavior of self-interested\nusers in online communities. Hence, traditional optimization methods for\ncommunities composed of compliant users such as network utility maximization\ncannot be applied here. In our prior work, we show how social reciprocation\nprotocols can be designed in online communities which have populations\nconsisting of a continuum of users and are stationary under stochastic\npermutations. Under these assumptions, we are able to prove that users\nvoluntarily comply with the pre-determined social norms and cooperate with\nother users in the community by providing their services. In this paper, we\ngeneralize the study by analyzing the interactions of self-interested users in\nonline communities with finite populations and are not stationary. To optimize\ntheir long-term performance based on their knowledge, users adapt their\nstrategies to play their best response by solving individual stochastic control\nproblems. The best-response dynamic introduces a stochastic dynamic process in\nthe community, in which the strategies of users evolve over time. We then\ninvestigate the long-term evolution of a community, and prove that the\ncommunity will converge to stochastically stable equilibria which are stable\nagainst stochastic permutations. Understanding the evolution of a community\nprovides protocol designers with guidelines for designing social norms in which\nno user has incentives to adapt its strategy and deviate from the prescribed\nprotocol, thereby ensuring that the adopted protocol will enable the community\nto achieve the optimal social welfare.\n",
          "  In this contribution, we propose a generic online (also sometimes called\nadaptive or recursive) version of the Expectation-Maximisation (EM) algorithm\napplicable to latent variable models of independent observations. Compared to\nthe algorithm of Titterington (1984), this approach is more directly connected\nto the usual EM algorithm and does not rely on integration with respect to the\ncomplete data distribution. The resulting algorithm is usually simpler and is\nshown to achieve convergence to the stationary points of the Kullback-Leibler\ndivergence between the marginal distribution of the observation and the model\ndistribution at the optimal rate, i.e., that of the maximum likelihood\nestimator. In addition, the proposed approach is also suitable for conditional\n(or regression) models, as illustrated in the case of the mixture of linear\nregressions model.\n",
          "  It is hard to exaggerate the role of economic aggregators -- functions that\nsummarize numerous and / or heterogeneous data -- in economic models since the\nearly XX$^{th}$ century. In many cases, as witnessed by the pioneering works of\nCobb and Douglas, these functions were information quantities tailored to\neconomic theories, i.e. they were built to fit economic phenomena. In this\npaper, we look at these functions from the complementary side: information. We\nuse a recent toolbox built on top of a vast class of distortions coined by\nBregman, whose application field rivals metrics' in various subfields of\nmathematics. This toolbox makes it possible to find the quality of an\naggregator (for consumptions, prices, labor, capital, wages, etc.), from the\nstandpoint of the information it carries. We prove a rather striking result.\n  From the informational standpoint, well-known economic aggregators do belong\nto the \\textit{optimal} set. As common economic assumptions enter the analysis,\nthis large set shrinks, and it essentially ends up \\textit{exactly fitting}\neither CES, or Cobb-Douglas, or both. To summarize, in the relevant economic\ncontexts, one could not have crafted better some aggregator from the\ninformation standpoint. We also discuss global economic behaviors of optimal\ninformation aggregators in general, and present a brief panorama of the links\nbetween economic and information aggregators.\n  Keywords: Economic Aggregators, CES, Cobb-Douglas, Bregman divergences\n",
          "  Multi-task learning is a learning paradigm which seeks to improve the\ngeneralization performance of a learning task with the help of some other\nrelated tasks. In this paper, we propose a regularization formulation for\nlearning the relationships between tasks in multi-task learning. This\nformulation can be viewed as a novel generalization of the regularization\nframework for single-task learning. Besides modeling positive task correlation,\nour method, called multi-task relationship learning (MTRL), can also describe\nnegative task correlation and identify outlier tasks based on the same\nunderlying principle. Under this regularization framework, the objective\nfunction of MTRL is convex. For efficiency, we use an alternating method to\nlearn the optimal model parameters for each task as well as the relationships\nbetween tasks. We study MTRL in the symmetric multi-task learning setting and\nthen generalize it to the asymmetric setting as well. We also study the\nrelationships between MTRL and some existing multi-task learning methods.\nExperiments conducted on a toy problem as well as several benchmark data sets\ndemonstrate the effectiveness of MTRL.\n",
          "  Graphical models are widely used in scienti fic and engineering research to\nrepresent conditional independence structures between random variables. In many\ncontrolled experiments, environmental changes or external stimuli can often\nalter the conditional dependence between the random variables, and potentially\nproduce significant structural changes in the corresponding graphical models.\nTherefore, it is of great importance to be able to detect such structural\nchanges from data, so as to gain novel insights into where and how the\nstructural changes take place and help the system adapt to the new environment.\nHere we report an effective learning strategy to extract structural changes in\nGaussian graphical model using l1-regularization based convex optimization. We\ndiscuss the properties of the problem formulation and introduce an efficient\nimplementation by the block coordinate descent algorithm. We demonstrate the\nprinciple of the approach on a numerical simulation experiment, and we then\napply the algorithm to the modeling of gene regulatory networks under different\nconditions and obtain promising yet biologically plausible results.\n",
          "  We analyze the problem of distributed power allocation for orthogonal\nmultiple access channels by considering a continuous non-cooperative game whose\nstrategy space represents the users' distribution of transmission power over\nthe network's channels. When the channels are static, we find that this game\nadmits an exact potential function and this allows us to show that it has a\nunique equilibrium almost surely. Furthermore, using the game's potential\nproperty, we derive a modified version of the replicator dynamics of\nevolutionary game theory which applies to this continuous game, and we show\nthat if the network's users employ a distributed learning scheme based on these\ndynamics, then they converge to equilibrium exponentially quickly. On the other\nhand, a major challenge occurs if the channels do not remain static but\nfluctuate stochastically over time, following a stationary ergodic process. In\nthat case, the associated ergodic game still admits a unique equilibrium, but\nthe learning analysis becomes much more complicated because the replicator\ndynamics are no longer deterministic. Nonetheless, by employing results from\nthe theory of stochastic approximation, we show that users still converge to\nthe game's unique equilibrium.\n  Our analysis hinges on a game-theoretical result which is of independent\ninterest: in finite player games which admit a (possibly nonlinear) convex\npotential function, the replicator dynamics (suitably modified to account for\nnonlinear payoffs) converge to an eps-neighborhood of an equilibrium at time of\norder O(log(1/eps)).\n",
          "  The maze traversal problem (finding the shortest distance to the goal from\nany position in a maze) has been an interesting challenge in computational\nintelligence. Recent work has shown that the cellular simultaneous recurrent\nneural network (CSRN) can solve this problem for simple mazes. This thesis\nfocuses on exploiting relevant information about the maze to improve learning\nand decrease the training time for the CSRN to solve mazes. Appropriate\nvariables are identified to create useful clusters using relevant information.\nThe CSRN was next modified to allow for an additional external input. With this\nadditional input, several methods were tested and results show that clustering\nthe mazes improves the overall learning of the traversal problem for the CSRN.\n",
          "  Bayesian networks (BN) are used in a big range of applications but they have\none issue concerning parameter learning. In real application, training data are\nalways incomplete or some nodes are hidden. To deal with this problem many\nlearning parameter algorithms are suggested foreground EM, Gibbs sampling and\nRBE algorithms. In order to limit the search space and escape from local maxima\nproduced by executing EM algorithm, this paper presents a learning parameter\nalgorithm that is a fusion of EM and RBE algorithms. This algorithm\nincorporates the range of a parameter into the EM algorithm. This range is\ncalculated by the first step of RBE algorithm allowing a regularization of each\nparameter in bayesian network after the maximization step of the EM algorithm.\nThe threshold EM algorithm is applied in brain tumor diagnosis and show some\nadvantages and disadvantages over the EM algorithm.\n",
          "  A key problem in sensor networks is to decide which sensors to query when, in\norder to obtain the most useful information (e.g., for performing accurate\nprediction), subject to constraints (e.g., on power and bandwidth). In many\napplications the utility function is not known a priori, must be learned from\ndata, and can even change over time. Furthermore for large sensor networks\nsolving a centralized optimization problem to select sensors is not feasible,\nand thus we seek a fully distributed solution. In this paper, we present\nDistributed Online Greedy (DOG), an efficient, distributed algorithm for\nrepeatedly selecting sensors online, only receiving feedback about the utility\nof the selected sensors. We prove very strong theoretical no-regret guarantees\nthat apply whenever the (unknown) utility function satisfies a natural\ndiminishing returns property called submodularity. Our algorithm has extremely\nlow communication requirements, and scales well to large sensor deployments. We\nextend DOG to allow observation-dependent sensor selection. We empirically\ndemonstrate the effectiveness of our algorithm on several real-world sensing\ntasks.\n",
          "  Relational data representations have become an increasingly important topic\ndue to the recent proliferation of network datasets (e.g., social, biological,\ninformation networks) and a corresponding increase in the application of\nstatistical relational learning (SRL) algorithms to these domains. In this\narticle, we examine a range of representation issues for graph-based relational\ndata. Since the choice of relational data representation for the nodes, links,\nand features can dramatically affect the capabilities of SRL algorithms, we\nsurvey approaches and opportunities for relational representation\ntransformation designed to improve the performance of these algorithms. This\nleads us to introduce an intuitive taxonomy for data representation\ntransformations in relational domains that incorporates link transformation and\nnode transformation as symmetric representation tasks. In particular, the\ntransformation tasks for both nodes and links include (i) predicting their\nexistence, (ii) predicting their label or type, (iii) estimating their weight\nor importance, and (iv) systematically constructing their relevant features. We\nmotivate our taxonomy through detailed examples and use it to survey and\ncompare competing approaches for each of these tasks. We also discuss general\nconditions for transforming links, nodes, and features. Finally, we highlight\nchallenges that remain to be addressed.\n",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          2.9956235885620117,
          3.0212109088897705,
          4.450608730316162,
          0.5330419540405273,
          5.638114929199219,
          2.659663438796997,
          3.047762393951416,
          6.189322471618652,
          3.626628875732422,
          -0.14599496126174927,
          3.7000763416290283,
          6.223709583282471,
          2.9462616443634033,
          3.8137972354888916,
          1.4923256635665894,
          1.8251770734786987,
          1.946651577949524,
          5.670187473297119,
          -0.0359511598944664,
          5.665669918060303,
          2.391151189804077,
          4.69061279296875,
          5.017590522766113,
          -0.02602558396756649,
          1.1211695671081543,
          -0.040601834654808044,
          1.5339441299438477,
          1.120299220085144,
          1.7993392944335938,
          0.041897132992744446,
          3.7745654582977295,
          2.6603543758392334,
          2.914926290512085,
          6.5173540115356445,
          1.4976311922073364,
          0.521014928817749,
          6.13949728012085,
          2.2631378173828125,
          2.7641642093658447,
          3.1217641830444336,
          0.17785859107971191,
          1.8774391412734985,
          3.029651165008545,
          5.723890781402588,
          3.7647523880004883,
          2.6586029529571533,
          0.9278503060340881,
          0.8278005123138428,
          3.5801596641540527,
          3.2053730487823486,
          5.837580680847168,
          7.615485668182373,
          0.8831841945648193,
          5.646885871887207,
          -0.13960371911525726,
          7.17391300201416,
          3.1108975410461426,
          6.803938865661621,
          2.911379814147949,
          2.083573341369629,
          3.7610573768615723,
          0.856440007686615,
          2.880542278289795,
          5.5872483253479,
          1.4876492023468018,
          6.841555595397949,
          6.093026638031006,
          4.436948299407959,
          1.184717059135437,
          5.359246730804443,
          2.3106415271759033,
          3.5442919731140137,
          2.328249216079712,
          6.849761486053467,
          4.795476913452148,
          1.0113881826400757,
          3.902190685272217,
          1.282110571861267,
          0.7010958194732666,
          4.438206195831299,
          1.9278583526611328,
          1.1616160869598389,
          4.525816440582275,
          3.218973159790039,
          3.4254188537597656,
          2.007448434829712,
          2.522667169570923,
          0.9110832214355469,
          4.518836975097656,
          0.2722511887550354,
          5.618277072906494,
          1.1243977546691895,
          2.6408348083496094,
          1.6976609230041504,
          4.564454078674316,
          -0.41474077105522156,
          5.614255905151367,
          5.616833209991455,
          7.586686611175537,
          5.994614124298096,
          6.980339527130127,
          2.8237297534942627,
          2.798342704772949,
          4.440529823303223,
          2.962449789047241,
          3.8982508182525635,
          0.8351386785507202,
          5.189562797546387,
          5.5782270431518555,
          1.0648651123046875,
          6.162182807922363,
          -0.15312595665454865,
          6.520503044128418,
          6.430055618286133,
          6.972376346588135,
          0.04767674207687378,
          3.261753559112549,
          6.0522541999816895,
          5.4273152351379395,
          2.8541903495788574,
          6.327347755432129,
          5.914194107055664,
          6.443085670471191,
          4.7571187019348145,
          5.102616786956787,
          6.444882392883301,
          3.370474100112915,
          4.731741428375244,
          1.8599212169647217,
          3.9561269283294678,
          4.732292175292969,
          6.777977466583252,
          7.266336917877197,
          2.8845129013061523,
          2.135634422302246,
          3.777006149291992,
          2.8940939903259277,
          -0.07583492994308472,
          3.1948750019073486,
          4.679330825805664,
          1.0208964347839355,
          6.85611629486084,
          4.529149055480957,
          2.664268732070923,
          0.5304252505302429,
          4.173254013061523,
          3.4573707580566406,
          6.894221305847168,
          4.8694233894348145,
          1.165206789970398,
          2.9988629817962646,
          1.0247676372528076,
          7.698911190032959,
          2.0838420391082764,
          7.6160173416137695,
          4.103066444396973,
          5.51035737991333,
          4.191087245941162,
          5.028578758239746,
          2.0778145790100098,
          -0.9005343914031982,
          -0.6674179434776306,
          -0.15545028448104858,
          2.472698450088501,
          4.011507511138916,
          3.6766157150268555,
          1.5465466976165771,
          1.799578070640564,
          3.093730926513672,
          2.3919758796691895,
          6.271578311920166,
          3.651228904724121,
          0.18472148478031158,
          1.0452162027359009,
          1.2132905721664429,
          1.664833664894104,
          1.147322416305542,
          1.8349592685699463,
          2.8482017517089844,
          3.3308210372924805,
          2.1653847694396973,
          2.158461093902588,
          1.4815504550933838,
          0.9245539307594299,
          3.755918025970459,
          3.383542537689209,
          1.9282547235488892,
          0.9017006754875183,
          0.06205708160996437,
          1.8504078388214111,
          3.1530535221099854,
          1.8597469329833984,
          2.894366979598999,
          3.1578493118286133,
          1.2737970352172852,
          5.413146495819092,
          3.5500423908233643,
          2.1675734519958496,
          -0.4099549949169159,
          1.126150369644165,
          0.266298770904541,
          2.180582284927368,
          5.108003616333008,
          6.130173683166504,
          0.48021870851516724,
          6.068580150604248,
          2.965865135192871,
          -0.25198352336883545,
          2.25048828125,
          1.0351613759994507,
          3.970252275466919,
          0.8743463754653931,
          7.594211578369141,
          3.3130130767822266,
          3.830051898956299,
          6.162378787994385,
          3.517127275466919,
          4.423465251922607,
          1.0589808225631714,
          6.407547950744629,
          1.6392145156860352,
          -0.6613640189170837,
          3.6133766174316406,
          2.6787662506103516,
          -0.6649149656295776,
          1.8288601636886597,
          3.954488754272461,
          4.6798295974731445,
          6.030986785888672,
          6.748394966125488,
          0.9107980132102966,
          7.562384605407715,
          6.554092884063721,
          4.660435199737549,
          3.6804089546203613,
          2.3265573978424072,
          -1.1161483526229858,
          0.3242151737213135,
          5.4613494873046875,
          3.3281612396240234,
          3.6600725650787354,
          5.971618175506592,
          -0.14629846811294556,
          2.319568157196045,
          6.367534637451172,
          -0.06154182553291321,
          4.453463077545166,
          6.98071813583374,
          3.0917160511016846,
          5.456935882568359,
          3.3623127937316895,
          4.866506576538086,
          1.8781465291976929,
          2.80671763420105,
          2.1208720207214355,
          3.4074339866638184,
          3.3705368041992188,
          2.80798602104187,
          1.046428918838501,
          4.709408760070801,
          2.973129987716675,
          0.941408634185791,
          -0.1457299143075943,
          0.18722423911094666,
          3.165959596633911,
          3.622905969619751,
          -0.1220148578286171,
          1.7949796915054321,
          1.2843315601348877,
          3.024789810180664,
          -0.057099148631095886,
          0.9220813512802124,
          2.2894227504730225,
          2.1549997329711914,
          1.3807841539382935,
          3.9738082885742188,
          3.8398962020874023,
          2.192355155944824,
          1.8664298057556152,
          3.5838661193847656,
          2.965538740158081,
          3.953514814376831,
          0.02029934711754322,
          4.714170932769775,
          1.425426959991455,
          2.897343397140503,
          2.1953699588775635,
          3.375840902328491,
          1.1100678443908691,
          1.3846423625946045,
          5.747098445892334,
          2.452742576599121,
          6.970219612121582,
          1.350188136100769,
          6.407302379608154,
          4.749880313873291,
          5.49208402633667,
          1.7996031045913696,
          2.897111654281616,
          2.4953415393829346,
          1.293464183807373,
          6.434092044830322,
          3.311241388320923,
          4.576902866363525,
          4.452165126800537,
          3.651850700378418,
          1.8009289503097534,
          1.6826322078704834,
          3.386951208114624,
          6.488413333892822,
          6.248894691467285,
          2.6084976196289062,
          0.9957324266433716,
          4.440769672393799,
          6.165680885314941,
          1.4903563261032104,
          5.602365493774414,
          0.5142076015472412,
          6.096310615539551,
          -0.675301194190979,
          2.2160351276397705,
          6.112821578979492,
          3.7933855056762695,
          1.1859906911849976,
          1.7854079008102417,
          2.2707760334014893,
          4.486769676208496,
          3.8483028411865234,
          2.9961211681365967,
          -0.3950415849685669,
          3.900331497192383,
          3.3137059211730957,
          4.437224864959717,
          3.204249620437622,
          2.9195809364318848,
          2.8732826709747314,
          2.1819357872009277,
          1.4406189918518066,
          3.0778207778930664,
          3.295240879058838,
          5.898002624511719,
          2.6302623748779297,
          1.013769507408142,
          5.937549114227295,
          4.684806823730469,
          2.1315762996673584,
          2.155038833618164,
          0.9485431909561157,
          2.374408006668091,
          2.866938352584839,
          5.612273216247559,
          2.416083335876465,
          4.682765007019043,
          4.7902092933654785,
          3.462315797805786,
          5.962579727172852,
          0.12119945138692856,
          1.0131336450576782,
          4.8046650886535645,
          1.4349902868270874,
          6.393278121948242,
          2.6557750701904297,
          5.764522552490234,
          1.2083911895751953,
          6.126497745513916,
          1.0786197185516357,
          1.4521526098251343,
          4.792291164398193,
          -0.6691703796386719,
          3.694472551345825,
          6.979602813720703,
          1.9937894344329834,
          2.0190799236297607,
          3.013057231903076,
          -0.15669332444667816,
          3.448605537414551,
          2.312279462814331,
          5.339013576507568,
          0.986051082611084,
          1.820238709449768,
          3.6040029525756836,
          1.0340663194656372,
          -1.114734411239624,
          5.059301853179932,
          2.3085145950317383,
          3.2814548015594482,
          5.905754089355469,
          5.293631553649902,
          2.4227030277252197,
          1.8094656467437744,
          5.594991683959961,
          1.0301969051361084,
          4.8052544593811035,
          -0.6693919897079468,
          2.201537847518921,
          5.450066089630127,
          -0.16088201105594635,
          2.171753168106079,
          2.0003857612609863,
          2.9228720664978027,
          4.530149936676025,
          5.771688461303711,
          3.872141122817993,
          6.093749523162842,
          5.55690860748291,
          3.392745018005371,
          2.1644880771636963,
          2.881516218185425,
          3.0528969764709473,
          1.0589760541915894,
          2.1915805339813232,
          1.1386116743087769,
          4.247648239135742,
          3.7754266262054443,
          2.4080615043640137,
          4.72199010848999,
          6.140394687652588,
          4.539462566375732,
          1.1445467472076416,
          7.615569591522217,
          3.393965721130371,
          1.1449333429336548,
          7.955383777618408,
          3.237386703491211,
          2.7250475883483887,
          2.287813663482666,
          2.3724470138549805,
          7.914124965667725,
          5.993790149688721,
          3.408571720123291,
          5.570626735687256,
          1.8730319738388062,
          3.2003490924835205
         ],
         "y": [
          5.196347713470459,
          8.304542541503906,
          9.117215156555176,
          8.365882873535156,
          8.17183780670166,
          10.159570693969727,
          5.222332000732422,
          8.388571739196777,
          5.003496170043945,
          10.262049674987793,
          8.968194961547852,
          8.12845230102539,
          6.83046293258667,
          7.404335975646973,
          7.0759501457214355,
          8.141639709472656,
          9.774897575378418,
          8.642525672912598,
          7.9900054931640625,
          6.002375602722168,
          8.277876853942871,
          7.902012825012207,
          7.055088520050049,
          7.9992594718933105,
          9.883881568908691,
          7.916977882385254,
          7.062168121337891,
          7.129867076873779,
          10.84286880493164,
          6.217249870300293,
          6.977047443389893,
          10.155479431152344,
          7.282865524291992,
          8.902694702148438,
          7.548274993896484,
          10.156455039978027,
          8.04543685913086,
          7.515299320220947,
          6.113165855407715,
          8.762465476989746,
          6.67604923248291,
          7.599225044250488,
          6.946846008300781,
          5.893033504486084,
          7.153828144073486,
          7.987957954406738,
          9.582623481750488,
          8.885445594787598,
          8.42196273803711,
          5.16552734375,
          5.948421955108643,
          6.9723405838012695,
          7.394038677215576,
          6.522418975830078,
          10.274109840393066,
          6.793425559997559,
          5.339418411254883,
          8.756749153137207,
          5.7287211418151855,
          5.556108474731445,
          5.952155113220215,
          11.012091636657715,
          10.113287925720215,
          8.680342674255371,
          8.782708168029785,
          8.189972877502441,
          5.895782470703125,
          4.256814002990723,
          8.247913360595703,
          8.813858985900879,
          10.329081535339355,
          8.052900314331055,
          10.399806022644043,
          8.21471118927002,
          9.30164623260498,
          11.074800491333008,
          5.635463237762451,
          10.23746109008789,
          6.496901512145996,
          4.265375137329102,
          5.736550331115723,
          6.702545642852783,
          8.274478912353516,
          8.804059982299805,
          8.490349769592285,
          6.058743000030518,
          10.057411193847656,
          8.865201950073242,
          6.736456871032715,
          6.639907360076904,
          6.115056037902832,
          9.063630104064941,
          10.197954177856445,
          4.929150581359863,
          7.556011199951172,
          7.849650859832764,
          8.915810585021973,
          9.161989212036133,
          6.519375324249268,
          5.8263654708862305,
          6.670094966888428,
          10.132078170776367,
          5.681334495544434,
          7.643725872039795,
          6.850711345672607,
          6.046054840087891,
          9.480827331542969,
          9.474014282226562,
          7.94563102722168,
          5.623105525970459,
          5.585682392120361,
          10.254647254943848,
          8.921412467956543,
          7.172362804412842,
          6.7155537605285645,
          6.082005977630615,
          5.469600677490234,
          8.533035278320312,
          6.1732401847839355,
          5.705104827880859,
          7.16420316696167,
          5.710019111633301,
          8.272963523864746,
          8.551445960998535,
          9.482640266418457,
          6.848062038421631,
          5.323585033416748,
          8.685556411743164,
          6.8934855461120605,
          4.237746715545654,
          7.845230579376221,
          6.370862007141113,
          7.461485862731934,
          7.835325241088867,
          10.699566841125488,
          7.507195472717285,
          6.204655647277832,
          10.242122650146484,
          8.375289916992188,
          7.908102989196777,
          11.144144058227539,
          6.62351131439209,
          8.512959480285645,
          7.472808837890625,
          8.362360000610352,
          9.30740737915039,
          5.020026683807373,
          6.641069412231445,
          8.633750915527344,
          7.702320575714111,
          8.281688690185547,
          6.93922233581543,
          6.990002632141113,
          6.537841320037842,
          6.928058624267578,
          9.30316162109375,
          6.098545074462891,
          8.265976905822754,
          7.246813774108887,
          7.743066787719727,
          8.143609046936035,
          6.2042107582092285,
          10.274347305297852,
          5.609592914581299,
          5.535229206085205,
          6.313738822937012,
          10.501559257507324,
          9.443570137023926,
          7.236847877502441,
          10.272370338439941,
          6.180812835693359,
          6.376863956451416,
          6.685937881469727,
          10.906702041625977,
          9.896282196044922,
          9.073616981506348,
          9.857707023620605,
          5.9234514236450195,
          10.133733749389648,
          7.674128532409668,
          7.634860515594482,
          5.356631278991699,
          7.6539716720581055,
          9.567051887512207,
          7.197585582733154,
          6.621525287628174,
          8.134608268737793,
          8.92091178894043,
          7.8610076904296875,
          10.810781478881836,
          8.50417709350586,
          10.786368370056152,
          6.224973678588867,
          7.263691425323486,
          11.244028091430664,
          9.315839767456055,
          8.180702209472656,
          5.471176624298096,
          7.870021820068359,
          10.490741729736328,
          6.688127517700195,
          5.495193958282471,
          7.100521564483643,
          8.066614151000977,
          8.375177383422852,
          5.602722644805908,
          8.310099601745605,
          10.838501930236816,
          7.307607650756836,
          10.486141204833984,
          5.556159496307373,
          9.600669860839844,
          6.378769397735596,
          5.520824909210205,
          8.99681568145752,
          6.8943939208984375,
          9.735702514648438,
          7.642894268035889,
          9.102073669433594,
          7.856138706207275,
          10.864447593688965,
          6.202601909637451,
          4.996486186981201,
          7.431754112243652,
          6.206671714782715,
          8.111201286315918,
          5.5765862464904785,
          7.639490127563477,
          5.786852836608887,
          6.712586879730225,
          8.864490509033203,
          6.3800578117370605,
          7.3337554931640625,
          8.34280014038086,
          8.61381721496582,
          10.325335502624512,
          8.135066986083984,
          6.23175573348999,
          6.115193843841553,
          7.6213836669921875,
          8.377159118652344,
          5.826250076293945,
          10.253007888793945,
          9.05091667175293,
          8.94118595123291,
          7.990659713745117,
          7.615762710571289,
          8.064984321594238,
          8.546947479248047,
          9.269146919250488,
          7.70780611038208,
          8.541839599609375,
          10.789227485656738,
          7.037775993347168,
          7.171902656555176,
          6.617220878601074,
          8.779010772705078,
          5.699925899505615,
          9.956665992736816,
          7.8604536056518555,
          7.5984907150268555,
          8.81571102142334,
          10.274162292480469,
          6.646865367889404,
          8.386258125305176,
          5.00860595703125,
          10.754249572753906,
          7.017215728759766,
          11.221131324768066,
          8.386842727661133,
          6.809785842895508,
          8.803620338439941,
          8.857134819030762,
          5.370882511138916,
          11.073301315307617,
          5.576244354248047,
          6.0724382400512695,
          8.440742492675781,
          7.379150867462158,
          8.56557846069336,
          5.285337448120117,
          9.680509567260742,
          6.184959888458252,
          8.60984992980957,
          9.0598783493042,
          6.05505895614624,
          5.435589790344238,
          7.7058563232421875,
          9.05759334564209,
          9.1879243850708,
          7.711121082305908,
          4.815347671508789,
          8.089428901672363,
          9.151359558105469,
          7.865723133087158,
          7.70443058013916,
          9.187437057495117,
          4.827102184295654,
          8.962300300598145,
          7.671379566192627,
          11.25115966796875,
          8.32177734375,
          8.760483741760254,
          8.514147758483887,
          4.252200603485107,
          9.334892272949219,
          5.839832782745361,
          6.89801549911499,
          6.607325553894043,
          6.110245704650879,
          7.7697930335998535,
          7.68522310256958,
          6.392327785491943,
          4.255175590515137,
          8.376547813415527,
          5.1662726402282715,
          8.11238956451416,
          6.945420265197754,
          7.799562454223633,
          6.191928863525391,
          8.31886100769043,
          5.644815444946289,
          7.539116859436035,
          11.15336799621582,
          7.943811893463135,
          7.971035480499268,
          7.6278605461120605,
          6.066684722900391,
          8.305100440979004,
          8.21216106414795,
          8.419464111328125,
          8.246268272399902,
          4.253869533538818,
          8.457221984863281,
          5.259183406829834,
          7.271439075469971,
          5.7014312744140625,
          7.512226104736328,
          7.37017297744751,
          5.086460590362549,
          8.204144477844238,
          6.3041205406188965,
          10.480598449707031,
          8.22739315032959,
          7.89368200302124,
          6.180963516235352,
          5.338718414306641,
          6.497033596038818,
          5.6338419914245605,
          10.125265121459961,
          5.921532154083252,
          10.449499130249023,
          7.905904769897461,
          9.305924415588379,
          6.702528953552246,
          8.08920955657959,
          7.816520690917969,
          6.638365745544434,
          9.290133476257324,
          7.83180046081543,
          8.128954887390137,
          10.171795845031738,
          9.159944534301758,
          9.941356658935547,
          5.626399040222168,
          6.94321346282959,
          7.669906139373779,
          9.316232681274414,
          6.202211856842041,
          9.25515365600586,
          8.101421356201172,
          7.339570999145508,
          5.6745758056640625,
          7.597046375274658,
          10.258373260498047,
          8.640088081359863,
          5.286929130554199,
          9.347554206848145,
          8.552894592285156,
          9.610494613647461,
          4.994255065917969,
          5.601784706115723,
          8.105572700500488,
          9.801254272460938,
          7.576119899749756,
          6.569876670837402,
          5.875538349151611,
          6.720311641693115,
          5.681260108947754,
          9.614028930664062,
          8.220118522644043,
          9.94357967376709,
          7.76990270614624,
          6.202075958251953,
          5.620358467102051,
          9.408120155334473,
          7.55993127822876,
          7.4938249588012695,
          6.633033275604248,
          7.164239883422852,
          7.6482415199279785,
          5.979957580566406,
          6.162403106689453,
          8.101723670959473,
          8.089808464050293,
          5.184152126312256,
          7.121623516082764,
          10.121637344360352,
          7.645003795623779,
          5.631424427032471,
          7.523839950561523,
          7.062560558319092,
          9.292264938354492,
          7.217498779296875,
          10.35983943939209,
          8.583921432495117,
          8.063220024108887,
          8.53133773803711,
          7.133708477020264,
          6.933459758758545,
          7.694305419921875,
          8.470094680786133,
          6.742509365081787,
          6.574065685272217,
          10.303498268127441,
          9.04098892211914,
          5.273548126220703,
          6.715933799743652,
          5.835231781005859,
          5.576539039611816,
          8.817405700683594,
          5.875072956085205,
          7.714720726013184
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Although the real reproducing kernels are used in an increasing number of\nmachine learning problems, complex kernels have not, yet, been used, in spite\nof their potential interest in applications such as communications. In this\nwork, we focus our attention on the complex gaussian kernel and its possible\napplication in the complex Kernel LMS algorithm. In order to derive the\ngradients needed to develop the complex kernel LMS (CKLMS), we employ the\npowerful tool of Wirtinger's Calculus, which has recently attracted much\nattention in the signal processing community. Writinger's calculus simplifies\ncomputations and offers an elegant tool for treating complex signals. To this\nend, the notion of Writinger's calculus is extended to include complex RKHSs.\nExperiments verify that the CKLMS offers significant performance improvements\nover the traditional complex LMS or Widely Linear complex LMS (WL-LMS)\nalgorithms, when dealing with nonlinearities.\n",
          "  Transportation distances have been used for more than a decade now in machine\nlearning to compare histograms of features. They have one parameter: the ground\nmetric, which can be any metric between the features themselves. As is the case\nfor all parameterized distances, transportation distances can only prove useful\nin practice when this parameter is carefully chosen. To date, the only option\navailable to practitioners to set the ground metric parameter was to rely on a\npriori knowledge of the features, which limited considerably the scope of\napplication of transportation distances. We propose to lift this limitation and\nconsider instead algorithms that can learn the ground metric using only a\ntraining set of labeled histograms. We call this approach ground metric\nlearning. We formulate the problem of learning the ground metric as the\nminimization of the difference of two polyhedral convex functions over a convex\nset of distance matrices. We follow the presentation of our algorithms with\npromising experimental results on binary classification tasks using GIST\ndescriptors of images taken in the Caltech-256 set.\n",
          "  Subgradient algorithms for training support vector machines have been quite\nsuccessful for solving large-scale and online learning problems. However, they\nhave been restricted to linear kernels and strongly convex formulations. This\npaper describes efficient subgradient approaches without such limitations. Our\napproaches make use of randomized low-dimensional approximations to nonlinear\nkernels, and minimization of a reduced primal formulation using an algorithm\nbased on robust stochastic approximation, which do not require strong\nconvexity. Experiments illustrate that our approaches produce solutions of\ncomparable prediction accuracy with the solutions acquired from existing SVM\nsolvers, but often in much shorter time. We also suggest efficient prediction\nschemes that depend only on the dimension of kernel approximation, not on the\nnumber of support vectors.\n",
          "  For a variety of regularized optimization problems in machine learning,\nalgorithms computing the entire solution path have been developed recently.\nMost of these methods are quadratic programs that are parameterized by a single\nparameter, as for example the Support Vector Machine (SVM). Solution path\nalgorithms do not only compute the solution for one particular value of the\nregularization parameter but the entire path of solutions, making the selection\nof an optimal parameter much easier.\n  It has been assumed that these piecewise linear solution paths have only\nlinear complexity, i.e. linearly many bends. We prove that for the support\nvector machine this complexity can be exponential in the number of training\npoints in the worst case. More strongly, we construct a single instance of n\ninput points in d dimensions for an SVM such that at least \\Theta(2^{n/2}) =\n\\Theta(2^d) many distinct subsets of support vectors occur as the\nregularization parameter changes.\n",
          "  In this work we present a quadratic programming approximation of the\nSemi-Supervised Support Vector Machine (S3VM) problem, namely approximate\nQP-S3VM, that can be efficiently solved using off the shelf optimization\npackages. We prove that this approximate formulation establishes a relation\nbetween the low density separation and the graph-based models of\nsemi-supervised learning (SSL) which is important to develop a unifying\nframework for semi-supervised learning methods. Furthermore, we propose the\nnovel idea of representing SSL problems as submodular set functions and use\nefficient submodular optimization algorithms to solve them. Using this new idea\nwe develop a representation of the approximate QP-S3VM as a maximization of a\nsubmodular set function which makes it possible to optimize using efficient\ngreedy algorithms. We demonstrate that the proposed methods are accurate and\nprovide significant improvement in time complexity over the state of the art in\nthe literature.\n",
          "  Often, high dimensional data lie close to a low-dimensional submanifold and\nit is of interest to understand the geometry of these submanifolds. The\nhomology groups of a manifold are important topological invariants that provide\nan algebraic summary of the manifold. These groups contain rich topological\ninformation, for instance, about the connected components, holes, tunnels and\nsometimes the dimension of the manifold. In this paper, we consider the\nstatistical problem of estimating the homology of a manifold from noisy samples\nunder several different noise models. We derive upper and lower bounds on the\nminimax risk for this problem. Our upper bounds are based on estimators which\nare constructed from a union of balls of appropriate radius around carefully\nselected points. In each case we establish complementary lower bounds using Le\nCam's lemma.\n",
          "  We propose a method for support vector machine classification using\nindefinite kernels. Instead of directly minimizing or stabilizing a nonconvex\nloss function, our algorithm simultaneously computes support vectors and a\nproxy kernel matrix used in forming the loss. This can be interpreted as a\npenalized kernel learning problem where indefinite kernel matrices are treated\nas a noisy observations of a true Mercer kernel. Our formulation keeps the\nproblem convex and relatively large problems can be solved efficiently using\nthe projected gradient or analytic center cutting plane methods. We compare the\nperformance of our technique with other methods on several classic data sets.\n",
          "  We find lower and upper bounds for the risk of estimating a manifold in\nHausdorff distance under several models. We also show that there are close\nconnections between manifold estimation and the problem of deconvolving a\nsingular measure.\n",
          "  This paper generalizes the traditional statistical concept of prediction\nintervals for arbitrary probability density functions in high-dimensional\nfeature spaces by introducing significance level distributions, which provides\ninterval-independent probabilities for continuous random variables. The\nadvantage of the transformation of a probability density function into a\nsignificance level distribution is that it enables one-class classification or\noutlier detection in a direct manner.\n",
          "  Approximations based on random Fourier features have recently emerged as an\nefficient and formally consistent methodology to design large-scale kernel\nmachines. By expressing the kernel as a Fourier expansion, features are\ngenerated based on a finite set of random basis projections, sampled from the\nFourier transform of the kernel, with inner products that are Monte Carlo\napproximations of the original kernel. Based on the observation that different\nkernel-induced Fourier sampling distributions correspond to different kernel\nparameters, we show that an optimization process in the Fourier domain can be\nused to identify the different frequency bands that are useful for prediction\non training data. Moreover, the application of group Lasso to random feature\nvectors corresponding to a linear combination of multiple kernels, leads to\nefficient and scalable reformulations of the standard multiple kernel learning\nmodel \\cite{Varma09}. In this paper we develop the linear Fourier approximation\nmethodology for both single and multiple gradient-based kernel learning and\nshow that it produces fast and accurate predictors on a complex dataset such as\nthe Visual Object Challenge 2011 (VOC2011).\n",
          "  The analysis of physiological processes over time are often given by\nspectrometric or gene expression profiles over time with only few time points\nbut a large number of measured variables. The analysis of such temporal\nsequences is challenging and only few methods have been proposed. The\ninformation can be encoded time independent, by means of classical expression\ndifferences for a single time point or in expression profiles over time.\nAvailable methods are limited to unsupervised and semi-supervised settings. The\npredictive variables can be identified only by means of wrapper or\npost-processing techniques. This is complicated due to the small number of\nsamples for such studies. Here, we present a supervised learning approach,\ntermed Supervised Topographic Mapping Through Time (SGTM-TT). It learns a\nsupervised mapping of the temporal sequences onto a low dimensional grid. We\nutilize a hidden markov model (HMM) to account for the time domain and\nrelevance learning to identify the relevant feature dimensions most predictive\nover time. The learned mapping can be used to visualize the temporal sequences\nand to predict the class of a new sequence. The relevance learning permits the\nidentification of discriminating masses or gen expressions and prunes\ndimensions which are unnecessary for the classification task or encode mainly\nnoise. In this way we obtain a very efficient learning system for temporal\nsequences. The results indicate that using simultaneous supervised learning and\nmetric adaptation significantly improves the prediction accuracy for\nsynthetically and real life data in comparison to the standard techniques. The\ndiscriminating features, identified by relevance learning, compare favorably\nwith the results of alternative methods. Our method permits the visualization\nof the data on a low dimensional grid, highlighting the observed temporal\nstructure.\n",
          "  We propose a focus of attention mechanism to speed up the Perceptron\nalgorithm. Focus of attention speeds up the Perceptron algorithm by lowering\nthe number of features evaluated throughout training and prediction. Whereas\nthe traditional Perceptron evaluates all the features of each example, the\nAttentive Perceptron evaluates less features for easy to classify examples,\nthereby achieving significant speedups and small losses in prediction accuracy.\nFocus of attention allows the Attentive Perceptron to stop the evaluation of\nfeatures at any interim point and filter the example. This creates an attentive\nfilter which concentrates computation at examples that are hard to classify,\nand quickly filters examples that are easy to classify.\n",
          "  Targeting at sparse learning, we construct Banach spaces B of functions on an\ninput space X with the properties that (1) B possesses an l1 norm in the sense\nthat it is isometrically isomorphic to the Banach space of integrable functions\non X with respect to the counting measure; (2) point evaluations are continuous\nlinear functionals on B and are representable through a bilinear form with a\nkernel function; (3) regularized learning schemes on B satisfy the linear\nrepresenter theorem. Examples of kernel functions admissible for the\nconstruction of such spaces are given.\n",
          "  This paper presents a kernel-based discriminative learning framework on\nprobability measures. Rather than relying on large collections of vectorial\ntraining examples, our framework learns using a collection of probability\ndistributions that have been constructed to meaningfully represent training\ndata. By representing these probability distributions as mean embeddings in the\nreproducing kernel Hilbert space (RKHS), we are able to apply many standard\nkernel-based learning techniques in straightforward fashion. To accomplish\nthis, we construct a generalization of the support vector machine (SVM) called\na support measure machine (SMM). Our analyses of SMMs provides several insights\ninto their relationship to traditional SVMs. Based on such insights, we propose\na flexible SVM (Flex-SVM) that places different kernel functions on each\ntraining example. Experimental results on both synthetic and real-world data\ndemonstrate the effectiveness of our proposed framework.\n",
          "  Signal Sequence Labeling consists in predicting a sequence of labels given an\nobserved sequence of samples. A naive way is to filter the signal in order to\nreduce the noise and to apply a classification algorithm on the filtered\nsamples. We propose in this paper to jointly learn the filter with the\nclassifier leading to a large margin filtering for classification. This method\nallows to learn the optimal cutoff frequency and phase of the filter that may\nbe different from zero. Two methods are proposed and tested on a toy dataset\nand on a real life BCI dataset from BCI Competition III.\n",
          "  We present a novel approach to learn a kernel-based regression function. It\nis based on the useof conical combinations of data-based parameterized kernels\nand on a new stochastic convex optimization procedure of which we establish\nconvergence guarantees. The overall learning procedure has the nice properties\nthat a) the learned conical combination is automatically designed to perform\nthe regression task at hand and b) the updates implicated by the optimization\nprocedure are quite inexpensive. In order to shed light on the appositeness of\nour learning strategy, we present empirical results from experiments conducted\non various benchmark datasets.\n",
          "  We present a framework for discriminative sequence classification where the\nlearner works directly in the high dimensional predictor space of all\nsubsequences in the training set. This is possible by employing a new\ncoordinate-descent algorithm coupled with bounding the magnitude of the\ngradient for selecting discriminative subsequences fast. We characterize the\nloss functions for which our generic learning algorithm can be applied and\npresent concrete implementations for logistic regression (binomial\nlog-likelihood loss) and support vector machines (squared hinge loss).\nApplication of our algorithm to protein remote homology detection and remote\nfold recognition results in performance comparable to that of state-of-the-art\nmethods (e.g., kernel support vector machines). Unlike state-of-the-art\nclassifiers, the resulting classification models are simply lists of weighted\ndiscriminative subsequences and can thus be interpreted and related to the\nbiological problem.\n",
          "  Degrading performance of indexing schemes for exact similarity search in high\ndimensions has long since been linked to histograms of distributions of\ndistances and other 1-Lipschitz functions getting concentrated. We discuss this\nobservation in the framework of the phenomenon of concentration of measure on\nthe structures of high dimension and the Vapnik-Chervonenkis theory of\nstatistical learning.\n",
          "  This paper presents regression models obtained from a process of blind\nprediction of peptide binding affinity from provided descriptors for several\ndistinct datasets as part of the 2006 Comparative Evaluation of Prediction\nAlgorithms (COEPRA) contest. This paper finds that kernel partial least\nsquares, a nonlinear partial least squares (PLS) algorithm, outperforms PLS,\nand that the incorporation of transferable atom equivalent features improves\npredictive capability.\n",
          "  In manifold learning, algorithms based on graph Laplacians constructed from\ndata have received considerable attention both in practical applications and\ntheoretical analysis. In particular, the convergence of graph Laplacians\nobtained from sampled data to certain continuous operators has become an active\nresearch topic recently. Most of the existing work has been done under the\nassumption that the data is sampled from a manifold without boundary or that\nthe functions of interests are evaluated at a point away from the boundary.\nHowever, the question of boundary behavior is of considerable practical and\ntheoretical interest. In this paper we provide an analysis of the behavior of\ngraph Laplacians at a point near or on the boundary, discuss their convergence\nrates and their implications and provide some numerical results. It turns out\nthat while points near the boundary occupy only a small part of the total\nvolume of a manifold, the behavior of graph Laplacian there has different\nscaling properties from its behavior elsewhere on the manifold, with global\neffects on the whole manifold, an observation with potentially important\nimplications for the general problem of learning on manifolds.\n",
          "  Let $\\XX$ be a compact, smooth, connected, Riemannian manifold without\nboundary, $G:\\XX\\times\\XX\\to \\RR$ be a kernel. Analogous to a radial basis\nfunction network, an eignet is an expression of the form $\\sum_{j=1}^M\na_jG(\\circ,y_j)$, where $a_j\\in\\RR$, $y_j\\in\\XX$, $1\\le j\\le M$. We describe a\ndeterministic, universal algorithm for constructing an eignet for approximating\nfunctions in $L^p(\\mu;\\XX)$ for a general class of measures $\\mu$ and kernels\n$G$. Our algorithm yields linear operators. Using the minimal separation\namongst the centers $y_j$ as the cost of approximation, we give modulus of\nsmoothness estimates for the degree of approximation by our eignets, and show\nby means of a converse theorem that these are the best possible for every\n\\emph{individual function}. We also give estimates on the coefficients $a_j$ in\nterms of the norm of the eignet. Finally, we demonstrate that if any sequence\nof eignets satisfies the optimal estimates for the degree of approximation of a\nsmooth function, measured in terms of the minimal separation, then the\nderivatives of the eignets also approximate the corresponding derivatives of\nthe target function in an optimal manner.\n",
          "  For supervised and unsupervised learning, positive definite kernels allow to\nuse large and potentially infinite dimensional feature spaces with a\ncomputational cost that only depends on the number of observations. This is\nusually done through the penalization of predictor functions by Euclidean or\nHilbertian norms. In this paper, we explore penalizing by sparsity-inducing\nnorms such as the l1-norm or the block l1-norm. We assume that the kernel\ndecomposes into a large sum of individual basis kernels which can be embedded\nin a directed acyclic graph; we show that it is then possible to perform kernel\nselection through a hierarchical multiple kernel learning framework, in\npolynomial time in the number of selected kernels. This framework is naturally\napplied to non linear variable selection; our extensive simulations on\nsynthetic datasets and datasets from the UCI repository show that efficiently\nexploring the large feature space through sparsity-inducing norms leads to\nstate-of-the-art predictive performance.\n",
          "  We extend the herding algorithm to continuous spaces by using the kernel\ntrick. The resulting \"kernel herding\" algorithm is an infinite memory\ndeterministic process that learns to approximate a PDF with a collection of\nsamples. We show that kernel herding decreases the error of expectations of\nfunctions in the Hilbert space at a rate O(1/T) which is much faster than the\nusual O(1/pT) for iid random samples. We illustrate kernel herding by\napproximating Bayesian predictive distributions.\n",
          "  This paper examines the problem of learning with a finite and possibly large\nset of p base kernels. It presents a theoretical and empirical analysis of an\napproach addressing this problem based on ensembles of kernel predictors. This\nincludes novel theoretical guarantees based on the Rademacher complexity of the\ncorresponding hypothesis sets, the introduction and analysis of a learning\nalgorithm based on these hypothesis sets, and a series of experiments using\nensembles of kernel predictors with several data sets. Both convex combinations\nof kernel-based hypotheses and more general Lq-regularized nonnegative\ncombinations are analyzed. These theoretical, algorithmic, and empirical\nresults are compared with those achieved by using learning kernel techniques,\nwhich can be viewed as another approach for solving the same problem.\n",
          "  Recently, a unified framework for adaptive kernel based signal processing of\ncomplex data was presented by the authors, which, besides offering techniques\nto map the input data to complex Reproducing Kernel Hilbert Spaces, developed a\nsuitable Wirtinger-like Calculus for general Hilbert Spaces. In this short\npaper, the extended Wirtinger's calculus is adopted to derive complex\nkernel-based widely-linear estimation filters. Furthermore, we illuminate\nseveral important characteristics of the widely linear filters. We show that,\nalthough in many cases the gains from adopting widely linear estimation\nfilters, as alternatives to ordinary linear ones, are rudimentary, for the case\nof kernel based widely linear filters significant performance improvements can\nbe obtained.\n",
          "  In this paper, we first demonstrate that b-bit minwise hashing, whose\nestimators are positive definite kernels, can be naturally integrated with\nlearning algorithms such as SVM and logistic regression. We adopt a simple\nscheme to transform the nonlinear (resemblance) kernel into linear (inner\nproduct) kernel; and hence large-scale problems can be solved extremely\nefficiently. Our method provides a simple effective solution to large-scale\nlearning in massive and extremely high-dimensional datasets, especially when\ndata do not fit in memory.\n  We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm\n(which is related the Count-Min (CM) sketch). Interestingly, VW has the same\nvariances as random projections. Our theoretical and empirical comparisons\nillustrate that usually $b$-bit minwise hashing is significantly more accurate\n(at the same storage) than VW (and random projections) in binary data.\nFurthermore, $b$-bit minwise hashing can be combined with VW to achieve further\nimprovements in terms of training speed, especially when $b$ is large.\n",
          "  Isometric feature mapping (Isomap) is a promising manifold learning method.\nHowever, Isomap fails to work on data which distribute on clusters in a single\nmanifold or manifolds. Many works have been done on extending Isomap to\nmulti-manifolds learning. In this paper, we first proposed a new\nmulti-manifolds learning algorithm (M-Isomap) with help of a general procedure.\nThe new algorithm preserves intra-manifold geodesics and multiple\ninter-manifolds edges precisely. Compared with previous methods, this algorithm\ncan isometrically learn data distributed on several manifolds. Secondly, the\noriginal multi-cluster manifold learning algorithm first proposed in\n\\cite{DCIsomap} and called D-C Isomap has been revised so that the revised D-C\nIsomap can learn multi-manifolds data. Finally, the features and effectiveness\nof the proposed multi-manifolds learning algorithms are demonstrated and\ncompared through experiments.\n",
          "  Metrics specifying distances between data points can be learned in a\ndiscriminative manner or from generative models. In this paper, we show how to\nunify generative and discriminative learning of metrics via a kernel learning\nframework. Specifically, we learn local metrics optimized from parametric\ngenerative models. These are then used as base kernels to construct a global\nkernel that minimizes a discriminative training criterion. We consider both\nlinear and nonlinear combinations of local metric kernels. Our empirical\nresults show that these combinations significantly improve performance on\nclassification tasks. The proposed learning algorithm is also very efficient,\nachieving order of magnitude speedup in training time compared to previous\ndiscriminative baseline methods.\n",
          "  We investigate a recently proposed family of positive-definite kernels that\nmimic the computation in large neural networks. We examine the properties of\nthese kernels using tools from differential geometry; specifically, we analyze\nthe geometry of surfaces in Hilbert space that are induced by these kernels.\nWhen this geometry is described by a Riemannian manifold, we derive results for\nthe metric, curvature, and volume element. Interestingly, though, we find that\nthe simplest kernel in this family does not admit such an interpretation. We\nexplore two variations of these kernels that mimic computation in neural\nnetworks with different activation functions. We experiment with these new\nkernels on several data sets and highlight their general trends in performance\nfor classification.\n",
          "  Over the last decade, kernel methods for nonlinear processing have\nsuccessfully been used in the machine learning community. The primary\nmathematical tool employed in these methods is the notion of the Reproducing\nKernel Hilbert Space. However, so far, the emphasis has been on batch\ntechniques. It is only recently, that online techniques have been considered in\nthe context of adaptive signal processing tasks. Moreover, these efforts have\nonly been focussed on real valued data sequences. To the best of our knowledge,\nno adaptive kernel-based strategy has been developed, so far, for complex\nvalued signals. Furthermore, although the real reproducing kernels are used in\nan increasing number of machine learning problems, complex kernels have not,\nyet, been used, in spite of their potential interest in applications that deal\nwith complex signals, with Communications being a typical example. In this\npaper, we present a general framework to attack the problem of adaptive\nfiltering of complex signals, using either real reproducing kernels, taking\nadvantage of a technique called \\textit{complexification} of real RKHSs, or\ncomplex reproducing kernels, highlighting the use of the complex gaussian\nkernel. In order to derive gradients of operators that need to be defined on\nthe associated complex RKHSs, we employ the powerful tool of Wirtinger's\nCalculus, which has recently attracted attention in the signal processing\ncommunity. To this end, in this paper, the notion of Wirtinger's calculus is\nextended, for the first time, to include complex RKHSs and use it to derive\nseveral realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm.\nExperiments verify that the CKLMS offers significant performance improvements\nover several linear and nonlinear algorithms, when dealing with nonlinearities.\n",
          "  We provide a simple method and relevant theoretical analysis for efficiently\nestimating higher-order lp distances. While the analysis mainly focuses on l4,\nour methodology extends naturally to p = 6,8,10..., (i.e., when p is even).\nDistance-based methods are popular in machine learning. In large-scale\napplications, storing, computing, and retrieving the distances can be both\nspace and time prohibitive. Efficient algorithms exist for estimating lp\ndistances if 0 < p <= 2. The task for p > 2 is known to be difficult. Our work\npartially fills this gap.\n",
          "  We identify the classical Perceptron algorithm with margin as a member of a\nbroader family of large margin classifiers which we collectively call the\nMargitron. The Margitron, (despite its) sharing the same update rule with the\nPerceptron, is shown in an incremental setting to converge in a finite number\nof updates to solutions possessing any desirable fraction of the maximum\nmargin. Experiments comparing the Margitron with decomposition SVMs on tasks\ninvolving linear kernels and 2-norm soft margin are also reported.\n",
          "  We consider the problem of positioning a cloud of points in the Euclidean\nspace $\\mathbb{R}^d$, using noisy measurements of a subset of pairwise\ndistances. This task has applications in various areas, such as sensor network\nlocalization and reconstruction of protein conformations from NMR measurements.\nAlso, it is closely related to dimensionality reduction problems and manifold\nlearning, where the goal is to learn the underlying global geometry of a data\nset using local (or partial) metric information. Here we propose a\nreconstruction algorithm based on semidefinite programming. For a random\ngeometric graph model and uniformly bounded noise, we provide a precise\ncharacterization of the algorithm's performance: In the noiseless case, we find\na radius $r_0$ beyond which the algorithm reconstructs the exact positions (up\nto rigid transformations). In the presence of noise, we obtain upper and lower\nbounds on the reconstruction error that match up to a factor that depends only\non the dimension $d$, and the average degree of the nodes in the graph.\n",
          "  We present multiplicative updates for solving hard and soft margin support\nvector machines (SVM) with non-negative kernels. They follow as a natural\nextension of the updates for non-negative matrix factorization. No additional\nparam- eter setting, such as choosing learning, rate is required. Ex- periments\ndemonstrate rapid convergence to good classifiers. We analyze the rates of\nasymptotic convergence of the up- dates and establish tight bounds. We test the\nperformance on several datasets using various non-negative kernels and report\nequivalent generalization errors to that of a standard SVM.\n",
          "  Estimating intrinsic dimensionality of data is a classic problem in pattern\nrecognition and statistics. Principal Component Analysis (PCA) is a powerful\ntool in discovering dimensionality of data sets with a linear structure; it,\nhowever, becomes ineffective when data have a nonlinear structure. In this\npaper, we propose a new PCA-based method to estimate intrinsic dimension of\ndata with nonlinear structures. Our method works by first finding a minimal\ncover of the data set, then performing PCA locally on each subset in the cover\nand finally giving the estimation result by checking up the data variance on\nall small neighborhood regions. The proposed method utilizes the whole data set\nto estimate its intrinsic dimension and is convenient for incremental learning.\nIn addition, our new PCA procedure can filter out noise in data and converge to\na stable estimation with the neighborhood region size increasing. Experiments\non synthetic and real world data sets show effectiveness of the proposed\nmethod.\n",
          "  The success of kernel-based learning methods depend on the choice of kernel.\nRecently, kernel learning methods have been proposed that use data to select\nthe most appropriate kernel, usually by combining a set of base kernels. We\nintroduce a new algorithm for kernel learning that combines a {\\em continuous\nset of base kernels}, without the common step of discretizing the space of base\nkernels. We demonstrate that our new method achieves state-of-the-art\nperformance across a variety of real-world datasets. Furthermore, we explicitly\ndemonstrate the importance of combining the right dictionary of kernels, which\nis problematic for methods based on a finite set of base kernels chosen a\npriori. Our method is not the first approach to work with continuously\nparameterized kernels. However, we show that our method requires substantially\nless computation than previous such approaches, and so is more amenable to\nmultiple dimensional parameterizations of base kernels, which we demonstrate.\n",
          "  We revisit the additive model learning literature and adapt a penalized\nspline formulation due to Eilers and Marx, to train additive classifiers\nefficiently. We also propose two new embeddings based two classes of orthogonal\nbasis with orthogonal derivatives, which can also be used to efficiently learn\nadditive classifiers. This paper follows the popular theme in the current\nliterature where kernel SVMs are learned much more efficiently using a\napproximate embedding and linear machine. In this paper we show that spline\nbasis are especially well suited for learning additive models because of their\nsparsity structure and the ease of computing the embedding which enables one to\ntrain these models in an online manner, without incurring the memory overhead\nof precomputing the storing the embeddings. We show interesting connections\nbetween B-Spline basis and histogram intersection kernel and show that for a\nparticular choice of regularization and degree of the B-Splines, our proposed\nlearning algorithm closely approximates the histogram intersection kernel SVM.\nThis enables one to learn additive models with almost no memory overhead\ncompared to fast a linear solver, such as LIBLINEAR, while being only 5-6X\nslower on average. On two large scale image classification datasets, MNIST and\nDaimler Chrysler pedestrians, the proposed additive classifiers are as accurate\nas the kernel SVM, while being two orders of magnitude faster to train.\n",
          "  Using a support vector machine requires to set two types of hyperparameters:\nthe soft margin parameter C and the parameters of the kernel. To perform this\nmodel selection task, the method of choice is cross-validation. Its\nleave-one-out variant is known to produce an estimator of the generalization\nerror which is almost unbiased. Its major drawback rests in its time\nrequirement. To overcome this difficulty, several upper bounds on the\nleave-one-out error of the pattern recognition SVM have been derived. Among\nthose bounds, the most popular one is probably the radius-margin bound. It\napplies to the hard margin pattern recognition SVM, and by extension to the\n2-norm SVM. In this report, we introduce a quadratic loss M-SVM, the M-SVM^2,\nas a direct extension of the 2-norm SVM to the multi-class case. For this\nmachine, a generalized radius-margin bound is then established.\n",
          "  We consider a general class of regularization methods which learn a vector of\nparameters on the basis of linear measurements. It is well known that if the\nregularizer is a nondecreasing function of the inner product then the learned\nvector is a linear combination of the input data. This result, known as the\n{\\em representer theorem}, is at the basis of kernel-based methods in machine\nlearning. In this paper, we prove the necessity of the above condition, thereby\ncompleting the characterization of kernel methods based on regularization. We\nfurther extend our analysis to regularization methods which learn a matrix, a\nproblem which is motivated by the application to multi-task learning. In this\ncontext, we study a more general representer theorem, which holds for a larger\nclass of regularizers. We provide a necessary and sufficient condition for\nthese class of matrix regularizers and highlight them with some concrete\nexamples of practical importance. Our analysis uses basic principles from\nmatrix theory, especially the useful notion of matrix nondecreasing function.\n",
          "  Most existing distance metric learning methods assume perfect side\ninformation that is usually given in pairwise or triplet constraints. Instead,\nin many real-world applications, the constraints are derived from side\ninformation, such as users' implicit feedbacks and citations among articles. As\na result, these constraints are usually noisy and contain many mistakes. In\nthis work, we aim to learn a distance metric from noisy constraints by robust\noptimization in a worst-case scenario, to which we refer as robust metric\nlearning. We formulate the learning task initially as a combinatorial\noptimization problem, and show that it can be elegantly transformed to a convex\nprogramming problem. We present an efficient learning algorithm based on smooth\noptimization [7]. It has a worst-case convergence rate of\nO(1/{\\surd}{\\varepsilon}) for smooth optimization problems, where {\\varepsilon}\nis the desired error of the approximate solution. Finally, our empirical study\nwith UCI data sets demonstrate the effectiveness of the proposed method in\ncomparison to state-of-the-art methods.\n",
          "  Recently, there has been much interest in spectral approaches to learning\nmanifolds---so-called kernel eigenmap methods. These methods have had some\nsuccesses, but their applicability is limited because they are not robust to\nnoise. To address this limitation, we look at two-manifold problems, in which\nwe simultaneously reconstruct two related manifolds, each representing a\ndifferent view of the same data. By solving these interconnected learning\nproblems together and allowing information to flow between them, two-manifold\nalgorithms are able to succeed where a non-integrated approach would fail: each\nview allows us to suppress noise in the other, reducing bias in the same way\nthat an instrumental variable allows us to remove bias in a {linear}\ndimensionality reduction problem. We propose a class of algorithms for\ntwo-manifold problems, based on spectral decomposition of cross-covariance\noperators in Hilbert space. Finally, we discuss situations where two-manifold\nproblems are useful, and demonstrate that solving a two-manifold problem can\naid in learning a nonlinear dynamical system from limited data.\n",
          "  This paper presents new and effective algorithms for learning kernels. In\nparticular, as shown by our empirical results, these algorithms consistently\noutperform the so-called uniform combination solution that has proven to be\ndifficult to improve upon in the past, as well as other algorithms for learning\nkernels based on convex combinations of base kernels in both classification and\nregression. Our algorithms are based on the notion of centered alignment which\nis used as a similarity measure between kernels or kernel matrices. We present\na number of novel algorithmic, theoretical, and empirical results for learning\nkernels based on our notion of centered alignment. In particular, we describe\nefficient algorithms for learning a maximum alignment kernel by showing that\nthe problem can be reduced to a simple QP and discuss a one-stage algorithm for\nlearning both a kernel and a hypothesis based on that kernel using an\nalignment-based regularization. Our theoretical results include a novel\nconcentration bound for centered alignment between kernel matrices, the proof\nof the existence of effective predictors for kernels with high alignment, both\nfor classification and for regression, and the proof of stability-based\ngeneralization bounds for a broad family of algorithms for learning kernels\nbased on centered alignment. We also report the results of experiments with our\ncentered alignment-based algorithms in both classification and regression.\n",
          "  We give a universal kernel that renders all the regular languages linearly\nseparable. We are not able to compute this kernel efficiently and conjecture\nthat it is intractable, but we do have an efficient $\\eps$-approximation.\n",
          "  Metric learning makes it plausible to learn distances for complex\ndistributions of data from labeled data. However, to date, most metric learning\nmethods are based on a single Mahalanobis metric, which cannot handle\nheterogeneous data well. Those that learn multiple metrics throughout the space\nhave demonstrated superior accuracy, but at the cost of computational\nefficiency. Here, we take a new angle to the metric learning problem and learn\na single metric that is able to implicitly adapt its distance function\nthroughout the feature space. This metric adaptation is accomplished by using a\nrandom forest-based classifier to underpin the distance function and\nincorporate both absolute pairwise position and standard relative position into\nthe representation. We have implemented and tested our method against state of\nthe art global and multi-metric methods on a variety of data sets. Overall, the\nproposed method outperforms both types of methods in terms of accuracy\n(consistently ranked first) and is an order of magnitude faster than state of\nthe art multi-metric methods (16x faster in the worst case).\n",
          "  We propose a method to efficiently construct data-dependent kernels which can\nmake use of large quantities of (unlabeled) data. Our construction makes an\napproximation in the standard construction of semi-supervised kernels in\nSindhwani et al. 2005. In typical cases these kernels can be computed in\nnearly-linear time (in the amount of data), improving on the cubic time of the\nstandard construction, enabling large scale semi-supervised learning in a\nvariety of contexts. The methods are validated on semi-supervised and\nunsupervised problems on data sets containing upto 64,000 sample points.\n",
          "  Kernel-based machine learning algorithms are based on mapping data from the\noriginal input feature space to a kernel feature space of higher dimensionality\nto solve a linear problem in that space. Over the last decade, kernel based\nclassification and regression approaches such as support vector machines have\nwidely been used in remote sensing as well as in various civil engineering\napplications. In spite of their better performance with different datasets,\nsupport vector machines still suffer from shortcomings such as\nvisualization/interpretation of model, choice of kernel and kernel specific\nparameter as well as the regularization parameter. Relevance vector machines\nare another kernel based approach being explored for classification and\nregression with in last few years. The advantages of the relevance vector\nmachines over the support vector machines is the availability of probabilistic\npredictions, using arbitrary kernel functions and not requiring setting of the\nregularization parameter. This paper presents a state-of-the-art review of SVM\nand RVM in remote sensing and provides some details of their use in other civil\nengineering application also.\n",
          "  We propose a method for nonparametric density estimation that exhibits\nrobustness to contamination of the training sample. This method achieves\nrobustness by combining a traditional kernel density estimator (KDE) with ideas\nfrom classical $M$-estimation. We interpret the KDE based on a radial, positive\nsemi-definite kernel as a sample mean in the associated reproducing kernel\nHilbert space. Since the sample mean is sensitive to outliers, we estimate it\nrobustly via $M$-estimation, yielding a robust kernel density estimator (RKDE).\n  An RKDE can be computed efficiently via a kernelized iteratively re-weighted\nleast squares (IRWLS) algorithm. Necessary and sufficient conditions are given\nfor kernelized IRWLS to converge to the global minimizer of the $M$-estimator\nobjective function. The robustness of the RKDE is demonstrated with a\nrepresenter theorem, the influence function, and experimental results for\ndensity estimation and anomaly detection.\n",
          "  This paper proposes a novel kernel approach to linear dimension reduction for\nsupervised learning. The purpose of the dimension reduction is to find\ndirections in the input space to explain the output as effectively as possible.\nThe proposed method uses an estimator for the gradient of regression function,\nbased on the covariance operators on reproducing kernel Hilbert spaces. In\ncomparison with other existing methods, the proposed one has wide applicability\nwithout strong assumptions on the distributions or the type of variables, and\nuses computationally simple eigendecomposition. Experimental results show that\nthe proposed method successfully finds the effective directions with efficient\ncomputation.\n",
          "  This paper studies the construction of a refinement kernel for a given\noperator-valued reproducing kernel such that the vector-valued reproducing\nkernel Hilbert space of the refinement kernel contains that of the given one as\na subspace. The study is motivated from the need of updating the current\noperator-valued reproducing kernel in multi-task learning when underfitting or\noverfitting occurs. Numerical simulations confirm that the established\nrefinement kernel method is able to meet this need. Various characterizations\nare provided based on feature maps and vector-valued integral representations\nof operator-valued reproducing kernels. Concrete examples of refining\ntranslation invariant and finite Hilbert-Schmidt operator-valued reproducing\nkernels are provided. Other examples include refinement of Hessian of\nscalar-valued translation-invariant kernels and transformation kernels.\nExistence and properties of operator-valued reproducing kernels preserved\nduring the refinement process are also investigated.\n",
          "  We prove that the optimal assignment kernel, proposed recently as an attempt\nto embed labeled graphs and more generally tuples of basic data to a Hilbert\nspace, is in fact not always positive definite.\n",
          "  This thesis presents a new methodology to analyze one-dimensional signals\ntrough a new approach called Multi Layer Analysis, for short MLA. It also\nprovides some new insights on the relationship between one-dimensional signals\nprocessed by MLA and tree kernels, test of randomness and signal processing\ntechniques. The MLA approach has a wide range of application to the fields of\npattern discovery and matching, computational biology and many other areas of\ncomputer science and signal processing. This thesis includes also some\napplications of this approach to real problems in biology and seismology.\n",
          "  We show how to incorporate information from labeled examples into nonnegative\nmatrix factorization (NMF), a popular unsupervised learning algorithm for\ndimensionality reduction. In addition to mapping the data into a space of lower\ndimensionality, our approach aims to preserve the nonnegative components of the\ndata that are important for classification. We identify these components from\nthe support vectors of large-margin classifiers and derive iterative updates to\npreserve them in a semi-supervised version of NMF. These updates have a simple\nmultiplicative form like their unsupervised counterparts; they are also\nguaranteed at each iteration to decrease their loss function---a weighted sum\nof I-divergences that captures the trade-off between unsupervised and\nsupervised learning. We evaluate these updates for dimensionality reduction\nwhen they are used as a precursor to linear classification. In this role, we\nfind that they yield much better performance than their unsupervised\ncounterparts. We also find one unexpected benefit of the low dimensional\nrepresentations discovered by our approach: often they yield more accurate\nclassifiers than both ordinary and transductive SVMs trained in the original\ninput space.\n",
          "  Most machine learning algorithms, such as classification or regression, treat\nthe individual data point as the object of interest. Here we consider extending\nmachine learning algorithms to operate on groups of data points. We suggest\ntreating a group of data points as an i.i.d. sample set from an underlying\nfeature distribution for that group. Our approach employs kernel machines with\na kernel on i.i.d. sample sets of vectors. We define certain kernel functions\non pairs of distributions, and then use a nonparametric estimator to\nconsistently estimate those functions based on sample sets. The projection of\nthe estimated Gram matrix to the cone of symmetric positive semi-definite\nmatrices enables us to use kernel machines for classification, regression,\nanomaly detection, and low-dimensional embedding in the space of distributions.\nWe present several numerical experiments both on real and simulated datasets to\ndemonstrate the advantages of our new approach.\n",
          "  Due to the growing ubiquity of unlabeled data, learning with unlabeled data\nis attracting increasing attention in machine learning. In this paper, we\npropose a novel semi-supervised kernel learning method which can seamlessly\ncombine manifold structure of unlabeled data and Regularized Least-Squares\n(RLS) to learn a new kernel. Interestingly, the new kernel matrix can be\nobtained analytically with the use of spectral decomposition of graph Laplacian\nmatrix. Hence, the proposed algorithm does not require any numerical\noptimization solvers. Moreover, by maximizing kernel target alignment on\nlabeled data, we can also learn model parameters automatically with a\nclosed-form solution. For a given graph Laplacian matrix, our proposed method\ndoes not need to tune any model parameter including the tradeoff parameter in\nRLS and the balance parameter for unlabeled data. Extensive experiments on ten\nbenchmark datasets show that our proposed two-stage parameter-free spectral\nkernel learning algorithm can obtain comparable performance with fine-tuned\nmanifold regularization methods in transductive setting, and outperform\nmultiple kernel learning in supervised setting.\n",
          "  In this paper, we propose to (seamlessly) integrate b-bit minwise hashing\nwith linear SVM to substantially improve the training (and testing) efficiency\nusing much smaller memory, with essentially no loss of accuracy. Theoretically,\nwe prove that the resemblance matrix, the minwise hashing matrix, and the b-bit\nminwise hashing matrix are all positive definite matrices (kernels).\nInterestingly, our proof for the positive definiteness of the b-bit minwise\nhashing kernel naturally suggests a simple strategy to integrate b-bit hashing\nwith linear SVM. Our technique is particularly useful when the data can not fit\nin memory, which is an increasingly critical issue in large-scale machine\nlearning. Our preliminary experimental results on a publicly available webspam\ndataset (350K samples and 16 million dimensions) verified the effectiveness of\nour algorithm. For example, the training time was reduced to merely a few\nseconds. In addition, our technique can be easily extended to many other linear\nand nonlinear machine learning applications such as logistic regression.\n",
          "  Support vector machines and kernel methods have recently gained considerable\nattention in chemoinformatics. They offer generally good performance for\nproblems of supervised classification or regression, and provide a flexible and\ncomputationally efficient framework to include relevant information and prior\nknowledge about the data and problems to be handled. In particular, with kernel\nmethods molecules do not need to be represented and stored explicitly as\nvectors or fingerprints, but only to be compared to each other through a\ncomparison function technically called a kernel. While classical kernels can be\nused to compare vector or fingerprint representations of molecules, completely\nnew kernels were developed in the recent years to directly compare the 2D or 3D\nstructures of molecules, without the need for an explicit vectorization step\nthrough the extraction of molecular descriptors. While still in their infancy,\nthese approaches have already demonstrated their relevance on several toxicity\nprediction and structure-activity relationship problems.\n",
          "  The learning of appropriate distance metrics is a critical problem in image\nclassification and retrieval. In this work, we propose a boosting-based\ntechnique, termed \\BoostMetric, for learning a Mahalanobis distance metric. One\nof the primary difficulties in learning such a metric is to ensure that the\nMahalanobis matrix remains positive semidefinite. Semidefinite programming is\nsometimes used to enforce this constraint, but does not scale well.\n\\BoostMetric is instead based on a key observation that any positive\nsemidefinite matrix can be decomposed into a linear positive combination of\ntrace-one rank-one matrices. \\BoostMetric thus uses rank-one positive\nsemidefinite matrices as weak learners within an efficient and scalable\nboosting-based learning process. The resulting method is easy to implement,\ndoes not require tuning, and can accommodate various types of constraints.\nExperiments on various datasets show that the proposed algorithm compares\nfavorably to those state-of-the-art methods in terms of classification accuracy\nand running time.\n",
          "  In this paper, the framework of kernel machines with two layers is\nintroduced, generalizing classical kernel methods. The new learning methodology\nprovide a formal connection between computational architectures with multiple\nlayers and the theme of kernel learning in standard regularization methods.\nFirst, a representer theorem for two-layer networks is presented, showing that\nfinite linear combinations of kernels on each layer are optimal architectures\nwhenever the corresponding functions solve suitable variational problems in\nreproducing kernel Hilbert spaces (RKHS). The input-output map expressed by\nthese architectures turns out to be equivalent to a suitable single-layer\nkernel machines in which the kernel function is also learned from the data.\nRecently, the so-called multiple kernel learning methods have attracted\nconsiderable attention in the machine learning literature. In this paper,\nmultiple kernel learning methods are shown to be specific cases of kernel\nmachines with two layers in which the second layer is linear. Finally, a simple\nand effective multiple kernel learning method called RLS2 (regularized least\nsquares with two layers) is introduced, and his performances on several\nlearning problems are extensively analyzed. An open source MATLAB toolbox to\ntrain and validate RLS2 models with a Graphic User Interface is available.\n",
          "  The present report, has been inspired by the need of the author and its\ncolleagues to understand the underlying theory of Wirtinger's Calculus and to\nfurther extend it to include the kernel case. The aim of the present manuscript\nis twofold: a) it endeavors to provide a more rigorous presentation of the\nrelated material, focusing on aspects that the author finds more insightful and\nb) it extends the notions of Wirtinger's calculus on general Hilbert spaces\n(such as Reproducing Hilbert Kernel Spaces).\n",
          "  The emergence of low-cost sensor architectures for diverse modalities has\nmade it possible to deploy sensor arrays that capture a single event from a\nlarge number of vantage points and using multiple modalities. In many\nscenarios, these sensors acquire very high-dimensional data such as audio\nsignals, images, and video. To cope with such high-dimensional data, we\ntypically rely on low-dimensional models. Manifold models provide a\nparticularly powerful model that captures the structure of high-dimensional\ndata when it is governed by a low-dimensional set of parameters. However, these\nmodels do not typically take into account dependencies among multiple sensors.\nWe thus propose a new joint manifold framework for data ensembles that exploits\nsuch dependencies. We show that simple algorithms can exploit the joint\nmanifold structure to improve their performance on standard signal processing\napplications. Additionally, recent results concerning dimensionality reduction\nfor manifolds enable us to formulate a network-scalable data compression scheme\nthat uses random projections of the sensed data. This scheme efficiently fuses\nthe data from all sensors through the addition of such projections, regardless\nof the data modalities and dimensions.\n",
          "  We consider a suboptimal solution path algorithm for the Support Vector\nMachine. The solution path algorithm is an effective tool for solving a\nsequence of a parametrized optimization problems in machine learning. The path\nof the solutions provided by this algorithm are very accurate and they satisfy\nthe optimality conditions more strictly than other SVM optimization algorithms.\nIn many machine learning application, however, this strict optimality is often\nunnecessary, and it adversely affects the computational efficiency. Our\nalgorithm can generate the path of suboptimal solutions within an arbitrary\nuser-specified tolerance level. It allows us to control the trade-off between\nthe accuracy of the solution and the computational cost. Moreover, We also show\nthat our suboptimal solutions can be interpreted as the solution of a\n\\emph{perturbed optimization problem} from the original one. We provide some\ntheoretical analyses of our algorithm based on this novel interpretation. The\nexperimental results also demonstrate the effectiveness of our algorithm.\n",
          "  The role of kernels is central to machine learning. Motivated by the\nimportance of power-law distributions in statistical modeling, in this paper,\nwe propose the notion of power-law kernels to investigate power-laws in\nlearning problem. We propose two power-law kernels by generalizing Gaussian and\nLaplacian kernels. This generalization is based on distributions, arising out\nof maximization of a generalized information measure known as nonextensive\nentropy that is very well studied in statistical mechanics. We prove that the\nproposed kernels are positive definite, and provide some insights regarding the\ncorresponding Reproducing Kernel Hilbert Space (RKHS). We also study practical\nsignificance of both kernels in classification and regression, and present some\nsimulation results.\n",
          "  We propose a new method for estimating the intrinsic dimension of a dataset\nby applying the principle of regularized maximum likelihood to the distances\nbetween close neighbors. We propose a regularization scheme which is motivated\nby divergence minimization principles. We derive the estimator by a Poisson\nprocess approximation, argue about its convergence properties and apply it to a\nnumber of simulated and real datasets. We also show it has the best overall\nperformance compared with two other intrinsic dimension estimators.\n",
          "  In this paper, we tackle the problem of online semi-supervised learning\n(SSL). When data arrive in a stream, the dual problems of computation and data\nstorage arise for any SSL method. We propose a fast approximate online SSL\nalgorithm that solves for the harmonic solution on an approximate graph. We\nshow, both empirically and theoretically, that good behavior can be achieved by\ncollapsing nearby points into a set of local \"representative points\" that\nminimize distortion. Moreover, we regularize the harmonic solution to achieve\nbetter stability properties. We apply our algorithm to face recognition and\noptical character recognition applications to show that we can take advantage\nof the manifold structure to outperform the previous methods. Unlike previous\nheuristic approaches, we show that our method yields provable performance\nbounds.\n",
          "  Manifold learning is a hot research topic in the field of computer science\nand has many applications in the real world. A main drawback of manifold\nlearning methods is, however, that there is no explicit mappings from the input\ndata manifold to the output embedding. This prohibits the application of\nmanifold learning methods in many practical problems such as classification and\ntarget detection. Previously, in order to provide explicit mappings for\nmanifold learning methods, many methods have been proposed to get an\napproximate explicit representation mapping with the assumption that there\nexists a linear projection between the high-dimensional data samples and their\nlow-dimensional embedding. However, this linearity assumption may be too\nrestrictive. In this paper, an explicit nonlinear mapping is proposed for\nmanifold learning, based on the assumption that there exists a polynomial\nmapping between the high-dimensional data samples and their low-dimensional\nrepresentations. As far as we know, this is the first time that an explicit\nnonlinear mapping for manifold learning is given. In particular, we apply this\nto the method of Locally Linear Embedding (LLE) and derive an explicit\nnonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial\nEmbedding (NPPE). Experimental results on both synthetic and real-world data\nshow that the proposed mapping is much more effective in preserving the local\nneighborhood information and the nonlinear geometry of the high-dimensional\ndata samples than previous work.\n",
          "  Rapid identification of object from radar cross section (RCS) signals is\nimportant for many space and military applications. This identification is a\nproblem in pattern recognition which either neural networks or support vector\nmachines should prove to be high-speed. Bayesian networks would also provide\nvalue but require significant preprocessing of the signals. In this paper, we\ndescribe the use of a support vector machine for object identification from\nsynthesized RCS data. Our best results are from data fusion of X-band and\nS-band signals, where we obtained 99.4%, 95.3%, 100% and 95.6% correct\nidentification for cylinders, frusta, spheres, and polygons, respectively. We\nalso compare our results with a Bayesian approach and show that the SVM is\nthree orders of magnitude faster, as measured by the number of floating point\noperations.\n",
          "  We present a streaming model for large-scale classification (in the context\nof $\\ell_2$-SVM) by leveraging connections between learning and computational\ngeometry. The streaming model imposes the constraint that only a single pass\nover the data is allowed. The $\\ell_2$-SVM is known to have an equivalent\nformulation in terms of the minimum enclosing ball (MEB) problem, and an\nefficient algorithm based on the idea of \\emph{core sets} exists (Core Vector\nMachine, CVM). CVM learns a $(1+\\varepsilon)$-approximate MEB for a set of\npoints and yields an approximate solution to corresponding SVM instance.\nHowever CVM works in batch mode requiring multiple passes over the data. This\npaper presents a single-pass SVM which is based on the minimum enclosing ball\nof streaming data. We show that the MEB updates for the streaming case can be\neasily adapted to learn the SVM weight vector in a way similar to using online\nstochastic gradient updates. Our algorithm performs polylogarithmic computation\nat each example, and requires very small and constant storage. Experimental\nresults show that, even in such restrictive settings, we can learn efficiently\nin just one pass and get accuracies comparable to other state-of-the-art SVM\nsolvers (batch and online). We also give an analysis of the algorithm, and\ndiscuss some open issues and possible extensions.\n",
          "  This paper presents a novel pairwise constraint propagation approach by\ndecomposing the challenging constraint propagation problem into a set of\nindependent semi-supervised learning subproblems which can be solved in\nquadratic time using label propagation based on k-nearest neighbor graphs.\nConsidering that this time cost is proportional to the number of all possible\npairwise constraints, our approach actually provides an efficient solution for\nexhaustively propagating pairwise constraints throughout the entire dataset.\nThe resulting exhaustive set of propagated pairwise constraints are further\nused to adjust the similarity matrix for constrained spectral clustering. Other\nthan the traditional constraint propagation on single-source data, our approach\nis also extended to more challenging constraint propagation on multi-source\ndata where each pairwise constraint is defined over a pair of data points from\ndifferent sources. This multi-source constraint propagation has an important\napplication to cross-modal multimedia retrieval. Extensive results have shown\nthe superior performance of our approach.\n",
          "  We present a simple, yet effective, approach to Semi-Supervised Learning. Our\napproach is based on estimating density-based distances (DBD) using a shortest\npath calculation on a graph. These Graph-DBD estimates can then be used in any\ndistance-based supervised learning method, such as Nearest Neighbor methods and\nSVMs with RBF kernels. In order to apply the method to very large data sets, we\nalso present a novel algorithm which integrates nearest neighbor computations\ninto the shortest path search and can find exact shortest paths even in\nextremely large dense graphs. Significant runtime improvement over the commonly\nused Laplacian regularization method is then shown on a large scale dataset.\n",
          "  The past century was era of linear systems. Either systems (especially\nindustrial ones) were simple (quasi)linear or linear approximations were\naccurate enough. In addition, just at the ending decades of the century\nprofusion of computing devices were available, before then due to lack of\ncomputational resources it was not easy to evaluate available nonlinear system\nstudies. At the moment both these two conditions changed, systems are highly\ncomplex and also pervasive amount of computation strength is cheap and easy to\nachieve. For recent era, a new branch of supervised learning well known as\nsurrogate modeling (meta-modeling, surface modeling) has been devised which\naimed at answering new needs of modeling realm. This short literature survey is\non to introduce surrogate modeling to whom is familiar with the concepts of\nsupervised learning. Necessity, challenges and visions of the topic are\nconsidered.\n",
          "  We present a novel approach for training kernel Support Vector Machines,\nestablish learning runtime guarantees for our method that are better then those\nof any other known kernelized SVM optimization approach, and show that our\nmethod works well in practice compared to existing alternatives.\n",
          "  We present a unified framework to study graph kernels, special cases of which\ninclude the random walk graph kernel \\citep{GaeFlaWro03,BorOngSchVisetal05},\nmarginalized graph kernel \\citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},\nand geometric kernel on graphs \\citep{Gaertner02}. Through extensions of linear\nalgebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a\nSylvester equation, we construct an algorithm that improves the time complexity\nof kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,\nconjugate gradient solvers or fixed-point iterations bring our algorithm into\nthe sub-cubic domain. Experiments on graphs from bioinformatics and other\napplication domains show that it is often more than a thousand times faster\nthan previous approaches. We then explore connections between diffusion kernels\n\\citep{KonLaf02}, regularization on graphs \\citep{SmoKon03}, and graph kernels,\nand use these connections to propose new graph kernels. Finally, we show that\nrational kernels \\citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized\nto graphs reduce to the random walk graph kernel.\n",
          "  We consider the problem of high-dimensional non-linear variable selection for\nsupervised learning. Our approach is based on performing linear selection among\nexponentially many appropriately defined positive definite kernels that\ncharacterize non-linear interactions between the original variables. To select\nefficiently from these many kernels, we use the natural hierarchical structure\nof the problem to extend the multiple kernel learning framework to kernels that\ncan be embedded in a directed acyclic graph; we show that it is then possible\nto perform kernel selection through a graph-adapted sparsity-inducing norm, in\npolynomial time in the number of selected kernels. Moreover, we study the\nconsistency of variable selection in high-dimensional settings, showing that\nunder certain assumptions, our regularization framework allows a number of\nirrelevant variables which is exponential in the number of observations. Our\nsimulations on synthetic datasets and datasets from the UCI repository show\nstate-of-the-art predictive performance for non-linear regression problems.\n",
          "  This paper focuses on the problem of kernelizing an existing supervised\nMahalanobis distance learner. The following features are included in the paper.\nFirstly, three popular learners, namely, \"neighborhood component analysis\",\n\"large margin nearest neighbors\" and \"discriminant neighborhood embedding\",\nwhich do not have kernel versions are kernelized in order to improve their\nclassification performances. Secondly, an alternative kernelization framework\ncalled \"KPCA trick\" is presented. Implementing a learner in the new framework\ngains several advantages over the standard framework, e.g. no mathematical\nformulas and no reprogramming are required for a kernel implementation, the\nframework avoids troublesome problems such as singularity, etc. Thirdly, while\nthe truths of representer theorems are just assumptions in previous papers\nrelated to ours, here, representer theorems are formally proven. The proofs\nvalidate both the kernel trick and the KPCA trick in the context of Mahalanobis\ndistance learning. Fourthly, unlike previous works which always apply brute\nforce methods to select a kernel, we investigate two approaches which can be\nefficiently adopted to construct an appropriate kernel for a given dataset.\nFinally, numerical results on various real-world datasets are presented.\n",
          "  An instance-weighted variant of the support vector machine (SVM) has\nattracted considerable attention recently since they are useful in various\nmachine learning tasks such as non-stationary data analysis, heteroscedastic\ndata modeling, transfer learning, learning to rank, and transduction. An\nimportant challenge in these scenarios is to overcome the computational\nbottleneck---instance weights often change dynamically or adaptively, and thus\nthe weighted SVM solutions must be repeatedly computed. In this paper, we\ndevelop an algorithm that can efficiently and exactly update the weighted SVM\nsolutions for arbitrary change of instance weights. Technically, this\ncontribution can be regarded as an extension of the conventional solution-path\nalgorithm for a single regularization parameter to multiple instance-weight\nparameters. However, this extension gives rise to a significant problem that\nbreakpoints (at which the solution path turns) have to be identified in\nhigh-dimensional space. To facilitate this, we introduce a parametric\nrepresentation of instance weights. We also provide a geometric interpretation\nin weight space using a notion of critical region: a polyhedron in which the\ncurrent affine solution remains to be optimal. Then we find breakpoints at\nintersections of the solution path and boundaries of polyhedrons. Through\nextensive experiments on various practical applications, we demonstrate the\nusefulness of the proposed algorithm.\n",
          "  Support vector machines (SVMs) are invaluable tools for many practical\napplications in artificial intelligence, e.g., classification and event\nrecognition. However, popular SVM solvers are not sufficiently efficient for\napplications with a great deal of samples as well as a large number of\nfeatures. In this paper, thus, we present NESVM, a fast gradient SVM solver\nthat can optimize various SVM models, e.g., classical SVM, linear programming\nSVM and least square SVM. Compared against SVM-Perf\n\\cite{SVM_Perf}\\cite{PerfML} (its convergence rate in solving the dual SVM is\nupper bounded by $\\mathcal O(1/\\sqrt{k})$, wherein $k$ is the number of\niterations.) and Pegasos \\cite{Pegasos} (online SVM that converges at rate\n$\\mathcal O(1/k)$ for the primal SVM), NESVM achieves the optimal convergence\nrate at $\\mathcal O(1/k^{2})$ and a linear time complexity. In particular,\nNESVM smoothes the non-differentiable hinge loss and $\\ell_1$-norm in the\nprimal SVM. Then the optimal gradient method without any line search is adopted\nto solve the optimization. In each iteration round, the current gradient and\nhistorical gradients are combined to determine the descent direction, while the\nLipschitz constant determines the step size. Only two matrix-vector\nmultiplications are required in each iteration round. Therefore, NESVM is more\nefficient than existing SVM solvers. In addition, NESVM is available for both\nlinear and nonlinear kernels. We also propose \"homotopy NESVM\" to accelerate\nNESVM by dynamically decreasing the smooth parameter and using the continuation\nmethod. Our experiments on census income categorization, indoor/outdoor scene\nclassification, event recognition and scene recognition suggest the efficiency\nand the effectiveness of NESVM. The MATLAB code of NESVM will be available on\nour website for further assessment.\n",
          "  We present a general framework of semi-supervised dimensionality reduction\nfor manifold learning which naturally generalizes existing supervised and\nunsupervised learning frameworks which apply the spectral decomposition.\nAlgorithms derived under our framework are able to employ both labeled and\nunlabeled examples and are able to handle complex problems where data form\nseparate clusters of manifolds. Our framework offers simple views, explains\nrelationships among existing frameworks and provides further extensions which\ncan improve existing algorithms. Furthermore, a new semi-supervised\nkernelization framework called ``KPCA trick'' is proposed to handle non-linear\nproblems.\n",
          "  The paper studies machine learning problems where each example is described\nusing a set of Boolean features and where hypotheses are represented by linear\nthreshold elements. One method of increasing the expressiveness of learned\nhypotheses in this context is to expand the feature set to include conjunctions\nof basic features. This can be done explicitly or where possible by using a\nkernel function. Focusing on the well known Perceptron and Winnow algorithms,\nthe paper demonstrates a tradeoff between the computational efficiency with\nwhich the algorithm can be run over the expanded feature space and the\ngeneralization ability of the corresponding learning algorithm. We first\ndescribe several kernel functions which capture either limited forms of\nconjunctions or all conjunctions. We show that these kernels can be used to\nefficiently run the Perceptron algorithm over a feature space of exponentially\nmany conjunctions; however we also show that using such kernels, the Perceptron\nalgorithm can provably make an exponential number of mistakes even when\nlearning simple functions. We then consider the question of whether kernel\nfunctions can analogously be used to run the multiplicative-update Winnow\nalgorithm over an expanded feature space of exponentially many conjunctions.\nKnown upper bounds imply that the Winnow algorithm can learn Disjunctive Normal\nForm (DNF) formulae with a polynomial mistake bound in this setting. However,\nwe prove that it is computationally hard to simulate Winnows behavior for\nlearning DNF over such a feature set. This implies that the kernel functions\nwhich correspond to running Winnow for this problem are not efficiently\ncomputable, and that there is no general construction that can run Winnow with\nkernels.\n",
          "  We show that the herding procedure of Welling (2009) takes exactly the form\nof a standard convex optimization algorithm--namely a conditional gradient\nalgorithm minimizing a quadratic moment discrepancy. This link enables us to\ninvoke convergence results from convex optimization and to consider faster\nalternatives for the task of approximating integrals in a reproducing kernel\nHilbert space. We study the behavior of the different variants through\nnumerical simulations. The experiments indicate that while we can improve over\nherding on the task of approximating integrals, the original herding algorithm\ntends to approach more often the maximum entropy distribution, shedding more\nlight on the learning bias behind herding.\n",
          "  Starting with a similarity function between objects, it is possible to define\na distance metric on pairs of objects, and more generally on probability\ndistributions over them. These distance metrics have a deep basis in functional\nanalysis, measure theory and geometric measure theory, and have a rich\nstructure that includes an isometric embedding into a (possibly infinite\ndimensional) Hilbert space. They have recently been applied to numerous\nproblems in machine learning and shape analysis.\n  In this paper, we provide the first algorithmic analysis of these distance\nmetrics. Our main contributions are as follows: (i) We present fast\napproximation algorithms for computing the kernel distance between two point\nsets P and Q that runs in near-linear time in the size of (P cup Q) (note that\nan explicit calculation would take quadratic time). (ii) We present\npolynomial-time algorithms for approximately minimizing the kernel distance\nunder rigid transformation; they run in time O(n + poly(1/epsilon, log n)).\n(iii) We provide several general techniques for reducing complex objects to\nconvenient sparse representations (specifically to point sets or sets of points\nsets) which approximately preserve the kernel distance. In particular, this\nallows us to reduce problems of computing the kernel distance between various\ntypes of objects such as curves, surfaces, and distributions to computing the\nkernel distance between point sets. These take advantage of the reproducing\nkernel Hilbert space and a new relation linking binary range spaces to\ncontinuous range spaces with bounded fat-shattering dimension.\n",
          "  In this paper, we consider the problem of estimating self-tuning histograms\nusing query workloads. To this end, we propose a general learning theoretic\nformulation. Specifically, we use query feedback from a workload as training\ndata to estimate a histogram with a small memory footprint that minimizes the\nexpected error on future queries. Our formulation provides a framework in which\ndifferent approaches can be studied and developed. We first study the simple\nclass of equi-width histograms and present a learning algorithm, EquiHist, that\nis competitive in many settings. We also provide formal guarantees for\nequi-width histograms that highlight scenarios in which equi-width histograms\ncan be expected to succeed or fail. We then go beyond equi-width histograms and\npresent a novel learning algorithm, SpHist, for estimating general histograms.\nHere we use Haar wavelets to reduce the problem of learning histograms to that\nof learning a sparse vector. Both algorithms have multiple advantages over\nexisting methods: 1) simple and scalable extensions to multi-dimensional data,\n2) scalability with number of histogram buckets and size of query feedback, 3)\nnatural extensions to incorporate new feedback and handle database updates. We\ndemonstrate these advantages over the current state-of-the-art, ISOMER, through\ndetailed experiments on real and synthetic data. In particular, we show that\nSpHist obtains up to 50% less error than ISOMER on real-world multi-dimensional\ndatasets.\n",
          "  Neighborhood graphs are gaining popularity as a concise data representation\nin machine learning. However, naive graph construction by pairwise distance\ncalculation takes $O(n^2)$ runtime for $n$ data points and this is\nprohibitively slow for millions of data points. For strings of equal length,\nthe multiple sorting method (Uno, 2008) can construct an $\\epsilon$-neighbor\ngraph in $O(n+m)$ time, where $m$ is the number of $\\epsilon$-neighbor pairs in\nthe data. To introduce this remarkably efficient algorithm to continuous\ndomains such as images, signals and texts, we employ a random projection method\nto convert vectors to strings. Theoretical results are presented to elucidate\nthe trade-off between approximation quality and computation time. Empirical\nresults show the efficiency of our method in comparison to fast nearest\nneighbor alternatives.\n",
          "  Support Vector Machines, SVMs, and the Large Margin Nearest Neighbor\nalgorithm, LMNN, are two very popular learning algorithms with quite different\nlearning biases. In this paper we bring them into a unified view and show that\nthey have a much stronger relation than what is commonly thought. We analyze\nSVMs from a metric learning perspective and cast them as a metric learning\nproblem, a view which helps us uncover the relations of the two algorithms. We\nshow that LMNN can be seen as learning a set of local SVM-like models in a\nquadratic space. Along the way and inspired by the metric-based interpretation\nof SVM s we derive a novel variant of SVMs, epsilon-SVM, to which LMNN is even\nmore similar. We give a unified view of LMNN and the different SVM variants.\nFinally we provide some preliminary experiments on a number of benchmark\ndatasets in which show that epsilon-SVM compares favorably both with respect to\nLMNN and SVM.\n",
          "  Learning linear combinations of multiple kernels is an appealing strategy\nwhen the right choice of features is unknown. Previous approaches to multiple\nkernel learning (MKL) promote sparse kernel combinations to support\ninterpretability and scalability. Unfortunately, this 1-norm MKL is rarely\nobserved to outperform trivial baselines in practical applications. To allow\nfor robust kernel mixtures, we generalize MKL to arbitrary norms. We devise new\ninsights on the connection between several existing MKL formulations and\ndevelop two efficient interleaved optimization strategies for arbitrary norms,\nlike p-norms with p>1. Empirically, we demonstrate that the interleaved\noptimization strategies are much faster compared to the commonly used wrapper\napproaches. A theoretical analysis and an experiment on controlled artificial\ndata experiment sheds light on the appropriateness of sparse, non-sparse and\n$\\ell_\\infty$-norm MKL in various scenarios. Empirical applications of p-norm\nMKL to three real-world problems from computational biology show that\nnon-sparse MKL achieves accuracies that go beyond the state-of-the-art.\n",
          "  Positive definite operator-valued kernels generalize the well-known notion of\nreproducing kernels, and are naturally adapted to multi-output learning\nsituations. This paper addresses the problem of learning a finite linear\ncombination of infinite-dimensional operator-valued kernels which are suitable\nfor extending functional data analysis methods to nonlinear contexts. We study\nthis problem in the case of kernel ridge regression for functional responses\nwith an lr-norm constraint on the combination coefficients. The resulting\noptimization problem is more involved than those of multiple scalar-valued\nkernel learning since operator-valued kernels pose more technical and\ntheoretical issues. We propose a multiple operator-valued kernel learning\nalgorithm based on solving a system of linear operator equations by using a\nblock coordinatedescent procedure. We experimentally validate our approach on a\nfunctional regression task in the context of finger movement prediction in\nbrain-computer interfaces.\n",
          "  Support vector machines (SVMs) are an extremely successful type of\nclassification and regression algorithms. Building an SVM entails solving a\nconstrained convex quadratic programming problem, which is quadratic in the\nnumber of training samples. We introduce an efficient parallel implementation\nof an support vector regression solver, based on the Gaussian Belief\nPropagation algorithm (GaBP).\n  In this paper, we demonstrate that methods from the complex system domain\ncould be utilized for performing efficient distributed computation. We compare\nthe proposed algorithm to previously proposed distributed and single-node SVM\nsolvers. Our comparison shows that the proposed algorithm is just as accurate\nas these solvers, while being significantly faster, especially for large\ndatasets. We demonstrate scalability of the proposed algorithm to up to 1,024\ncomputing nodes and hundreds of thousands of data points using an IBM Blue Gene\nsupercomputer. As far as we know, our work is the largest parallel\nimplementation of belief propagation ever done, demonstrating the applicability\nof this algorithm for large scale distributed computing systems.\n",
          "  We address in this paper the problem of multi-channel signal sequence\nlabeling. In particular, we consider the problem where the signals are\ncontaminated by noise or may present some dephasing with respect to their\nlabels. For that, we propose to jointly learn a SVM sample classifier with a\ntemporal filtering of the channels. This will lead to a large margin filtering\nthat is adapted to the specificity of each channel (noise and time-lag). We\nderive algorithms to solve the optimization problem and we discuss different\nfilter regularizations for automated scaling or selection of channels. Our\napproach is tested on a non-linear toy example and on a BCI dataset. Results\nshow that the classification performance on these problems can be improved by\nlearning a large margin filtering.\n",
          "  In the process of training Support Vector Machines (SVMs) by decomposition\nmethods, working set selection is an important technique, and some exciting\nschemes were employed into this field. To improve working set selection, we\npropose a new model for working set selection in sequential minimal\noptimization (SMO) decomposition methods. In this model, it selects B as\nworking set without reselection. Some properties are given by simple proof, and\nexperiments demonstrate that the proposed method is in general faster than\nexisting methods.\n",
          "  We consider the problem of classification using similarity/distance functions\nover data. Specifically, we propose a framework for defining the goodness of a\n(dis)similarity function with respect to a given learning task and propose\nalgorithms that have guaranteed generalization properties when working with\nsuch good functions. Our framework unifies and generalizes the frameworks\nproposed by [Balcan-Blum ICML 2006] and [Wang et al ICML 2007]. An attractive\nfeature of our framework is its adaptability to data - we do not promote a\nfixed notion of goodness but rather let data dictate it. We show, by giving\ntheoretical guarantees that the goodness criterion best suited to a problem can\nitself be learned which makes our approach applicable to a variety of domains\nand problems. We propose a landmarking-based approach to obtaining a classifier\nfrom such learned goodness criteria. We then provide a novel diversity based\nheuristic to perform task-driven selection of landmark points instead of random\nselection. We demonstrate the effectiveness of our goodness criteria learning\nmethod as well as the landmark selection heuristic on a variety of\nsimilarity-based learning datasets and benchmark UCI datasets on which our\nmethod consistently outperforms existing approaches by a significant margin.\n",
          "  We present a system and a set of techniques for learning linear predictors\nwith convex losses on terascale datasets, with trillions of features, {The\nnumber of features here refers to the number of non-zero entries in the data\nmatrix.} billions of training examples and millions of parameters in an hour\nusing a cluster of 1000 machines. Individually none of the component techniques\nare new, but the careful synthesis required to obtain an efficient\nimplementation is. The result is, up to our knowledge, the most scalable and\nefficient linear learning system reported in the literature (as of 2011 when\nour experiments were conducted). We describe and thoroughly evaluate the\ncomponents of the system, showing the importance of the various design choices.\n",
          "  To help understand various reproducing kernels used in applied sciences, we\ninvestigate the inclusion relation of two reproducing kernel Hilbert spaces.\nCharacterizations in terms of feature maps of the corresponding reproducing\nkernels are established. A full table of inclusion relations among widely-used\ntranslation invariant kernels is given. Concrete examples for Hilbert-Schmidt\nkernels are presented as well. We also discuss the preservation of such a\nrelation under various operations of reproducing kernels. Finally, we briefly\ndiscuss the special inclusion with a norm equivalence.\n",
          "  We find the minimax rate of convergence in Hausdorff distance for estimating\na manifold M of dimension d embedded in R^D given a noisy sample from the\nmanifold. We assume that the manifold satisfies a smoothness condition and that\nthe noise distribution has compact support. We show that the optimal rate of\nconvergence is n^{-2/(2+d)}. Thus, the minimax rate depends only on the\ndimension of the manifold, not on the dimension of the space in which M is\nembedded.\n",
          "  Approximating non-linear kernels using feature maps has gained a lot of\ninterest in recent years due to applications in reducing training and testing\ntimes of SVM classifiers and other kernel based learning algorithms. We extend\nthis line of work and present low distortion embeddings for dot product kernels\ninto linear Euclidean spaces. We base our results on a classical result in\nharmonic analysis characterizing all dot product kernels and use it to define\nrandomized feature maps into explicit low dimensional Euclidean spaces in which\nthe native dot product provides an approximation to the dot product kernel with\nhigh confidence.\n",
          "  In this paper, we study two general classes of optimization algorithms for\nkernel methods with convex loss function and quadratic norm regularization, and\nanalyze their convergence. The first approach, based on fixed-point iterations,\nis simple to implement and analyze, and can be easily parallelized. The second,\nbased on coordinate descent, exploits the structure of additively separable\nloss functions to compute solutions of line searches in closed form. Instances\nof these general classes of algorithms are already incorporated into state of\nthe art machine learning software for large scale problems. We start from a\nsolution characterization of the regularized problem, obtained using\nsub-differential calculus and resolvents of monotone operators, that holds for\ngeneral convex loss functions regardless of differentiability. The two\nmethodologies described in the paper can be regarded as instances of non-linear\nJacobi and Gauss-Seidel algorithms, and are both well-suited to solve large\nscale problems.\n",
          "  Multiple kernel learning (MKL), structured sparsity, and multi-task learning\nhave recently received considerable attention. In this paper, we show how\ndifferent MKL algorithms can be understood as applications of either\nregularization on the kernel weights or block-norm-based regularization, which\nis more common in structured sparsity and multi-task learning. We show that\nthese two regularization strategies can be systematically mapped to each other\nthrough a concave conjugate operation. When the kernel-weight-based regularizer\nis separable into components, we can naturally consider a generative\nprobabilistic model behind MKL. Based on this model, we propose learning\nalgorithms for the kernel weights through the maximization of marginal\nlikelihood. We show through numerical experiments that $\\ell_2$-norm MKL and\nElastic-net MKL achieve comparable accuracy to uniform kernel combination.\nAlthough uniform kernel combination might be preferable from its simplicity,\n$\\ell_2$-norm MKL and Elastic-net MKL can learn the usefulness of the\ninformation sources represented as kernels. In particular, Elastic-net MKL\nachieves sparsity in the kernel weights.\n",
          "  This thesis derives, tests and applies two linear projection algorithms for\nmachine learning under non-stationarity. The first finds a direction in a\nlinear space upon which a data set is maximally non-stationary. The second aims\nto robustify two-way classification against non-stationarity. The algorithm is\ntested on a key application scenario, namely Brain Computer Interfacing.\n",
          "  In many scientific disciplines structures in high-dimensional data have to be\nfound, e.g., in stellar spectra, in genome data, or in face recognition tasks.\nIn this work we present a novel approach to non-linear dimensionality\nreduction. It is based on fitting K-nearest neighbor regression to the\nunsupervised regression framework for learning of low-dimensional manifolds.\nSimilar to related approaches that are mostly based on kernel methods,\nunsupervised K-nearest neighbor (UNN) regression optimizes latent variables\nw.r.t. the data space reconstruction error employing the K-nearest neighbor\nheuristic. The problem of optimizing latent neighborhoods is difficult to\nsolve, but the UNN formulation allows the design of efficient strategies that\niteratively embed latent points to fixed neighborhood topologies. UNN is well\nappropriate for sorting of high-dimensional data. The iterative variants are\nanalyzed experimentally.\n",
          "  Over the last decade, kernel methods for nonlinear processing have\nsuccessfully been used in the machine learning community. However, so far, the\nemphasis has been on batch techniques. It is only recently, that online\nadaptive techniques have been considered in the context of signal processing\ntasks. To the best of our knowledge, no kernel-based strategy has been\ndeveloped, so far, that is able to deal with complex valued signals. In this\npaper, we take advantage of a technique called complexification of real RKHSs\nto attack this problem. In order to derive gradients and subgradients of\noperators that need to be defined on the associated complex RKHSs, we employ\nthe powerful tool ofWirtinger's Calculus, which has recently attracted much\nattention in the signal processing community. Writinger's calculus simplifies\ncomputations and offers an elegant tool for treating complex signals. To this\nend, in this paper, the notion of Writinger's calculus is extended, for the\nfirst time, to include complex RKHSs and use it to derive the Complex Kernel\nLeast-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS can be\nused to derive nonlinear stable algorithms, which offer significant performance\nimprovements over the traditional complex LMS orWidely Linear complex LMS\n(WL-LMS) algorithms, when dealing with nonlinearities.\n",
          "  Kernel methods are successful approaches for different machine learning\nproblems. This success is mainly rooted in using feature maps and kernel\nmatrices. Some methods rely on the eigenvalues/eigenvectors of the kernel\nmatrix, while for other methods the spectral information can be used to\nestimate the excess risk. An important question remains on how close the sample\neigenvalues/eigenvectors are to the population values. In this paper, we\nimprove earlier results on concentration bounds for eigenvalues of general\nkernel matrices. For distance and inner product kernel functions, e.g. radial\nbasis functions, we provide new concentration bounds, which are characterized\nby the eigenvalues of the sample covariance matrix. Meanwhile, the obstacles\nfor sharper bounds are accounted for and partially addressed. As a case study,\nwe derive a concentration inequality for sample kernel target-alignment.\n",
          "  Models for near-rigid shape matching are typically based on distance-related\nfeatures, in order to infer matches that are consistent with the isometric\nassumption. However, real shapes from image datasets, even when expected to be\nrelated by \"almost isometric\" transformations, are actually subject not only to\nnoise but also, to some limited degree, to variations in appearance and scale.\nIn this paper, we introduce a graphical model that parameterises appearance,\ndistance, and angle features and we learn all of the involved parameters via\nstructured prediction. The outcome is a model for near-rigid shape matching\nwhich is robust in the sense that it is able to capture the possibly limited\nbut still important scale and appearance variations. Our experimental results\nreveal substantial improvements upon recent successful models, while\nmaintaining similar running times.\n",
          "  In this paper, we present a computer-assisted method for facial\nreconstruction. This method provides an estimation of the facial shape\nassociated with unidentified skeletal remains. Current computer-assisted\nmethods using a statistical framework rely on a common set of extracted points\nlocated on the bone and soft-tissue surfaces. Most of the facial reconstruction\nmethods then consist of predicting the position of the soft-tissue surface\npoints, when the positions of the bone surface points are known. We propose to\nuse Latent Root Regression for prediction. The results obtained are then\ncompared to those given by Principal Components Analysis linear models. In\nconjunction, we have evaluated the influence of the number of skull landmarks\nused. Anatomical skull landmarks are completed iteratively by points located\nupon geodesics which link these anatomical landmarks, thus enabling us to\nartificially increase the number of skull points. Facial points are obtained\nusing a mesh-matching algorithm between a common reference mesh and individual\nsoft-tissue surface meshes. The proposed method is validated in term of\naccuracy, based on a leave-one-out cross-validation test applied to a\nhomogeneous database. Accuracy measures are obtained by computing the distance\nbetween the original face surface and its reconstruction. Finally, these\nresults are discussed referring to current computer-assisted reconstruction\nfacial techniques.\n",
          "  There is growing body of learning problems for which it is natural to\norganize the parameters into matrix, so as to appropriately regularize the\nparameters under some matrix norm (in order to impose some more sophisticated\nprior knowledge). This work describes and analyzes a systematic method for\nconstructing such matrix-based, regularization methods. In particular, we focus\non how the underlying statistical properties of a given problem can help us\ndecide which regularization function is appropriate.\n  Our methodology is based on the known duality fact: that a function is\nstrongly convex with respect to some norm if and only if its conjugate function\nis strongly smooth with respect to the dual norm. This result has already been\nfound to be a key component in deriving and analyzing several learning\nalgorithms. We demonstrate the potential of this framework by deriving novel\ngeneralization and regret bounds for multi-task learning, multi-class learning,\nand kernel learning.\n",
          "  Manifold learning is a hot research topic in the field of computer science. A\ncrucial issue with current manifold learning methods is that they lack a\nnatural quantitative measure to assess the quality of learned embeddings, which\ngreatly limits their applications to real-world problems. In this paper, a new\nembedding quality assessment method for manifold learning, named as\nNormalization Independent Embedding Quality Assessment (NIEQA), is proposed.\nCompared with current assessment methods which are limited to isometric\nembeddings, the NIEQA method has a much larger application range due to two\nfeatures. First, it is based on a new measure which can effectively evaluate\nhow well local neighborhood geometry is preserved under normalization, hence it\ncan be applied to both isometric and normalized embeddings. Second, it can\nprovide both local and global evaluations to output an overall assessment.\nTherefore, NIEQA can serve as a natural tool in model selection and evaluation\ntasks for manifold learning. Experimental results on benchmark data sets\nvalidate the effectiveness of the proposed method.\n",
          "  We propose a framework for analyzing and comparing distributions, allowing us\nto design statistical tests to determine if two samples are drawn from\ndifferent distributions. Our test statistic is the largest difference in\nexpectations over functions in the unit ball of a reproducing kernel Hilbert\nspace (RKHS). We present two tests based on large deviation bounds for the test\nstatistic, while a third is based on the asymptotic distribution of this\nstatistic. The test statistic can be computed in quadratic time, although\nefficient linear time approximations are available. Several classical metrics\non distributions are recovered when the function space used to compute the\ndifference in expectations is allowed to be more general (eg. a Banach space).\nWe apply our two-sample tests to a variety of problems, including attribute\nmatching for databases using the Hungarian marriage method, where they perform\nstrongly. Excellent performance is also obtained when comparing distributions\nover graphs, for which these are the first such tests.\n",
          "  Minwise hashing is the standard technique in the context of search and\ndatabases for efficiently estimating set (e.g., high-dimensional 0/1 vector)\nsimilarities. Recently, b-bit minwise hashing was proposed which significantly\nimproves upon the original minwise hashing in practice by storing only the\nlowest b bits of each hashed value, as opposed to using 64 bits. b-bit hashing\nis particularly effective in applications which mainly concern sets of high\nsimilarities (e.g., the resemblance >0.5). However, there are other important\napplications in which not just pairs of high similarities matter. For example,\nmany learning algorithms require all pairwise similarities and it is expected\nthat only a small fraction of the pairs are similar. Furthermore, many\napplications care more about containment (e.g., how much one object is\ncontained by another object) than the resemblance. In this paper, we show that\nthe estimators for minwise hashing and b-bit minwise hashing used in the\ncurrent practice can be systematically improved and the improvements are most\nsignificant for set pairs of low resemblance and high containment.\n",
          "  Learning in Riemannian orbifolds is motivated by existing machine learning\nalgorithms that directly operate on finite combinatorial structures such as\npoint patterns, trees, and graphs. These methods, however, lack statistical\njustification. This contribution derives consistency results for learning\nproblems in structured domains and thereby generalizes learning in vector\nspaces and manifolds.\n",
          "  We present a novel approach for learning nonlinear dynamic models, which\nleads to a new set of tools capable of solving problems that are otherwise\ndifficult. We provide theory showing this new approach is consistent for models\nwith long range structure, and apply the approach to motion capture and\nhigh-dimensional video data, yielding results superior to standard\nalternatives.\n",
          "  The classical perceptron rule provides a varying upper bound on the maximum\nmargin, namely the length of the current weight vector divided by the total\nnumber of updates up to that time. Requiring that the perceptron updates its\ninternal state whenever the normalized margin of a pattern is found not to\nexceed a certain fraction of this dynamic upper bound we construct a new\napproximate maximum margin classifier called the perceptron with dynamic margin\n(PDM). We demonstrate that PDM converges in a finite number of steps and derive\nan upper bound on them. We also compare experimentally PDM with other\nperceptron-like algorithms and support vector machines on hard margin tasks\ninvolving linear kernels which are equivalent to 2-norm soft margin.\n",
          "  A typical approach in estimating the learning rate of a regularized learning\nscheme is to bound the approximation error by the sum of the sampling error,\nthe hypothesis error and the regularization error. Using a reproducing kernel\nspace that satisfies the linear representer theorem brings the advantage of\ndiscarding the hypothesis error from the sum automatically. Following this\ndirection, we illustrate how reproducing kernel Banach spaces with the l1 norm\ncan be applied to improve the learning rate estimate of l1-regularization in\nmachine learning.\n",
          "  This document reviews the definition of the kernel distance, providing a\ngentle introduction tailored to a reader with background in theoretical\ncomputer science, but limited exposure to technology more common to machine\nlearning, functional analysis and geometric measure theory. The key aspect of\nthe kernel distance developed here is its interpretation as an L_2 distance\nbetween probability measures or various shapes (e.g. point sets, curves,\nsurfaces) embedded in a vector space (specifically an RKHS). This structure\nenables several elegant and efficient solutions to data analysis problems. We\nconclude with a glimpse into the mathematical underpinnings of this measure,\nhighlighting its recent independent evolution in two separate fields.\n",
          "  For a wide variety of regularization methods, algorithms computing the entire\nsolution path have been developed recently. Solution path algorithms do not\nonly compute the solution for one particular value of the regularization\nparameter but the entire path of solutions, making the selection of an optimal\nparameter much easier. Most of the currently used algorithms are not robust in\nthe sense that they cannot deal with general or degenerate input. Here we\npresent a new robust, generic method for parametric quadratic programming. Our\nalgorithm directly applies to nearly all machine learning applications, where\nso far every application required its own different algorithm.\n  We illustrate the usefulness of our method by applying it to a very low rank\nproblem which could not be solved by existing path tracking methods, namely to\ncompute part-worth values in choice based conjoint analysis, a popular\ntechnique from market research to estimate consumers preferences on a class of\nparameterized options.\n",
          "  We generated a dataset of 200 GB with 10^9 features, to test our recent b-bit\nminwise hashing algorithms for training very large-scale logistic regression\nand SVM. The results confirm our prior work that, compared with the VW hashing\nalgorithm (which has the same variance as random projections), b-bit minwise\nhashing is substantially more accurate at the same storage. For example, with\nmerely 30 hashed values per data point, b-bit minwise hashing can achieve\nsimilar accuracies as VW with 2^14 hashed values per data point.\n  We demonstrate that the preprocessing cost of b-bit minwise hashing is\nroughly on the same order of magnitude as the data loading time. Furthermore,\nby using a GPU, the preprocessing cost can be reduced to a small fraction of\nthe data loading time.\n  Minwise hashing has been widely used in industry, at least in the context of\nsearch. One reason for its popularity is that one can efficiently simulate\npermutations by (e.g.,) universal hashing. In other words, there is no need to\nstore the permutation matrix. In this paper, we empirically verify this\npractice, by demonstrating that even using the simplest 2-universal hashing\ndoes not degrade the learning performance.\n",
          "  We introduce two kernels that extend the mean map, which embeds probability\nmeasures in Hilbert spaces. The generative mean map kernel (GMMK) is a smooth\nsimilarity measure between probabilistic models. The latent mean map kernel\n(LMMK) generalizes the non-iid formulation of Hilbert space embeddings of\nempirical distributions in order to incorporate latent variable models. When\ncomparing certain classes of distributions, the GMMK exhibits beneficial\nregularization and generalization properties not shown for previous generative\nkernels. We present experiments comparing support vector machine performance\nusing the GMMK and LMMK between hidden Markov models to the performance of\nother methods on discrete and continuous observation sequence data. The results\nsuggest that, in many cases, the GMMK has generalization error competitive with\nor better than other methods.\n",
          "  This paper proposes some extensions to the work on kernels dedicated to\nstring or time series global alignment based on the aggregation of scores\nobtained by local alignments. The extensions we propose allow to construct,\nfrom classical recursive definition of elastic distances, recursive edit\ndistance (or time-warp) kernels that are positive definite if some sufficient\nconditions are satisfied. The sufficient conditions we end-up with are original\nand weaker than those proposed in earlier works, although a recursive\nregularizing term is required to get the proof of the positive definiteness as\na direct consequence of the Haussler's convolution theorem. The classification\nexperiment we conducted on three classical time warp distances (two of which\nbeing metrics), using Support Vector Machine classifier, leads to conclude\nthat, when the pairwise distance matrix obtained from the training data is\n\\textit{far} from definiteness, the positive definite recursive elastic kernels\noutperform in general the distance substituting kernels for the classical\nelastic distances we have tested.\n",
          "  Applications in machine learning and data mining require computing pairwise\nLp distances in a data matrix A. For massive high-dimensional data, computing\nall pairwise distances of A can be infeasible. In fact, even storing A or all\npairwise distances of A in the memory may be also infeasible. This paper\nproposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where\np is even) distances into a sum of 2 marginal norms and p-1 ``inner products''\nat different orders. Then we apply normal or sub-Gaussian random projections to\napproximate the resultant ``inner products,'' assuming that the marginal norms\ncan be computed exactly by a linear scan. We propose two strategies for\napplying random projections. The basic projection strategy requires only one\nprojection matrix but it is more difficult to analyze, while the alternative\nprojection strategy requires p-1 projection matrices but its theoretical\nanalysis is much easier. In terms of the accuracy, at least for p=4, the basic\nstrategy is always more accurate than the alternative strategy if the data are\nnon-negative, which is common in reality.\n",
          "  Variable selection and dimension reduction are two commonly adopted\napproaches for high-dimensional data analysis, but have traditionally been\ntreated separately. Here we propose an integrated approach, called sparse\ngradient learning (SGL), for variable selection and dimension reduction via\nlearning the gradients of the prediction function directly from samples. By\nimposing a sparsity constraint on the gradients, variable selection is achieved\nby selecting variables corresponding to non-zero partial derivatives, and\neffective dimensions are extracted based on the eigenvectors of the derived\nsparse empirical gradient covariance matrix. An error analysis is given for the\nconvergence of the estimated gradients to the true ones in both the Euclidean\nand the manifold setting. We also develop an efficient forward-backward\nsplitting algorithm to solve the SGL problem, making the framework practically\nscalable for medium or large datasets. The utility of SGL for variable\nselection and feature extraction is explicitly given and illustrated on\nartificial data as well as real-world examples. The main advantages of our\nmethod include variable selection for both linear and nonlinear predictions,\neffective dimension reduction with sparse loadings, and an efficient algorithm\nfor large p, small n problems.\n",
          "  Maximum Variance Unfolding (MVU) and its variants have been very successful\nin embedding data-manifolds in lower dimensional spaces, often revealing the\ntrue intrinsic dimension. In this paper we show how to also incorporate\nsupervised class information into an MVU-like method without breaking its\nconvexity. We call this method the Isometric Separation Map and we show that\nthe resulting kernel matrix can be used as a binary/multiclass Support Vector\nMachine-like method in a semi-supervised (transductive) framework. We also show\nthat the method always finds a kernel matrix that linearly separates the\ntraining data exactly without projecting them in infinite dimensional spaces.\nIn traditional SVMs we choose a kernel and hope that the data become linearly\nseparable in the kernel space. In this paper we show how the hyperplane can be\nchosen ad-hoc and the kernel is trained so that data are always linearly\nseparable. Comparisons with Large Margin SVMs show comparable performance.\n",
          "  Kernel density estimation, a.k.a. Parzen windows, is a popular density\nestimation method, which can be used for outlier detection or clustering. With\nmultivariate data, its performance is heavily reliant on the metric used within\nthe kernel. Most earlier work has focused on learning only the bandwidth of the\nkernel (i.e., a scalar multiplicative factor). In this paper, we propose to\nlearn a full Euclidean metric through an expectation-minimization (EM)\nprocedure, which can be seen as an unsupervised counterpart to neighbourhood\ncomponent analysis (NCA). In order to avoid overfitting with a fully\nnonparametric density estimator in high dimensions, we also consider a\nsemi-parametric Gaussian-Parzen density model, where some of the variables are\nmodelled through a jointly Gaussian density, while others are modelled through\nParzen windows. For these two models, EM leads to simple closed-form updates\nbased on matrix inversions and eigenvalue decompositions. We show empirically\nthat our method leads to density estimators with higher test-likelihoods than\nnatural competing methods, and that the metrics may be used within most\nunsupervised learning techniques that rely on such metrics, such as spectral\nclustering or manifold learning methods. Finally, we present a stochastic\napproximation scheme which allows for the use of this method in a large-scale\nsetting.\n",
          "  A Support Vector Method for multivariate performance measures was recently\nintroduced by Joachims (2005). The underlying optimization problem is currently\nsolved using cutting plane methods such as SVM-Perf and BMRM. One can show that\nthese algorithms converge to an eta accurate solution in O(1/Lambda*e)\niterations, where lambda is the trade-off parameter between the regularizer and\nthe loss function. We present a smoothing strategy for multivariate performance\nscores, in particular precision/recall break-even point and ROCArea. When\ncombined with Nesterov's accelerated gradient algorithm our smoothing strategy\nyields an optimization algorithm which converges to an eta accurate solution in\nO(min{1/e,1/sqrt(lambda*e)}) iterations. Furthermore, the cost per iteration of\nour scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on a\nnumber of publicly available datasets shows that our method converges\nsignificantly faster than cutting plane methods without sacrificing\ngeneralization ability.\n",
          "  One of the major challenges of ECoG-based Brain-Machine Interfaces is the\nmovement prediction of a human subject. Several methods exist to predict an arm\n2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is\nto predict individual finger movements (5-D trajectory). The difficulty lies in\nthe fact that there is no simple relation between ECoG signals and finger\nmovement. We propose in this paper to decode finger flexions using switching\nmodels. This method permits to simplify the system as it is now described as an\nensemble of linear models depending on an internal state. We show that an\ninteresting accuracy prediction can be obtained by such a model.\n",
          "  The large number of spectral variables in most data sets encountered in\nspectral chemometrics often renders the prediction of a dependent variable\nuneasy. The number of variables hopefully can be reduced, by using either\nprojection techniques or selection methods; the latter allow for the\ninterpretation of the selected variables. Since the optimal approach of testing\nall possible subsets of variables with the prediction model is intractable, an\nincremental selection approach using a nonparametric statistics is a good\noption, as it avoids the computationally intensive use of the model itself. It\nhas two drawbacks however: the number of groups of variables to test is still\nhuge, and colinearities can make the results unstable. To overcome these\nlimitations, this paper presents a method to select groups of spectral\nvariables. It consists in a forward-backward procedure applied to the\ncoefficients of a B-Spline representation of the spectra. The criterion used in\nthe forward-backward procedure is the mutual information, allowing to find\nnonlinear dependencies between variables, on the contrary of the generally used\ncorrelation. The spline representation is used to get interpretability of the\nresults, as groups of consecutive spectral variables will be selected. The\nexperiments conducted on NIR spectra from fescue grass and diesel fuels show\nthat the method provides clearly identified groups of selected variables,\nmaking interpretation easy, while keeping a low computational load. The\nprediction performances obtained using the selected coefficients are higher\nthan those obtained by the same method applied directly to the original\nvariables and similar to those obtained using traditional models, although\nusing significantly less spectral variables.\n",
          "  We propose a randomized algorithm for training Support vector machines(SVMs)\non large datasets. By using ideas from Random projections we show that the\ncombinatorial dimension of SVMs is $O({log} n)$ with high probability. This\nestimate of combinatorial dimension is used to derive an iterative algorithm,\ncalled RandSVM, which at each step calls an existing solver to train SVMs on a\nrandomly chosen subset of size $O({log} n)$. The algorithm has probabilistic\nguarantees and is capable of training SVMs with Kernels for both classification\nand regression problems. Experiments done on synthetic and real life data sets\ndemonstrate that the algorithm scales up existing SVM learners, without loss of\naccuracy.\n",
          "  We present three generalisations of Kernel Principal Components Analysis\n(KPCA) which incorporate knowledge of the class labels of a subset of the data\npoints. The first, MV-KPCA, penalises within class variances similar to Fisher\ndiscriminant analysis. The second, LSKPCA is a hybrid of least squares\nregression and kernel PCA. The final LR-KPCA is an iteratively reweighted\nversion of the previous which achieves a sigmoid loss function on the labeled\npoints. We provide a theoretical risk bound as well as illustrative experiments\non real and toy data sets.\n",
          "  We show how text from news articles can be used to predict intraday price\nmovements of financial assets using support vector machines. Multiple kernel\nlearning is used to combine equity returns with text as predictive features to\nincrease classification performance and we develop an analytic center cutting\nplane method to solve the kernel learning problem efficiently. We observe that\nwhile the direction of returns is not predictable using either text or returns,\ntheir size is, with text features producing significantly better performance\nthan historical returns alone.\n",
          "  The paper addresses the problem of learning a regression model parameterized\nby a fixed-rank positive semidefinite matrix. The focus is on the nonlinear\nnature of the search space and on scalability to high-dimensional problems. The\nmathematical developments rely on the theory of gradient descent algorithms\nadapted to the Riemannian geometry that underlies the set of fixed-rank\npositive semidefinite matrices. In contrast with previous contributions in the\nliterature, no restrictions are imposed on the range space of the learned\nmatrix. The resulting algorithms maintain a linear complexity in the problem\nsize and enjoy important invariance properties. We apply the proposed\nalgorithms to the problem of learning a distance function parameterized by a\npositive semidefinite matrix. Good performance is observed on classical\nbenchmarks.\n",
          "  In recent years, the spectral analysis of appropriately defined kernel\nmatrices has emerged as a principled way to extract the low-dimensional\nstructure often prevalent in high-dimensional data. Here we provide an\nintroduction to spectral methods for linear and nonlinear dimension reduction,\nemphasizing ways to overcome the computational limitations currently faced by\npractitioners with massive datasets. In particular, a data subsampling or\nlandmark selection process is often employed to construct a kernel based on\npartial information, followed by an approximate spectral analysis termed the\nNystrom extension. We provide a quantitative framework to analyse this\nprocedure, and use it to demonstrate algorithmic performance bounds on a range\nof practical approaches designed to optimize the landmark selection process. We\ncompare the practical implications of these bounds by way of real-world\nexamples drawn from the field of computer vision, whereby low-dimensional\nmanifold structure is shown to emerge from high-dimensional video data streams.\n",
          "  To classify time series by nearest neighbors, we need to specify or learn one\nor several distance measures. We consider variations of the Mahalanobis\ndistance measures which rely on the inverse covariance matrix of the data.\nUnfortunately --- for time series data --- the covariance matrix has often low\nrank. To alleviate this problem we can either use a pseudoinverse, covariance\nshrinking or limit the matrix to its diagonal. We review these alternatives and\nbenchmark them against competitive methods such as the related Large Margin\nNearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)\ndistance. As we expected, we find that the DTW is superior, but the Mahalanobis\ndistance measures are one to two orders of magnitude faster. To get best\nresults with Mahalanobis distance measures, we recommend learning one distance\nmeasure per class using either covariance shrinking or the diagonal approach.\n",
          "  Metric and kernel learning are important in several machine learning\napplications. However, most existing metric learning algorithms are limited to\nlearning metrics over low-dimensional data, while existing kernel learning\nalgorithms are often limited to the transductive setting and do not generalize\nto new data points. In this paper, we study metric learning as a problem of\nlearning a linear transformation of the input data. We show that for\nhigh-dimensional data, a particular framework for learning a linear\ntransformation of the data based on the LogDet divergence can be efficiently\nkernelized to learn a metric (or equivalently, a kernel function) over an\narbitrarily high dimensional space. We further demonstrate that a wide class of\nconvex loss functions for learning linear transformations can similarly be\nkernelized, thereby considerably expanding the potential applications of metric\nlearning. We demonstrate our learning approach by applying it to large-scale\nreal world problems in computer vision and text mining.\n",
          "  Low-dimensional embedding, manifold learning, clustering, classification, and\nanomaly detection are among the most important problems in machine learning.\nThe existing methods usually consider the case when each instance has a fixed,\nfinite-dimensional feature representation. Here we consider a different\nsetting. We assume that each instance corresponds to a continuous probability\ndistribution. These distributions are unknown, but we are given some i.i.d.\nsamples from each distribution. Our goal is to estimate the distances between\nthese distributions and use these distances to perform low-dimensional\nembedding, clustering/classification, or anomaly detection for the\ndistributions. We present estimation algorithms, describe how to apply them for\nmachine learning tasks on distributions, and show empirical results on\nsynthetic data, real word images, and astronomical data sets.\n",
          "  We present a technique for spatiotemporal data analysis called nonlinear\nLaplacian spectral analysis (NLSA), which generalizes singular spectrum\nanalysis (SSA) to take into account the nonlinear manifold structure of complex\ndata sets. The key principle underlying NLSA is that the functions used to\nrepresent temporal patterns should exhibit a degree of smoothness on the\nnonlinear data manifold M; a constraint absent from classical SSA. NLSA\nenforces such a notion of smoothness by requiring that temporal patterns belong\nin low-dimensional Hilbert spaces V_l spanned by the leading l Laplace-Beltrami\neigenfunctions on M. These eigenfunctions can be evaluated efficiently in high\nambient-space dimensions using sparse graph-theoretic algorithms. Moreover,\nthey provide orthonormal bases to expand a family of linear maps, whose\nsingular value decomposition leads to sets of spatiotemporal patterns at\nprogressively finer resolution on the data manifold. The Riemannian measure of\nM and an adaptive graph kernel width enhances the capability of NLSA to detect\nimportant nonlinear processes, including intermittency and rare events. The\nminimum dimension of V_l required to capture these features while avoiding\noverfitting is estimated here using spectral entropy criteria.\n",
          "  Recent research on multiple kernel learning has lead to a number of\napproaches for combining kernels in regularized risk minimization. The proposed\napproaches include different formulations of objectives and varying\nregularization strategies. In this paper we present a unifying general\noptimization criterion for multiple kernel learning and show how existing\nformulations are subsumed as special cases. We also derive the criterion's dual\nrepresentation, which is suitable for general smooth optimization algorithms.\nFinally, we evaluate multiple kernel learning in this framework analytically\nusing a Rademacher complexity bound on the generalization error and empirically\nin a set of experiments.\n",
          "  Point clouds are sets of points in two or three dimensions. Most kernel\nmethods for learning on sets of points have not yet dealt with the specific\ngeometrical invariances and practical constraints associated with point clouds\nin computer vision and graphics. In this paper, we present extensions of graph\nkernels for point clouds, which allow to use kernel methods for such ob jects\nas shapes, line drawings, or any three-dimensional point clouds. In order to\ndesign rich and numerically efficient kernels with as few free parameters as\npossible, we use kernels between covariance matrices and their factorizations\non graphical models. We derive polynomial time dynamic programming recursions\nand present applications to recognition of handwritten digits and Chinese\ncharacters from few training examples.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_kernels_kernel_regularization",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_kernels_kernel_regularization"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.563809394836426,
          1.6379235982894897,
          2.681516647338867,
          2.856703281402588,
          1.9422858953475952,
          0.9997252821922302,
          2.417921543121338,
          1.0240010023117065,
          1.796420931816101,
          2.1674304008483887,
          1.6330245733261108,
          2.5756964683532715,
          2.381638288497925,
          2.2569451332092285,
          2.3562893867492676,
          2.3183610439300537,
          1.747668981552124,
          1.7527172565460205,
          1.9458909034729004,
          1.0718642473220825,
          0.9861966967582703,
          1.9206260442733765,
          2.4418277740478516,
          2.408461809158325,
          2.571455717086792,
          2.544491767883301,
          1.2628536224365234,
          1.7272871732711792,
          1.8915705680847168,
          2.5655109882354736,
          1.7470594644546509,
          2.5660152435302734,
          0.9934170246124268,
          2.5168309211730957,
          1.1121612787246704,
          2.197080612182617,
          2.2851099967956543,
          2.4671287536621094,
          2.392159938812256,
          1.7598307132720947,
          1.285138487815857,
          1.9777952432632446,
          2.369955539703369,
          1.6809937953948975,
          1.8153700828552246,
          2.314439535140991,
          2.03135347366333,
          1.6230567693710327,
          2.5418479442596436,
          2.03692889213562,
          1.95809805393219,
          1.4755960702896118,
          1.974537968635559,
          1.412697434425354,
          2.5670013427734375,
          1.911736249923706,
          1.6478387117385864,
          2.3664157390594482,
          2.5601863861083984,
          1.2608373165130615,
          2.798081398010254,
          2.7129034996032715,
          1.2132986783981323,
          1.894529938697815,
          1.2983518838882446,
          2.4093968868255615,
          2.7877895832061768,
          -0.8668909668922424,
          1.8133471012115479,
          1.5049498081207275,
          2.5311055183410645,
          2.0035736560821533,
          1.8294051885604858,
          1.591789960861206,
          2.8206794261932373,
          2.7568624019622803,
          1.328330636024475,
          2.2591872215270996,
          2.573789596557617,
          1.6388534307479858,
          2.5622341632843018,
          1.7998408079147339,
          1.8936805725097656,
          2.2351508140563965,
          2.460254430770874,
          2.7547390460968018,
          2.165332555770874,
          2.6663131713867188,
          1.6595224142074585,
          1.8229384422302246,
          2.5331850051879883,
          1.0220390558242798,
          1.9059646129608154,
          2.6088674068450928,
          2.3238093852996826,
          2.528061866760254,
          1.172946810722351,
          2.5684168338775635,
          1.9443053007125854,
          1.2236785888671875,
          1.0831021070480347,
          2.544644832611084,
          1.2034848928451538,
          2.3315742015838623,
          2.5127577781677246,
          0.9687740206718445,
          1.1129422187805176,
          2.585359573364258,
          2.425349473953247,
          1.8633090257644653,
          2.727410078048706,
          2.5537338256835938,
          2.3116469383239746,
          1.559324026107788,
          1.743875503540039,
          1.6037700176239014,
          1.4631786346435547,
          1.4760501384735107,
          2.818984031677246,
          2.379777669906616,
          1.5527465343475342,
          2.602518081665039,
          1.9536428451538086,
          2.385967254638672,
          2.2293338775634766,
          1.2045291662216187,
          1.5519485473632812,
          1.7404849529266357,
          1.3468941450119019,
          1.1348861455917358,
          2.40889835357666,
          1.7099688053131104,
          1.9783200025558472
         ],
         "y": [
          9.470057487487793,
          8.797643661499023,
          8.955670356750488,
          9.02927017211914,
          8.36368179321289,
          9.43819808959961,
          8.795921325683594,
          9.482134819030762,
          8.801702499389648,
          9.107791900634766,
          8.637680053710938,
          8.083465576171875,
          9.419984817504883,
          8.652620315551758,
          9.071334838867188,
          9.111084938049316,
          8.645659446716309,
          8.815373420715332,
          9.210933685302734,
          9.529678344726562,
          9.537525177001953,
          9.352546691894531,
          8.752096176147461,
          8.987236976623535,
          9.475963592529297,
          8.348871231079102,
          9.439176559448242,
          8.798808097839355,
          8.941680908203125,
          9.47800350189209,
          8.716793060302734,
          8.755379676818848,
          9.604931831359863,
          8.780718803405762,
          9.6607666015625,
          8.972712516784668,
          9.075929641723633,
          8.66305923461914,
          9.348222732543945,
          8.844088554382324,
          9.438040733337402,
          8.98210620880127,
          9.491726875305176,
          8.617538452148438,
          8.205209732055664,
          8.668793678283691,
          9.026172637939453,
          9.233004570007324,
          9.461101531982422,
          9.115854263305664,
          8.517404556274414,
          9.321250915527344,
          8.979687690734863,
          9.346768379211426,
          8.352993965148926,
          9.044532775878906,
          8.931998252868652,
          9.202789306640625,
          9.479191780090332,
          9.455939292907715,
          8.991491317749023,
          8.623103141784668,
          9.497662544250488,
          8.376789093017578,
          9.41388988494873,
          8.692935943603516,
          8.940744400024414,
          8.229409217834473,
          8.366608619689941,
          9.468546867370605,
          8.83784008026123,
          9.088522911071777,
          9.476775169372559,
          8.897431373596191,
          8.98932933807373,
          8.941025733947754,
          9.364385604858398,
          8.061576843261719,
          8.827523231506348,
          8.897088050842285,
          8.171537399291992,
          8.572989463806152,
          8.690339088439941,
          9.191755294799805,
          9.292078018188477,
          9.003711700439453,
          9.054409980773926,
          8.899325370788574,
          8.528576850891113,
          9.589319229125977,
          9.458097457885742,
          9.514360427856445,
          9.028740882873535,
          9.295462608337402,
          9.193632125854492,
          9.007052421569824,
          9.245019912719727,
          9.470458030700684,
          9.036738395690918,
          9.003883361816406,
          9.148502349853516,
          9.176891326904297,
          9.481162071228027,
          8.689262390136719,
          8.318705558776855,
          9.5634183883667,
          9.097945213317871,
          8.752192497253418,
          9.416424751281738,
          8.918742179870605,
          9.121275901794434,
          8.345444679260254,
          8.702614784240723,
          8.82053279876709,
          8.778916358947754,
          9.605318069458008,
          9.370594024658203,
          9.048147201538086,
          9.02964973449707,
          9.124025344848633,
          9.497828483581543,
          8.826356887817383,
          9.069717407226562,
          8.761286735534668,
          9.444962501525879,
          9.457281112670898,
          8.809362411499023,
          8.853009223937988,
          9.013026237487793,
          9.495575904846191,
          9.142168998718262,
          8.848359107971191,
          9.021101951599121
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  In this theoretical paper we are concerned with the problem of learning a\nvalue function by a smooth general function approximator, to solve a\ndeterministic episodic control problem in a large continuous state space. It is\nshown that learning the gradient of the value-function at every point along a\ntrajectory generated by a greedy policy is a sufficient condition for the\ntrajectory to be locally extremal, and often locally optimal, and we argue that\nthis brings greater efficiency to value-function learning. This contrasts to\ntraditional value-function learning in which the value-function must be learnt\nover the whole of state space.\n  It is also proven that policy-gradient learning applied to a greedy policy on\na value-function produces a weight update equivalent to a value-gradient weight\nupdate, which provides a surprising connection between these two alternative\nparadigms of reinforcement learning, and a convergence proof for control\nproblems with a value function represented by a general smooth function\napproximator.\n",
          "  The use of mobile robots is being popular over the world mainly for\nautonomous explorations in hazardous/ toxic or unknown environments. This\nexploration will be more effective and efficient if the explorations in unknown\nenvironment can be aided with the learning from past experiences. Currently\nreinforcement learning is getting more acceptances for implementing learning in\nrobots from the system-environment interactions. This learning can be\nimplemented using the concept of both single-agent and multiagent. This paper\ndescribes such a multiagent approach for implementing a type of reinforcement\nlearning using a priority based behaviour-based architecture. This proposed\nmethodology has been successfully tested in both indoor and outdoor\nenvironments.\n",
          "  General-purpose, intelligent, learning agents cycle through sequences of\nobservations, actions, and rewards that are complex, uncertain, unknown, and\nnon-Markovian. On the other hand, reinforcement learning is well-developed for\nsmall finite state Markov decision processes (MDPs). Up to now, extracting the\nright state representations out of bare observations, that is, reducing the\ngeneral agent setup to the MDP framework, is an art that involves significant\neffort by designers. The primary goal of this work is to automate the reduction\nprocess and thereby significantly expand the scope of many existing\nreinforcement learning algorithms and the agents that employ them. Before we\ncan think of mechanizing this search for suitable MDPs, we need a formal\nobjective criterion. The main contribution of this article is to develop such a\ncriterion. I also integrate the various parts into one learning algorithm.\nExtensions to more realistic dynamic Bayesian networks are developed in Part\nII. The role of POMDPs is also considered there.\n",
          "  A technique for speeding up reinforcement learning algorithms by using time\nmanipulation is proposed. It is applicable to failure-avoidance control\nproblems running in a computer simulation. Turning the time of the simulation\nbackwards on failure events is shown to speed up the learning by 260% and\nimprove the state space exploration by 12% on the cart-pole balancing task,\ncompared to the conventional Q-learning and Actor-Critic algorithms.\n",
          "  Most conventional Reinforcement Learning (RL) algorithms aim to optimize\ndecision-making rules in terms of the expected returns. However, especially for\nrisk management purposes, other risk-sensitive criteria such as the\nvalue-at-risk or the expected shortfall are sometimes preferred in real\napplications. Here, we describe a parametric method for estimating density of\nthe returns, which allows us to handle various criteria in a unified manner. We\nfirst extend the Bellman equation for the conditional expected return to cover\na conditional probability density of the returns. Then we derive an extension\nof the TD-learning algorithm for estimating the return densities in an unknown\nenvironment. As test instances, several parametric density estimation\nalgorithms are presented for the Gaussian, Laplace, and skewed Laplace\ndistributions. We show that these algorithms lead to risk-sensitive as well as\nrobust RL paradigms through numerical experiments.\n",
          "  We propose a new, nonparametric approach to estimating the value function in\nreinforcement learning. This approach makes use of a recently developed\nrepresentation of conditional distributions as functions in a reproducing\nkernel Hilbert space. Such representations bypass the need for estimating\ntransition probabilities, and apply to any domain on which kernels can be\ndefined. Our approach avoids the need to approximate intractable integrals\nsince expectations are represented as RKHS inner products whose computation has\nlinear complexity in the sample size. Thus, we can efficiently perform value\nfunction estimation in a wide variety of settings, including finite state\nspaces, continuous states spaces, and partially observable tasks where only\nsensor measurements are available. A second advantage of the approach is that\nwe learn the conditional distribution representation from a training sample,\nand do not require an exhaustive exploration of the state space. We prove\nconvergence of our approach either to the optimal policy, or to the closest\nprojection of the optimal policy in our model class, under reasonable\nassumptions. In experiments, we demonstrate the performance of our algorithm on\na learning task in a continuous state space (the under-actuated pendulum), and\non a navigation problem where only images from a sensor are observed. We\ncompare with least-squares policy iteration where a Gaussian process is used\nfor value function estimation. Our algorithm achieves better performance in\nboth tasks.\n",
          "  There has been a lot of recent work on Bayesian methods for reinforcement\nlearning exhibiting near-optimal online performance. The main obstacle facing\nsuch methods is that in most problems of interest, the optimal solution\ninvolves planning in an infinitely large tree. However, it is possible to\nobtain stochastic lower and upper bounds on the value of each tree node. This\nenables us to use stochastic branch and bound algorithms to search the tree\nefficiently. This paper proposes two such algorithms and examines their\ncomplexity in this setting.\n",
          "  Serious Games (SGs) have experienced a tremendous outburst these last years.\nVideo game companies have been producing fun, user-friendly SGs, but their\neducational value has yet to be proven. Meanwhile, cognition research scientist\nhave been developing SGs in such a way as to guarantee an educational gain, but\nthe fun and attractive characteristics featured often would not meet the\npublic's expectations. The ideal SG must combine these two aspects while still\nbeing economically viable. In this article, we propose a production chain model\nto efficiently conceive and produce SGs that are certified for their\neducational gain and fun qualities. Each step of this chain will be described\nalong with the human actors, the tools and the documents that intervene.\n",
          "  In experimenting with off-policy temporal difference (TD) methods in\nhierarchical reinforcement learning (HRL) systems, we have observed unwanted\non-policy learning under reproducible conditions. Here we present modifications\nto several TD methods that prevent unintentional on-policy learning from\noccurring. These modifications create a tension between exploration and\nlearning. Traditional TD methods require commitment to finishing subtasks\nwithout exploration in order to update Q-values for early actions with high\nprobability. One-step intra-option learning and temporal second difference\ntraces (TSDT) do not suffer from this limitation. We demonstrate that our HRL\nsystem is efficient without commitment to completion of subtasks in a\ncliff-walking domain, contrary to a widespread claim in the literature that it\nis critical for efficiency of learning. Furthermore, decreasing commitment as\nexploration progresses is shown to improve both online performance and the\nresultant policy in the taxicab domain, opening a new avenue for research into\nwhen it is more beneficial to continue with the current subtask or to replan.\n",
          "  General purpose intelligent learning agents cycle through (complex,non-MDP)\nsequences of observations, actions, and rewards. On the other hand,\nreinforcement learning is well-developed for small finite state Markov Decision\nProcesses (MDPs). So far it is an art performed by human designers to extract\nthe right state representation out of the bare observations, i.e. to reduce the\nagent setup to the MDP framework. Before we can think of mechanizing this\nsearch for suitable MDPs, we need a formal objective criterion. The main\ncontribution of this article is to develop such a criterion. I also integrate\nthe various parts into one learning algorithm. Extensions to more realistic\ndynamic Bayesian networks are developed in a companion article.\n",
          "  This paper introduces a principled approach for the design of a scalable\ngeneral reinforcement learning agent. This approach is based on a direct\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\nlearning agents. Previously, it has been unclear whether the theory of AIXI\ncould motivate the design of practical algorithms. We answer this hitherto open\nquestion in the affirmative, by providing the first computationally feasible\napproximation to the AIXI agent. To develop our approximation, we introduce a\nMonte Carlo Tree Search algorithm along with an agent-specific extension of the\nContext Tree Weighting algorithm. Empirically, we present a set of encouraging\nresults on a number of stochastic, unknown, and partially observable domains.\n",
          "  We address the problem of reinforcement learning in which observations may\nexhibit an arbitrary form of stochastic dependence on past observations and\nactions, i.e. environments more general than (PO)MDPs. The task for an agent is\nto attain the best possible asymptotic reward where the true generating\nenvironment is unknown but belongs to a known countable family of environments.\nWe find some sufficient conditions on the class of environments under which an\nagent exists which attains the best asymptotic reward for any environment in\nthe class. We analyze how tight these conditions are and how they relate to\ndifferent probabilistic assumptions known in reinforcement learning and related\nfields, such as Markov Decision Processes and mixing conditions.\n",
          "  The use of Reinforcement Learning in real-world scenarios is strongly limited\nby issues of scale. Most RL learning algorithms are unable to deal with\nproblems composed of hundreds or sometimes even dozens of possible actions, and\ntherefore cannot be applied to many real-world problems. We consider the RL\nproblem in the supervised classification framework where the optimal policy is\nobtained through a multiclass classifier, the set of classes being the set of\nactions of the problem. We introduce error-correcting output codes (ECOCs) in\nthis setting and propose two new methods for reducing complexity when using\nrollouts-based approaches. The first method consists in using an ECOC-based\nclassifier as the multiclass classifier, reducing the learning complexity from\nO(A2) to O(Alog(A)). We then propose a novel method that profits from the\nECOC's coding dictionary to split the initial MDP into O(log(A)) seperate\ntwo-action MDPs. This second method reduces learning complexity even further,\nfrom O(A2) to O(log(A)), thus rendering problems with large action sets\ntractable. We finish by experimentally demonstrating the advantages of our\napproach on a set of benchmark problems, both in speed and performance.\n",
          "  The explore{exploit dilemma is one of the central challenges in Reinforcement\nLearning (RL). Bayesian RL solves the dilemma by providing the agent with\ninformation in the form of a prior distribution over environments; however,\nfull Bayesian planning is intractable. Planning with the mean MDP is a common\nmyopic approximation of Bayesian planning. We derive a novel reward bonus that\nis a function of the posterior distribution over environments, which, when\nadded to the reward in planning with the mean MDP, results in an agent which\nexplores efficiently and effectively. Although our method is similar to\nexisting methods when given an uninformative or unstructured prior, unlike\nexisting methods, our method can exploit structured priors. We prove that our\nmethod results in a polynomial sample complexity and empirically demonstrate\nits advantages in a structured exploration task.\n",
          "  A mechanism called Eligibility Propagation is proposed to speed up the Time\nHopping technique used for faster Reinforcement Learning in simulations.\nEligibility Propagation provides for Time Hopping similar abilities to what\neligibility traces provide for conventional Reinforcement Learning. It\npropagates values from one state to all of its temporal predecessors using a\nstate transitions graph. Experiments on a simulated biped crawling robot\nconfirm that Eligibility Propagation accelerates the learning process more than\n3 times.\n",
          "  A central problem in artificial intelligence is that of planning to maximize\nfuture reward under uncertainty in a partially observable environment. In this\npaper we propose and demonstrate a novel algorithm which accurately learns a\nmodel of such an environment directly from sequences of action-observation\npairs. We then close the loop from observations to actions by planning in the\nlearned model and recovering a policy which is near-optimal in the original\nenvironment. Specifically, we present an efficient and statistically consistent\nspectral algorithm for learning the parameters of a Predictive State\nRepresentation (PSR). We demonstrate the algorithm by learning a model of a\nsimulated high-dimensional, vision-based mobile robot planning task, and then\nperform approximate point-based planning in the learned PSR. Analysis of our\nresults shows that the algorithm learns a state space which efficiently\ncaptures the essential features of the environment. This representation allows\naccurate prediction with a small number of parameters, and enables successful\nand efficient planning.\n",
          "  Artificial general intelligence aims to create agents capable of learning to\nsolve arbitrary interesting problems. We define two versions of asymptotic\noptimality and prove that no agent can satisfy the strong version while in some\ncases, depending on discounting, there does exist a non-computable weak\nasymptotically optimal agent.\n",
          "  Two meta-evolutionary optimization strategies described in this paper\naccelerate the convergence of evolutionary programming algorithms while still\nretaining much of their ability to deal with multi-modal problems. The\nstrategies, called directional mutation and recorded step in this paper, can\noperate independently but together they greatly enhance the ability of\nevolutionary programming algorithms to deal with fitness landscapes\ncharacterized by long narrow valleys. The directional mutation aspect of this\ncombined method uses correlated meta-mutation but does not introduce a full\ncovariance matrix. These new methods are thus much more economical in terms of\nstorage for problems with high dimensionality. Additionally, directional\nmutation is rotationally invariant which is a substantial advantage over\nself-adaptive methods which use a single variance per coordinate for problems\nwhere the natural orientation of the problem is not oriented along the axes.\n",
          "  The exploration-exploitation trade-off is among the central challenges of\nreinforcement learning. The optimal Bayesian solution is intractable in\ngeneral. This paper studies to what extent analytic statements about optimal\nlearning are possible if all beliefs are Gaussian processes. A first order\napproximation of learning of both loss and dynamics, for nonlinear,\ntime-varying systems in continuous time and space, subject to a relatively weak\nrestriction on the dynamics, is described by an infinite-dimensional partial\ndifferential equation. An approximate finite-dimensional projection gives an\nimpression for how this result may be helpful.\n",
          "  In this paper we propose an algorithm for polynomial-time reinforcement\nlearning in factored Markov decision processes (FMDPs). The factored optimistic\ninitial model (FOIM) algorithm, maintains an empirical model of the FMDP in a\nconventional way, and always follows a greedy policy with respect to its model.\nThe only trick of the algorithm is that the model is initialized\noptimistically. We prove that with suitable initialization (i) FOIM converges\nto the fixed point of approximate value iteration (AVI); (ii) the number of\nsteps when the agent makes non-near-optimal decisions (with respect to the\nsolution of AVI) is polynomial in all relevant quantities; (iii) the per-step\ncosts of the algorithm are also polynomial. To our best knowledge, FOIM is the\nfirst algorithm with these properties. This extended version contains the\nrigorous proofs of the main theorem. A version of this paper appeared in\nICML'09.\n",
          "  In this paper we propose a novel algorithm, factored value iteration (FVI),\nfor the approximate solution of factored Markov decision processes (fMDPs). The\ntraditional approximate value iteration algorithm is modified in two ways. For\none, the least-squares projection operator is modified so that it does not\nincrease max-norm, and thus preserves convergence. The other modification is\nthat we uniformly sample polynomially many samples from the (exponentially\nlarge) state space. This way, the complexity of our algorithm becomes\npolynomial in the size of the fMDP description length. We prove that the\nalgorithm is convergent. We also derive an upper bound on the difference\nbetween our approximate solution and the optimal one, and also on the error\nintroduced by sampling. We analyze various projection operators with respect to\ntheir computation complexity and their convergence when combined with\napproximate value iteration.\n",
          "  However utilizing rich, interactive solutions can make learning more\neffective and attractive, scenario- and game-based educational resources on the\nweb are not widely used. Creating these applications is a complex, expensive\nand challenging process. Development frameworks and authoring tools hardly\nsupport reusable components, teamwork and learning management\nsystem-independent courseware architecture. In this article we initiate the\nconcept of a low-level, thick-client solution addressing these problems. With\nsome example applications we try to demonstrate, how a framework, based on this\nconcept can be useful for developing scenario- and game-based e-learning\nenvironments.\n",
          "  Bayesian priors offer a compact yet general means of incorporating domain\nknowledge into many learning tasks. The correctness of the Bayesian analysis\nand inference, however, largely depends on accuracy and correctness of these\npriors. PAC-Bayesian methods overcome this problem by providing bounds that\nhold regardless of the correctness of the prior distribution. This paper\nintroduces the first PAC-Bayesian bound for the batch reinforcement learning\nproblem with function approximation. We show how this bound can be used to\nperform model-selection in a transfer learning scenario. Our empirical results\nconfirm that PAC-Bayesian policy evaluation is able to leverage prior\ndistributions when they are informative and, unlike standard Bayesian RL\napproaches, ignore them when they are misleading.\n",
          "  Transfer reinforcement learning (RL) methods leverage on the experience\ncollected on a set of source tasks to speed-up RL algorithms. A simple and\neffective approach is to transfer samples from source tasks and include them\ninto the training set used to solve a given target task. In this paper, we\ninvestigate the theoretical properties of this transfer method and we introduce\nnovel algorithms adapting the transfer process on the basis of the similarity\nbetween source and target tasks. Finally, we report illustrative experimental\nresults in a continuous chain problem.\n",
          "  We state the problem of inverse reinforcement learning in terms of preference\nelicitation, resulting in a principled (Bayesian) statistical formulation. This\ngeneralises previous work on Bayesian inverse reinforcement learning and allows\nus to obtain a posterior distribution on the agent's preferences, policy and\noptionally, the obtained reward sequence, from observations. We examine the\nrelation of the resulting approach to other statistical methods for inverse\nreinforcement learning via analysis and experimental results. We show that\npreferences can be determined accurately, even if the observed agent's policy\nis sub-optimal with respect to its own preferences. In that case, significantly\nimproved policies with respect to the agent's preferences are obtained,\ncompared to both other methods and to the performance of the demonstrated\npolicy.\n",
          "  In large systems, it is important for agents to learn to act effectively, but\nsophisticated multi-agent learning algorithms generally do not scale. An\nalternative approach is to find restricted classes of games where simple,\nefficient algorithms converge. It is shown that stage learning efficiently\nconverges to Nash equilibria in large anonymous games if best-reply dynamics\nconverge. Two features are identified that improve convergence. First, rather\nthan making learning more difficult, more agents are actually beneficial in\nmany settings. Second, providing agents with statistical information about the\nbehavior of others can significantly reduce the number of observations needed.\n",
          "  This paper gives specific divergence examples of value-iteration for several\nmajor Reinforcement Learning and Adaptive Dynamic Programming algorithms, when\nusing a function approximator for the value function. These divergence examples\ndiffer from previous divergence examples in the literature, in that they are\napplicable for a greedy policy, i.e. in a \"value iteration\" scenario. Perhaps\nsurprisingly, with a greedy policy, it is also possible to get divergence for\nthe algorithms TD(1) and Sarsa(1). In addition to these divergences, we also\nachieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and\nGDHP.\n",
          "  The task of keyhole (unobtrusive) plan recognition is central to adaptive\ngame AI. \"Tech trees\" or \"build trees\" are the core of real-time strategy (RTS)\ngame strategic (long term) planning. This paper presents a generic and simple\nBayesian model for RTS build tree prediction from noisy observations, which\nparameters are learned from replays (game logs). This unsupervised machine\nlearning approach involves minimal work for the game developers as it leverage\nplayers' data (com- mon in RTS). We applied it to StarCraft1 and showed that it\nyields high quality and robust predictions, that can feed an adaptive AI.\n",
          "  In this paper, we propose a novel policy iteration method, called dynamic\npolicy programming (DPP), to estimate the optimal policy in the\ninfinite-horizon Markov decision processes. We prove the finite-iteration and\nasymptotic l\\infty-norm performance-loss bounds for DPP in the presence of\napproximation/estimation error. The bounds are expressed in terms of the\nl\\infty-norm of the average accumulated error as opposed to the l\\infty-norm of\nthe error in the case of the standard approximate value iteration (AVI) and the\napproximate policy iteration (API). This suggests that DPP can achieve a better\nperformance than AVI and API since it averages out the simulation noise caused\nby Monte-Carlo sampling throughout the learning process. We examine this\ntheoretical results numerically by com- paring the performance of the\napproximate variants of DPP with existing reinforcement learning (RL) methods\non different problem domains. Our results show that, in all cases, DPP-based\nalgorithms outperform other RL methods by a wide margin.\n",
          "  The Turing Test (TT) checks for human intelligence, rather than any putative\ngeneral intelligence. It involves repeated interaction requiring learning in\nthe form of adaption to the human conversation partner. It is a macro-level\npost-hoc test in contrast to the definition of a Turing Machine (TM), which is\na prior micro-level definition. This raises the question of whether learning is\njust another computational process, i.e. can be implemented as a TM. Here we\nargue that learning or adaption is fundamentally different from computation,\nthough it does involve processes that can be seen as computations. To\nillustrate this difference we compare (a) designing a TM and (b) learning a TM,\ndefining them for the purpose of the argument. We show that there is a\nwell-defined sequence of problems which are not effectively designable but are\nlearnable, in the form of the bounded halting problem. Some characteristics of\nhuman intelligence are reviewed including it's: interactive nature, learning\nabilities, imitative tendencies, linguistic ability and context-dependency. A\nstory that explains some of these is the Social Intelligence Hypothesis. If\nthis is broadly correct, this points to the necessity of a considerable period\nof acculturation (social learning in context) if an artificial intelligence is\nto pass the TT. Whilst it is always possible to 'compile' the results of\nlearning into a TM, this would not be a designed TM and would not be able to\ncontinually adapt (pass future TTs). We conclude three things, namely that: a\npurely \"designed\" TM will never pass the TT; that there is no such thing as a\ngeneral intelligence since it necessary involves learning; and that\nlearning/adaption and computation should be clearly distinguished.\n",
          "  A fundamental task in detecting foreground objects in both static and dynamic\nscenes is to take the best choice of color system representation and the\nefficient technique for background modeling. We propose in this paper a\nnon-parametric algorithm dedicated to segment and to detect objects in color\nimages issued from a football sports meeting. Indeed segmentation by pixel\nconcern many applications and revealed how the method is robust to detect\nobjects, even in presence of strong shadows and highlights. In the other hand\nto refine their playing strategy such as in football, handball, volley ball,\nRugby..., the coach need to have a maximum of technical-tactics information\nabout the on-going of the game and the players. We propose in this paper a\nrange of algorithms allowing the resolution of many problems appearing in the\nautomated process of team identification, where each player is affected to his\ncorresponding team relying on visual data. The developed system was tested on a\nmatch of the Tunisian national competition. This work is prominent for many\nnext computer vision studies as it's detailed in this study.\n",
          "  In the Bayesian approach to sequential decision making, exact calculation of\nthe (subjective) utility is intractable. This extends to most special cases of\ninterest, such as reinforcement learning problems. While utility bounds are\nknown to exist for this problem, so far none of them were particularly tight.\nIn this paper, we show how to efficiently calculate a lower bound, which\ncorresponds to the utility of a near-optimal memoryless policy for the decision\nproblem, which is generally different from both the Bayes-optimal policy and\nthe policy which is optimal for the expected MDP under the current belief. We\nthen show how these can be applied to obtain robust exploration policies in a\nBayesian reinforcement learning setting.\n",
          "  Feature Markov Decision Processes (PhiMDPs) are well-suited for learning\nagents in general environments. Nevertheless, unstructured (Phi)MDPs are\nlimited to relatively simple environments. Structured MDPs like Dynamic\nBayesian Networks (DBNs) are used for large-scale real-world problems. In this\narticle I extend PhiMDP to PhiDBN. The primary contribution is to derive a cost\ncriterion that allows to automatically extract the most relevant features from\nthe environment, leading to the \"best\" DBN representation. I discuss all\nbuilding blocks required for a complete general learning algorithm.\n",
          "  Although exploratory behaviors are ubiquitous in the animal kingdom, their\ncomputational underpinnings are still largely unknown. Behavioral Psychology\nhas identified learning as a primary drive underlying many exploratory\nbehaviors. Exploration is seen as a means for an animal to gather sensory data\nuseful for reducing its ignorance about the environment. While related problems\nhave been addressed in Data Mining and Reinforcement Learning, the\ncomputational modeling of learning-driven exploration by embodied agents is\nlargely unrepresented.\n  Here, we propose a computational theory for learning-driven exploration based\non the concept of missing information that allows an agent to identify\ninformative actions using Bayesian inference. We demonstrate that when\nembodiment constraints are high, agents must actively coordinate their actions\nto learn efficiently. Compared to earlier approaches, our exploration policy\nyields more efficient learning across a range of worlds with diverse\nstructures. The improved learning in turn affords greater success in general\ntasks including navigation and reward gathering. We conclude by discussing how\nthe proposed theory relates to previous information-theoretic objectives of\nbehavior, such as predictive information and the free energy principle, and how\nit might contribute to a general theory of exploratory behavior.\n",
          "  Most of computer science focuses on automatically solving given computational\nproblems. I focus on automatically inventing or discovering problems in a way\ninspired by the playful behavior of animals and humans, to train a more and\nmore general problem solver from scratch in an unsupervised fashion. Consider\nthe infinite set of all computable descriptions of tasks with possibly\ncomputable solutions. The novel algorithmic framework POWERPLAY (2011)\ncontinually searches the space of possible pairs of new tasks and modifications\nof the current problem solver, until it finds a more powerful problem solver\nthat provably solves all previously learned tasks plus the new one, while the\nunmodified predecessor does not. Wow-effects are achieved by continually making\npreviously learned skills more efficient such that they require less time and\nspace. New skills may (partially) re-use previously learned skills. POWERPLAY's\nsearch orders candidate pairs of tasks and solver modifications by their\nconditional computational (time & space) complexity, given the stored\nexperience so far. The new task and its corresponding task-solving skill are\nthose first found and validated. The computational costs of validating new\ntasks need not grow with task repertoire size. POWERPLAY's ongoing search for\nnovelty keeps breaking the generalization abilities of its present solver. This\nis related to Goedel's sequence of increasingly powerful formal theories based\non adding formerly unprovable statements to the axioms without affecting\npreviously provable theorems. The continually increasing repertoire of problem\nsolving procedures can be exploited by a parallel search for solutions to\nadditional externally posed tasks. POWERPLAY may be viewed as a greedy but\npractical implementation of basic principles of creativity. A first\nexperimental analysis can be found in separate papers [53,54].\n",
          "  Research in reinforcement learning has produced algorithms for optimal\ndecision making under uncertainty that fall within two main types. The first\nemploys a Bayesian framework, where optimality improves with increased\ncomputational time. This is because the resulting planning task takes the form\nof a dynamic programming problem on a belief tree with an infinite number of\nstates. The second type employs relatively simple algorithm which are shown to\nsuffer small regret within a distribution-free framework. This paper presents a\nlower bound and a high probability upper bound on the optimal value function\nfor the nodes in the Bayesian belief tree, which are analogous to similar\nbounds in POMDPs. The bounds are then used to create more efficient strategies\nfor exploring the tree. The resulting algorithms are compared with the\ndistribution-free algorithm UCB1, as well as a simpler baseline algorithm on\nmulti-armed bandit problems.\n",
          "  This paper introduces a principled approach for the design of a scalable\ngeneral reinforcement learning agent. Our approach is based on a direct\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\nlearning agents. Previously, it has been unclear whether the theory of AIXI\ncould motivate the design of practical algorithms. We answer this hitherto open\nquestion in the affirmative, by providing the first computationally feasible\napproximation to the AIXI agent. To develop our approximation, we introduce a\nnew Monte-Carlo Tree Search algorithm along with an agent-specific extension to\nthe Context Tree Weighting algorithm. Empirically, we present a set of\nencouraging results on a variety of stochastic and partially observable\ndomains. We conclude by proposing a number of directions for future research.\n",
          "  We describe a preliminary investigation into learning a Chess player's style\nfrom game records. The method is based on attempting to learn features of a\nplayer's individual evaluation function using the method of temporal\ndifferences, with the aid of a conventional Chess engine architecture. Some\nencouraging results were obtained in learning the styles of two recent Chess\nworld champions, and we report on our attempt to use the learnt styles to\ndiscriminate between the players from game records by trying to detect who was\nplaying white and who was playing black. We also discuss some limitations of\nour approach and propose possible directions for future research. The method we\nhave presented may also be applicable to other strategic games, and may even be\ngeneralisable to other domains where sequences of agents' actions are recorded.\n",
          "  Traditional Reinforcement Learning (RL) has focused on problems involving\nmany states and few actions, such as simple grid worlds. Most real world\nproblems, however, are of the opposite type, Involving Few relevant states and\nmany actions. For example, to return home from a conference, humans identify\nonly few subgoal states such as lobby, taxi, airport etc. Each valid behavior\nconnecting two such states can be viewed as an action, and there are trillions\nof them. Assuming the subgoal identification problem is already solved, the\nquality of any RL method---in real-world settings---depends less on how well it\nscales with the number of states than on how well it scales with the number of\nactions. This is where our new method T-Learning excels, by evaluating the\nrelatively few possible transits from one state to another in a\npolicy-independent way, rather than a huge number of state-action pairs, or\nstates in traditional policy-dependent ways. Illustrative experiments\ndemonstrate that performance improvements of T-Learning over Q-learning can be\narbitrarily large.\n",
          "  Knowledge Representation is important issue in reinforcement learning. In\nthis paper, we bridge the gap between reinforcement learning and knowledge\nrepresentation, by providing a rich knowledge representation framework, based\non normal logic programs with answer set semantics, that is capable of solving\nmodel-free reinforcement learning problems for more complex do-mains and\nexploits the domain-specific knowledge. We prove the correctness of our\napproach. We show that the complexity of finding an offline and online policy\nfor a model-free reinforcement learning problem in our approach is NP-complete.\nMoreover, we show that any model-free reinforcement learning problem in MDP\nenvironment can be encoded as a SAT problem. The importance of that is\nmodel-free reinforcement\n",
          "  Estimator algorithms in learning automata are useful tools for adaptive,\nreal-time optimization in computer science and engineering applications. This\npaper investigates theoretical convergence properties for a special case of\nestimator algorithms: the pursuit learning algorithm. In this note, we identify\nand fill a gap in existing proofs of probabilistic convergence for pursuit\nlearning. It is tradition to take the pursuit learning tuning parameter to be\nfixed in practical applications, but our proof sheds light on the importance of\na vanishing sequence of tuning parameters in a theoretical convergence\nanalysis.\n",
          "  In this article, we work towards the goal of developing agents that can learn\nto act in complex worlds. We develop a probabilistic, relational planning rule\nrepresentation that compactly models noisy, nondeterministic action effects,\nand show how such rules can be effectively learned. Through experiments in\nsimple planning domains and a 3D simulated blocks world with realistic physics,\nwe demonstrate that this learning algorithm allows agents to effectively model\nworld dynamics.\n",
          "  The recursive least-squares (RLS) algorithm is one of the most well-known\nalgorithms used in adaptive filtering, system identification and adaptive\ncontrol. Its popularity is mainly due to its fast convergence speed, which is\nconsidered to be optimal in practice. In this paper, RLS methods are used to\nsolve reinforcement learning problems, where two new reinforcement learning\nalgorithms using linear value function approximators are proposed and analyzed.\nThe two algorithms are called RLS-TD(lambda) and Fast-AHC (Fast Adaptive\nHeuristic Critic), respectively. RLS-TD(lambda) can be viewed as the extension\nof RLS-TD(0) from lambda=0 to general lambda within interval [0,1], so it is a\nmulti-step temporal-difference (TD) learning algorithm using RLS methods. The\nconvergence with probability one and the limit of convergence of RLS-TD(lambda)\nare proved for ergodic Markov chains. Compared to the existing LS-TD(lambda)\nalgorithm, RLS-TD(lambda) has advantages in computation and is more suitable\nfor online learning. The effectiveness of RLS-TD(lambda) is analyzed and\nverified by learning prediction experiments of Markov chains with a wide range\nof parameter settings. The Fast-AHC algorithm is derived by applying the\nproposed RLS-TD(lambda) algorithm in the critic network of the adaptive\nheuristic critic method. Unlike conventional AHC algorithm, Fast-AHC makes use\nof RLS methods to improve the learning-prediction efficiency in the critic.\nLearning control experiments of the cart-pole balancing and the acrobot\nswing-up problems are conducted to compare the data efficiency of Fast-AHC with\nconventional AHC. From the experimental results, it is shown that the data\nefficiency of learning control can also be improved by using RLS methods in the\nlearning-prediction process of the critic. The performance of Fast-AHC is also\ncompared with that of the AHC method using LS-TD(lambda). Furthermore, it is\ndemonstrated in the experiments that different initial values of the variance\nmatrix in RLS-TD(lambda) are required to get better performance not only in\nlearning prediction but also in learning control. The experimental results are\nanalyzed based on the existing theoretical work on the transient phase of\nforgetting factor RLS methods.\n",
          "  We propose a new approach to value function approximation which combines\nlinear temporal difference reinforcement learning with subspace identification.\nIn practical applications, reinforcement learning (RL) is complicated by the\nfact that state is either high-dimensional or partially observable. Therefore,\nRL methods are designed to work with features of state rather than state\nitself, and the success or failure of learning is often determined by the\nsuitability of the selected features. By comparison, subspace identification\n(SSID) methods are designed to select a feature set which preserves as much\ninformation as possible about state. In this paper we connect the two\napproaches, looking at the problem of reinforcement learning with a large set\nof features, each of which may only be marginally useful for value function\napproximation. We introduce a new algorithm for this situation, called\nPredictive State Temporal Difference (PSTD) learning. As in SSID for predictive\nstate representations, PSTD finds a linear compression operator that projects a\nlarge set of features down to a small set that preserves the maximum amount of\npredictive information. As in RL, PSTD then uses a Bellman recursion to\nestimate a value function. We discuss the connection between PSTD and prior\napproaches in RL and SSID. We prove that PSTD is statistically consistent,\nperform several experiments that illustrate its properties, and demonstrate its\npotential on a difficult optimal stopping problem.\n",
          "  Cyber-physical systems, such as mobile robots, must respond adaptively to\ndynamic operating conditions. Effective operation of these systems requires\nthat sensing and actuation tasks are performed in a timely manner.\nAdditionally, execution of mission specific tasks such as imaging a room must\nbe balanced against the need to perform more general tasks such as obstacle\navoidance. This problem has been addressed by maintaining relative utilization\nof shared resources among tasks near a user-specified target level. Producing\noptimal scheduling strategies requires complete prior knowledge of task\nbehavior, which is unlikely to be available in practice. Instead, suitable\nscheduling strategies must be learned online through interaction with the\nsystem. We consider the sample complexity of reinforcement learning in this\ndomain, and demonstrate that while the problem state space is countably\ninfinite, we may leverage the problem's structure to guarantee efficient\nlearning.\n",
          "  This paper I assume that in humans the creation of knowledge depends on a\ndiscrete time, or stage, sequential decision-making process subjected to a\nstochastic, information transmitting environment. For each time-stage, this\nenvironment randomly transmits Shannon type information-packets to the\ndecision-maker, who examines each of them for relevancy and then determines his\noptimal choices. Using this set of relevant information-packets, the\ndecision-maker adapts, over time, to the stochastic nature of his environment,\nand optimizes the subjective expected rate-of-growth of knowledge. The\ndecision-maker's optimal actions, lead to a decision function that involves,\nover time, his view of the subjective entropy of the environmental process and\nother important parameters at each time-stage of the process. Using this model\nof human behavior, one could create psychometric experiments using computer\nsimulation and real decision-makers, to play programmed games to measure the\nresulting human performance.\n",
          "  We propose a novel reformulation of the stochastic optimal control problem as\nan approximate inference problem, demonstrating, that such a interpretation\nleads to new practical methods for the original problem. In particular we\ncharacterise a novel class of iterative solutions to the stochastic optimal\ncontrol problem based on a natural relaxation of the exact dual formulation.\nThese theoretical insights are applied to the Reinforcement Learning problem\nwhere they lead to new model free, off policy methods for discrete and\ncontinuous problems.\n",
          "  Reinforcement learning has solid foundations, but becomes inefficient in\npartially observed (non-Markovian) environments. Thus, a learning agent -born\nwith a representation and a policy- might wish to investigate to what extent\nthe Markov property holds. We propose a learning architecture that utilizes\ncombinatorial policy optimization to overcome non-Markovity and to develop\nefficient behaviors, which are easy to inherit, tests the Markov property of\nthe behavioral states, and corrects against non-Markovity by running a\ndeterministic factored Finite State Model, which can be learned. We illustrate\nthe properties of architecture in the near deterministic Ms. Pac-Man game. We\nanalyze the architecture from the point of view of evolutionary, individual,\nand social learning.\n",
          "  Many reinforcement learning exploration techniques are overly optimistic and\ntry to explore every state. Such exploration is impossible in environments with\nthe unlimited number of states. I propose to use simulated exploration with an\noptimistic model to discover promising paths for real exploration. This reduces\nthe needs for the real exploration.\n",
          "  We derive an equation for temporal difference learning from statistical\nprinciples. Specifically, we start with the variational principle and then\nbootstrap to produce an updating rule for discounted state value estimates. The\nresulting equation is similar to the standard equation for temporal difference\nlearning with eligibility traces, so called TD(lambda), however it lacks the\nparameter alpha that specifies the learning rate. In the place of this free\nparameter there is now an equation for the learning rate that is specific to\neach state transition. We experimentally test this new learning rule against\nTD(lambda) and find that it offers superior performance in various settings.\nFinally, we make some preliminary investigations into how to extend our new\ntemporal difference algorithm to reinforcement learning. To do this we combine\nour update equation with both Watkins' Q(lambda) and Sarsa(lambda) and find\nthat it again offers superior performance without a learning rate parameter.\n",
          "  There are two distinct approaches to solving reinforcement learning problems,\nnamely, searching in value function space and searching in policy space.\nTemporal difference methods and evolutionary algorithms are well-known examples\nof these approaches. Kaelbling, Littman and Moore recently provided an\ninformative survey of temporal difference methods. This article focuses on the\napplication of evolutionary algorithms to the reinforcement learning problem,\nemphasizing alternative policy representations, credit assignment methods, and\nproblem-specific genetic operators. Strengths and weaknesses of the\nevolutionary approach to reinforcement learning are presented, along with a\nsurvey of representative applications.\n",
          "  Time delays are components that make time-lag in systems response. They arise\nin physical, chemical, biological and economic systems, as well as in the\nprocess of measurement and computation. In this work, we implement Genetic\nAlgorithm (GA) in determining PID controller parameters to compensate the delay\nin First Order Lag plus Time Delay (FOLPD) and compare the results with\nIterative Method and Ziegler-Nichols rule results.\n",
          "  In a Role-Playing Game, finding optimal trajectories is one of the most\nimportant tasks. In fact, the strategy decision system becomes a key component\nof a game engine. Determining the way in which decisions are taken (online,\nbatch or simulated) and the consumed resources in decision making (e.g.\nexecution time, memory) will influence, in mayor degree, the game performance.\nWhen classical search algorithms such as A* can be used, they are the very\nfirst option. Nevertheless, such methods rely on precise and complete models of\nthe search space, and there are many interesting scenarios where their\napplication is not possible. Then, model free methods for sequential decision\nmaking under uncertainty are the best choice. In this paper, we propose a\nheuristic planning strategy to incorporate the ability of heuristic-search in\npath-finding into a Dyna agent. The proposed Dyna-H algorithm, as A* does,\nselects branches more likely to produce outcomes than other branches. Besides,\nit has the advantages of being a model-free online reinforcement learning\nalgorithm. The proposal was evaluated against the one-step Q-Learning and\nDyna-Q algorithms obtaining excellent experimental results: Dyna-H\nsignificantly overcomes both methods in all experiments. We suggest also, a\nfunctional analogy between the proposed sampling from worst trajectories\nheuristic and the role of dreams (e.g. nightmares) in human behavior.\n",
          "  This paper introduces an approach to Reinforcement Learning Algorithm by\ncomparing their immediate rewards using a variation of Q-Learning algorithm.\nUnlike the conventional Q-Learning, the proposed algorithm compares current\nreward with immediate reward of past move and work accordingly. Relative reward\nbased Q-learning is an approach towards interactive learning. Q-Learning is a\nmodel free reinforcement learning method that used to learn the agents. It is\nobserved that under normal circumstances algorithm take more episodes to reach\noptimal Q-value due to its normal reward or sometime negative reward. In this\nnew form of algorithm agents select only those actions which have a higher\nimmediate reward signal in comparison to previous one. The contribution of this\narticle is the presentation of new Q-Learning Algorithm in order to maximize\nthe performance of algorithm and reduce the number of episode required to reach\noptimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20\nGrid world deterministic environment and the result for the two forms of\nQ-Learning Algorithms is given.\n",
          "  Controller design faces a trade-off between robustness and performance, and\nthe reliability of linear controllers has caused many practitioners to focus on\nthe former. However, there is renewed interest in improving system performance\nto deal with growing energy constraints. This paper describes a learning-based\nmodel predictive control (LBMPC) scheme that provides deterministic guarantees\non robustness, while statistical identification tools are used to identify\nricher models of the system in order to improve performance; the benefits of\nthis framework are that it handles state and input constraints, optimizes\nsystem performance with respect to a cost function, and can be designed to use\na wide variety of parametric or nonparametric statistical tools. The main\ninsight of LBMPC is that safety and performance can be decoupled under\nreasonable conditions in an optimization framework by maintaining two models of\nthe system. The first is an approximate model with bounds on its uncertainty,\nand the second model is updated by statistical methods. LBMPC improves\nperformance by choosing inputs that minimize a cost subject to the learned\ndynamics, and it ensures safety and robustness by checking whether these same\ninputs keep the approximate model stable when it is subject to uncertainty.\nFurthermore, we show that if the system is sufficiently excited, then the LBMPC\ncontrol action probabilistically converges to that of an MPC computed using the\ntrue dynamics.\n",
          "  Feature selection in reinforcement learning (RL), i.e. choosing basis\nfunctions such that useful approximations of the unkown value function can be\nobtained, is one of the main challenges in scaling RL to real-world\napplications. Here we consider the Gaussian process based framework GPTD for\napproximate policy evaluation, and propose feature selection through marginal\nlikelihood optimization of the associated hyperparameters. Our approach has two\nappealing benefits: (1) given just sample transitions, we can solve the policy\nevaluation problem fully automatically (without looking at the learning task,\nand, in theory, independent of the dimensionality of the state space), and (2)\nmodel selection allows us to consider more sophisticated kernels, which in turn\nenable us to identify relevant subspaces and eliminate irrelevant state\nvariables such that we can achieve substantial computational savings and\nimproved prediction performance.\n",
          "  Experimental verification has been the method of choice for verifying the\nstability of a multi-agent reinforcement learning (MARL) algorithm as the\nnumber of agents grows and theoretical analysis becomes prohibitively complex.\nFor cooperative agents, where the ultimate goal is to optimize some global\nmetric, the stability is usually verified by observing the evolution of the\nglobal performance metric over time. If the global metric improves and\neventually stabilizes, it is considered a reasonable verification of the\nsystem's stability.\n  The main contribution of this note is establishing the need for better\nexperimental frameworks and measures to assess the stability of large-scale\nadaptive cooperative systems. We show an experimental case study where the\nstability of the global performance metric can be rather deceiving, hiding an\nunderlying instability in the system that later leads to a significant drop in\nperformance. We then propose an alternative metric that relies on agents' local\npolicies and show, experimentally, that our proposed metric is more effective\n(than the traditional global performance metric) in exposing the instability of\nMARL algorithms.\n",
          "  A fundamental problem in control is to learn a model of a system from\nobservations that is useful for controller synthesis. To provide good\nperformance guarantees, existing methods must assume that the real system is in\nthe class of models considered during learning. We present an iterative method\nwith strong guarantees even in the agnostic case where the system is not in the\nclass. In particular, we show that any no-regret online learning algorithm can\nbe used to obtain a near-optimal policy, provided some model achieves low\ntraining error and access to a good exploration distribution. Our approach\napplies to both discrete and continuous domains. We demonstrate its efficacy\nand scalability on a challenging helicopter domain from the literature.\n",
          "  This report outlines the use of a relational representation in a Multi-Agent\ndomain to model the behaviour of the whole system. A desired property in this\nsystems is the ability of the team members to work together to achieve a common\ngoal in a cooperative manner. The aim is to define a systematic method to\nverify the effective collaboration among the members of a team and comparing\nthe different multi-agent behaviours. Using external observations of a\nMulti-Agent System to analyse, model, recognize agent behaviour could be very\nuseful to direct team actions. In particular, this report focuses on the\nchallenge of autonomous unsupervised sequential learning of the team's\nbehaviour from observations. Our approach allows to learn a symbolic sequence\n(a relational representation) to translate raw multi-agent, multi-variate\nobservations of a dynamic, complex environment, into a set of sequential\nbehaviours that are characteristic of the team in question, represented by a\nset of sequences expressed in first-order logic atoms. We propose to use a\nrelational learning algorithm to mine meaningful frequent patterns among the\nrelational sequences to characterise team behaviours. We compared the\nperformance of two teams in the RoboCup four-legged league environment, that\nhave a very different approach to the game. One uses a Case Based Reasoning\napproach, the other uses a pure reactive behaviour.\n",
          "  Shaping has proven to be a powerful but precarious means of improving\nreinforcement learning performance. Ng, Harada, and Russell (1999) proposed the\npotential-based shaping algorithm for adding shaping rewards in a way that\nguarantees the learner will learn optimal behavior. In this note, we prove\ncertain similarities between this shaping algorithm and the initialization step\nrequired for several reinforcement learning algorithms. More specifically, we\nprove that a reinforcement learner with initial Q-values based on the shaping\nalgorithm's potential function make the same updates throughout learning as a\nlearner receiving potential-based shaping rewards. We further prove that under\na broad category of policies, the behavior of these two learners are\nindistinguishable. The comparison provides intuition on the theoretical\nproperties of the shaping algorithm as well as a suggestion for a simpler\nmethod for capturing the algorithm's benefit. In addition, the equivalence\nraises previously unaddressed issues concerning the efficiency of learning with\npotential-based shaping.\n",
          "  We consider model-based reinforcement learning in finite Markov De- cision\nProcesses (MDPs), focussing on so-called optimistic strategies. In MDPs,\noptimism can be implemented by carrying out extended value it- erations under a\nconstraint of consistency with the estimated model tran- sition probabilities.\nThe UCRL2 algorithm by Auer, Jaksch and Ortner (2009), which follows this\nstrategy, has recently been shown to guarantee near-optimal regret bounds. In\nthis paper, we strongly argue in favor of using the Kullback-Leibler (KL)\ndivergence for this purpose. By studying the linear maximization problem under\nKL constraints, we provide an ef- ficient algorithm, termed KL-UCRL, for\nsolving KL-optimistic extended value iteration. Using recent deviation bounds\non the KL divergence, we prove that KL-UCRL provides the same guarantees as\nUCRL2 in terms of regret. However, numerical experiments on classical\nbenchmarks show a significantly improved behavior, particularly when the MDP\nhas reduced connectivity. To support this observation, we provide elements of\ncom- parison between the two algorithms based on geometric considerations.\n",
          "  The exploration-exploitation dilemma has been an intriguing and unsolved\nproblem within the framework of reinforcement learning. \"Optimism in the face\nof uncertainty\" and model building play central roles in advanced exploration\nmethods. Here, we integrate several concepts and obtain a fast and simple\nalgorithm. We show that the proposed algorithm finds a near-optimal policy in\npolynomial time, and give experimental evidence that it is robust and efficient\ncompared to its ascendants.\n",
          "  Imitation can be viewed as a means of enhancing learning in multiagent\nenvironments. It augments an agent's ability to learn useful behaviors by\nmaking intelligent use of the knowledge implicit in behaviors demonstrated by\ncooperative teachers or other more experienced agents. We propose and study a\nformal model of implicit imitation that can accelerate reinforcement learning\ndramatically in certain cases. Roughly, by observing a mentor, a\nreinforcement-learning agent can extract information about its own capabilities\nin, and the relative value of, unvisited parts of the state space. We study two\nspecific instantiations of this model, one in which the learning agent and the\nmentor have identical abilities, and one designed to deal with agents and\nmentors with different action sets. We illustrate the benefits of implicit\nimitation by integrating it with prioritized sweeping, and demonstrating\nimproved performance and convergence through observation of single and multiple\nmentors. Though we make some stringent assumptions regarding observability and\npossible interactions, we briefly comment on extensions of the model that relax\nthese restricitions.\n",
          "  The problem of multi-agent learning and adaptation has attracted a great deal\nof attention in recent years. It has been suggested that the dynamics of multi\nagent learning can be studied using replicator equations from population\nbiology. Most existing studies so far have been limited to discrete strategy\nspaces with a small number of available actions. In many cases, however, the\nchoices available to agents are better characterized by continuous spectra.\nThis paper suggests a generalization of the replicator framework that allows to\nstudy the adaptive dynamics of Q-learning agents with continuous strategy\nspaces. Instead of probability vectors, agents strategies are now characterized\nby probability measures over continuous variables. As a result, the ordinary\ndifferential equations for the discrete case are replaced by a system of\ncoupled integral--differential replicator equations that describe the mutual\nevolution of individual agent strategies. We derive a set of functional\nequations describing the steady state of the replicator dynamics, examine their\nsolutions for several two-player games, and confirm our analytical results\nusing simulations.\n",
          "  We present an implementation of model-based online reinforcement learning\n(RL) for continuous domains with deterministic transitions that is specifically\ndesigned to achieve low sample complexity. To achieve low sample complexity,\nsince the environment is unknown, an agent must intelligently balance\nexploration and exploitation, and must be able to rapidly generalize from\nobservations. While in the past a number of related sample efficient RL\nalgorithms have been proposed, to allow theoretical analysis, mainly\nmodel-learners with weak generalization capabilities were considered. Here, we\nseparate function approximation in the model learner (which does require\nsamples) from the interpolation in the planner (which does not require\nsamples). For model-learning we apply Gaussian processes regression (GP) which\nis able to automatically adjust itself to the complexity of the problem (via\nBayesian hyperparameter selection) and, in practice, often able to learn a\nhighly accurate model from very little data. In addition, a GP provides a\nnatural way to determine the uncertainty of its predictions, which allows us to\nimplement the \"optimism in the face of uncertainty\" principle used to\nefficiently control exploration. Our method is evaluated on four common\nbenchmark domains.\n",
          "  We introduce a class of learning problems where the agent is presented with a\nseries of tasks. Intuitively, if there is relation among those tasks, then the\ninformation gained during execution of one task has value for the execution of\nanother task. Consequently, the agent is intrinsically motivated to explore its\nenvironment beyond the degree necessary to solve the current task it has at\nhand. We develop a decision theoretic setting that generalises standard\nreinforcement learning tasks and captures this intuition. More precisely, we\nconsider a multi-stage stochastic game between a learning agent and an\nopponent. We posit that the setting is a good model for the problem of\nlife-long learning in uncertain environments, where while resources must be\nspent learning about currently important tasks, there is also the need to\nallocate effort towards learning about aspects of the world which are not\nrelevant at the moment. This is due to the fact that unpredictable future\nevents may lead to a change of priorities for the decision maker. Thus, in some\nsense, the model \"explains\" the necessity of curiosity. Apart from introducing\nthe general formalism, the paper provides algorithms. These are evaluated\nexperimentally in some exemplary domains. In addition, performance bounds are\nproven for some cases of this problem.\n",
          "  In this paper, we present algorithms that perform gradient ascent of the\naverage reward in a partially observable Markov decision process (POMDP). These\nalgorithms are based on GPOMDP, an algorithm introduced in a companion paper\n(Baxter and Bartlett, this volume), which computes biased estimates of the\nperformance gradient in POMDPs. The algorithm's chief advantages are that it\nuses only one free parameter beta, which has a natural interpretation in terms\nof bias-variance trade-off, it requires no knowledge of the underlying state,\nand it can be applied to infinite state, control and observation spaces. We\nshow how the gradient estimates produced by GPOMDP can be used to perform\ngradient ascent, both with a traditional stochastic-gradient algorithm, and\nwith an algorithm based on conjugate-gradients that utilizes gradient\ninformation to bracket maxima in line searches. Experimental results are\npresented illustrating both the theoretical results of (Baxter and Bartlett,\nthis volume) on a toy problem, and practical aspects of the algorithms on a\nnumber of more realistic problems.\n",
          "  Actor-Critic based approaches were among the first to address reinforcement\nlearning in a general setting. Recently, these algorithms have gained renewed\ninterest due to their generality, good convergence properties, and possible\nbiological relevance. In this paper, we introduce an online temporal difference\nbased actor-critic algorithm which is proved to converge to a neighborhood of a\nlocal maximum of the average reward. Linear function approximation is used by\nthe critic in order estimate the value function, and the temporal difference\nsignal, which is passed from the critic to the actor. The main distinguishing\nfeature of the present convergence proof is that both the actor and the critic\noperate on a similar time scale, while in most current convergence proofs they\nare required to have very different time scales in order to converge. Moreover,\nthe same temporal difference signal is used to update the parameters of both\nthe actor and the critic. A limitation of the proposed approach, compared to\nresults available for two time scale convergence, is that convergence is\nguaranteed only to a neighborhood of an optimal value, rather to an optimal\nvalue itself. The single time scale and identical temporal difference signal\nused by the actor and the critic, may provide a step towards constructing more\nbiologically realistic models of reinforcement learning in the brain.\n",
          "  The aim of this work is to address the question of whether we can in\nprinciple design rational decision-making agents or artificial intelligences\nembedded in computable physics such that their decisions are optimal in\nreasonable mathematical senses. Recent developments in rare event probability\nestimation, recursive bayesian inference, neural networks, and probabilistic\nplanning are sufficient to explicitly approximate reinforcement learners of the\nAIXI style with non-trivial model classes (here, the class of resource-bounded\nTuring machines). Consideration of the effects of resource limitations in a\nconcrete implementation leads to insights about possible architectures for\nlearning systems using optimal decision makers as components.\n",
          "  Recent research in multi-robot exploration and mapping has focused on\nsampling environmental fields, which are typically modeled using the Gaussian\nprocess (GP). Existing information-theoretic exploration strategies for\nlearning GP-based environmental field maps adopt the non-Markovian problem\nstructure and consequently scale poorly with the length of history of\nobservations. Hence, it becomes computationally impractical to use these\nstrategies for in situ, real-time active sampling. To ease this computational\nburden, this paper presents a Markov-based approach to efficient\ninformation-theoretic path planning for active sampling of GP-based fields. We\nanalyze the time complexity of solving the Markov-based path planning problem,\nand demonstrate analytically that it scales better than that of deriving the\nnon-Markovian strategies with increasing length of planning horizon. For a\nclass of exploration tasks called the transect sampling task, we provide\ntheoretical guarantees on the active sampling performance of our Markov-based\npolicy, from which ideal environmental field conditions and sampling task\nsettings can be established to limit its performance degradation due to\nviolation of the Markov assumption. Empirical evaluation on real-world\ntemperature and plankton density field data shows that our Markov-based policy\ncan generally achieve active sampling performance comparable to that of the\nwidely-used non-Markovian greedy policies under less favorable realistic field\nconditions and task settings while enjoying significant computational gain over\nthem.\n",
          "  This paper studies the coupling of internally guided learning and social\ninteraction, and more specifically the improvement owing to demonstrations of\nthe learning by intrinsic motivation. We present Socially Guided Intrinsic\nMotivation by Demonstration (SGIM-D), an algorithm for learning in continuous,\nunbounded and non-preset environments. After introducing social learning and\nintrinsic motivation, we describe the design of our algorithm, before showing\nthrough a fishing experiment that SGIM-D efficiently combines the advantages of\nsocial learning and intrinsic motivation to gain a wide repertoire while being\nspecialised in specific subspaces.\n",
          "  Adaptive control problems are notoriously difficult to solve even in the\npresence of plant-specific controllers. One way to by-pass the intractable\ncomputation of the optimal policy is to restate the adaptive control as the\nminimization of the relative entropy of a controller that ignores the true\nplant dynamics from an informed controller. The solution is given by the\nBayesian control rule-a set of equations characterizing a stochastic adaptive\ncontroller for the class of possible plant dynamics. Here, the Bayesian control\nrule is applied to derive BCR-MDP, a controller to solve undiscounted Markov\ndecision processes with finite state and action spaces and unknown dynamics. In\nparticular, we derive a non-parametric conjugate prior distribution over the\npolicy space that encapsulates the agent's whole relevant history and we\npresent a Gibbs sampler to draw random policies from this distribution.\nPreliminary results show that BCR-MDP successfully avoids sub-optimal limit\ncycles due to its built-in mechanism to balance exploration versus\nexploitation.\n",
          "  Explaining adaptive behavior is a central problem in artificial intelligence\nresearch. Here we formalize adaptive agents as mixture distributions over\nsequences of inputs and outputs (I/O). Each distribution of the mixture\nconstitutes a `possible world', but the agent does not know which of the\npossible worlds it is actually facing. The problem is to adapt the I/O stream\nin a way that is compatible with the true world. A natural measure of\nadaptation can be obtained by the Kullback-Leibler (KL) divergence between the\nI/O distribution of the true world and the I/O distribution expected by the\nagent that is uncertain about possible worlds. In the case of pure input\nstreams, the Bayesian mixture provides a well-known solution for this problem.\nWe show, however, that in the case of I/O streams this solution breaks down,\nbecause outputs are issued by the agent itself and require a different\nprobabilistic syntax as provided by intervention calculus. Based on this\ncalculus, we obtain a Bayesian control rule that allows modeling adaptive\nbehavior with mixture distributions over I/O streams. This rule might allow for\na novel approach to adaptive control based on a minimum KL-principle.\n",
          "  We apply kernel-based methods to solve the difficult reinforcement learning\nproblem of 3vs2 keepaway in RoboCup simulated soccer. Key challenges in\nkeepaway are the high-dimensionality of the state space (rendering conventional\ndiscretization-based function approximation like tilecoding infeasible), the\nstochasticity due to noise and multiple learning agents needing to cooperate\n(meaning that the exact dynamics of the environment are unknown) and real-time\nlearning (meaning that an efficient online implementation is required). We\nemploy the general framework of approximate policy iteration with\nleast-squares-based policy evaluation. As underlying function approximator we\nconsider the family of regularization networks with subset of regressors\napproximation. The core of our proposed solution is an efficient recursive\nimplementation with automatic supervised selection of relevant basis functions.\nSimulation results indicate that the behavior learned through our approach\nclearly outperforms the best results obtained earlier with tilecoding by Stone\net al. (2005).\n",
          "  Designing the dialogue policy of a spoken dialogue system involves many\nnontrivial choices. This paper presents a reinforcement learning approach for\nautomatically optimizing a dialogue policy, which addresses the technical\nchallenges in applying reinforcement learning to a working dialogue system with\nhuman users. We report on the design, construction and empirical evaluation of\nNJFun, an experimental spoken dialogue system that provides users with access\nto information about fun things to do in New Jersey. Our results show that by\noptimizing its performance via reinforcement learning, NJFun measurably\nimproves system performance.\n",
          "  Q-learning is a reliable but inefficient off-policy temporal-difference\nmethod, backing up reward only one step at a time. Replacing traces, using a\nrecency heuristic, are more efficient but less reliable. In this work, we\nintroduce model-free, off-policy temporal difference methods that make better\nuse of experience than Watkins' Q(\\lambda). We introduce both Optimistic\nQ(\\lambda) and the temporal second difference trace (TSDT). TSDT is\nparticularly powerful in deterministic domains. TSDT uses neither recency nor\nfrequency heuristics, storing (s,a,r,s',\\delta) so that off-policy updates can\nbe performed after apparently suboptimal actions have been taken. There are\nadditional advantages when using state abstraction, as in MAXQ. We demonstrate\nthat TSDT does significantly better than both Q-learning and Watkins'\nQ(\\lambda) in a deterministic cliff-walking domain. Results in a noisy\ncliff-walking domain are less advantageous for TSDT, but demonstrate the\nefficacy of Optimistic Q(\\lambda), a replacing trace with some of the\nadvantages of TSDT.\n",
          "  We study the minmax optimization problem introduced in [22] for computing\npolicies for batch mode reinforcement learning in a deterministic setting.\nFirst, we show that this problem is NP-hard. In the two-stage case, we provide\ntwo relaxation schemes. The first relaxation scheme works by dropping some\nconstraints in order to obtain a problem that is solvable in polynomial time.\nThe second relaxation scheme, based on a Lagrangian relaxation where all\nconstraints are dualized, leads to a conic quadratic programming problem. We\nalso theoretically prove and empirically illustrate that both relaxation\nschemes provide better results than those given in [22].\n",
          "  Several researchers have recently investigated the connection between\nreinforcement learning and classification. We are motivated by proposals of\napproximate policy iteration schemes without value functions which focus on\npolicy representation using classifiers and address policy learning as a\nsupervised learning problem. This paper proposes variants of an improved policy\niteration scheme which addresses the core sampling problem in evaluating a\npolicy through simulation as a multi-armed bandit machine. The resulting\nalgorithm offers comparable performance to the previous algorithm achieved,\nhowever, with significantly less computational effort. An order of magnitude\nimprovement is demonstrated experimentally in two standard reinforcement\nlearning domains: inverted pendulum and mountain-car.\n",
          "  In this paper, we consider Markov Decision Processes (MDPs) with error\nstates. Error states are those states entering which is undesirable or\ndangerous. We define the risk with respect to a policy as the probability of\nentering such a state when the policy is pursued. We consider the problem of\nfinding good policies whose risk is smaller than some user-specified threshold,\nand formalize it as a constrained MDP with two criteria. The first criterion\ncorresponds to the value function originally given. We will show that the risk\ncan be formulated as a second criterion function based on a cumulative return,\nwhose definition is independent of the original value function. We present a\nmodel free, heuristic reinforcement learning algorithm that aims at finding\ngood deterministic policies. It is based on weighting the original value\nfunction and the risk. The weight parameter is adapted in order to find a\nfeasible solution for the constrained problem that has a good performance with\nrespect to the value function. The algorithm was successfully applied to the\ncontrol of a feed tank with stochastic inflows that lies upstream of a\ndistillation column. This control task was originally formulated as an optimal\ncontrol problem with chance constraints, and it was solved under certain\nassumptions on the model to obtain an optimal solution. The power of our\nlearning algorithm is that it can be used even when some of these restrictive\nassumptions are relaxed.\n",
          "  This paper introduces a new approach to solve sensor management problems.\nClassically sensor management problems can be well formalized as\nPartially-Observed Markov Decision Processes (POMPD). The original approach\ndevelopped here consists in deriving the optimal parameterized policy based on\na stochastic gradient estimation. We assume in this work that it is possible to\nlearn the optimal policy off-line (in simulation) using models of the\nenvironement and of the sensor(s). The learned policy can then be used to\nmanage the sensor(s). In order to approximate the gradient in a stochastic\ncontext, we introduce a new method to approximate the gradient, based on\nInfinitesimal Perturbation Approximation (IPA). The effectiveness of this\ngeneral framework is illustrated by the managing of an Electronically Scanned\nArray Radar. First simulations results are finally proposed.\n",
          "  We consider the problem of reinforcement learning using function\napproximation, where the approximating basis can change dynamically while\ninteracting with the environment. A motivation for such an approach is\nmaximizing the value function fitness to the problem faced. Three errors are\nconsidered: approximation square error, Bellman residual, and projected Bellman\nresidual. Algorithms under the actor-critic framework are presented, and shown\nto converge. The advantage of such an adaptive basis is demonstrated in\nsimulations.\n",
          "  This paper proposes a method to construct an adaptive agent that is universal\nwith respect to a given class of experts, where each expert is an agent that\nhas been designed specifically for a particular environment. This adaptive\ncontrol problem is formalized as the problem of minimizing the relative entropy\nof the adaptive agent from the expert that is most suitable for the unknown\nenvironment. If the agent is a passive observer, then the optimal solution is\nthe well-known Bayesian predictor. However, if the agent is active, then its\npast actions need to be treated as causal interventions on the I/O stream\nrather than normal probability conditions. Here it is shown that the solution\nto this new variational problem is given by a stochastic controller called the\nBayesian control rule, which implements adaptive behavior as a mixture of\nexperts. Furthermore, it is shown that under mild assumptions, the Bayesian\ncontrol rule converges to the control law of the most suitable expert.\n",
          "  Inverse reinforcement learning (IRL) addresses the problem of recovering a\ntask description given a demonstration of the optimal policy used to solve such\na task. The optimal policy is usually provided by an expert or teacher, making\nIRL specially suitable for the problem of apprenticeship learning. The task\ndescription is encoded in the form of a reward function of a Markov decision\nprocess (MDP). Several algorithms have been proposed to find the reward\nfunction corresponding to a set of demonstrations. One of the algorithms that\nhas provided best results in different applications is a gradient method to\noptimize a policy squared error criterion. On a parallel line of research,\nother authors have presented recently a gradient approximation of the maximum\nlikelihood estimate of the reward signal. In general, both approaches\napproximate the gradient estimate and the criteria at different stages to make\nthe algorithm tractable and efficient. In this work, we provide a detailed\ndescription of the different methods to highlight differences in terms of\nreward estimation, policy similarity and computational costs. We also provide\nexperimental results to evaluate the differences in performance of the methods.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_reinforcement_learning_planning",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_reinforcement_learning_planning"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.492058753967285,
          6.783344268798828,
          6.877922058105469,
          6.590780258178711,
          6.435105323791504,
          6.413942337036133,
          6.840849876403809,
          7.383741855621338,
          6.646856784820557,
          6.8731689453125,
          6.803086757659912,
          7.019355773925781,
          6.725493431091309,
          6.59507417678833,
          6.618710041046143,
          6.464375019073486,
          7.00862979888916,
          6.1944804191589355,
          6.565629482269287,
          6.7619428634643555,
          6.6884942054748535,
          7.4582953453063965,
          6.429346084594727,
          6.332141399383545,
          6.66807222366333,
          7.33315372467041,
          6.497517108917236,
          6.827398300170898,
          6.61204719543457,
          7.04991340637207,
          2.6868736743927,
          6.703746318817139,
          6.832409381866455,
          6.769979953765869,
          7.127206802368164,
          6.74791955947876,
          6.880710601806641,
          7.164817810058594,
          6.736490249633789,
          6.859729290008545,
          6.564389228820801,
          6.91635274887085,
          6.499632358551025,
          6.479658126831055,
          6.605632781982422,
          7.3874735832214355,
          6.6630635261535645,
          6.95079231262207,
          6.615616321563721,
          6.5639262199401855,
          6.4012274742126465,
          6.378377914428711,
          6.879137992858887,
          6.60538387298584,
          6.214320659637451,
          6.345746040344238,
          7.301640033721924,
          6.4664835929870605,
          7.058669090270996,
          6.566371917724609,
          6.735723495483398,
          6.673811435699463,
          7.007141590118408,
          7.63271951675415,
          6.502079486846924,
          7.132091045379639,
          6.698068618774414,
          6.436258316040039,
          6.898168087005615,
          6.523694038391113,
          6.995575904846191,
          6.739421367645264,
          6.900845527648926,
          6.511842727661133,
          6.759253978729248,
          6.614714622497559,
          6.716991424560547,
          6.592102527618408,
          6.720225811004639,
          6.612100601196289,
          6.493727207183838,
          6.809127330780029,
          6.622120380401611,
          6.690271377563477
         ],
         "y": [
          5.693324565887451,
          5.8358049392700195,
          5.982895851135254,
          5.700723648071289,
          6.1121697425842285,
          6.0207648277282715,
          6.138063430786133,
          6.272190570831299,
          5.686412334442139,
          5.981070518493652,
          6.081853866577148,
          6.1001200675964355,
          5.8220086097717285,
          6.143959045410156,
          5.7123212814331055,
          6.007414817810059,
          6.038905143737793,
          5.575174331665039,
          6.290690898895264,
          6.207259654998779,
          6.2803449630737305,
          6.320390701293945,
          6.154750823974609,
          6.1497392654418945,
          6.250433921813965,
          6.2078094482421875,
          5.7432050704956055,
          6.165079593658447,
          6.237858295440674,
          5.936927795410156,
          6.166971206665039,
          6.305994033813477,
          5.979812145233154,
          6.026960849761963,
          6.066098690032959,
          6.264721393585205,
          6.033115386962891,
          6.055981159210205,
          5.787471771240234,
          5.9233245849609375,
          6.268313884735107,
          5.887808322906494,
          5.674176216125488,
          5.7391180992126465,
          6.043668270111084,
          6.2993597984313965,
          6.344369411468506,
          5.928286552429199,
          5.8285651206970215,
          5.642627239227295,
          5.625527381896973,
          5.585849761962891,
          5.972640514373779,
          5.6389360427856445,
          6.228821277618408,
          6.0284743309021,
          6.166260719299316,
          6.25782585144043,
          5.908715724945068,
          5.632284641265869,
          6.235546112060547,
          6.236854076385498,
          5.97764778137207,
          6.513383865356445,
          6.152856826782227,
          6.135446548461914,
          6.367946147918701,
          5.640286922454834,
          5.974704265594482,
          6.1420488357543945,
          6.045369625091553,
          6.341291427612305,
          6.275731086730957,
          5.966007232666016,
          5.80665397644043,
          5.696310043334961,
          6.448147296905518,
          6.021368026733398,
          6.116344451904297,
          6.222182750701904,
          5.7246623039245605,
          6.36507511138916,
          6.185776233673096,
          6.033173561096191
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Many problems in machine learning and statistics can be formulated as\n(generalized) eigenproblems. In terms of the associated optimization problem,\ncomputing linear eigenvectors amounts to finding critical points of a quadratic\nfunction subject to quadratic constraints. In this paper we show that a certain\nclass of constrained optimization problems with nonquadratic objective and\nconstraints can be understood as nonlinear eigenproblems. We derive a\ngeneralization of the inverse power method which is guaranteed to converge to a\nnonlinear eigenvector. We apply the inverse power method to 1-spectral\nclustering and sparse PCA which can naturally be formulated as nonlinear\neigenproblems. In both applications we achieve state-of-the-art results in\nterms of solution quality and runtime. Moving beyond the standard eigenproblem\nshould be useful also in many other applications and our inverse power method\ncan be easily adapted to new problems.\n",
          "  This paper proposes a new distance metric between clusterings that\nincorporates information about the spatial distribution of points and clusters.\nOur approach builds on the idea of a Hilbert space-based representation of\nclusters as a combination of the representations of their constituent points.\nWe use this representation and the underlying metric to design a\nspatially-aware consensus clustering procedure. This consensus procedure is\nimplemented via a novel reduction to Euclidean clustering, and is both simple\nand efficient. All of our results apply to both soft and hard clusterings. We\naccompany these algorithms with a detailed experimental evaluation that\ndemonstrates the efficiency and quality of our techniques.\n",
          "  Median clustering extends popular neural data analysis methods such as the\nself-organizing map or neural gas to general data structures given by a\ndissimilarity matrix only. This offers flexible and robust global data\ninspection methods which are particularly suited for a variety of data as\noccurs in biomedical domains. In this chapter, we give an overview about median\nclustering and its properties and extensions, with a particular focus on\nefficient implementations adapted to large scale data analysis.\n",
          "  Affinity propagation is an exemplar-based clustering algorithm that finds a\nset of data-points that best exemplify the data, and associates each datapoint\nwith one exemplar. We extend affinity propagation in a principled way to solve\nthe hierarchical clustering problem, which arises in a variety of domains\nincluding biology, sensor networks and decision making in operational research.\nWe derive an inference algorithm that operates by propagating information up\nand down the hierarchy, and is efficient despite the high-order potentials\nrequired for the graphical model formulation. We demonstrate that our method\noutperforms greedy techniques that cluster one layer at a time. We show that on\nan artificial dataset designed to mimic the HIV-strain mutation dynamics, our\nmethod outperforms related methods. For real HIV sequences, where the ground\ntruth is not available, we show our method achieves better results, in terms of\nthe underlying objective function, and show the results correspond meaningfully\nto geographical location and strain subtypes. Finally we report results on\nusing the method for the analysis of mass spectra, showing it performs\nfavorably compared to state-of-the-art methods.\n",
          "  Model selection in clustering requires (i) to specify a suitable clustering\nprinciple and (ii) to control the model order complexity by choosing an\nappropriate number of clusters depending on the noise level in the data. We\nadvocate an information theoretic perspective where the uncertainty in the\nmeasurements quantizes the set of data partitionings and, thereby, induces\nuncertainty in the solution space of clusterings. A clustering model, which can\ntolerate a higher level of fluctuations in the measurements than alternative\nmodels, is considered to be superior provided that the clustering solution is\nequally informative. This tradeoff between \\emph{informativeness} and\n\\emph{robustness} is used as a model selection criterion. The requirement that\ndata partitionings should generalize from one data set to an equally probable\nsecond data set gives rise to a new notion of structure induced information.\n",
          "  With inspiration from Random Forests (RF) in the context of classification, a\nnew clustering ensemble method---Cluster Forests (CF) is proposed.\nGeometrically, CF randomly probes a high-dimensional data cloud to obtain \"good\nlocal clusterings\" and then aggregates via spectral clustering to obtain\ncluster assignments for the whole dataset. The search for good local\nclusterings is guided by a cluster quality measure kappa. CF progressively\nimproves each local clustering in a fashion that resembles the tree growth in\nRF. Empirical studies on several real-world datasets under two different\nperformance metrics show that CF compares favorably to its competitors.\nTheoretical analysis reveals that the kappa measure makes it possible to grow\nthe local clustering in a desirable way---it is \"noise-resistant\". A\nclosed-form expression is obtained for the mis-clustering rate of spectral\nclustering under a perturbation model, which yields new insights into some\naspects of spectral clustering.\n",
          "  One of the most prominent challenges in clustering is \"the user's dilemma,\"\nwhich is the problem of selecting an appropriate clustering algorithm for a\nspecific task. A formal approach for addressing this problem relies on the\nidentification of succinct, user-friendly properties that formally capture when\ncertain clustering methods are preferred over others.\n  Until now these properties focused on advantages of classical Linkage-Based\nalgorithms, failing to identify when other clustering paradigms, such as\npopular center-based methods, are preferable. We present surprisingly simple\nnew properties that delineate the differences between common clustering\nparadigms, which clearly and formally demonstrates advantages of center-based\napproaches for some applications. These properties address how sensitive\nalgorithms are to changes in element frequencies, which we capture in a\ngeneralized setting where every element is associated with a real-valued\nweight.\n",
          "  We consider inapproximability of the correlation clustering problem defined\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\nvertices into clusters so that the number of pairs correctly (resp.\nincorrectly) classified with respect to the labels is maximized (resp.\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\nrespectively, and have been studied on complete graphs, where every edge is\nlabeled, and general graphs, where some edge might not have been labeled.\nNatural edge-weighted versions of both problems have been studied as well. Let\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$\nessentially belongs to the same hardness class in the following sense: if there\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\n$\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S',\nS'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda\n+ \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high\nprobability. A similar statement also holds for $S-MinDisagree. This result\nimplies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree\nwithin a factor of $80/79-\\epsilon$, improving upon a previous known factor of\n$116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}.\n",
          "  Clusters of genes that have evolved by repeated segmental duplication present\ndifficult challenges throughout genomic analysis, from sequence assembly to\nfunctional analysis. Improved understanding of these clusters is of utmost\nimportance, since they have been shown to be the source of evolutionary\ninnovation, and have been linked to multiple diseases, including HIV and a\nvariety of cancers. Previously, Zhang et al. (2008) developed an algorithm for\nreconstructing parsimonious evolutionary histories of such gene clusters, using\nonly human genomic sequence data. In this paper, we propose a probabilistic\nmodel for the evolution of gene clusters on a phylogeny, and an MCMC algorithm\nfor reconstruction of duplication histories from genomic sequences in multiple\nspecies. Several projects are underway to obtain high quality BAC-based\nassemblies of duplicated clusters in multiple species, and we anticipate that\nour method will be useful in analyzing these valuable new data sets.\n",
          "  Hierarchical structure is ubiquitous in data across many domains. There are\nmany hierarchical clustering methods, frequently used by domain experts, which\nstrive to discover this structure. However, most of these methods limit\ndiscoverable hierarchies to those with binary branching structure. This\nlimitation, while computationally convenient, is often undesirable. In this\npaper we explore a Bayesian hierarchical clustering algorithm that can produce\ntrees with arbitrary branching structure at each node, known as rose trees. We\ninterpret these trees as mixtures over partitions of a data set, and use a\ncomputationally efficient, greedy agglomerative algorithm to find the rose\ntrees which have high marginal likelihood given the data. Lastly, we perform\nexperiments which demonstrate that rose trees are better models of data than\nthe typical binary trees returned by other hierarchical clustering algorithms.\n",
          "  This paper introduces a model based upon games on an evolving network, and\ndevelops three clustering algorithms according to it. In the clustering\nalgorithms, data points for clustering are regarded as players who can make\ndecisions in games. On the network describing relationships among data points,\nan edge-removing-and-rewiring (ERR) function is employed to explore in a\nneighborhood of a data point, which removes edges connecting to neighbors with\nsmall payoffs, and creates new edges to neighbors with larger payoffs. As such,\nthe connections among data points vary over time. During the evolution of\nnetwork, some strategies are spread in the network. As a consequence, clusters\nare formed automatically, in which data points with the same evolutionarily\nstable strategy are collected as a cluster, so the number of evolutionarily\nstable strategies indicates the number of clusters. Moreover, the experimental\nresults have demonstrated that data points in datasets are clustered reasonably\nand efficiently, and the comparison with other algorithms also provides an\nindication of the effectiveness of the proposed algorithms.\n",
          "  One of the most popular algorithms for clustering in Euclidean space is the\n$k$-means algorithm; $k$-means is difficult to analyze mathematically, and few\ntheoretical guarantees are known about it, particularly when the data is {\\em\nwell-clustered}. In this paper, we attempt to fill this gap in the literature\nby analyzing the behavior of $k$-means on well-clustered data. In particular,\nwe study the case when each cluster is distributed as a different Gaussian --\nor, in other words, when the input comes from a mixture of Gaussians.\n  We analyze three aspects of the $k$-means algorithm under this assumption.\nFirst, we show that when the input comes from a mixture of two spherical\nGaussians, a variant of the 2-means algorithm successfully isolates the\nsubspace containing the means of the mixture components. Second, we show an\nexact expression for the convergence of our variant of the 2-means algorithm,\nwhen the input is a very large number of samples from a mixture of spherical\nGaussians. Our analysis does not require any lower bound on the separation\nbetween the mixture components.\n  Finally, we study the sample requirement of $k$-means; for a mixture of 2\nspherical Gaussians, we show an upper bound on the number of samples required\nby a variant of 2-means to get close to the true solution. The sample\nrequirement grows with increasing dimensionality of the data, and decreasing\nseparation between the means of the Gaussians. To match our upper bound, we\nshow an information-theoretic lower bound on any algorithm that learns mixtures\nof two spherical Gaussians; our lower bound indicates that in the case when the\noverlap between the probability masses of the two distributions is small, the\nsample requirement of $k$-means is {\\em near-optimal}.\n",
          "  We describe the Median K-Flats (MKF) algorithm, a simple online method for\nhybrid linear modeling, i.e., for approximating data by a mixture of flats.\nThis algorithm simultaneously partitions the data into clusters while finding\ntheir corresponding best approximating l1 d-flats, so that the cumulative l1\nerror is minimized. The current implementation restricts d-flats to be\nd-dimensional linear subspaces. It requires a negligible amount of storage, and\nits complexity, when modeling data consisting of N points in D-dimensional\nEuclidean space with K d-dimensional linear subspaces, is of order O(n K d D+n\nd^2 D), where n is the number of iterations required for convergence\n(empirically on the order of 10^4). Since it is an online algorithm, data can\nbe supplied to it incrementally and it can incrementally produce the\ncorresponding output. The performance of the algorithm is carefully evaluated\nusing synthetic and real data.\n",
          "  Clustering is considered a non-supervised learning setting, in which the goal\nis to partition a collection of data points into disjoint clusters. Often a\nbound $k$ on the number of clusters is given or assumed by the practitioner.\nMany versions of this problem have been defined, most notably $k$-means and\n$k$-median.\n  An underlying problem with the unsupervised nature of clustering it that of\ndetermining a similarity function. One approach for alleviating this difficulty\nis known as clustering with side information, alternatively, semi-supervised\nclustering. Here, the practitioner incorporates side information in the form of\n\"must be clustered\" or \"must be separated\" labels for data point pairs. Each\nsuch piece of information comes at a \"query cost\" (often involving human\nresponse solicitation). The collection of labels is then incorporated in the\nusual clustering algorithm as either strict or as soft constraints, possibly\nadding a pairwise constraint penalty function to the chosen clustering\nobjective.\n  Our work is mostly related to clustering with side information. We ask how to\nchoose the pairs of data points. Our analysis gives rise to a method provably\nbetter than simply choosing them uniformly at random. Roughly speaking, we show\nthat the distribution must be biased so as more weight is placed on pairs\nincident to elements in smaller clusters in some optimal solution. Of course we\ndo not know the optimal solution, hence we don't know the bias. Using the\nrecently introduced method of $\\eps$-smooth relative regret approximations of\nAilon, Begleiter and Ezra, we can show an iterative process that improves both\nthe clustering and the bias in tandem. The process provably converges to the\noptimal solution faster (in terms of query cost) than an algorithm selecting\npairs uniformly.\n",
          "  Identifying clusters of similar objects in data plays a significant role in a\nwide range of applications. As a model problem for clustering, we consider the\ndensest k-disjoint-clique problem, whose goal is to identify the collection of\nk disjoint cliques of a given weighted complete graph maximizing the sum of the\ndensities of the complete subgraphs induced by these cliques. In this paper, we\nestablish conditions ensuring exact recovery of the densest k cliques of a\ngiven graph from the optimal solution of a particular semidefinite program. In\nparticular, the semidefinite relaxation is exact for input graphs corresponding\nto data consisting of k large, distinct clusters and a smaller number of\noutliers. This approach also yields a semidefinite relaxation for the\nbiclustering problem with similar recovery guarantees. Given a set of objects\nand a set of features exhibited by these objects, biclustering seeks to\nsimultaneously group the objects and features according to their expression\nlevels. This problem may be posed as partitioning the nodes of a weighted\nbipartite complete graph such that the sum of the densities of the resulting\nbipartite complete subgraphs is maximized. As in our analysis of the densest\nk-disjoint-clique problem, we show that the correct partition of the objects\nand features can be recovered from the optimal solution of a semidefinite\nprogram in the case that the given data consists of several disjoint sets of\nobjects exhibiting similar features. Empirical evidence from numerical\nexperiments supporting these theoretical guarantees is also provided.\n",
          "  We study the topic of dimensionality reduction for $k$-means clustering.\nDimensionality reduction encompasses the union of two approaches: \\emph{feature\nselection} and \\emph{feature extraction}. A feature selection based algorithm\nfor $k$-means clustering selects a small subset of the input features and then\napplies $k$-means clustering on the selected features. A feature extraction\nbased algorithm for $k$-means clustering constructs a small set of new\nartificial features and then applies $k$-means clustering on the constructed\nfeatures. Despite the significance of $k$-means clustering as well as the\nwealth of heuristic methods addressing it, provably accurate feature selection\nmethods for $k$-means clustering are not known. On the other hand, two provably\naccurate feature extraction methods for $k$-means clustering are known in the\nliterature; one is based on random projections and the other is based on the\nsingular value decomposition (SVD).\n  This paper makes further progress towards a better understanding of\ndimensionality reduction for $k$-means clustering. Namely, we present the first\nprovably accurate feature selection method for $k$-means clustering and, in\naddition, we present two feature extraction methods. The first feature\nextraction method is based on random projections and it improves upon the\nexisting results in terms of time complexity and number of features needed to\nbe extracted. The second feature extraction method is based on fast approximate\nSVD factorizations and it also improves upon the existing results in terms of\ntime complexity. The proposed algorithms are randomized and provide\nconstant-factor approximation guarantees with respect to the optimal $k$-means\nobjective value.\n",
          "  In many physical, statistical, biological and other investigations it is\ndesirable to approximate a system of points by objects of lower dimension\nand/or complexity. For this purpose, Karl Pearson invented principal component\nanalysis in 1901 and found 'lines and planes of closest fit to system of\npoints'. The famous k-means algorithm solves the approximation problem too, but\nby finite sets instead of lines and planes. This chapter gives a brief\npractical introduction into the methods of construction of general principal\nobjects, i.e. objects embedded in the 'middle' of the multidimensional data\nset. As a basis, the unifying framework of mean squared distance approximation\nof finite datasets is selected. Principal graphs and manifolds are constructed\nas generalisations of principal components and k-means principal points. For\nthis purpose, the family of expectation/maximisation algorithms with nearest\ngeneralisations is presented. Construction of principal graphs with controlled\ncomplexity is based on the graph grammar approach.\n",
          "  In data analysis new forms of complex data have to be considered like for\nexample (symbolic data, functional data, web data, trees, SQL query and\nmultimedia data, ...). In this context classical data analysis for knowledge\ndiscovery based on calculating the center of gravity can not be used because\ninput are not $\\mathbb{R}^p$ vectors. In this paper, we present an application\non real world symbolic data using the self-organizing map. To this end, we\npropose an extension of the self-organizing map that can handle symbolic data.\n",
          "  This paper considers the problem of clustering a collection of unlabeled data\npoints assumed to lie near a union of lower-dimensional planes. As is common in\ncomputer vision or unsupervised learning applications, we do not know in\nadvance how many subspaces there are nor do we have any information about their\ndimensions. We develop a novel geometric analysis of an algorithm named sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, 2009. CVPR 2009 (2009) 2790-2797. IEEE], which significantly\nbroadens the range of problems where it is provably effective. For instance, we\nshow that SSC can recover multiple subspaces, each of dimension comparable to\nthe ambient dimension. We also prove that SSC can correctly cluster data points\neven when the subspaces of interest intersect. Further, we develop an extension\nof SSC that succeeds when the data set is corrupted with possibly\noverwhelmingly many outliers. Underlying our analysis are clear geometric\ninsights, which may bear on other sparse recovery problems. A numerical study\ncomplements our theoretical analysis and demonstrates the effectiveness of\nthese methods.\n",
          "  The k-means algorithm is a well-known method for partitioning n points that\nlie in the d-dimensional space into k clusters. Its main features are\nsimplicity and speed in practice. Theoretically, however, the best known upper\nbound on its running time (i.e. O(n^{kd})) can be exponential in the number of\npoints. Recently, Arthur and Vassilvitskii [3] showed a super-polynomial\nworst-case analysis, improving the best known lower bound from \\Omega(n) to\n2^{\\Omega(\\sqrt{n})} with a construction in d=\\Omega(\\sqrt{n}) dimensions. In\n[3] they also conjectured the existence of superpolynomial lower bounds for any\nd >= 2.\n  Our contribution is twofold: we prove this conjecture and we improve the\nlower bound, by presenting a simple construction in the plane that leads to the\nexponential lower bound 2^{\\Omega(n)}.\n",
          "  We present a new algorithm for clustering points in R^n. The key property of\nthe algorithm is that it is affine-invariant, i.e., it produces the same\npartition for any affine transformation of the input. It has strong guarantees\nwhen the input is drawn from a mixture model. For a mixture of two arbitrary\nGaussians, the algorithm correctly classifies the sample assuming only that the\ntwo components are separable by a hyperplane, i.e., there exists a halfspace\nthat contains most of one Gaussian and almost none of the other in probability\nmass. This is nearly the best possible, improving known results substantially.\nFor k > 2 components, the algorithm requires only that there be some\n(k-1)-dimensional subspace in which the emoverlap in every direction is small.\nHere we define overlap to be the ratio of the following two quantities: 1) the\naverage squared distance between a point and the mean of its component, and 2)\nthe average squared distance between a point and the mean of the mixture. The\nmain result may also be stated in the language of linear discriminant analysis:\nif the standard Fisher discriminant is small enough, labels are not needed to\nestimate the optimal subspace for projection. Our main tools are isotropic\ntransformation, spectral projection and a simple reweighting technique. We call\nthis combination isotropic PCA.\n",
          "  Clustering is an unsupervised learning method that constitutes a cornerstone\nof an intelligent data analysis process. It is used for the exploration of\ninter-relationships among a collection of patterns, by organizing them into\nhomogeneous clusters. Clustering has been dynamically applied to a variety of\ntasks in the field of Information Retrieval (IR). Clustering has become one of\nthe most active area of research and the development. Clustering attempts to\ndiscover the set of consequential groups where those within each group are more\nclosely related to one another than the others assigned to different groups.\nThe resultant clusters can provide a structure for organizing large bodies of\ntext for efficient browsing and searching. There exists a wide variety of\nclustering algorithms that has been intensively studied in the clustering\nproblem. Among the algorithms that remain the most common and effectual, the\niterative optimization clustering algorithms have been demonstrated reasonable\nperformance for clustering, e.g. the Expectation Maximization (EM) algorithm\nand its variants, and the well known k-means algorithm. This paper presents an\nanalysis on how partition method clustering techniques - EM, K -means and K*\nMeans algorithm work on heartspect dataset with below mentioned features -\nPurity, Entropy, CPU time, Cluster wise analysis, Mean value analysis and inter\ncluster distance. Thus the paper finally provides the experimental results of\ndatasets for five clusters to strengthen the results that the quality of the\nbehavior in clusters in EM algorithm is far better than k-means algorithm and\nk*means algorithm.\n",
          "  This paper presents a concise tutorial on spectral clustering for broad\nspectrum graphs which include unipartite (undirected) graph, bipartite graph,\nand directed graph. We show how to transform bipartite graph and directed graph\ninto corresponding unipartite graph, therefore allowing a unified treatment to\nall cases. In bipartite graph, we show that the relaxed solution to the $K$-way\nco-clustering can be found by computing the left and right eigenvectors of the\ndata matrix. This gives a theoretical basis for $K$-way spectral co-clustering\nalgorithms proposed in the literatures. We also show that solving row and\ncolumn co-clustering is equivalent to solving row and column clustering\nseparately, thus giving a theoretical support for the claim: ``column\nclustering implies row clustering and vice versa''. And in the last part, we\ngeneralize the Ky Fan theorem---which is the central theorem for explaining\nspectral clustering---to rectangular complex matrix motivated by the results\nfrom bipartite graph analysis.\n",
          "  In many real-world problems, we are dealing with collections of\nhigh-dimensional data, such as images, videos, text and web documents, DNA\nmicroarray data, and more. Often, high-dimensional data lie close to\nlow-dimensional structures corresponding to several classes or categories the\ndata belongs to. In this paper, we propose and study an algorithm, called\nSparse Subspace Clustering (SSC), to cluster data points that lie in a union of\nlow-dimensional subspaces. The key idea is that, among infinitely many possible\nrepresentations of a data point in terms of other points, a sparse\nrepresentation corresponds to selecting a few points from the same subspace.\nThis motivates solving a sparse optimization program whose solution is used in\na spectral clustering framework to infer the clustering of data into subspaces.\nSince solving the sparse optimization program is in general NP-hard, we\nconsider a convex relaxation and show that, under appropriate conditions on the\narrangement of subspaces and the distribution of data, the proposed\nminimization program succeeds in recovering the desired sparse representations.\nThe proposed algorithm can be solved efficiently and can handle data points\nnear the intersections of subspaces. Another key advantage of the proposed\nalgorithm with respect to the state of the art is that it can deal with data\nnuisances, such as noise, sparse outlying entries, and missing entries,\ndirectly by incorporating the model of the data into the sparse optimization\nprogram. We demonstrate the effectiveness of the proposed algorithm through\nexperiments on synthetic data as well as the two real-world problems of motion\nsegmentation and face clustering.\n",
          "  Data analysis and data mining are concerned with unsupervised pattern finding\nand structure determination in data sets. \"Structure\" can be understood as\nsymmetry and a range of symmetries are expressed by hierarchy. Such symmetries\ndirectly point to invariants, that pinpoint intrinsic properties of the data\nand of the background empirical domain of interest. We review many aspects of\nhierarchy here, including ultrametric topology, generalized ultrametric,\nlinkages with lattices and other discrete algebraic structures and with p-adic\nnumber representations. By focusing on symmetries in data we have a powerful\nmeans of structuring and analyzing massive, high dimensional data stores. We\nillustrate the powerfulness of hierarchical clustering in case studies in\nchemistry and finance, and we provide pointers to other published case studies.\n",
          "  This paper presents an algebro-geometric solution to the problem of\nsegmenting an unknown number of subspaces of unknown and varying dimensions\nfrom sample data points. We represent the subspaces with a set of homogeneous\npolynomials whose degree is the number of subspaces and whose derivatives at a\ndata point give normal vectors to the subspace passing through the point. When\nthe number of subspaces is known, we show that these polynomials can be\nestimated linearly from data; hence, subspace segmentation is reduced to\nclassifying one point per subspace. We select these points optimally from the\ndata set by minimizing certain distance function, thus dealing automatically\nwith moderate noise in the data. A basis for the complement of each subspace is\nthen recovered by applying standard PCA to the collection of derivatives\n(normal vectors). Extensions of GPCA that deal with data in a high- dimensional\nspace and with an unknown number of subspaces are also presented. Our\nexperiments on low-dimensional data show that GPCA outperforms existing\nalgebraic algorithms based on polynomial factorization and provides a good\ninitialization to iterative techniques such as K-subspaces and Expectation\nMaximization. We also present applications of GPCA to computer vision problems\nsuch as face clustering, temporal video segmentation, and 3D motion\nsegmentation from point correspondences in multiple affine views.\n",
          "  Recently there is a line of research work proposing to employ Spectral\nClustering (SC) to segment (group){Throughout the paper, we use segmentation,\nclustering, and grouping, and their verb forms, interchangeably.}\nhigh-dimensional structural data such as those (approximately) lying on\nsubspaces {We follow {liu2010robust} and use the term \"subspace\" to denote both\nlinear subspaces and affine subspaces. There is a trivial conversion between\nlinear subspaces and affine subspaces as mentioned therein.} or low-dimensional\nmanifolds. By learning the affinity matrix in the form of sparse\nreconstruction, techniques proposed in this vein often considerably boost the\nperformance in subspace settings where traditional SC can fail. Despite the\nsuccess, there are fundamental problems that have been left unsolved: the\nspectrum property of the learned affinity matrix cannot be gauged in advance,\nand there is often one ugly symmetrization step that post-processes the\naffinity for SC input. Hence we advocate to enforce the symmetric positive\nsemidefinite constraint explicitly during learning (Low-Rank Representation\nwith Positive SemiDefinite constraint, or LRR-PSD), and show that factually it\ncan be solved in an exquisite scheme efficiently instead of general-purpose SDP\nsolvers that usually scale up poorly. We provide rigorous mathematical\nderivations to show that, in its canonical form, LRR-PSD is equivalent to the\nrecently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and\nhence offer theoretic and practical insights to both LRR-PSD and LRR, inviting\nfuture research. As per the computational cost, our proposal is at most\ncomparable to that of LRR, if not less. We validate our theoretic analysis and\noptimization scheme by experiments on both synthetic and real data sets.\n",
          "  Functional data analysis involves data described by regular functions rather\nthan by a finite number of real valued variables. While some robust data\nanalysis methods can be applied directly to the very high dimensional vectors\nobtained from a fine grid sampling of functional data, all methods benefit from\na prior simplification of the functions that reduces the redundancy induced by\nthe regularity. In this paper we propose to use a clustering approach that\ntargets variables rather than individual to design a piecewise constant\nrepresentation of a set of functions. The contiguity constraint induced by the\nfunctional nature of the variables allows a polynomial complexity algorithm to\ngive the optimal solution.\n",
          "  In recent years, spectral clustering has become one of the most popular\nmodern clustering algorithms. It is simple to implement, can be solved\nefficiently by standard linear algebra software, and very often outperforms\ntraditional clustering algorithms such as the k-means algorithm. On the first\nglance spectral clustering appears slightly mysterious, and it is not obvious\nto see why it works at all and what it really does. The goal of this tutorial\nis to give some intuition on those questions. We describe different graph\nLaplacians and their basic properties, present the most common spectral\nclustering algorithms, and derive those algorithms from scratch by several\ndifferent approaches. Advantages and disadvantages of the different spectral\nclustering algorithms are discussed.\n",
          "  In this paper we have investigated the performance of PSO Particle Swarm\nOptimization based clustering on few real world data sets and one artificial\ndata set. The performances are measured by two metric namely quantization error\nand inter-cluster distance. The K means clustering algorithm is first\nimplemented for all data sets, the results of which form the basis of\ncomparison of PSO based approaches. We have explored different variants of PSO\nsuch as gbest, lbest ring, lbest vonneumann and Hybrid PSO for comparison\npurposes. The results reveal that PSO based clustering algorithms perform\nbetter compared to K means in all data sets.\n",
          "  The problem of clustering is considered, for the case when each data point is\na sample generated by a stationary ergodic process. We propose a very natural\nasymptotic notion of consistency, and show that simple consistent algorithms\nexist, under most general non-parametric assumptions. The notion of consistency\nis as follows: two samples should be put into the same cluster if and only if\nthey were generated by the same distribution. With this notion of consistency,\nclustering generalizes such classical statistical problems as homogeneity\ntesting and process classification. We show that, for the case of a known\nnumber of clusters, consistency can be achieved under the only assumption that\nthe joint distribution of the data is stationary ergodic (no parametric or\nMarkovian assumptions, no assumptions of independence, neither between nor\nwithin the samples). If the number of clusters is unknown, consistency can be\nachieved under appropriate assumptions on the mixing rates of the processes.\n(again, no parametric or independence assumptions). In both cases we give\nexamples of simple (at most quadratic in each argument) algorithms which are\nconsistent.\n",
          "  To understand complex biological systems, the research community has produced\nhuge corpus of gene expression data. A large number of clustering approaches\nhave been proposed for the analysis of gene expression data. However,\nextracting important biological knowledge is still harder. To address this\ntask, clustering techniques are used. In this paper, hybrid Hierarchical\nk-Means algorithm is used for clustering and biclustering gene expression data\nis used. To discover both local and global clustering structure biclustering\nand clustering algorithms are utilized. A validation technique, Figure of Merit\nis used to determine the quality of clustering results. Appropriate knowledge\nis mined from the clusters by embedding a BLAST similarity search program into\nthe clustering and biclustering process. To discover both local and global\nclustering structure biclustering and clustering algorithms are utilized. To\ndetermine the quality of clustering results, a validation technique, Figure of\nMerit is used. Appropriate knowledge is mined from the clusters by embedding a\nBLAST similarity search program into the clustering and biclustering process.\n",
          "  Eigenvector localization refers to the situation when most of the components\nof an eigenvector are zero or near-zero. This phenomenon has been observed on\neigenvectors associated with extremal eigenvalues, and in many of those cases\nit can be meaningfully interpreted in terms of \"structural heterogeneities\" in\nthe data. For example, the largest eigenvectors of adjacency matrices of large\ncomplex networks often have most of their mass localized on high-degree nodes;\nand the smallest eigenvectors of the Laplacians of such networks are often\nlocalized on small but meaningful community-like sets of nodes. Here, we\ndescribe localization associated with low-order eigenvectors, i.e.,\neigenvectors corresponding to eigenvalues that are not extremal but that are\n\"buried\" further down in the spectrum. Although we have observed it in several\nunrelated applications, this phenomenon of low-order eigenvector localization\ndefies common intuitions and simple explanations, and it creates serious\ndifficulties for the applicability of popular eigenvector-based machine\nlearning and data analysis tools. After describing two examples where low-order\neigenvector localization arises, we present a very simple model that\nqualitatively reproduces several of the empirically-observed results. This\nmodel suggests certain coarse structural similarities among the\nseemingly-unrelated applications where we have observed low-order eigenvector\nlocalization, and it may be used as a diagnostic tool to help extract insight\nfrom data graphs when such low-order eigenvector localization is present.\n",
          "  Microarrays are made it possible to simultaneously monitor the expression\nprofiles of thousands of genes under various experimental conditions. It is\nused to identify the co-expressed genes in specific cells or tissues that are\nactively used to make proteins. This method is used to analysis the gene\nexpression, an important task in bioinformatics research. Cluster analysis of\ngene expression data has proved to be a useful tool for identifying\nco-expressed genes, biologically relevant groupings of genes and samples. In\nthis paper we applied K-Means with Automatic Generations of Merge Factor for\nISODATA- AGMFI. Though AGMFI has been applied for clustering of Gene Expression\nData, this proposed Enhanced Automatic Generations of Merge Factor for ISODATA-\nEAGMFI Algorithms overcome the drawbacks of AGMFI in terms of specifying the\noptimal number of clusters and initialization of good cluster centroids.\nExperimental results on Gene Expression Data show that the proposed EAGMFI\nalgorithms could identify compact clusters with perform well in terms of the\nSilhouette Coefficients cluster measure.\n",
          "  Among all the partition based clustering algorithms K-means is the most\npopular and well known method. It generally shows impressive results even in\nconsiderably large data sets. The computational complexity of K-means does not\nsuffer from the size of the data set. The main disadvantage faced in performing\nthis clustering is that the selection of initial means. If the user does not\nhave adequate knowledge about the data set, it may lead to erroneous results.\nThe algorithm Automatic Initialization of Means (AIM), which is an extension to\nK-means, has been proposed to overcome the problem of initial mean generation.\nIn this paper an attempt has been made to compare the performance of the\nalgorithms through implementation\n",
          "  Many clustering schemes are defined by optimizing an objective function\ndefined on the partitions of the underlying set of a finite metric space. In\nthis paper, we construct a framework for studying what happens when we instead\nimpose various structural conditions on the clustering schemes, under the\ngeneral heading of functoriality. Functoriality refers to the idea that one\nshould be able to compare the results of clustering algorithms as one varies\nthe data set, for example by adding points or by applying functions to it. We\nshow that within this framework, one can prove a theorems analogous to one of\nJ. Kleinberg, in which for example one obtains an existence and uniqueness\ntheorem instead of a non-existence result.\n  We obtain a full classification of all clustering schemes satisfying a\ncondition we refer to as excisiveness. The classification can be changed by\nvarying the notion of maps of finite metric spaces. The conditions occur\nnaturally when one considers clustering as the statistical version of the\ngeometric notion of connected components. By varying the degree of\nfunctoriality that one requires from the schemes it is possible to construct\nricher families of clustering schemes that exhibit sensitivity to density.\n",
          "  A $p$-adic modification of the split-LBG classification method is presented\nin which first clusterings and then cluster centers are computed which locally\nminimise an energy function. The outcome for a fixed dataset is independent of\nthe prime number $p$ with finitely many exceptions. The methods are applied to\nthe construction of $p$-adic classifiers in the context of learning.\n",
          "  In the past few years powerful generalizations to the Euclidean k-means\nproblem have been made, such as Bregman clustering [7], co-clustering (i.e.,\nsimultaneous clustering of rows and columns of an input matrix) [9,18], and\ntensor clustering [8,34]. Like k-means, these more general problems also suffer\nfrom the NP-hardness of the associated optimization. Researchers have developed\napproximation algorithms of varying degrees of sophistication for k-means,\nk-medians, and more recently also for Bregman clustering [2]. However, there\nseem to be no approximation algorithms for Bregman co- and tensor clustering.\nIn this paper we derive the first (to our knowledge) guaranteed methods for\nthese increasingly important clustering settings. Going beyond Bregman\ndivergences, we also prove an approximation factor for tensor clustering with\narbitrary separable metrics. Through extensive experiments we evaluate the\ncharacteristics of our method, and show that it also has practical impact.\n",
          "  Many methods have been developed for data clustering, such as k-means,\nexpectation maximization and algorithms based on graph theory. In this latter\ncase, graphs are generally constructed by taking into account the Euclidian\ndistance as a similarity measure, and partitioned using spectral methods.\nHowever, these methods are not accurate when the clusters are not well\nseparated. In addition, it is not possible to automatically determine the\nnumber of clusters. These limitations can be overcome by taking into account\nnetwork community identification algorithms. In this work, we propose a\nmethodology for data clustering based on complex networks theory. We compare\ndifferent metrics for quantifying the similarity between objects and take into\naccount three community finding techniques. This approach is applied to two\nreal-world databases and to two sets of artificially generated data. By\ncomparing our method with traditional clustering approaches, we verify that the\nproximity measures given by the Chebyshev and Manhattan distances are the most\nsuitable metrics to quantify the similarity between objects. In addition, the\ncommunity identification method based on the greedy optimization provides the\nsmallest misclassification rates.\n",
          "  We propose in this paper an exploratory analysis algorithm for functional\ndata. The method partitions a set of functions into $K$ clusters and represents\neach cluster by a simple prototype (e.g., piecewise constant). The total number\nof segments in the prototypes, $P$, is chosen by the user and optimally\ndistributed among the clusters via two dynamic programming algorithms. The\npractical relevance of the method is shown on two real world datasets.\n",
          "  The problem of clustering is considered, for the case when each data point is\na sample generated by a stationary ergodic process. We propose a very natural\nasymptotic notion of consistency, and show that simple consistent algorithms\nexist, under most general non-parametric assumptions. The notion of consistency\nis as follows: two samples should be put into the same cluster if and only if\nthey were generated by the same distribution. With this notion of consistency,\nclustering generalizes such classical statistical problems as homogeneity\ntesting and process classification. We show that, for the case of a known\nnumber of clusters, consistency can be achieved under the only assumption that\nthe joint distribution of the data is stationary ergodic (no parametric or\nMarkovian assumptions, no assumptions of independence, neither between nor\nwithin the samples). If the number of clusters is unknown, consistency can be\nachieved under appropriate assumptions on the mixing rates of the processes.\n(again, no parametric or independence assumptions). In both cases we give\nexamples of simple (at most quadratic in each argument) algorithms which are\nconsistent.\n",
          "  In many practical applications of clustering, the objects to be clustered\nevolve over time, and a clustering result is desired at each time step. In such\napplications, evolutionary clustering typically outperforms traditional static\nclustering by producing clustering results that reflect long-term trends while\nbeing robust to short-term variations. Several evolutionary clustering\nalgorithms have recently been proposed, often by adding a temporal smoothness\npenalty to the cost function of a static clustering method. In this paper, we\nintroduce a different approach to evolutionary clustering by accurately\ntracking the time-varying proximities between objects followed by static\nclustering. We present an evolutionary clustering framework that adaptively\nestimates the optimal smoothing parameter using shrinkage estimation, a\nstatistical approach that improves a naive estimate using additional\ninformation. The proposed framework can be used to extend a variety of static\nclustering algorithms, including hierarchical, k-means, and spectral\nclustering, into evolutionary clustering algorithms. Experiments on synthetic\nand real data sets indicate that the proposed framework outperforms static\nclustering and existing evolutionary clustering algorithms in many scenarios.\n",
          "  This paper considers the problem of clustering a partially observed\nunweighted graph---i.e., one where for some node pairs we know there is an edge\nbetween them, for some others we know there is no edge, and for the remaining\nwe do not know whether or not there is an edge. We want to organize the nodes\ninto disjoint clusters so that there is relatively dense (observed)\nconnectivity within clusters, and sparse across clusters.\n  We take a novel yet natural approach to this problem, by focusing on finding\nthe clustering that minimizes the number of \"disagreements\"---i.e., the sum of\nthe number of (observed) missing edges within clusters, and (observed) present\nedges across clusters. Our algorithm uses convex optimization; its basis is a\nreduction of disagreement minimization to the problem of recovering an\n(unknown) low-rank matrix and an (unknown) sparse matrix from their partially\nobserved sum. We evaluate the performance of our algorithm on the classical\nPlanted Partition/Stochastic Block Model. Our main theorem provides sufficient\nconditions for the success of our algorithm as a function of the minimum\ncluster size, edge density and observation probability; in particular, the\nresults characterize the tradeoff between the observation probability and the\nedge density gap. When there are a constant number of clusters of equal size,\nour results are optimal up to logarithmic factors.\n",
          "  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\nthe problem of computing $x^*$ that minimizes the expression $\\sum_{f\\in\nF}f(x)$, over $x\\in X$. A typical application is \\emph{shape fitting}, where we\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\na (possibly infinite) family $X$ of shapes. Here, each point $p\\in P$\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\nand we seek a shape $x$ that minimizes the sum of distances from each point in\n$P$. In the $k$-clustering variant, each $x\\in X$ is a tuple of $k$ shapes, and\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\n  Our main result is a unified framework for constructing {\\em coresets} and\n{\\em approximate clustering} for such general sets of functions. To achieve our\nresults, we forge a link between the classic and well defined notion of\n$\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\nto the relatively new (and not so consistent) paradigm of coresets, which are\nsome kind of \"compressed representation\" of the input set $F$. Using\ntraditional techniques, a coreset usually implies an LTAS (linear time\napproximation scheme) for the corresponding optimization problem, which can be\ncomputed in parallel, via one pass over the data, and using only\npolylogarithmic space (i.e, in the streaming model).\n  We show how to generalize the results of our framework for squared distances\n(as in $k$-mean), distances to the $q$th power, and deterministic\nconstructions.\n",
          "  We consider the model introduced by Bilu and Linial (2010), who study\nproblems for which the optimal clustering does not change when distances are\nperturbed. They show that even when a problem is NP-hard, it is sometimes\npossible to obtain efficient algorithms for instances resilient to certain\nmultiplicative perturbations, e.g. on the order of $O(\\sqrt{n})$ for max-cut\nclustering. Awasthi et al. (2010) consider center-based objectives, and Balcan\nand Liang (2011) analyze the $k$-median and min-sum objectives, giving\nefficient algorithms for instances resilient to certain constant multiplicative\nperturbations.\n  Here, we are motivated by the question of to what extent these assumptions\ncan be relaxed while allowing for efficient algorithms. We show there is little\nroom to improve these results by giving NP-hardness lower bounds for both the\n$k$-median and min-sum objectives. On the other hand, we show that constant\nmultiplicative resilience parameters can be so strong as to make the clustering\nproblem trivial, leaving only a narrow range of resilience parameters for which\nclustering is interesting. We also consider a model of additive perturbations\nand give a correspondence between additive and multiplicative notions of\nstability. Our results provide a close examination of the consequences of\nassuming stability in data.\n",
          "  In this paper we present a new algorithm for learning oblique decision trees.\nMost of the current decision tree algorithms rely on impurity measures to\nassess the goodness of hyperplanes at each node while learning a decision tree\nin a top-down fashion. These impurity measures do not properly capture the\ngeometric structures in the data. Motivated by this, our algorithm uses a\nstrategy to assess the hyperplanes in such a way that the geometric structure\nin the data is taken into account. At each node of the decision tree, we find\nthe clustering hyperplanes for both the classes and use their angle bisectors\nas the split rule at that node. We show through empirical studies that this\nidea leads to small decision trees and better performance. We also present some\nanalysis to show that the angle bisectors of clustering hyperplanes that we use\nas the split rules at each node, are solutions of an interesting optimization\nproblem and hence argue that this is a principled method of learning a decision\ntree.\n",
          "  Clustering is an unsupervised technique of Data Mining. It means grouping\nsimilar objects together and separating the dissimilar ones. Each object in the\ndata set is assigned a class label in the clustering process using a distance\nmeasure. This paper has captured the problems that are faced in real when\nclustering algorithms are implemented .It also considers the most extensively\nused tools which are readily available and support functions which ease the\nprogramming. Once algorithms have been implemented, they also need to be tested\nfor its validity. There exist several validation indexes for testing the\nperformance and accuracy which have also been discussed here.\n",
          "  Clustering is a common technique for statistical data analysis, Clustering is\nthe process of grouping the data into classes or clusters so that objects\nwithin a cluster have high similarity in comparison to one another, but are\nvery dissimilar to objects in other clusters. Dissimilarities are assessed\nbased on the attribute values describing the objects. Often, distance measures\nare used. Clustering is an unsupervised learning technique, where interesting\npatterns and structures can be found directly from very large data sets with\nlittle or none of the background knowledge. This paper also considers the\npartitioning of m-dimensional lattice graphs using Fiedler's approach, which\nrequires the determination of the eigenvector belonging to the second smallest\nEigenvalue of the Laplacian with K-means partitioning algorithm.\n",
          "  This paper proposes a novel similarity measure for clustering sequential\ndata. We first construct a common state-space by training a single\nprobabilistic model with all the sequences in order to get a unified\nrepresentation for the dataset. Then, distances are obtained attending to the\ntransition matrices induced by each sequence in that state-space. This approach\nsolves some of the usual overfitting and scalability issues of the existing\nsemi-parametric techniques, that rely on training a model for each sequence.\nEmpirical studies on both synthetic and real-world datasets illustrate the\nadvantages of the proposed similarity measure for clustering sequences.\n",
          "  Recent spectral clustering methods are a propular and powerful technique for\ndata clustering. These methods need to solve the eigenproblem whose\ncomputational complexity is $O(n^3)$, where $n$ is the number of data samples.\nIn this paper, a non-eigenproblem based clustering method is proposed to deal\nwith the clustering problem. Its performance is comparable to the spectral\nclustering algorithms but it is more efficient with computational complexity\n$O(n^2)$. We show that with a transitive distance and an observed property,\ncalled K-means duality, our algorithm can be used to handle data sets with\ncomplex cluster shapes, multi-scale clusters, and noise. Moreover, no\nparameters except the number of clusters need to be set in our algorithm.\n",
          "  We herein introduce a new method of interpretable clustering that uses\nunsupervised binary trees. It is a three-stage procedure, the first stage of\nwhich entails a series of recursive binary splits to reduce the heterogeneity\nof the data within the new subsamples. During the second stage (pruning),\nconsideration is given to whether adjacent nodes can be aggregated. Finally,\nduring the third stage (joining), similar clusters are joined together, even if\nthey do not share the same parent originally. Consistency results are obtained,\nand the procedure is used on simulated and real data sets.\n",
          "  Many data analysis methods cannot be applied to data that are not represented\nby a fixed number of real values, whereas most of real world observations are\nnot readily available in such a format. Vector based data analysis methods have\ntherefore to be adapted in order to be used with non standard complex data. A\nflexible and general solution for this adaptation is to use a (dis)similarity\nmeasure. Indeed, thanks to expert knowledge on the studied data, it is\ngenerally possible to define a measure that can be used to make pairwise\ncomparison between observations. General data analysis methods are then\nobtained by adapting existing methods to (dis)similarity matrices. In this\narticle, we propose an adaptation of Kohonen's Self Organizing Map (SOM) to\n(dis)similarity data. The proposed algorithm is an adapted version of the\nvector based batch SOM. The method is validated on real world data: we provide\nan analysis of the usage patterns of the web site of the Institut National de\nRecherche en Informatique et Automatique, constructed thanks to web log mining\nmethod.\n",
          "  We study feature selection for $k$-means clustering. Although the literature\ncontains many methods with good empirical performance, algorithms with provable\ntheoretical behavior have only recently been developed. Unfortunately, these\nalgorithms are randomized and fail with, say, a constant probability. We\naddress this issue by presenting a deterministic feature selection algorithm\nfor k-means with theoretical guarantees. At the heart of our algorithm lies a\ndeterministic method for decompositions of the identity.\n",
          "  Constrained clustering has been well-studied for algorithms such as $K$-means\nand hierarchical clustering. However, how to satisfy many constraints in these\nalgorithmic settings has been shown to be intractable. One alternative to\nencode many constraints is to use spectral clustering, which remains a\ndeveloping area. In this paper, we propose a flexible framework for constrained\nspectral clustering. In contrast to some previous efforts that implicitly\nencode Must-Link and Cannot-Link constraints by modifying the graph Laplacian\nor constraining the underlying eigenspace, we present a more natural and\nprincipled formulation, which explicitly encodes the constraints as part of a\nconstrained optimization problem. Our method offers several practical\nadvantages: it can encode the degree of belief in Must-Link and Cannot-Link\nconstraints; it guarantees to lower-bound how well the given constraints are\nsatisfied using a user-specified threshold; it can be solved deterministically\nin polynomial time through generalized eigendecomposition. Furthermore, by\ninheriting the objective function from spectral clustering and encoding the\nconstraints explicitly, much of the existing analysis of unconstrained spectral\nclustering techniques remains valid for our formulation. We validate the\neffectiveness of our approach by empirical results on both artificial and real\ndatasets. We also demonstrate an innovative use of encoding large number of\nconstraints: transfer learning via constraints.\n",
          "  We suggest using the max-norm as a convex surrogate constraint for\nclustering. We show how this yields a better exact cluster recovery guarantee\nthan previously suggested nuclear-norm relaxation, and study the effectiveness\nof our method, and other related convex relaxations, compared to other\nclustering approaches.\n",
          "  Recently a new clustering algorithm called 'affinity propagation' (AP) has\nbeen proposed, which efficiently clustered sparsely related data by passing\nmessages between data points. However, we want to cluster large scale data\nwhere the similarities are not sparse in many cases. This paper presents two\nvariants of AP for grouping large scale data with a dense similarity matrix.\nThe local approach is partition affinity propagation (PAP) and the global\nmethod is landmark affinity propagation (LAP). PAP passes messages in the\nsubsets of data first and then merges them as the number of initial step of\niterations; it can effectively reduce the number of iterations of clustering.\nLAP passes messages between the landmark data points first and then clusters\nnon-landmark data points; it is a large global approximation method to speed up\nclustering. Experiments are conducted on many datasets, such as random data\npoints, manifold subspaces, images of faces and Chinese calligraphy, and the\nresults demonstrate that the two approaches are feasible and practicable.\n",
          "  This paper considers the clustering problem for large data sets. We propose\nan approach based on distributed optimization. The clustering problem is\nformulated as an optimization problem of maximizing the classification gain. We\nshow that the optimization problem can be reformulated and decomposed into\nsmall-scale sub optimization problems by using the Dantzig-Wolfe decomposition\nmethod. Generally speaking, the Dantzig-Wolfe method can only be used for\nconvex optimization problems, where the duality gaps are zero. Even though, the\nconsidered optimization problem in this paper is non-convex, we prove that the\nduality gap goes to zero, as the problem size goes to infinity. Therefore, the\nDantzig-Wolfe method can be applied here. In the proposed approach, the\nclustering problem is iteratively solved by a group of computers coordinated by\none center processor, where each computer solves one independent small-scale\nsub optimization problem during each iteration, and only a small amount of data\ncommunication is needed between the computers and center processor. Numerical\nresults show that the proposed approach is effective and efficient.\n",
          "  The proposal is to use clusters, graphs and networks as models in order to\nanalyse the Web structure. Clusters, graphs and networks provide knowledge\nrepresentation and organization. Clusters were generated by co-site analysis.\nThe sample is a set of academic Web sites from the countries belonging to the\nEuropean Union. These clusters are here revisited from the point of view of\ngraph theory and social network analysis. This is a quantitative and structural\nanalysis. In fact, the Internet is a computer network that connects people and\norganizations. Thus we may consider it to be a social network. The set of Web\nacademic sites represents an empirical social network, and is viewed as a\nvirtual community. The network structural properties are here analysed applying\ntogether cluster analysis, graph theory and social network analysis.\n",
          "  Spectral clustering is a novel clustering method which can detect complex\nshapes of data clusters. However, it requires the eigen decomposition of the\ngraph Laplacian matrix, which is proportion to $O(n^3)$ and thus is not\nsuitable for large scale systems. Recently, many methods have been proposed to\naccelerate the computational time of spectral clustering. These approximate\nmethods usually involve sampling techniques by which a lot information of the\noriginal data may be lost. In this work, we propose a fast and accurate\nspectral clustering approach using an approximate commute time embedding, which\nis similar to the spectral embedding. The method does not require using any\nsampling technique and computing any eigenvector at all. Instead it uses random\nprojection and a linear time solver to find the approximate embedding. The\nexperiments in several synthetic and real datasets show that the proposed\napproach has better clustering quality and is faster than the state-of-the-art\napproximate spectral clustering methods.\n",
          "  In recent years, predicting the user's next request in web navigation has\nreceived much attention. An information source to be used for dealing with such\nproblem is the left information by the previous web users stored at the web\naccess log on the web servers. Purposed systems for this problem work based on\nthis idea that if a large number of web users request specific pages of a\nwebsite on a given session, it can be concluded that these pages are satisfying\nsimilar information needs, and therefore they are conceptually related. In this\nstudy, a new clustering approach is introduced that employs logical path\nstoring of a website pages as another parameter which is regarded as a\nsimilarity parameter and conceptual relation between web pages. The results of\nsimulation have shown that the proposed approach is more than others precise in\ndetermining the clusters.\n",
          "  We have proposed a model based upon flocking on a complex network, and then\ndeveloped two clustering algorithms on the basis of it. In the algorithms,\nfirstly a \\textit{k}-nearest neighbor (knn) graph as a weighted and directed\ngraph is produced among all data points in a dataset each of which is regarded\nas an agent who can move in space, and then a time-varying complex network is\ncreated by adding long-range links for each data point. Furthermore, each data\npoint is not only acted by its \\textit{k} nearest neighbors but also \\textit{r}\nlong-range neighbors through fields established in space by them together, so\nit will take a step along the direction of the vector sum of all fields. It is\nmore important that these long-range links provides some hidden information for\neach data point when it moves and at the same time accelerate its speed\nconverging to a center. As they move in space according to the proposed model,\ndata points that belong to the same class are located at a same position\ngradually, whereas those that belong to different classes are away from one\nanother. Consequently, the experimental results have demonstrated that data\npoints in datasets are clustered reasonably and efficiently, and the rates of\nconvergence of clustering algorithms are fast enough. Moreover, the comparison\nwith other algorithms also provides an indication of the effectiveness of the\nproposed approach.\n",
          "  Nearest neighbor (k-NN) graphs are widely used in machine learning and data\nmining applications, and our aim is to better understand what they reveal about\nthe cluster structure of the unknown underlying distribution of points.\nMoreover, is it possible to identify spurious structures that might arise due\nto sampling variability?\n  Our first contribution is a statistical analysis that reveals how certain\nsubgraphs of a k-NN graph form a consistent estimator of the cluster tree of\nthe underlying distribution of points. Our second and perhaps most important\ncontribution is the following finite sample guarantee. We carefully work out\nthe tradeoff between aggressive and conservative pruning and are able to\nguarantee the removal of all spurious cluster structures at all levels of the\ntree while at the same time guaranteeing the recovery of salient clusters. This\nis the first such finite sample result in the context of clustering.\n",
          "  Most classification methods are based on the assumption that data conforms to\na stationary distribution. The machine learning domain currently suffers from a\nlack of classification techniques that are able to detect the occurrence of a\nchange in the underlying data distribution. Ignoring possible changes in the\nunderlying concept, also known as concept drift, may degrade the performance of\nthe classification model. Often these changes make the model inconsistent and\nregular updatings become necessary. Taking the temporal dimension into account\nduring the analysis of Web usage data is a necessity, since the way a site is\nvisited may indeed evolve due to modifications in the structure and content of\nthe site, or even due to changes in the behavior of certain user groups. One\nsolution to this problem, proposed in this article, is to update models using\nsummaries obtained by means of an evolutionary approach based on an intelligent\nclustering approach. We carry out various clustering strategies that are\napplied on time sub-periods. To validate our approach we apply two external\nevaluation criteria which compare different partitions from the same data set.\nOur experiments show that the proposed approach is efficient to detect the\noccurrence of changes.\n",
          "  We theoretically study semi-supervised clustering in sparse graphs in the\npresence of pairwise constraints on the cluster assignments of nodes. We focus\non bi-cluster graphs, and study the impact of semi-supervision for varying\nconstraint density and overlap between the clusters. Recent results for\nunsupervised clustering in sparse graphs indicate that there is a critical\nratio of within-cluster and between-cluster connectivities below which clusters\ncannot be recovered with better than random accuracy. The goal of this paper is\nto examine the impact of pairwise constraints on the clustering accuracy. Our\nresults suggests that the addition of constraints does not provide automatic\nimprovement over the unsupervised case. When the density of the constraints is\nsufficiently small, their only impact is to shift the detection threshold while\npreserving the criticality. Conversely, if the density of (hard) constraints is\nabove the percolation threshold, the criticality is suppressed and the\ndetection threshold disappears.\n",
          "  We introduce a modified model of random walk, and then develop two novel\nclustering algorithms based on it. In the algorithms, each data point in a\ndataset is considered as a particle which can move at random in space according\nto the preset rules in the modified model. Further, this data point may be also\nviewed as a local control subsystem, in which the controller adjusts its\ntransition probability vector in terms of the feedbacks of all data points, and\nthen its transition direction is identified by an event-generating function.\nFinally, the positions of all data points are updated. As they move in space,\ndata points collect gradually and some separating parts emerge among them\nautomatically. As a consequence, data points that belong to the same class are\nlocated at a same position, whereas those that belong to different classes are\naway from one another. Moreover, the experimental results have demonstrated\nthat data points in the test datasets are clustered reasonably and efficiently,\nand the comparison with other algorithms also provides an indication of the\neffectiveness of the proposed algorithms.\n",
          "  In many real world applications, data cannot be accurately represented by\nvectors. In those situations, one possible solution is to rely on dissimilarity\nmeasures that enable sensible comparison between observations. Kohonen's\nSelf-Organizing Map (SOM) has been adapted to data described only through their\ndissimilarity matrix. This algorithm provides both non linear projection and\nclustering of non vector data. Unfortunately, the algorithm suffers from a high\ncost that makes it quite difficult to use with voluminous data sets. In this\npaper, we propose a new algorithm that provides an important reduction of the\ntheoretical cost of the dissimilarity SOM without changing its outcome (the\nresults are exactly the same as the ones obtained with the original algorithm).\nMoreover, we introduce implementation methods that result in very short running\ntimes. Improvements deduced from the theoretical cost model are validated on\nsimulated and real world data (a word list clustering problem). We also\ndemonstrate that the proposed implementation methods reduce by a factor up to 3\nthe running time of the fast algorithm over a standard implementation.\n",
          "  The diameter $k$-clustering problem is the problem of partitioning a finite\nsubset of $\\mathbb{R}^d$ into $k$ subsets called clusters such that the maximum\ndiameter of the clusters is minimized. One early clustering algorithm that\ncomputes a hierarchy of approximate solutions to this problem (for all values\nof $k$) is the agglomerative clustering algorithm with the complete linkage\nstrategy. For decades, this algorithm has been widely used by practitioners.\nHowever, it is not well studied theoretically. In this paper, we analyze the\nagglomerative complete linkage clustering algorithm. Assuming that the\ndimension $d$ is a constant, we show that for any $k$ the solution computed by\nthis algorithm is an $O(\\log k)$-approximation to the diameter $k$-clustering\nproblem. Our analysis does not only hold for the Euclidean distance but for any\nmetric that is based on a norm. Furthermore, we analyze the closely related\n$k$-center and discrete $k$-center problem. For the corresponding agglomerative\nalgorithms, we deduce an approximation factor of $O(\\log k)$ as well.\n",
          "  We propose a new clustering technique that can be regarded as a numerical\nmethod to compute the proximity gestalt. The method analyzes edge length\nstatistics in the MST of the dataset and provides an a contrario cluster\ndetection criterion. The approach is fully parametric on the chosen distance\nand can detect arbitrarily shaped clusters. The method is also automatic, in\nthe sense that only a single parameter is left to the user. This parameter has\nan intuitive interpretation as it controls the expected number of false\ndetections. We show that the iterative application of our method can (1)\nprovide robustness to noise and (2) solve a masking phenomenon in which a\nhighly populated and salient cluster dominates the scene and inhibits the\ndetection of less-populated, but still salient, clusters.\n",
          "  Hierarchical clustering based on pairwise similarities is a common tool used\nin a broad range of scientific applications. However, in many problems it may\nbe expensive to obtain or compute similarities between the items to be\nclustered. This paper investigates the hierarchical clustering of N items based\non a small subset of pairwise similarities, significantly less than the\ncomplete set of N(N-1)/2 similarities. First, we show that if the intracluster\nsimilarities exceed intercluster similarities, then it is possible to correctly\ndetermine the hierarchical clustering from as few as 3N log N similarities. We\ndemonstrate this order of magnitude savings in the number of pairwise\nsimilarities necessitates sequentially selecting which similarities to obtain\nin an adaptive fashion, rather than picking them at random. We then propose an\nactive clustering method that is robust to a limited fraction of anomalous\nsimilarities, and show how even in the presence of these noisy similarity\nvalues we can resolve the hierarchical clustering using only O(N log^2 N)\npairwise similarities.\n",
          "  File type identification and file type clustering may be difficult tasks that\nhave an increasingly importance in the field of computer and network security.\nClassical methods of file type detection including considering file extensions\nand magic bytes can be easily spoofed. Content-based file type detection is a\nnewer way that is taken into account recently. In this paper, a new\ncontent-based method for the purpose of file type detection and file type\nclustering is proposed that is based on the PCA and neural networks. The\nproposed method has a good accuracy and is fast enough.\n",
          "  We study clustering on graphs with multiple edge types. Our main motivation\nis that similarities between objects can be measured in many different metrics.\nFor instance similarity between two papers can be based on common authors,\nwhere they are published, keyword similarity, citations, etc. As such, graphs\nwith multiple edges is a more accurate model to describe similarities between\nobjects. Each edge/metric provides only partial information about the data;\nrecovering full information requires aggregation of all the similarity metrics.\nClustering becomes much more challenging in this context, since in addition to\nthe difficulties of the traditional clustering problem, we have to deal with a\nspace of clusterings. We generalize the concept of clustering in single-edge\ngraphs to multi-edged graphs and investigate problems such as: Can we find a\nclustering that remains good, even if we change the relative weights of\nmetrics? How can we describe the space of clusterings efficiently? Can we find\nunexpected clusterings (a good clustering that is distant from all given\nclusterings)? If given the ground-truth clustering, can we recover how the\nweights for edge types were aggregated? %In this paper, we discuss these\nproblems and the underlying algorithmic challenges and propose some solutions.\nWe also present two case studies: one based on papers on Arxiv and one based on\nCIA World Factbook.\n",
          "  Very large databases are required to store massive amounts of data that are\ncontinuously inserted and queried. Analyzing huge data sets and extracting\nvaluable pattern in many applications are interesting for researchers. We can\nidentify two main groups of techniques for huge data bases mining. One group\nrefers to streaming data and applies mining techniques whereas second group\nattempts to solve this problem directly with efficient algorithms. Recently\nmany researchers have focused on data stream as an efficient strategy against\nhuge data base mining instead of mining on entire data base. The main problem\nin data stream mining means evolving data is more difficult to detect in this\ntechniques therefore unsupervised methods should be applied. However,\nclustering techniques can lead us to discover hidden information. In this\nsurvey, we try to clarify: first, the different problem definitions related to\ndata stream clustering in general; second, the specific difficulties\nencountered in this field of research; third, the varying assumptions,\nheuristics, and intuitions forming the basis of different approaches; and how\nseveral prominent solutions tackle different problems. Index Terms- Data\nStream, Clustering, K-Means, Concept drift\n",
          "  Notwithstanding the popularity of conventional clustering algorithms such as\nK-means and probabilistic clustering, their clustering results are sensitive to\nthe presence of outliers in the data. Even a few outliers can compromise the\nability of these algorithms to identify meaningful hidden structures rendering\ntheir outcome unreliable. This paper develops robust clustering algorithms that\nnot only aim to cluster the data, but also to identify the outliers. The novel\napproaches rely on the infrequent presence of outliers in the data which\ntranslates to sparsity in a judiciously chosen domain. Capitalizing on the\nsparsity in the outlier domain, outlier-aware robust K-means and probabilistic\nclustering approaches are proposed. Their novelty lies on identifying outliers\nwhile effecting sparsity in the outlier domain through carefully chosen\nregularization. A block coordinate descent approach is developed to obtain\niterative algorithms with convergence guarantees and small excess computational\ncomplexity with respect to their non-robust counterparts. Kernelized versions\nof the robust clustering algorithms are also developed to efficiently handle\nhigh-dimensional data, identify nonlinearly separable clusters, or even cluster\nobjects that are not represented by vectors. Numerical tests on both synthetic\nand real datasets validate the performance and applicability of the novel\nalgorithms.\n",
          "  Observational data usually comes with a multimodal nature, which means that\nit can be naturally represented by a multi-layer graph whose layers share the\nsame set of vertices (users) with different edges (pairwise relationships). In\nthis paper, we address the problem of combining different layers of the\nmulti-layer graph for improved clustering of the vertices compared to using\nlayers independently. We propose two novel methods, which are based on joint\nmatrix factorization and graph regularization framework respectively, to\nefficiently combine the spectrum of the multiple graph layers, namely the\neigenvectors of the graph Laplacian matrices. In each case, the resulting\ncombination, which we call a \"joint spectrum\" of multiple graphs, is used for\nclustering the vertices. We evaluate our approaches by simulations with several\nreal world social network datasets. Results demonstrate the superior or\ncompetitive performance of the proposed methods over state-of-the-art technique\nand common baseline methods, such as co-regularization and summation of\ninformation from individual graphs.\n",
          "  Motivated by the fact that distances between data points in many real-world\nclustering instances are often based on heuristic measures, Bilu and\nLinial~\\cite{BL} proposed analyzing objective based clustering problems under\nthe assumption that the optimum clustering to the objective is preserved under\nsmall multiplicative perturbations to distances between points. The hope is\nthat by exploiting the structure in such instances, one can overcome worst case\nhardness results.\n  In this paper, we provide several results within this framework. For\ncenter-based objectives, we present an algorithm that can optimally cluster\ninstances resilient to perturbations of factor $(1 + \\sqrt{2})$, solving an\nopen problem of Awasthi et al.~\\cite{ABS10}. For $k$-median, a center-based\nobjective of special interest, we additionally give algorithms for a more\nrelaxed assumption in which we allow the optimal solution to change in a small\n$\\epsilon$ fraction of the points after perturbation. We give the first bounds\nknown for $k$-median under this more realistic and more general assumption. We\nalso provide positive results for min-sum clustering which is typically a\nharder objective than center-based objectives from approximability standpoint.\nOur algorithms are based on new linkage criteria that may be of independent\ninterest.\n  Additionally, we give sublinear-time algorithms, showing algorithms that can\nreturn an implicit clustering from only access to a small random sample.\n",
          "  We provide a new framework for generating multiple good quality partitions\n(clusterings) of a single data set. Our approach decomposes this problem into\ntwo components, generating many high-quality partitions, and then grouping\nthese partitions to obtain k representatives. The decomposition makes the\napproach extremely modular and allows us to optimize various criteria that\ncontrol the choice of representative partitions.\n",
          "  We formulate weighted graph clustering as a prediction problem: given a\nsubset of edge weights we analyze the ability of graph clustering to predict\nthe remaining edge weights. This formulation enables practical and theoretical\ncomparison of different approaches to graph clustering as well as comparison of\ngraph clustering with other possible ways to model the graph. We adapt the\nPAC-Bayesian analysis of co-clustering (Seldin and Tishby, 2008; Seldin, 2009)\nto derive a PAC-Bayesian generalization bound for graph clustering. The bound\nshows that graph clustering should optimize a trade-off between empirical data\nfit and the mutual information that clusters preserve on the graph nodes. A\nsimilar trade-off derived from information-theoretic considerations was already\nshown to produce state-of-the-art results in practice (Slonim et al., 2005;\nYom-Tov and Slonim, 2009). This paper supports the empirical evidence by\nproviding a better theoretical foundation, suggesting formal generalization\nguarantees, and offering a more accurate way to deal with finite sample issues.\nWe derive a bound minimization algorithm and show that it provides good results\nin real-life problems and that the derived PAC-Bayesian bound is reasonably\ntight.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_clusterings_clustering_cluster",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_clusterings_clustering_cluster"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.905358076095581,
          -1.099799633026123,
          -0.8945366740226746,
          -0.5716897249221802,
          -1.116761565208435,
          -0.23742011189460754,
          -1.1536529064178467,
          -1.1577821969985962,
          -0.47071573138237,
          -0.514606237411499,
          -1.161270022392273,
          -0.9847837686538696,
          -1.112377405166626,
          -0.9635080695152283,
          -1.0718698501586914,
          -0.6061477661132812,
          -0.7087110280990601,
          -0.8183338046073914,
          -0.9666339755058289,
          -1.1631991863250732,
          -1.0281742811203003,
          -0.5429821610450745,
          -0.7924146056175232,
          -0.9934935569763184,
          -0.6755258440971375,
          -0.9627847075462341,
          -0.9504478573799133,
          -1.2014141082763672,
          -0.7782461047172546,
          -0.6169242858886719,
          -0.9402238130569458,
          -0.577878475189209,
          -0.8226441740989685,
          -0.6217173933982849,
          -0.5725850462913513,
          -1.1669204235076904,
          -0.4960107207298279,
          -1.0582948923110962,
          -0.8301914930343628,
          -1.1896566152572632,
          -0.9160940647125244,
          -0.4659741222858429,
          -1.0683655738830566,
          -1.1823880672454834,
          -1.1787519454956055,
          -0.6242445111274719,
          -0.47847461700439453,
          -0.7108736634254456,
          -0.8796800971031189,
          -0.730859100818634,
          -0.6199512481689453,
          -0.8013515472412109,
          -0.6518277525901794,
          -0.8897057771682739,
          -1.073457956314087,
          -0.6891414523124695,
          -1.0106801986694336,
          -0.7685400247573853,
          -0.8012102246284485,
          -0.4564366638660431,
          -1.1725713014602661,
          -0.761157214641571,
          -0.4627767503261566,
          -1.027204155921936,
          -1.1423388719558716,
          -0.7796941995620728,
          -1.2086013555526733,
          -0.8226442337036133,
          -0.6389399170875549,
          -0.35648876428604126,
          -0.9783987402915955,
          -0.502128005027771,
          -0.1834152191877365,
          -0.7978744506835938,
          -1.1749181747436523,
          -0.6801036596298218,
          -1.0896004438400269,
          -0.8347344398498535
         ],
         "y": [
          8.278473854064941,
          7.747765064239502,
          7.592520713806152,
          7.755609035491943,
          7.6707048416137695,
          7.83112096786499,
          7.72683048248291,
          7.810997009277344,
          7.810469627380371,
          7.63210391998291,
          7.69345235824585,
          7.537147521972656,
          7.69367790222168,
          7.78853178024292,
          8.040847778320312,
          7.569496154785156,
          8.201498985290527,
          7.538436412811279,
          8.22458553314209,
          7.715217113494873,
          7.792844772338867,
          7.4264912605285645,
          8.111308097839355,
          8.172208786010742,
          7.741830825805664,
          8.221061706542969,
          8.243328094482422,
          7.8955535888671875,
          8.035696983337402,
          7.471625328063965,
          7.460714817047119,
          7.478720664978027,
          8.12234878540039,
          7.538438320159912,
          7.461940288543701,
          7.720223903656006,
          7.485955238342285,
          7.666047096252441,
          7.960254669189453,
          7.793931484222412,
          7.4690423011779785,
          7.602204322814941,
          8.064966201782227,
          7.755459308624268,
          7.748244762420654,
          7.677067756652832,
          7.407743453979492,
          7.79915714263916,
          7.437948703765869,
          7.945290565490723,
          7.606348514556885,
          7.487072467803955,
          7.660111904144287,
          8.177760124206543,
          8.101249694824219,
          7.8396735191345215,
          8.139516830444336,
          7.927841663360596,
          8.089720726013184,
          7.3239827156066895,
          7.68651819229126,
          7.781253337860107,
          7.367455005645752,
          8.047046661376953,
          7.669060230255127,
          7.547026634216309,
          7.710663318634033,
          7.836565971374512,
          7.755216121673584,
          7.349920272827148,
          7.892107009887695,
          7.341094493865967,
          7.923691749572754,
          8.136578559875488,
          7.718564510345459,
          7.622690200805664,
          7.853910446166992,
          7.768309116363525
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This paper aims to showcase the measure of structural diversity of an\nensemble of 9 classifiers and then map a relationship between this structural\ndiversity and accuracy. The structural diversity was induced by having\ndifferent architectures or structures of the classifiers The Genetical\nAlgorithms (GA) were used to derive the relationship between diversity and the\nclassification accuracy by evolving the classifiers and then picking 9\nclassifiers out on an ensemble of 60 classifiers. It was found that as the\nensemble became diverse the accuracy improved. However at a certain diversity\nmeasure the accuracy began to drop. The Kohavi-Wolpert variance method is used\nto measure the diversity of the ensemble. A method of voting is used to\naggregate the results from each classifier. The lowest error was observed at a\ndiversity measure of 0.16 with a mean square error of 0.274, when taking 0.2024\nas maximum diversity measured. The parameters that were varied were: the number\nof hidden nodes, learning rate and the activation function.\n",
          "  Imbalanced data sets containing much more background than signal instances\nare very common in particle physics, and will also be characteristic for the\nupcoming analyses of LHC data. Following up the work presented at ACAT 2008, we\nuse the multivariate technique presented there (a rule growing algorithm with\nthe meta-methods bagging and instance weighting) on much more imbalanced data\nsets, especially a selection of D0 decays without the use of particle\nidentification. It turns out that the quality of the result strongly depends on\nthe number of background instances used for training. We discuss methods to\nexploit this in order to improve the results significantly, and how to handle\nand reduce the size of large training sets without loss of result quality in\ngeneral. We will also comment on how to take into account statistical\nfluctuation in receiver operation characteristic curves (ROC) for comparing\nclassifier methods.\n",
          "  Support Vector Machines (SVMs) are a relatively new supervised classification\ntechnique to the land cover mapping community. They have their roots in\nStatistical Learning Theory and have gained prominence because they are robust,\naccurate and are effective even when using a small training sample. By their\nnature SVMs are essentially binary classifiers, however, they can be adopted to\nhandle the multiple classification tasks common in remote sensing studies. The\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\ntheir impact and implication for land cover mapping. The main finding from this\nresearch is that whereas the 1AA technique is more predisposed to yielding\nunclassified and mixed pixels, the resulting classification accuracy is not\nsignificantly different from 1A1 approach. It is the authors conclusions that\nultimately the choice of technique adopted boils down to personal preference\nand the uniqueness of the dataset at hand.\n",
          "  This article describes an approach to designing a distributed and modular\nneural classifier. This approach introduces a new hierarchical clustering that\nenables one to determine reliable regions in the representation space by\nexploiting supervised information. A multilayer perceptron is then associated\nwith each of these detected clusters and charged with recognizing elements of\nthe associated cluster while rejecting all others. The obtained global\nclassifier is comprised of a set of cooperating neural networks and completed\nby a K-nearest neighbor classifier charged with treating elements rejected by\nall the neural networks. Experimental results for the handwritten digit\nrecognition problem and comparison with neural and statistical nonmodular\nclassifiers are given.\n",
          "  One of the objectives of designing feature selection learning algorithms is\nto obtain classifiers that depend on a small number of attributes and have\nverifiable future performance guarantees. There are few, if any, approaches\nthat successfully address the two goals simultaneously. Performance guarantees\nbecome crucial for tasks such as microarray data analysis due to very small\nsample sizes resulting in limited empirical evaluation. To the best of our\nknowledge, such algorithms that give theoretical bounds on the future\nperformance have not been proposed so far in the context of the classification\nof gene expression data. In this work, we investigate the premise of learning a\nconjunction (or disjunction) of decision stumps in Occam's Razor, Sample\nCompression, and PAC-Bayes learning settings for identifying a small subset of\nattributes that can be used to perform reliable classification tasks. We apply\nthe proposed approaches for gene identification from DNA microarray data and\ncompare our results to those of well known successful approaches proposed for\nthe task. We show that our algorithm not only finds hypotheses with much\nsmaller number of genes while giving competitive classification accuracy but\nalso have tight risk guarantees on future performance unlike other approaches.\nThe proposed approaches are general and extensible in terms of both designing\nnovel algorithms and application to other domains.\n",
          "  Prediction markets are used in real life to predict outcomes of interest such\nas presidential elections. This paper presents a mathematical theory of\nartificial prediction markets for supervised learning of conditional\nprobability estimators. The artificial prediction market is a novel method for\nfusing the prediction information of features or trained classifiers, where the\nfusion result is the contract price on the possible outcomes. The market can be\ntrained online by updating the participants' budgets using training examples.\nInspired by the real prediction markets, the equations that govern the market\nare derived from simple and reasonable assumptions. Efficient numerical\nalgorithms are presented for solving these equations. The obtained artificial\nprediction market is shown to be a maximum likelihood estimator. It generalizes\nlinear aggregation, existent in boosting and random forest, as well as logistic\nregression and some kernel methods. Furthermore, the market mechanism allows\nthe aggregation of specialized classifiers that participate only on specific\ninstances. Experimental comparisons show that the artificial prediction markets\noften outperform random forest and implicit online learning on synthetic data\nand real UCI datasets. Moreover, an extensive evaluation for pelvic and\nabdominal lymph node detection in CT data shows that the prediction market\nimproves adaboost's detection rate from 79.6% to 81.2% at 3 false\npositives/volume.\n",
          "  In this paper entropy based methods are compared and used to measure\nstructural diversity of an ensemble of 21 classifiers. This measure is mostly\napplied in ecology, whereby species counts are used as a measure of diversity.\nThe measures used were Shannon entropy, Simpsons and the Berger Parker\ndiversity indexes. As the diversity indexes increased so did the accuracy of\nthe ensemble. An ensemble dominated by classifiers with the same structure\nproduced poor accuracy. Uncertainty rule from information theory was also used\nto further define diversity. Genetic algorithms were used to find the optimal\nensemble by using the diversity indices as the cost function. The method of\nvoting was used to aggregate the decisions.\n",
          "  In this paper, we propose a special fusion method for combining ensembles of\nbase classifiers utilizing new neural networks in order to improve overall\nefficiency of classification. While ensembles are designed such that each\nclassifier is trained independently while the decision fusion is performed as a\nfinal procedure, in this method, we would be interested in making the fusion\nprocess more adaptive and efficient. This new combiner, called Neural Network\nKernel Least Mean Square1, attempts to fuse outputs of the ensembles of\nclassifiers. The proposed Neural Network has some special properties such as\nKernel abilities,Least Mean Square features, easy learning over variants of\npatterns and traditional neuron capabilities. Neural Network Kernel Least Mean\nSquare is a special neuron which is trained with Kernel Least Mean Square\nproperties. This new neuron is used as a classifiers combiner to fuse outputs\nof base neural network classifiers. Performance of this method is analyzed and\ncompared with other fusion methods. The analysis represents higher performance\nof our new method as opposed to others.\n",
          "  Diabetes is a major health problem in both developing and developed countries\nand its incidence is rising dramatically. In this study, we investigate a novel\nautomatic approach to diagnose Diabetes disease based on Feature Weighted\nSupport Vector Machines (FW-SVMs) and Modified Cuckoo Search (MCS). The\nproposed model consists of three stages: Firstly, PCA is applied to select an\noptimal subset of features out of set of all the features. Secondly, Mutual\nInformation is employed to construct the FWSVM by weighting different features\nbased on their degree of importance. Finally, since parameter selection plays a\nvital role in classification accuracy of SVMs, MCS is applied to select the\nbest parameter values. The proposed MI-MCS-FWSVM method obtains 93.58% accuracy\non UCI dataset. The experimental results demonstrate that our method\noutperforms the previous methods by not only giving more accurate results but\nalso significantly speeding up the classification procedure.\n",
          "  Recent advances in tissue microarray technology have allowed\nimmunohistochemistry to become a powerful medium-to-high throughput analysis\ntool, particularly for the validation of diagnostic and prognostic biomarkers.\nHowever, as study size grows, the manual evaluation of these assays becomes a\nprohibitive limitation; it vastly reduces throughput and greatly increases\nvariability and expense. We propose an algorithm - Tissue Array Co-Occurrence\nMatrix Analysis (TACOMA) - for quantifying cellular phenotypes based on\ntextural regularity summarized by local inter-pixel relationships. The\nalgorithm can be easily trained for any staining pattern, is absent of\nsensitive tuning parameters and has the ability to report salient pixels in an\nimage that contribute to its score. Pathologists' input via informative\ntraining patches is an important aspect of the algorithm that allows the\ntraining for any specific marker or cell type. With co-training, the error rate\nof TACOMA can be reduced substantially for a very small training sample (e.g.,\nwith size 30). We give theoretical insights into the success of co-training via\nthinning of the feature set in a high-dimensional setting when there is\n\"sufficient\" redundancy among the features. TACOMA is flexible, transparent and\nprovides a scoring process that can be evaluated with clarity and confidence.\nIn a study based on an estrogen receptor (ER) marker, we show that TACOMA is\ncomparable to, or outperforms, pathologists' performance in terms of accuracy\nand repeatability.\n",
          "  Support Vector Machines (SVMs) are a relatively new supervised classification\ntechnique to the land cover mapping community. They have their roots in\nStatistical Learning Theory and have gained prominence because they are robust,\naccurate and are effective even when using a small training sample. By their\nnature SVMs are essentially binary classifiers, however, they can be adopted to\nhandle the multiple classification tasks common in remote sensing studies. The\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\ntheir impact and implication for land cover mapping. The main finding from this\nresearch is that whereas the 1AA technique is more predisposed to yielding\nunclassified and mixed pixels, the resulting classification accuracy is not\nsignificantly different from 1A1 approach. It is the authors conclusion\ntherefore that ultimately the choice of technique adopted boils down to\npersonal preference and the uniqueness of the dataset at hand.\n",
          "  One of the important techniques of Data mining is Classification. Many real\nworld problems in various fields such as business, science, industry and\nmedicine can be solved by using classification approach. Neural Networks have\nemerged as an important tool for classification. The advantages of Neural\nNetworks helps for efficient classification of given data. In this study a\nHeart diseases dataset is analyzed using Neural Network approach. To increase\nthe efficiency of the classification process parallel approach is also adopted\nin the training phase.\n",
          "  This paper presents a tumor detection algorithm from mammogram. The proposed\nsystem focuses on the solution of two problems. One is how to detect tumors as\nsuspicious regions with a very weak contrast to their background and another is\nhow to extract features which categorize tumors. The tumor detection method\nfollows the scheme of (a) mammogram enhancement. (b) The segmentation of the\ntumor area. (c) The extraction of features from the segmented tumor area. (d)\nThe use of SVM classifier. The enhancement can be defined as conversion of the\nimage quality to a better and more understandable level. The mammogram\nenhancement procedure includes filtering, top hat operation, DWT. Then the\ncontrast stretching is used to increase the contrast of the image. The\nsegmentation of mammogram images has been playing an important role to improve\nthe detection and diagnosis of breast cancer. The most common segmentation\nmethod used is thresholding. The features are extracted from the segmented\nbreast area. Next stage include, which classifies the regions using the SVM\nclassifier. The method was tested on 75 mammographic images, from the mini-MIAS\ndatabase. The methodology achieved a sensitivity of 88.75%.\n",
          "  We investigate the performance of a simple signed distance function (SDF)\nbased method by direct comparison with standard SVM packages, as well as\nK-nearest neighbor and RBFN methods. We present experimental results comparing\nthe SDF approach with other classifiers on both synthetic geometric problems\nand five benchmark clinical microarray data sets. On both geometric problems\nand microarray data sets, the non-optimized SDF based classifiers perform just\nas well or slightly better than well-developed, standard SVM methods. These\nresults demonstrate the potential accuracy of SDF-based methods on some types\nof problems.\n",
          "  In this paper we apply computer learning methods to diagnosing ovarian cancer\nusing the level of the standard biomarker CA125 in conjunction with information\nprovided by mass-spectrometry. We are working with a new data set collected\nover a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,\nour algorithm gives probability predictions for the disease. To estimate\nclassification accuracy we convert probability predictions into strict\npredictions. Our algorithm makes fewer errors than almost any linear\ncombination of the CA125 level and one peak's intensity (taken on the log\nscale). To check the power of our algorithm we use it to test the hypothesis\nthat CA125 and the peaks do not contain useful information for the prediction\nof the disease at a particular time before the diagnosis. Our algorithm\nproduces $p$-values that are better than those produced by the algorithm that\nhas been previously applied to this data set. Our conclusion is that the\nproposed algorithm is more reliable for prediction on new data.\n",
          "  Nowadays government and private agencies use remote sensing imagery for a\nwide range of applications from military applications to farm development. The\nimages may be a panchromatic, multispectral, hyperspectral or even\nultraspectral of terra bytes. Remote sensing image classification is one\namongst the most significant application worlds for remote sensing. A few\nnumber of image classification algorithms have proved good precision in\nclassifying remote sensing data. But, of late, due to the increasing\nspatiotemporal dimensions of the remote sensing data, traditional\nclassification algorithms have exposed weaknesses necessitating further\nresearch in the field of remote sensing image classification. So an efficient\nclassifier is needed to classify the remote sensing images to extract\ninformation. We are experimenting with both supervised and unsupervised\nclassification. Here we compare the different classification methods and their\nperformances. It is found that Mahalanobis classifier performed the best in our\nclassification.\n",
          "  In many fields where human understanding plays a crucial role, such as\nbioprocesses, the capacity of extracting knowledge from data is of critical\nimportance. Within this framework, fuzzy learning methods, if properly used,\ncan greatly help human experts. Amongst these methods, the aim of orthogonal\ntransformations, which have been proven to be mathematically robust, is to\nbuild rules from a set of training data and to select the most important ones\nby linear regression or rank revealing techniques. The OLS algorithm is a good\nrepresentative of those methods. However, it was originally designed so that it\nonly cared about numerical performance. Thus, we propose some modifications of\nthe original method to take interpretability into account. After recalling the\noriginal algorithm, this paper presents the changes made to the original\nmethod, then discusses some results obtained from benchmark problems. Finally,\nthe algorithm is applied to a real-world fault detection depollution problem.\n",
          "  Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is\nthe methodology of soft computing. IDS, as a pattern-based processing unit,\nextracts useful information from a system subjected to modeling. In spite of\nits excellent potential in solving problems such as classification and modeling\ncompared to other soft computing tools, finding its simple and fast hardware\nimplementation is still a challenge. This paper describes a new hardware\nimplementation of IDS method based on the memristor crossbar structure. In\naddition of simplicity, being completely real-time, having low latency and the\nability to continue working after the occurrence of power breakdown are some of\nthe advantages of our proposed circuit.\n",
          "  Ensemble methods, such as stacking, are designed to boost predictive accuracy\nby blending the predictions of multiple machine learning models. Recent work\nhas shown that the use of meta-features, additional inputs describing each\nexample in a dataset, can boost the performance of ensemble methods, but the\ngreatest reported gains have come from nonlinear procedures requiring\nsignificant tuning and training time. Here, we present a linear technique,\nFeature-Weighted Linear Stacking (FWLS), that incorporates meta-features for\nimproved accuracy while retaining the well-known virtues of linear regression\nregarding speed, stability, and interpretability. FWLS combines model\npredictions linearly using coefficients that are themselves linear functions of\nmeta-features. This technique was a key facet of the solution of the second\nplace team in the recently concluded Netflix Prize competition. Significant\nincreases in accuracy over standard linear stacking are demonstrated on the\nNetflix Prize collaborative filtering dataset.\n",
          "  COMET is a single-pass MapReduce algorithm for learning on large-scale data.\nIt builds multiple random forest ensembles on distributed blocks of data and\nmerges them into a mega-ensemble. This approach is appropriate when learning\nfrom massive-scale data that is too large to fit on a single machine. To get\nthe best accuracy, IVoting should be used instead of bagging to generate the\ntraining subset for each decision tree in the random forest. Experiments with\ntwo large datasets (5GB and 50GB compressed) show that COMET compares favorably\n(in both accuracy and training time) to learning on a subsample of data using a\nserial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble\nevaluation which dynamically decides how many ensemble members to evaluate per\ndata point; this can reduce evaluation cost by 100X or more.\n",
          "  In this study, a new Stacked Generalization technique called Fuzzy Stacked\nGeneralization (FSG) is proposed to minimize the difference between N -sample\nand large-sample classification error of the Nearest Neighbor classifier. The\nproposed FSG employs a new hierarchical distance learning strategy to minimize\nthe error difference. For this purpose, we first construct an ensemble of\nbase-layer fuzzy k- Nearest Neighbor (k-NN) classifiers, each of which receives\na different feature set extracted from the same sample set. The fuzzy\nmembership values computed at the decision space of each fuzzy k-NN classifier\nare concatenated to form the feature vectors of a fusion space. Finally, the\nfeature vectors are fed to a meta-layer classifier to learn the degree of\naccuracy of the decisions of the base-layer classifiers for meta-layer\nclassification. Rather than the power of the individual base layer-classifiers,\ndiversity and cooperation of the classifiers become an important issue to\nimprove the overall performance of the proposed FSG. A weak base-layer\nclassifier may boost the overall performance more than a strong classifier, if\nit is capable of recognizing the samples, which are not recognized by the rest\nof the classifiers, in its own feature space. The experiments explore the type\nof the collaboration among the individual classifiers required for an improved\nperformance of the suggested architecture. Experiments on multiple feature\nreal-world datasets show that the proposed FSG performs better than the state\nof the art ensemble learning algorithms such as Adaboost, Random Subspace and\nRotation Forest. On the other hand, compatible performances are observed in the\nexperiments on single feature multi-attribute datasets.\n",
          "  The Fuzzy Gene Filter (FGF) is an optimised Fuzzy Inference System designed\nto rank genes in order of differential expression, based on expression data\ngenerated in a microarray experiment. This paper examines the effectiveness of\nthe FGF for feature selection using various classification architectures. The\nFGF is compared to three of the most common gene ranking algorithms: t-test,\nWilcoxon test and ROC curve analysis. Four classification schemes are used to\ncompare the performance of the FGF vis-a-vis the standard approaches: K Nearest\nNeighbour (KNN), Support Vector Machine (SVM), Naive Bayesian Classifier (NBC)\nand Artificial Neural Network (ANN). A nested stratified Leave-One-Out Cross\nValidation scheme is used to identify the optimal number top ranking genes, as\nwell as the optimal classifier parameters. Two microarray data sets are used\nfor the comparison: a prostate cancer data set and a lymphoma data set.\n",
          "  In this paper, we prove a crucial theorem called Mirroring Theorem which\naffirms that given a collection of samples with enough information in it such\nthat it can be classified into classes and subclasses then (i) There exists a\nmapping which classifies and subclassifies these samples (ii) There exists a\nhierarchical classifier which can be constructed by using Mirroring Neural\nNetworks (MNNs) in combination with a clustering algorithm that can approximate\nthis mapping. Thus, the proof of the Mirroring theorem provides a theoretical\nbasis for the existence and a practical feasibility of constructing\nhierarchical classifiers, given the maps. Our proposed Mirroring Theorem can\nalso be considered as an extension to Kolmogrovs theorem in providing a\nrealistic solution for unsupervised classification. The techniques we develop,\nare general in nature and have led to the construction of learning machines\nwhich are (i) tree like in structure, (ii) modular (iii) with each module\nrunning on a common algorithm (tandem algorithm) and (iv) selfsupervised. We\nhave actually built the architecture, developed the tandem algorithm of such a\nhierarchical classifier and demonstrated it on an example problem.\n",
          "  A number of representation schemes have been presented for use within\nLearning Classifier Systems, ranging from binary encodings to neural networks.\nThis paper presents results from an investigation into using a discrete\ndynamical system representation within the XCS Learning Classifier System. In\nparticular, asynchronous random Boolean networks are used to represent the\ntraditional condition-action production system rules. It is shown possible to\nuse self-adaptive, open-ended evolution to design an ensemble of such discrete\ndynamical systems within XCS to solve a number of well-known test problems.\n",
          "  A computational challenge to validate the candidate disease genes identified\nin a high-throughput genomic study is to elucidate the associations between the\nset of candidate genes and disease phenotypes. The conventional gene set\nenrichment analysis often fails to reveal associations between disease\nphenotypes and the gene sets with a short list of poorly annotated genes,\nbecause the existing annotations of disease causative genes are incomplete. We\npropose a network-based computational approach called rcNet to discover the\nassociations between gene sets and disease phenotypes. Assuming coherent\nassociations between the genes ranked by their relevance to the query gene set,\nand the disease phenotypes ranked by their relevance to the hidden target\ndisease phenotypes of the query gene set, we formulate a learning framework\nmaximizing the rank coherence with respect to the known disease phenotype-gene\nassociations. An efficient algorithm coupling ridge regression with label\npropagation, and two variants are introduced to find the optimal solution of\nthe framework. We evaluated the rcNet algorithms and existing baseline methods\nwith both leave-one-out cross-validation and a task of predicting recently\ndiscovered disease-gene associations in OMIM. The experiments demonstrated that\nthe rcNet algorithms achieved the best overall rankings compared to the\nbaselines. To further validate the reproducibility of the performance, we\napplied the algorithms to identify the target diseases of novel candidate\ndisease genes obtained from recent studies of GWAS, DNA copy number variation\nanalysis, and gene expression profiling. The algorithms ranked the target\ndisease of the candidate genes at the top of the rank list in many cases across\nall the three case studies. The rcNet algorithms are available as a webtool for\ndisease and gene set association analysis at\nhttp://compbio.cs.umn.edu/dgsa_rcNet.\n",
          "  A number of representation schemes have been presented for use within\nlearning classifier systems, ranging from binary encodings to neural networks.\nThis paper presents results from an investigation into using discrete and fuzzy\ndynamical system representations within the XCSF learning classifier system. In\nparticular, asynchronous random Boolean networks are used to represent the\ntraditional condition-action production system rules in the discrete case and\nasynchronous fuzzy logic networks in the continuous-valued case. It is shown\npossible to use self-adaptive, open-ended evolution to design an ensemble of\nsuch dynamical systems within XCSF to solve a number of well-known test\nproblems.\n",
          "  (ABRIDGED) In previous work, two platforms have been developed for testing\ncomputer-vision algorithms for robotic planetary exploration (McGuire et al.\n2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been\ntested at geological and astrobiological field sites in Spain (Rivas\nVaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a\ngeological field site in Malta. In this work, we (i) apply a Hopfield\nneural-network algorithm for novelty detection based upon color, (ii) integrate\na field-capable digital microscope on the wearable computer platform, (iii)\ntest this novelty detection with the digital microscope at Rivas Vaciamadrid,\n(iv) develop a Bluetooth communication mode for the phone-camera platform, in\norder to allow access to a mobile processing computer at the field sites, and\n(v) test the novelty detection on the Bluetooth-enabled phone-camera connected\nto a netbook computer at the Mars Desert Research Station in Utah. This systems\nengineering and field testing have together allowed us to develop a real-time\ncomputer-vision system that is capable, for example, of identifying lichens as\nnovel within a series of images acquired in semi-arid desert environments. We\nacquired sequences of images of geologic outcrops in Utah and Spain consisting\nof various rock types and colors to test this algorithm. The algorithm robustly\nrecognized previously-observed units by their color, while requiring only a\nsingle image or a few images to learn colors as familiar, demonstrating its\nfast learning capability.\n",
          "  Standard hybrid learners that use domain knowledge require stronger knowledge\nthat is hard and expensive to acquire. However, weaker domain knowledge can\nbenefit from prior knowledge while being cost effective. Weak knowledge in the\nform of feature relative importance (FRI) is presented and explained. Feature\nrelative importance is a real valued approximation of a feature's importance\nprovided by experts. Advantage of using this knowledge is demonstrated by IANN,\na modified multilayer neural network algorithm. IANN is a very simple\nmodification of standard neural network algorithm but attains significant\nperformance gains. Experimental results in the field of molecular biology show\nhigher performance over other empirical learning algorithms including standard\nbackpropagation and support vector machines. IANN performance is even\ncomparable to a theory refinement system KBANN that uses stronger domain\nknowledge. This shows Feature relative importance can improve performance of\nexisting empirical learning algorithms significantly with minimal effort.\n",
          "  The Ripper algorithm is designed to generate rule sets for large datasets\nwith many features. However, it was shown that the algorithm struggles with\nclassification performance in the presence of missing data. The algorithm\nstruggles to classify instances when the quality of the data deteriorates as a\nresult of increasing missing data. In this paper, a feature selection technique\nis used to help improve the classification performance of the Ripper model.\nPrincipal component analysis and evidence automatic relevance determination\ntechniques are used to improve the performance. A comparison is done to see\nwhich technique helps the algorithm improve the most. Training datasets with\ncompletely observable data were used to construct the model and testing\ndatasets with missing values were used for measuring accuracy. The results\nshowed that principal component analysis is a better feature selection for the\nRipper in improving the classification performance.\n",
          "  Many regression problems involve not one but several response variables\n(y's). Often the responses are suspected to share a common underlying\nstructure, in which case it may be advantageous to share information across\nthem; this is known as multitask learning. As a special case, we can use\nmultiple responses to better identify shared predictive features -- a project\nwe might call multitask feature selection.\n  This thesis is organized as follows. Section 1 introduces feature selection\nfor regression, focusing on ell_0 regularization methods and their\ninterpretation within a Minimum Description Length (MDL) framework. Section 2\nproposes a novel extension of MDL feature selection to the multitask setting.\nThe approach, called the \"Multiple Inclusion Criterion\" (MIC), is designed to\nborrow information across regression tasks by more easily selecting features\nthat are associated with multiple responses. We show in experiments on\nsynthetic and real biological data sets that MIC can reduce prediction error in\nsettings where features are at least partially shared across responses. Section\n3 surveys hypothesis testing by regression with a single response, focusing on\nthe parallel between the standard Bonferroni correction and an MDL approach.\nMirroring the ideas in Section 2, Section 4 proposes a novel MIC approach to\nhypothesis testing with multiple responses and shows that on synthetic data\nwith significant sharing of features across responses, MIC sometimes\noutperforms standard FDR-controlling methods in terms of finding true positives\nfor a given level of false positives. Section 5 concludes.\n",
          "  The main principle of stacked generalization (or Stacking) is using a\nsecond-level generalizer to combine the outputs of base classifiers in an\nensemble. In this paper, we investigate different combination types under the\nstacking framework; namely weighted sum (WS), class-dependent weighted sum\n(CWS) and linear stacked generalization (LSG). For learning the weights, we\npropose using regularized empirical risk minimization with the hinge loss. In\naddition, we propose using group sparsity for regularization to facilitate\nclassifier selection. We performed experiments using two different ensemble\nsetups with differing diversities on 8 real-world datasets. Results show the\npower of regularized learning with the hinge loss function. Using sparse\nregularization, we are able to reduce the number of selected classifiers of the\ndiverse ensemble without sacrificing accuracy. With the non-diverse ensembles,\nwe even gain accuracy on average by using sparse regularization.\n",
          "  In this paper I present an extended implementation of the Random ferns\nalgorithm contained in the R package rFerns. It differs from the original by\nthe ability of consuming categorical and numerical attributes instead of only\nbinary ones. Also, instead of using simple attribute subspace ensemble it\nemploys bagging and thus produce error approximation and variable importance\nmeasure modelled after Random forest algorithm. I also present benchmarks'\nresults which show that although Random ferns' accuracy is mostly smaller than\nachieved by Random forest, its speed and good quality of importance measure it\nprovides make rFerns a reasonable choice for a specific applications.\n",
          "  We study the prevalent problem when a test distribution differs from the\ntraining distribution. We consider a setting where our training set consists of\na small number of sample domains, but where we have many samples in each\ndomain. Our goal is to generalize to a new domain. For example, we may want to\nlearn a similarity function using only certain classes of objects, but we\ndesire that this similarity function be applicable to object classes not\npresent in our training sample (e.g. we might seek to learn that \"dogs are\nsimilar to dogs\" even though images of dogs were absent from our training set).\nOur theoretical analysis shows that we can select many more features than\ndomains while avoiding overfitting by utilizing data-dependent variance\nproperties. We present a greedy feature selection algorithm based on using\nT-statistics. Our experiments validate this theory showing that our T-statistic\nbased greedy feature selection is more robust at avoiding overfitting than the\nclassical greedy procedure.\n",
          "  Bayesian model averaging (BMA) is an approach to average over alternative\nmodels; yet, it usually gets excessively concentrated around the single most\nprobable model, therefore achieving only sub-optimal classification\nperformance. The compression-based approach (Boulle, 2007) overcomes this\nproblem, averaging over the different models by applying a logarithmic\nsmoothing over the models' posterior probabilities. This approach has shown\nexcellent performances when applied to ensembles of naive Bayes classifiers.\nAODE is another ensemble of models with high performance (Webb, 2005), based on\na collection of non-naive classifiers (called SPODE) whose probabilistic\npredictions are aggregated by simple arithmetic mean. Aggregating the SPODEs\nvia BMA rather than by arithmetic mean deteriorates the performance; instead,\nwe aggregate the SPODEs via the compression coefficients and we show that the\nresulting classifier obtains a slight but consistent improvement over AODE.\nHowever, an important issue in any Bayesian ensemble of models is the\narbitrariness in the choice of the prior over the models. We address this\nproblem by the paradigm of credal classification, namely by substituting the\nunique prior with a set of priors. Credal classifier automatically recognize\nthe prior-dependent instances, namely the instances whose most probable class\nvaries, when different priors are considered; in these cases, credal\nclassifiers remain reliable by returning a set of classes rather than a single\nclass. We thus develop the credal version of both the BMA-based and the\ncompression-based ensemble of SPODEs, substituting the single prior over the\nmodels by a set of priors. Experiments show that both credal classifiers\nprovide higher classification reliability than their determinate counterparts;\nmoreover the compression-based credal classifier compares favorably to previous\ncredal classifiers.\n",
          "  The problem of classifying sonar signals from rocks and mines first studied\nby Gorman and Sejnowski has become a benchmark against which many learning\nalgorithms have been tested. We show that both the training set and the test\nset of this benchmark are linearly separable, although with different\nhyperplanes. Moreover, the complete set of learning and test patterns together,\nis also linearly separable. We give the weights that separate these sets, which\nmay be used to compare results found by other algorithms.\n",
          "  In this paper, an Entropy functional based online Adaptive Decision Fusion\n(EADF) framework is developed for image analysis and computer vision\napplications. In this framework, it is assumed that the compound algorithm\nconsists of several sub-algorithms each of which yielding its own decision as a\nreal number centered around zero, representing the confidence level of that\nparticular sub-algorithm. Decision values are linearly combined with weights\nwhich are updated online according to an active fusion method based on\nperforming entropic projections onto convex sets describing sub-algorithms. It\nis assumed that there is an oracle, who is usually a human operator, providing\nfeedback to the decision fusion method. A video based wildfire detection system\nis developed to evaluate the performance of the algorithm in handling the\nproblems where data arrives sequentially. In this case, the oracle is the\nsecurity guard of the forest lookout tower verifying the decision of the\ncombined algorithm. Simulation results are presented. The EADF framework is\nalso tested with a standard dataset.\n",
          "  Feature selection is an important pre-processing step for many pattern\nclassification tasks. Traditionally, feature selection methods are designed to\nobtain a feature subset that can lead to high classification accuracy. However,\nclassification accuracy has recently been shown to be an inappropriate\nperformance metric of classification systems in many cases. Instead, the Area\nUnder the receiver operating characteristic Curve (AUC) and its multi-class\nextension, MAUC, have been proved to be better alternatives. Hence, the target\nof classification system design is gradually shifting from seeking a system\nwith the maximum classification accuracy to obtaining a system with the maximum\nAUC/MAUC. Previous investigations have shown that traditional feature selection\nmethods need to be modified to cope with this new objective. These methods most\noften are restricted to binary classification problems only. In this study, a\nfilter feature selection method, namely MAUC Decomposition based Feature\nSelection (MDFS), is proposed for multi-class classification problems. To the\nbest of our knowledge, MDFS is the first method specifically designed to select\nfeatures for building classification systems with maximum MAUC. Extensive\nempirical results demonstrate the advantage of MDFS over several compared\nfeature selection methods.\n",
          "  Feature selection refers to the problem of selecting relevant features which\nproduce the most predictive outcome. In particular, feature selection task is\ninvolved in datasets containing huge number of features. Rough set theory has\nbeen one of the most successful methods used for feature selection. However,\nthis method is still not able to find optimal subsets. This paper proposes a\nnew feature selection method based on Rough set theory hybrid with Bee Colony\nOptimization (BCO) in an attempt to combat this. This proposed work is applied\nin the medical domain to find the minimal reducts and experimentally compared\nwith the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods\nsuch as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle\nSwarm Optimization (PSO).\n",
          "  This paper proposes an unsupervised learning technique by using Multi-layer\nMirroring Neural Network and Forgy's clustering algorithm. Multi-layer\nMirroring Neural Network is a neural network that can be trained with\ngeneralized data inputs (different categories of image patterns) to perform\nnon-linear dimensionality reduction and the resultant low-dimensional code is\nused for unsupervised pattern classification using Forgy's algorithm. By\nadapting the non-linear activation function (modified sigmoidal function) and\ninitializing the weights and bias terms to small random values, mirroring of\nthe input pattern is initiated. In training, the weights and bias terms are\nchanged in such a way that the input presented is reproduced at the output by\nback propagating the error. The mirroring neural network is capable of reducing\nthe input vector to a great degree (approximately 1/30th the original size) and\nalso able to reconstruct the input pattern at the output layer from this\nreduced code units. The feature set (output of central hidden layer) extracted\nfrom this network is fed to Forgy's algorithm, which classify input data\npatterns into distinguishable classes. In the implementation of Forgy's\nalgorithm, initial seed points are selected in such a way that they are distant\nenough to be perfectly grouped into different categories. Thus a new method of\nunsupervised learning is formulated and demonstrated in this paper. This method\ngave impressive results when applied to classification of different image\npatterns.\n",
          "  Unsupervised aggregation of independently built univariate predictors is\nexplored as an alternative regularization approach for noisy, sparse datasets.\nBipartite ranking algorithm Smooth Rank implementing this approach is\nintroduced. The advantages of this algorithm are demonstrated on two types of\nproblems. First, Smooth Rank is applied to two-class problems from bio-medical\nfield, where ranking is often preferable to classification. In comparison\nagainst SVMs with radial and linear kernels, Smooth Rank had the best\nperformance on 8 out of 12 benchmark benchmarks. The second area of application\nis survival analysis, which is reduced here to bipartite ranking in a way which\nallows one to use commonly accepted measures of methods performance. In\ncomparison of Smooth Rank with Cox PH regression and CoxPath methods, Smooth\nRank proved to be the best on 9 out of 10 benchmark datasets.\n",
          "  We introduce a simple and computationally trivial method for binary\nclassification based on the evaluation of potential functions. We demonstrate\nthat despite the conceptual and computational simplicity of the method its\nperformance can match or exceed that of standard Support Vector Machine\nmethods.\n",
          "  We propose a novel classification technique whose aim is to select an\nappropriate representation for each datapoint, in contrast to the usual\napproach of selecting a representation encompassing the whole dataset. This\ndatum-wise representation is found by using a sparsity inducing empirical risk,\nwhich is a relaxation of the standard L 0 regularized risk. The classification\nproblem is modeled as a sequential decision process that sequentially chooses,\nfor each datapoint, which features to use before classifying. Datum-Wise\nClassification extends naturally to multi-class tasks, and we describe a\nspecific case where our inference has equivalent complexity to a traditional\nlinear classifier, while still using a variable number of features. We compare\nour classifier to classical L 1 regularized linear models (L 1-SVM and LARS) on\na set of common binary and multi-class datasets and show that for an equal\naverage number of features used we can get improved performance using our\nmethod.\n",
          "  This article focuses on signal classification for deep-sea acoustic neutrino\ndetection. In the deep sea, the background of transient signals is very\ndiverse. Approaches like matched filtering are not sufficient to distinguish\nbetween neutrino-like signals and other transient signals with similar\nsignature, which are forming the acoustic background for neutrino detection in\nthe deep-sea environment. A classification system based on machine learning\nalgorithms is analysed with the goal to find a robust and effective way to\nperform this task. For a well-trained model, a testing error on the level of\none percent is achieved for strong classifiers like Random Forest and Boosting\nTrees using the extracted features of the signal as input and utilising dense\nclusters of sensors instead of single sensors.\n",
          "  This correspondence studies the basic problem of classifications - how to\nevaluate different classifiers. Although the conventional performance indexes,\nsuch as accuracy, are commonly used in classifier selection or evaluation,\ninformation-based criteria, such as mutual information, are becoming popular in\nfeature/model selections. In this work, we propose to assess classifiers in\nterms of normalized mutual information (NI), which is novel and well defined in\na compact range for classifier evaluation. We derive close-form relations of\nnormalized mutual information with respect to accuracy, precision, and recall\nin binary classifications. By exploring the relations among them, we reveal\nthat NI is actually a set of nonlinear functions, with a concordant\npower-exponent form, to each performance index. The relations can also be\nexpressed with respect to precision and recall, or to false alarm and hitting\nrate (recall).\n",
          "  Data from spectrophotometers form vectors of a large number of exploitable\nvariables. Building quantitative models using these variables most often\nrequires using a smaller set of variables than the initial one. Indeed, a too\nlarge number of input variables to a model results in a too large number of\nparameters, leading to overfitting and poor generalization abilities. In this\npaper, we suggest the use of the mutual information measure to select variables\nfrom the initial set. The mutual information measures the information content\nin input variables with respect to the model output, without making any\nassumption on the model that will be used; it is thus suitable for nonlinear\nmodelling. In addition, it leads to the selection of variables among the\ninitial set, and not to linear or nonlinear combinations of them. Without\ndecreasing the model performances compared to other variable projection\nmethods, it allows therefore a greater interpretability of the results.\n",
          "  Feature selection is an indispensable preprocessing step when mining huge\ndatasets that can significantly improve the overall system performance.\nTherefore in this paper we focus on a hybrid approach of feature selection.\nThis method falls into two phases. The filter phase select the features with\nhighest information gain and guides the initialization of search process for\nwrapper phase whose output the final feature subset. The final feature subsets\nare passed through the Knearest neighbor classifier for classification of\nattacks. The effectiveness of this algorithm is demonstrated on DARPA KDDCUP99\ncyber attack dataset.\n",
          "  The main purpose of Feature Subset Selection is to find a reduced subset of\nattributes from a data set described by a feature set. The task of a feature\nselection algorithm (FSA) is to provide with a computational solution motivated\nby a certain definition of relevance or by a reliable evaluation measure. In\nthis paper several fundamental algorithms are studied to assess their\nperformance in a controlled experimental scenario. A measure to evaluate FSAs\nis devised that computes the degree of matching between the output given by a\nFSA and the known optimal solutions. An extensive experimental study on\nsynthetic problems is carried out to assess the behaviour of the algorithms in\nterms of solution accuracy and size as a function of the relevance,\nirrelevance, redundancy and size of the data samples. The controlled\nexperimental conditions facilitate the derivation of better-supported and\nmeaningful conclusions.\n",
          "  In this paper we propose a new algorithm for learning polyhedral classifiers\nwhich we call as Polyceptron. It is a Perception like algorithm which updates\nthe parameters only when the current classifier misclassifies any training\ndata. We give both batch and online version of Polyceptron algorithm. Finally\nwe give experimental results to show the effectiveness of our approach.\n",
          "  Ensemble classification is an emerging approach to land cover mapping whereby\nthe final classification output is a result of a consensus of classifiers.\nIntuitively, an ensemble system should consist of base classifiers which are\ndiverse i.e. classifiers whose decision boundaries err differently. In this\npaper ensemble feature selection is used to impose diversity in ensembles. The\nfeatures of the constituent base classifiers for each ensemble were created\nthrough an exhaustive search algorithm using different separability indices.\nFor each ensemble, the classification accuracy was derived as well as a\ndiversity measure purported to give a measure of the inensemble diversity. The\ncorrelation between ensemble classification accuracy and diversity measure was\ndetermined to establish the interplay between the two variables. From the\nfindings of this paper, diversity measures as currently formulated do not\nprovide an adequate means upon which to constitute ensembles for land cover\nmapping.\n",
          "  This paper presents a new hybrid learning algorithm for unsupervised\nclassification tasks. We combined Fuzzy c-means learning algorithm and a\nsupervised version of Minimerror to develop a hybrid incremental strategy\nallowing unsupervised classifications. We applied this new approach to a\nreal-world database in order to know if the information contained in unlabeled\nfeatures of a Geographic Information System (GIS), allows to well classify it.\nFinally, we compared our results to a classical supervised classification\nobtained by a multilayer perceptron.\n",
          "  We present three related ways of using Transfer Learning to improve feature\nselection. The three methods address different problems, and hence share\ndifferent kinds of information between tasks or feature classes, but all three\nare based on the information theoretic Minimum Description Length (MDL)\nprinciple and share the same underlying Bayesian interpretation. The first\nmethod, MIC, applies when predictive models are to be built simultaneously for\nmultiple tasks (``simultaneous transfer'') that share the same set of features.\nMIC allows each feature to be added to none, some, or all of the task models\nand is most beneficial for selecting a small set of predictive features from a\nlarge pool of features, as is common in genomic and biological datasets. Our\nsecond method, TPC (Three Part Coding), uses a similar methodology for the case\nwhen the features can be divided into feature classes. Our third method,\nTransfer-TPC, addresses the ``sequential transfer'' problem in which the task\nto which we want to transfer knowledge may not be known in advance and may have\ndifferent amounts of data than the other tasks. Transfer-TPC is most beneficial\nwhen we want to transfer knowledge between tasks which have unequal amounts of\nlabeled data, for example the data for disambiguating the senses of different\nverbs. We demonstrate the effectiveness of these approaches with experimental\nresults on real world data pertaining to genomics and to Word Sense\nDisambiguation (WSD).\n",
          "  The DNA microarray technology has modernized the approach of biology research\nin such a way that scientists can now measure the expression levels of\nthousands of genes simultaneously in a single experiment. Gene expression\nprofiles, which represent the state of a cell at a molecular level, have great\npotential as a medical diagnosis tool. But compared to the number of genes\ninvolved, available training data sets generally have a fairly small sample\nsize for classification. These training data limitations constitute a challenge\nto certain classification methodologies. Feature selection techniques can be\nused to extract the marker genes which influence the classification accuracy\neffectively by eliminating the un wanted noisy and redundant genes This paper\npresents a review of feature selection techniques that have been employed in\nmicro array data based cancer classification and also the predominant role of\nSVM for cancer classification.\n",
          "  Selecting the best classifier among the available ones is a difficult task,\nespecially when only instances of one class exist. In this work we examine the\nnotion of combining one-class classifiers as an alternative for selecting the\nbest classifier. In particular, we propose two new one-class classification\nperformance measures to weigh classifiers and show that a simple ensemble that\nimplements these measures can outperform the most popular one-class ensembles.\nFurthermore, we propose a new one-class ensemble scheme, TUPSO, which uses\nmeta-learning to combine one-class classifiers. Our experiments demonstrate the\nsuperiority of TUPSO over all other tested ensembles and show that the TUPSO\nperformance is statistically indistinguishable from that of the hypothetical\nbest classifier.\n",
          "  In this paper, we study the application of GIST SVM in disease prediction\n(detection of cancer). Pattern classification problems can be effectively\nsolved by Support vector machines. Here we propose a classifier which can\ndifferentiate patients having benign and malignant cancer cells. To improve the\naccuracy of classification, we propose to determine the optimal size of the\ntraining set and perform feature selection. To find the optimal size of the\ntraining set, different sizes of training sets are experimented and the one\nwith highest classification rate is selected. The optimal features are selected\nthrough their F-Scores.\n",
          "  In medical risk modeling, typical data are \"scarce\": they have relatively\nsmall number of training instances (N), censoring, and high dimensionality (M).\nWe show that the problem may be effectively simplified by reducing it to\nbipartite ranking, and introduce new bipartite ranking algorithm, Smooth Rank,\nfor robust learning on scarce data. The algorithm is based on ensemble learning\nwith unsupervised aggregation of predictors. The advantage of our approach is\nconfirmed in comparison with two \"gold standard\" risk modeling methods on 10\nreal life survival analysis datasets, where the new approach has the best\nresults on all but two datasets with the largest ratio N/M. For systematic\nstudy of the effects of data scarcity on modeling by all three methods, we\nconducted two types of computational experiments: on real life data with\nrandomly drawn training sets of different sizes, and on artificial data with\nincreasing number of features. Both experiments demonstrated that Smooth Rank\nhas critical advantage over the popular methods on the scarce data; it does not\nsuffer from overfitting where other methods do.\n",
          "  Bias - variance decomposition of the expected error defined for regression\nand classification problems is an important tool to study and compare different\nalgorithms, to find the best areas for their application. Here the\ndecomposition is introduced for the survival analysis problem. In our\nexperiments, we study bias -variance parts of the expected error for two\nalgorithms: original Cox proportional hazard regression and CoxPath, path\nalgorithm for L1-regularized Cox regression, on the series of increased\ntraining sets. The experiments demonstrate that, contrary expectations, CoxPath\ndoes not necessarily have an advantage over Cox regression.\n",
          "  Recently, several classifiers that combine primary tumor data, like gene\nexpression data, and secondary data sources, such as protein-protein\ninteraction networks, have been proposed for predicting outcome in breast\ncancer. In these approaches, new composite features are typically constructed\nby aggregating the expression levels of several genes. The secondary data\nsources are employed to guide this aggregation. Although many studies claim\nthat these approaches improve classification performance over single gene\nclassifiers, the gain in performance is difficult to assess. This stems mainly\nfrom the fact that different breast cancer data sets and validation procedures\nare employed to assess the performance. Here we address these issues by\nemploying a large cohort of six breast cancer data sets as benchmark set and by\nperforming an unbiased evaluation of the classification accuracies of the\ndifferent approaches. Contrary to previous claims, we find that composite\nfeature classifiers do not outperform simple single gene classifiers. We\ninvestigate the effect of (1) the number of selected features; (2) the specific\ngene set from which features are selected; (3) the size of the training set and\n(4) the heterogeneity of the data set on the performance of composite feature\nand single gene classifiers. Strikingly, we find that randomization of\nsecondary data sources, which destroys all biological information in these\nsources, does not result in a deterioration in performance of composite feature\nclassifiers. Finally, we show that when a proper correction for gene set size\nis performed, the stability of single gene sets is similar to the stability of\ncomposite feature sets. Based on these results there is currently no reason to\nprefer prognostic classifiers based on composite features over single gene\nclassifiers for predicting outcome in breast cancer.\n",
          "  Unsupervised classification algorithm based on clonal selection principle\nnamed Unsupervised Clonal Selection Classification (UCSC) is proposed in this\npaper. The new proposed algorithm is data driven and self-adaptive, it adjusts\nits parameters to the data to make the classification operation as fast as\npossible. The performance of UCSC is evaluated by comparing it with the well\nknown K-means algorithm using several artificial and real-life data sets. The\nexperiments show that the proposed UCSC algorithm is more reliable and has high\nclassification precision comparing to traditional classification methods such\nas K-means.\n",
          "  A number of representation schemes have been presented for use within\nLearning Classifier Systems, ranging from binary encodings to Neural Networks,\nand more recently Dynamical Genetic Programming (DGP). This paper presents\nresults from an investigation into using a fuzzy DGP representation within the\nXCSF Learning Classifier System. In particular, asynchronous Fuzzy Logic\nNetworks are used to represent the traditional condition-action production\nsystem rules. It is shown possible to use self-adaptive, open-ended evolution\nto design an ensemble of such fuzzy dynamical systems within XCSF to solve\nseveral well-known continuous-valued test problems.\n",
          "  Biogeography is the study of the geographical distribution of biological\norganisms. The mindset of the engineer is that we can learn from nature.\nBiogeography Based Optimization is a burgeoning nature inspired technique to\nfind the optimal solution of the problem. Satellite image classification is an\nimportant task because it is the only way we can know about the land cover map\nof inaccessible areas. Though satellite images have been classified in past by\nusing various techniques, the researchers are always finding alternative\nstrategies for satellite image classification so that they may be prepared to\nselect the most appropriate technique for the feature extraction task in hand.\nThis paper is focused on classification of the satellite image of a particular\nland cover using the theory of Biogeography based Optimization. The original\nBBO algorithm does not have the inbuilt property of clustering which is\nrequired during image classification. Hence modifications have been proposed to\nthe original algorithm and the modified algorithm is used to classify the\nsatellite image of a given region. The results indicate that highly accurate\nland cover features can be extracted effectively when the proposed algorithm is\nused.\n",
          "  Combining the mutual information criterion with a forward feature selection\nstrategy offers a good trade-off between optimality of the selected feature\nsubset and computation time. However, it requires to set the parameter(s) of\nthe mutual information estimator and to determine when to halt the forward\nprocedure. These two choices are difficult to make because, as the\ndimensionality of the subset increases, the estimation of the mutual\ninformation becomes less and less reliable. This paper proposes to use\nresampling methods, a K-fold cross-validation and the permutation test, to\naddress both issues. The resampling methods bring information about the\nvariance of the estimator, information which can then be used to automatically\nset the parameter and to calculate a threshold to stop the forward procedure.\nThe procedure is illustrated on a synthetic dataset as well as on real-world\nexamples.\n",
          "  The selection of the best classification algorithm for a given dataset is a\nvery widespread problem, occuring each time one has to choose a classifier to\nsolve a real-world problem. It is also a complex task with many important\nmethodological decisions to make. Among those, one of the most crucial is the\nchoice of an appropriate measure in order to properly assess the classification\nperformance and rank the algorithms. In this article, we focus on this specific\ntask. We present the most popular measures and compare their behavior through\ndiscrimination plots. We then discuss their properties from a more theoretical\nperspective. It turns out several of them are equivalent for classifiers\ncomparison purposes. Futhermore. they can also lead to interpretation problems.\nAmong the numerous measures proposed over the years, it appears that the\nclassical overall success rate and marginal rates are the more suitable for\nclassifier comparison task.\n",
          "  We propose a tree regularization framework, which enables many tree models to\nperform feature selection efficiently. The key idea of the regularization\nframework is to penalize selecting a new feature for splitting when its gain\n(e.g. information gain) is similar to the features used in previous splits. The\nregularization framework is applied on random forest and boosted trees here,\nand can be easily applied to other tree models. Experimental studies show that\nthe regularized trees can select high-quality feature subsets with regard to\nboth strong and weak classifiers. Because tree models can naturally deal with\ncategorical and numerical variables, missing values, different scales between\nvariables, interactions and nonlinearities etc., the tree regularization\nframework provides an effective and efficient feature selection solution for\nmany practical problems.\n",
          "  The selection of features that are relevant for a prediction or\nclassification problem is an important problem in many domains involving\nhigh-dimensional data. Selecting features helps fighting the curse of\ndimensionality, improving the performances of prediction or classification\nmethods, and interpreting the application. In a nonlinear context, the mutual\ninformation is widely used as relevance criterion for features and sets of\nfeatures. Nevertheless, it suffers from at least three major limitations:\nmutual information estimators depend on smoothing parameters, there is no\ntheoretically justified stopping criterion in the feature selection greedy\nprocedure, and the estimation itself suffers from the curse of dimensionality.\nThis chapter shows how to deal with these problems. The two first ones are\naddressed by using resampling techniques that provide a statistical basis to\nselect the estimator parameters and to stop the search procedure. The third one\nis addressed by modifying the mutual information criterion into a measure of\nhow features are complementary (and not only informative) for the problem at\nhand.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_classifiers_classifier_classification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_classifiers_classifier_classification"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.7264906167984009,
          1.192167043685913,
          0.6421983242034912,
          0.38004133105278015,
          0.9267507195472717,
          1.130469560623169,
          0.7852079272270203,
          0.6830348372459412,
          0.916120171546936,
          0.8912381529808044,
          0.6363939046859741,
          1.1387478113174438,
          0.7491530776023865,
          0.9225882887840271,
          0.9514506459236145,
          0.6160244345664978,
          0.8396284580230713,
          5.5331244468688965,
          0.8451020121574402,
          0.11045272648334503,
          0.7108182907104492,
          0.9195615649223328,
          0.42400500178337097,
          5.556904315948486,
          0.936733067035675,
          5.550656318664551,
          0.5634376406669617,
          0.879227876663208,
          1.0341295003890991,
          1.284875750541687,
          1.074691653251648,
          0.13606047630310059,
          1.398293137550354,
          3.859058141708374,
          1.9262322187423706,
          0.7659048438072205,
          1.0980887413024902,
          1.1753276586532593,
          0.38378581404685974,
          1.1483486890792847,
          0.9635114669799805,
          1.137087345123291,
          1.7966810464859009,
          1.4540259838104248,
          1.4501811265945435,
          4.708190441131592,
          1.2798793315887451,
          2.553551197052002,
          0.7125064134597778,
          0.4564136862754822,
          1.2592803239822388,
          0.9277563095092773,
          0.8447914719581604,
          0.9225181937217712,
          1.1579127311706543,
          1.1397335529327393,
          0.9469522833824158,
          0.38026759028434753,
          5.550663471221924,
          0.6056671142578125,
          1.3402220010757446,
          1.0765297412872314,
          1.0466054677963257,
          1.3426086902618408,
          1.3515009880065918
         ],
         "y": [
          7.570555210113525,
          8.32032299041748,
          7.981372356414795,
          7.3851518630981445,
          7.961048126220703,
          7.876941680908203,
          7.64476203918457,
          7.4787373542785645,
          8.040959358215332,
          7.898865699768066,
          7.976513862609863,
          7.154770374298096,
          8.097543716430664,
          8.038567543029785,
          7.93264102935791,
          8.010064125061035,
          7.448225975036621,
          5.862556457519531,
          7.607616901397705,
          7.807262897491455,
          7.483092308044434,
          7.940890312194824,
          7.398367404937744,
          5.7672295570373535,
          7.780589580535889,
          5.785334587097168,
          8.209660530090332,
          7.3714375495910645,
          8.329534530639648,
          8.42752456665039,
          7.7465596199035645,
          7.827563762664795,
          8.28280258178711,
          6.171623229980469,
          8.39184856414795,
          7.819515228271484,
          8.275578498840332,
          8.026729583740234,
          7.390195369720459,
          7.849404811859131,
          8.06161880493164,
          8.156476020812988,
          8.312356948852539,
          8.240532875061035,
          8.269430160522461,
          10.0159273147583,
          8.104040145874023,
          8.79106330871582,
          7.645268440246582,
          7.301008701324463,
          8.402703285217285,
          7.987643241882324,
          7.620968818664551,
          8.025040626525879,
          7.84445858001709,
          7.893232822418213,
          7.822530746459961,
          7.417868614196777,
          5.773893356323242,
          7.949376583099365,
          8.268816947937012,
          7.732703685760498,
          8.255036354064941,
          8.310503005981445,
          7.790194511413574
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  We consider a combinatorial generalization of the classical multi-armed\nbandit problem that is defined as follows. There is a given bipartite graph of\n$M$ users and $N \\geq M$ resources. For each user-resource pair $(i,j)$, there\nis an associated state that evolves as an aperiodic irreducible finite-state\nMarkov chain with unknown parameters, with transitions occurring each time the\nparticular user $i$ is allocated resource $j$. The user $i$ receives a reward\nthat depends on the corresponding state each time it is allocated the resource\n$j$. The system objective is to learn the best matching of users to resources\nso that the long-term sum of the rewards received by all users is maximized.\nThis corresponds to minimizing regret, defined here as the gap between the\nexpected total reward that can be obtained by the best-possible static matching\nand the expected total reward that can be achieved by a given algorithm. We\npresent a polynomial-storage and polynomial-complexity-per-step\nmatching-learning algorithm for this problem. We show that this algorithm can\nachieve a regret that is uniformly arbitrarily close to logarithmic in time and\npolynomial in the number of users and resources. This formulation is broadly\napplicable to scheduling and switching problems in networks and significantly\nextends prior results in the area.\n",
          "  We develop a coherent framework for integrative simultaneous analysis of the\nexploration-exploitation and model order selection trade-offs. We improve over\nour preceding results on the same subject (Seldin et al., 2011) by combining\nPAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a\ncombination is also of independent interest for studies of multiple\nsimultaneously evolving martingales.\n",
          "  In this paper we initiate the study of optimization of bandit type problems\nin scenarios where the feedback of a play is not immediately known. This arises\nnaturally in allocation problems which have been studied extensively in the\nliterature, albeit in the absence of delays in the feedback. We study this\nproblem in the Bayesian setting. In presence of delays, no solution with\nprovable guarantees is known to exist with sub-exponential running time.\n  We show that bandit problems with delayed feedback that arise in allocation\nsettings can be forced to have significant structure, with a slight loss in\noptimality. This structure gives us the ability to reason about the\nrelationship of single arm policies to the entangled optimum policy, and\neventually leads to a O(1) approximation for a significantly general class of\npriors. The structural insights we develop are of key interest and carry over\nto the setting where the feedback of an action is available instantaneously,\nand we improve all previous results in this setting as well.\n",
          "  This paper addresses the problem of minimizing a convex, Lipschitz function\n$f$ over a convex, compact set $\\xset$ under a stochastic bandit feedback\nmodel. In this model, the algorithm is allowed to observe noisy realizations of\nthe function value $f(x)$ at any query point $x \\in \\xset$. The quantity of\ninterest is the regret of the algorithm, which is the sum of the function\nvalues at algorithm's query points minus the optimal function value. We\ndemonstrate a generalization of the ellipsoid algorithm that incurs\n$\\otil(\\poly(d)\\sqrt{T})$ regret. Since any algorithm has regret at least\n$\\Omega(\\sqrt{T})$ on this problem, our algorithm is optimal in terms of the\nscaling with $T$.\n",
          "  We address the online linear optimization problem with bandit feedback. Our\ncontribution is twofold. First, we provide an algorithm (based on exponential\nweights) with a regret of order $\\sqrt{d n \\log N}$ for any finite action set\nwith $N$ actions, under the assumption that the instantaneous loss is bounded\nby 1. This shaves off an extraneous $\\sqrt{d}$ factor compared to previous\nworks, and gives a regret bound of order $d \\sqrt{n \\log n}$ for any compact\nset of actions. Without further assumptions on the action set, this last bound\nis minimax optimal up to a logarithmic factor. Interestingly, our result also\nshows that the minimax regret for bandit linear optimization with expert advice\nin $d$ dimension is the same as for the basic $d$-armed bandit with expert\nadvice. Our second contribution is to show how to use the Mirror Descent\nalgorithm to obtain computationally efficient strategies with minimax optimal\nregret bounds in specific examples. More precisely we study two canonical\naction sets: the hypercube and the Euclidean ball. In the former case, we\nobtain the first computationally efficient algorithm with a $d \\sqrt{n}$\nregret, thus improving by a factor $\\sqrt{d \\log n}$ over the best known result\nfor a computationally efficient algorithm. In the latter case, our approach\ngives the first algorithm with a $\\sqrt{d n \\log n}$ regret, again shaving off\nan extraneous $\\sqrt{d}$ compared to previous works.\n",
          "  The on-line shortest path problem is considered under various models of\npartial monitoring. Given a weighted directed acyclic graph whose edge weights\ncan change in an arbitrary (adversarial) way, a decision maker has to choose in\neach round of a game a path between two distinguished vertices such that the\nloss of the chosen path (defined as the sum of the weights of its composing\nedges) be as small as possible. In a setting generalizing the multi-armed\nbandit problem, after choosing a path, the decision maker learns only the\nweights of those edges that belong to the chosen path. For this problem, an\nalgorithm is given whose average cumulative loss in n rounds exceeds that of\nthe best path, matched off-line to the entire sequence of the edge weights, by\na quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on\nthe number of edges of the graph. The algorithm can be implemented with linear\ncomplexity in the number of rounds n and in the number of edges. An extension\nto the so-called label efficient setting is also given, in which the decision\nmaker is informed about the weights of the edges corresponding to the chosen\npath at a total of m << n time instances. Another extension is shown where the\ndecision maker competes against a time-varying path, a generalization of the\nproblem of tracking the best expert. A version of the multi-armed bandit\nsetting for shortest path is also discussed where the decision maker learns\nonly the total weight of the chosen path but not the weights of the individual\nedges on the path. Applications to routing in packet switched networks along\nwith simulation results are also presented.\n",
          "  We introduce a rich class of graphical models for multi-armed bandit problems\nthat permit both the state or context space and the action space to be very\nlarge, yet succinctly specify the payoffs for any context-action pair. Our main\nresult is an algorithm for such models whose regret is bounded by the number of\nparameters and whose running time depends only on the treewidth of the graph\nsubstructure induced by the action space.\n",
          "  Contextual bandit learning is a reinforcement learning problem where the\nlearner repeatedly receives a set of features (context), takes an action and\nreceives a reward based on the action and context. We consider this problem\nunder a realizability assumption: there exists a function in a (known) function\nclass, always capable of predicting the expected reward, given the action and\ncontext. Under this assumption, we show three things. We present a new\nalgorithm---Regressor Elimination--- with a regret similar to the agnostic\nsetting (i.e. in the absence of realizability assumption). We prove a new lower\nbound showing no algorithm can achieve superior performance in the worst case\neven with the realizability assumption. However, we do show that for any set of\npolicies (mapping contexts to actions), there is a distribution over rewards\n(given context) such that our new algorithm has constant regret unlike the\nprevious approaches.\n",
          "  In a multi-armed bandit problem, an online algorithm chooses from a set of\nstrategies in a sequence of trials so as to maximize the total payoff of the\nchosen strategies. While the performance of bandit algorithms with a small\nfinite strategy set is quite well understood, bandit problems with large\nstrategy sets are still a topic of very active investigation, motivated by\npractical applications such as online auctions and web advertisement. The goal\nof such research is to identify broad and natural classes of strategy sets and\npayoff functions which enable the design of efficient solutions. In this work\nwe study a very general setting for the multi-armed bandit problem in which the\nstrategies form a metric space, and the payoff function satisfies a Lipschitz\ncondition with respect to the metric. We refer to this problem as the\n\"Lipschitz MAB problem\". We present a complete solution for the multi-armed\nproblem in this setting. That is, for every metric space (L,X) we define an\nisometry invariant which bounds from below the performance of Lipschitz MAB\nalgorithms for X, and we present an algorithm which comes arbitrarily close to\nmeeting this bound. Furthermore, our technique gives even better results for\nbenign payoff functions.\n",
          "  The personalization of treatment via bio-markers and other risk categories\nhas drawn increasing interest among clinical scientists. Personalized treatment\nstrategies can be learned using data from clinical trials, but such trials are\nvery costly to run. This paper explores the use of active learning techniques\nto design more efficient trials, addressing issues such as whom to recruit, at\nwhat point in the trial, and which treatment to assign, throughout the duration\nof the trial. We propose a minimax bandit model with two different optimization\ncriteria, and discuss the computational challenges and issues pertaining to\nthis approach. We evaluate our active learning policies using both simulated\ndata, and data modeled after a clinical trial for treating depressed\nindividuals, and contrast our methods with other plausible active learning\npolicies.\n",
          "  We study the regret of optimal strategies for online convex optimization\ngames. Using von Neumann's minimax theorem, we show that the optimal regret in\nthis adversarial setting is closely related to the behavior of the empirical\nminimization algorithm in a stochastic process setting: it is equal to the\nmaximum, over joint distributions of the adversary's action sequence, of the\ndifference between a sum of minimal expected losses and the minimal empirical\nloss. We show that the optimal regret has a natural geometric interpretation,\nsince it can be viewed as the gap in Jensen's inequality for a concave\nfunctional--the minimizer over the player's actions of expected loss--defined\non a set of probability distributions. We use this expression to obtain upper\nand lower bounds on the regret of an optimal strategy for a variety of online\nlearning problems. Our method provides upper bounds without the need to\nconstruct a learning algorithm; the lower bounds provide explicit optimal\nstrategies for the adversary.\n",
          "  We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal),\nwhose regret is, essentially, optimal both for adversarial rewards and for\nstochastic rewards. Specifically, SAO combines the square-root worst-case\nregret of Exp3 (Auer et al., SIAM J. on Computing 2002) and the\n(poly)logarithmic regret of UCB1 (Auer et al., Machine Learning 2002) for\nstochastic rewards. Adversarial rewards and stochastic rewards are the two main\nsettings in the literature on (non-Bayesian) multi-armed bandits. Prior work on\nmulti-armed bandits treats them separately, and does not attempt to jointly\noptimize for both. Our result falls into a general theme of achieving good\nworst-case performance while also taking advantage of \"nice\" problem instances,\nan important issue in the design of algorithms with partially known inputs.\n",
          "  We present an algorithm which attains O(\\sqrt{T}) internal (and thus\nexternal) regret for finite games with partial monitoring under the local\nobservability condition. Recently, this condition has been shown by (Bartok,\nPal, and Szepesvari, 2011) to imply the O(\\sqrt{T}) rate for partial monitoring\ngames against an i.i.d. opponent, and the authors conjectured that the same\nholds for non-stochastic adversaries. Our result is in the affirmative, and it\ncompletes the characterization of possible rates for finite partial-monitoring\ngames, an open question stated by (Cesa-Bianchi, Lugosi, and Stoltz, 2006). Our\nregret guarantees also hold for the more general model of partial monitoring\nwith random signals.\n",
          "  We address the problem of learning in an online, bandit setting where the\nlearner must repeatedly select among $K$ actions, but only receives partial\nfeedback based on its choices. We establish two new facts: First, using a new\nalgorithm called Exp4.P, we show that it is possible to compete with the best\nin a set of $N$ experts with probability $1-\\delta$ while incurring regret at\nmost $O(\\sqrt{KT\\ln(N/\\delta)})$ over $T$ time steps. The new algorithm is\ntested empirically in a large-scale, real-world dataset. Second, we give a new\nalgorithm called VE that competes with a possibly infinite set of policies of\nVC-dimension $d$ while incurring regret at most $O(\\sqrt{T(d\\ln(T) + \\ln\n(1/\\delta))})$ with probability $1-\\delta$. These guarantees improve on those\nof all previous algorithms, whether in a stochastic or adversarial environment,\nand bring us closer to providing supervised learning type guarantees for the\ncontextual bandit setting.\n",
          "  We study the problem of optimizing a graph-structured objective function\nunder \\emph{adversarial} uncertainty. This problem can be modeled as a\ntwo-persons zero-sum game between an Engineer and Nature. The Engineer controls\na subset of the variables (nodes in the graph), and tries to assign their\nvalues to maximize an objective function. Nature controls the complementary\nsubset of variables and tries to minimize the same objective. This setting\nencompasses estimation and optimization problems under model uncertainty, and\nstrategic problems with a graph structure. Von Neumann's minimax theorem\nguarantees the existence of a (minimax) pair of randomized strategies that\nprovide optimal robustness for each player against its adversary.\n  We prove several structural properties of this strategy pair in the case of\ngraph-structured payoff function. In particular, the randomized minimax\nstrategies (distributions over variable assignments) can be chosen in such a\nway to satisfy the Markov property with respect to the graph. This\nsignificantly reduces the problem dimensionality. Finally we introduce a\nmessage passing algorithm to solve this minimax problem. The algorithm\ngeneralizes max-product belief propagation to this new domain.\n",
          "  In the classic multi-armed bandits problem, the goal is to have a policy for\ndynamically operating arms that each yield stochastic rewards with unknown\nmeans. The key metric of interest is regret, defined as the gap between the\nexpected total reward accumulated by an omniscient player that knows the reward\nmeans for each arm, and the expected total reward accumulated by the given\npolicy. The policies presented in prior work have storage, computation and\nregret all growing linearly with the number of arms, which is not scalable when\nthe number of arms is large. We consider in this work a broad class of\nmulti-armed bandits with dependent arms that yield rewards as a linear\ncombination of a set of unknown parameters. For this general framework, we\npresent efficient policies that are shown to achieve regret that grows\nlogarithmically with time, and polynomially in the number of unknown parameters\n(even though the number of dependent arms may grow exponentially). Furthermore,\nthese policies only require storage that grows linearly in the number of\nunknown parameters. We show that this generalization is broadly applicable and\nuseful for many interesting tasks in networks that can be formulated as\ntractable combinatorial optimization problems with linear objective functions,\nsuch as maximum weight matching, shortest path, and minimum spanning tree\ncomputations.\n",
          "  In the Multi-Armed Bandit (MAB) problem, there is a given set of arms with\nunknown reward models. At each time, a player selects one arm to play, aiming\nto maximize the total expected reward over a horizon of length T. An approach\nbased on a Deterministic Sequencing of Exploration and Exploitation (DSEE) is\ndeveloped for constructing sequential arm selection policies. It is shown that\nfor all light-tailed reward distributions, DSEE achieves the optimal\nlogarithmic order of the regret, where regret is defined as the total expected\nreward loss against the ideal case with known reward models. For heavy-tailed\nreward distributions, DSEE achieves O(T^1/p) regret when the moments of the\nreward distributions exist up to the pth order for 1<p<=2 and O(T^1/(1+p/2))\nfor p>2. With the knowledge of an upperbound on a finite moment of the\nheavy-tailed reward distributions, DSEE offers the optimal logarithmic regret\norder. The proposed DSEE approach complements existing work on MAB by providing\ncorresponding results for general reward distributions. Furthermore, with a\nclearly defined tunable parameter-the cardinality of the exploration sequence,\nthe DSEE approach is easily extendable to variations of MAB, including MAB with\nvarious objectives, decentralized MAB with multiple players and incomplete\nreward observations under collisions, MAB with unknown Markov dynamics, and\ncombinatorial MAB with dependent arms that often arise in network optimization\nproblems such as the shortest path, the minimum spanning, and the dominating\nset problems under unknown random weights.\n",
          "  Approachability has become a standard tool in analyzing earning algorithms in\nthe adversarial online learning setup. We develop a variant of approachability\nfor games where there is ambiguity in the obtained reward that belongs to a\nset, rather than being a single vector. Using this variant we tackle the\nproblem of approachability in games with partial monitoring and develop simple\nand efficient algorithms (i.e., with constant per-step complexity) for this\nsetup. We finally consider external regret and internal regret in repeated\ngames with partial monitoring and derive regret-minimizing strategies based on\napproachability theory.\n",
          "  We consider the problem of sequential sampling from a finite number of\nindependent statistical populations to maximize the expected infinite horizon\naverage outcome per period, under a constraint that the expected average\nsampling cost does not exceed an upper bound. The outcome distributions are not\nknown. We construct a class of consistent adaptive policies, under which the\naverage outcome converges with probability 1 to the true value under complete\ninformation for all distributions with finite means. We also compare the rate\nof convergence for various policies in this class using simulation.\n",
          "  In this paper, we consider the problem of multi-armed bandits with a large,\npossibly infinite number of correlated arms. We assume that the arms have\nBernoulli distributed rewards, independent across time, where the probabilities\nof success are parametrized by known attribute vectors for each arm, as well as\nan unknown preference vector, each of dimension $n$. For this model, we seek an\nalgorithm with a total regret that is sub-linear in time and independent of the\nnumber of arms. We present such an algorithm, which we call the Two-Phase\nAlgorithm, and analyze its performance. We show upper bounds on the total\nregret which applies uniformly in time, for both the finite and infinite arm\ncases. The asymptotics of the finite arm bound show that for any $f \\in\n\\omega(\\log(T))$, the total regret can be made to be $O(n \\cdot f(T))$. In the\ninfinite arm case, the total regret is $O(\\sqrt{n^3 T})$.\n",
          "  Algorithm selection is typically based on models of algorithm performance,\nlearned during a separate offline training sequence, which can be prohibitively\nexpensive. In recent work, we adopted an online approach, in which a\nperformance model is iteratively updated and used to guide selection on a\nsequence of problem instances. The resulting exploration-exploitation trade-off\nwas represented as a bandit problem with expert advice, using an existing\nsolver for this game, but this required the setting of an arbitrary bound on\nalgorithm runtimes, thus invalidating the optimal regret of the solver. In this\npaper, we propose a simpler framework for representing algorithm selection as a\nbandit problem, with partial information, and an unknown bound on losses. We\nadapt an existing solver to this game, proving a bound on its expected regret,\nwhich holds also for the resulting algorithm selection technique. We present\npreliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT\nbenchmark.\n",
          "  We consider a generalization of stochastic bandits where the set of arms,\n$\\cX$, is allowed to be a generic measurable space and the mean-payoff function\nis \"locally Lipschitz\" with respect to a dissimilarity function that is known\nto the decision maker. Under this condition we construct an arm selection\npolicy, called HOO (hierarchical optimistic optimization), with improved regret\nbounds compared to previous results for a large class of problems. In\nparticular, our results imply that if $\\cX$ is the unit hypercube in a\nEuclidean space and the mean-payoff function has a finite number of global\nmaxima around which the behavior of the function is locally continuous with a\nknown smoothness degree, then the expected regret of HOO is bounded up to a\nlogarithmic factor by $\\sqrt{n}$, i.e., the rate of growth of the regret is\nindependent of the dimension of the space. We also prove the minimax optimality\nof our algorithm when the dissimilarity is a metric. Our basic strategy has\nquadratic computational complexity as a function of the number of time steps\nand does not rely on the doubling trick. We also introduce a modified strategy,\nwhich relies on the doubling trick but runs in linearithmic time. Both results\nare improvements with respect to previous approaches.\n",
          "  We provide a formal, simple and intuitive theory of rational decision making\nincluding sequential decisions that affect the environment. The theory has a\ngeometric flavor, which makes the arguments easy to visualize and understand.\nOur theory is for complete decision makers, which means that they have a\ncomplete set of preferences. Our main result shows that a complete rational\ndecision maker implicitly has a probabilistic model of the environment. We have\na countable version of this result that brings light on the issue of countable\nvs finite additivity by showing how it depends on the geometry of the space\nwhich we have preferences over. This is achieved through fruitfully connecting\nrationality with the Hahn-Banach Theorem. The theory presented here can be\nviewed as a formalization and extension of the betting odds approach to\nprobability of Ramsey and De Finetti.\n",
          "  We consider the problem of dynamic pricing with limited supply. A seller has\n$k$ identical items for sale and is facing $n$ potential buyers (\"agents\") that\nare arriving sequentially. Each agent is interested in buying one item. Each\nagent's value for an item is an IID sample from some fixed distribution with\nsupport $[0,1]$. The seller offers a take-it-or-leave-it price to each arriving\nagent (possibly different for different agents), and aims to maximize his\nexpected revenue.\n  We focus on \"prior-independent\" mechanisms -- ones that do not use any\ninformation about the distribution. They are desirable because knowing the\ndistribution is unrealistic in many practical scenarios. We study how the\nrevenue of such mechanisms compares to the revenue of the optimal offline\nmechanism that knows the distribution (\"offline benchmark\").\n  We present a prior-independent dynamic pricing mechanism whose revenue is at\nmost $O((k \\log n)^{2/3})$ less than the offline benchmark, for every\ndistribution that is regular. In fact, this guarantee holds without *any*\nassumptions if the benchmark is relaxed to fixed-price mechanisms. Further, we\nprove a matching lower bound. The performance guarantee for the same mechanism\ncan be improved to $O(\\sqrt{k} \\log n)$, with a distribution-dependent\nconstant, if $k/n$ is sufficiently small. We show that, in the worst case over\nall demand distributions, this is essentially the best rate that can be\nobtained with a distribution-specific constant.\n  On a technical level, we exploit the connection to multi-armed bandits (MAB).\nWhile dynamic pricing with unlimited supply can easily be seen as an MAB\nproblem, the intuition behind MAB approaches breaks when applied to the setting\nwith limited supply. Our high-level conceptual contribution is that even the\nlimited supply setting can be fruitfully treated as a bandit problem.\n",
          "  We consider a bandit problem over a graph where the rewards are not directly\nobserved. Instead, the decision maker can compare two nodes and receive\n(stochastic) information pertaining to the difference in their value. The graph\nstructure describes the set of possible comparisons. Consequently, comparing\nbetween two nodes that are relatively far requires estimating the difference\nbetween every pair of nodes on the path between them. We analyze this problem\nfrom the perspective of sample complexity: How many queries are needed to find\nan approximately optimal node with probability more than $1-\\delta$ in the PAC\nsetup? We show that the topology of the graph plays a crucial in defining the\nsample complexity: graphs with a low diameter have a much better sample\ncomplexity.\n",
          "  We consider packing LP's with $m$ rows where all constraint coefficients are\nnormalized to be in the unit interval. The n columns arrive in random order and\nthe goal is to set the corresponding decision variables irrevocably when they\narrive so as to obtain a feasible solution maximizing the expected reward.\nPrevious (1 - \\epsilon)-competitive algorithms require the right-hand side of\nthe LP to be Omega((m/\\epsilon^2) log (n/\\epsilon)), a bound that worsens with\nthe number of columns and rows. However, the dependence on the number of\ncolumns is not required in the single-row case and known lower bounds for the\ngeneral case are also independent of n.\n  Our goal is to understand whether the dependence on n is required in the\nmulti-row case, making it fundamentally harder than the single-row version. We\nrefute this by exhibiting an algorithm which is (1 - \\epsilon)-competitive as\nlong as the right-hand sides are Omega((m^2/\\epsilon^2) log (m/\\epsilon)). Our\ntechniques refine previous PAC-learning based approaches which interpret the\nonline decisions as linear classifications of the columns based on sampled dual\nprices. The key ingredient of our improvement comes from a non-standard\ncovering argument together with the realization that only when the columns of\nthe LP belong to few 1-d subspaces we can obtain small such covers; bounding\nthe size of the cover constructed also relies on the geometry of linear\nclassifiers. General packing LP's are handled by perturbing the input columns,\nwhich can be seen as making the learning problem more robust.\n",
          "  In citep{Hazan-2008-extract}, the authors showed that the regret of online\nlinear optimization can be bounded by the total variation of the cost vectors.\nIn this paper, we extend this result to general online convex optimization. We\nfirst analyze the limitations of the algorithm in \\citep{Hazan-2008-extract}\nwhen applied it to online convex optimization. We then present two algorithms\nfor online convex optimization whose regrets are bounded by the variation of\ncost functions. We finally consider the bandit setting, and present a\nrandomized algorithm for online bandit convex optimization with a\nvariation-based regret bound. We show that the regret bound for online bandit\nconvex optimization is optimal when the variation of cost functions is\nindependent of the number of trials.\n",
          "  We consider online learning in partial-monitoring games against an oblivious\nadversary. We show that when the number of actions available to the learner is\ntwo and the game is nontrivial then it is reducible to a bandit-like game and\nthus the minimax regret is $\\Theta(\\sqrt{T})$.\n",
          "  In budget-limited multi-armed bandit (MAB) problems, the learner's actions\nare costly and constrained by a fixed budget. Consequently, an optimal\nexploitation policy may not be to pull the optimal arm repeatedly, as is the\ncase in other variants of MAB, but rather to pull the sequence of different\narms that maximises the agent's total reward within the budget. This difference\nfrom existing MABs means that new approaches to maximising the total reward are\nrequired. Given this, we develop two pulling policies, namely: (i) KUBE; and\n(ii) fractional KUBE. Whereas the former provides better performance up to 40%\nin our experimental settings, the latter is computationally less expensive. We\nalso prove logarithmic upper bounds for the regret of both policies, and show\nthat these bounds are asymptotically optimal (i.e. they only differ from the\nbest possible regret by a constant factor).\n",
          "  We consider an adversarial online learning setting where a decision maker can\nchoose an action in every stage of the game. In addition to observing the\nreward of the chosen action, the decision maker gets side observations on the\nreward he would have obtained had he chosen some of the other actions. The\nobservation structure is encoded as a graph, where node i is linked to node j\nif sampling i provides information on the reward of j. This setting naturally\ninterpolates between the well-known \"experts\" setting, where the decision maker\ncan view all rewards, and the multi-armed bandits setting, where the decision\nmaker can only view the reward of the chosen action. We develop practical\nalgorithms with provable regret guarantees, which depend on non-trivial\ngraph-theoretic properties of the information feedback structure. We also\nprovide partially-matching lower bounds.\n",
          "  We consider a multi-armed bandit problem in a setting where each arm produces\na noisy reward realization which depends on an observable random covariate. As\nopposed to the traditional static multi-armed bandit problem, this setting\nallows for dynamically changing rewards that better describe applications where\nside information is available. We adopt a nonparametric model where the\nexpected rewards are smooth functions of the covariate and where the hardness\nof the problem is captured by a margin parameter. To maximize the expected\ncumulative reward, we introduce a policy called Adaptively Binned Successive\nElimination (abse) that adaptively decomposes the global problem into suitably\n\"localized\" static bandit problems. This policy constructs an adaptive\npartition using a variant of the Successive Elimination (se) policy. Our\nresults include sharper regret bounds for the se policy in a static bandit\nproblem and minimax optimal regret bounds for the abse policy in the dynamic\nproblem.\n",
          "  We develop a new tool for data-dependent analysis of the\nexploration-exploitation trade-off in learning under limited feedback. Our tool\nis based on two main ingredients. The first ingredient is a new concentration\ninequality that makes it possible to control the concentration of weighted\naverages of multiple (possibly uncountably many) simultaneously evolving and\ninterdependent martingales. The second ingredient is an application of this\ninequality to the exploration-exploitation trade-off via importance weighted\nsampling. We apply the new tool to the stochastic multiarmed bandit problem,\nhowever, the main importance of this paper is the development and understanding\nof the new tool rather than improvement of existing algorithms for stochastic\nmultiarmed bandits. In the follow-up work we demonstrate that the new tool can\nimprove over state-of-the-art in structurally richer problems, such as\nstochastic multiarmed bandits with side information (Seldin et al., 2011a).\n",
          "  We consider the framework of stochastic multi-armed bandit problems and study\nthe possibilities and limitations of forecasters that perform an on-line\nexploration of the arms. These forecasters are assessed in terms of their\nsimple regret, a regret notion that captures the fact that exploration is only\nconstrained by the number of available rounds (not necessarily known in\nadvance), in contrast to the case when the cumulative regret is considered and\nwhen exploitation needs to be performed at the same time. We believe that this\nperformance criterion is suited to situations when the cost of pulling an arm\nis expressed in terms of resources rather than rewards. We discuss the links\nbetween the simple and the cumulative regret. One of the main results in the\ncase of a finite number of arms is a general lower bound on the simple regret\nof a forecaster in terms of its cumulative regret: the smaller the latter, the\nlarger the former. Keeping this result in mind, we then exhibit upper bounds on\nthe simple regret of some forecasters. The paper ends with a study devoted to\ncontinuous-armed bandit problems; we show that the simple regret can be\nminimized with respect to a family of probability distributions if and only if\nthe cumulative regret can be minimized for it. Based on this equivalence, we\nare able to prove that the separable metric spaces are exactly the metric\nspaces on which these regrets can be minimized with respect to the family of\nall probability distributions with continuous mean-payoff functions.\n",
          "  Reinforcement learning addresses the dilemma between exploration to find\nprofitable actions and exploitation to act according to the best observations\nalready made. Bandit problems are one such class of problems in stateless\nenvironments that represent this explore/exploit situation. We propose a\nlearning algorithm for bandit problems based on fractional expectation of\nrewards acquired. The algorithm is theoretically shown to converge on an\neta-optimal arm and achieve O(n) sample complexity. Experimental results show\nthe algorithm incurs substantially lower regrets than parameter-optimized\neta-greedy and SoftMax approaches and other low sample complexity\nstate-of-the-art techniques.\n",
          "  We present two alternative ways to apply PAC-Bayesian analysis to sequences\nof dependent random variables. The first is based on a new lemma that enables\nto bound expectations of convex functions of certain dependent random variables\nby expectations of the same functions of independent Bernoulli random\nvariables. This lemma provides an alternative tool to Hoeffding-Azuma\ninequality to bound concentration of martingale values. Our second approach is\nbased on integration of Hoeffding-Azuma inequality with PAC-Bayesian analysis.\nWe also introduce a way to apply PAC-Bayesian analysis in situation of limited\nfeedback. We combine the new tools to derive PAC-Bayesian generalization and\nregret bounds for the multiarmed bandit problem. Although our regret bound is\nnot yet as tight as state-of-the-art regret bounds based on other\nwell-established techniques, our results significantly expand the range of\npotential applications of PAC-Bayesian analysis and introduce a new analysis\ntool to reinforcement learning and many other fields, where martingales and\nlimited feedback are encountered.\n",
          "  The Lipschitz multi-armed bandit (MAB) problem generalizes the classical\nmulti-armed bandit problem by assuming one is given side information consisting\nof a priori upper bounds on the difference in expected payoff between certain\npairs of strategies. Classical results of (Lai and Robbins 1985) and (Auer et\nal. 2002) imply a logarithmic regret bound for the Lipschitz MAB problem on\nfinite metric spaces. Recent results on continuum-armed bandit problems and\ntheir generalizations imply lower bounds of $\\sqrt{t}$, or stronger, for many\ninfinite metric spaces such as the unit interval. Is this dichotomy universal?\nWe prove that the answer is yes: for every metric space, the optimal regret of\na Lipschitz MAB algorithm is either bounded above by any $f\\in \\omega(\\log t)$,\nor bounded below by any $g\\in o(\\sqrt{t})$. Perhaps surprisingly, this\ndichotomy does not coincide with the distinction between finite and infinite\nmetric spaces; instead it depends on whether the completion of the metric space\nis compact and countable. Our proof connects upper and lower bound techniques\nin online learning with classical topological notions such as perfect sets and\nthe Cantor-Bendixson theorem. Among many other results, we show a similar\ndichotomy for the \"full-feedback\" (a.k.a., \"best-expert\") version.\n",
          "  This paper presents a finite-time analysis of the KL-UCB algorithm, an\nonline, horizon-free index policy for stochastic bandit problems. We prove two\ndistinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm\nsatisfies a uniformly better regret bound than UCB or UCB2; second, in the\nspecial case of Bernoulli rewards, it reaches the lower bound of Lai and\nRobbins. Furthermore, we show that simple adaptations of the KL-UCB algorithm\nare also optimal for specific classes of (possibly unbounded) rewards,\nincluding those generated from exponential families of distributions. A\nlarge-scale numerical study comparing KL-UCB with its main competitors (UCB,\nUCB2, UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and\nstable, including for short time horizons. KL-UCB is also the only method that\nalways performs better than the basic UCB policy. Our regret bounds rely on\ndeviations results of independent interest which are stated and proved in the\nAppendix. As a by-product, we also obtain an improved regret bound for the\nstandard UCB algorithm.\n",
          "  We provide consistent random algorithms for sequential decision under partial\nmonitoring, i.e. when the decision maker does not observe the outcomes but\nreceives instead random feedback signals. Those algorithms have no internal\nregret in the sense that, on the set of stages where the decision maker chose\nhis action according to a given law, the average payoff could not have been\nimproved in average by using any other fixed law.\n  They are based on a generalization of calibration, no longer defined in terms\nof a Voronoi diagram but instead of a Laguerre diagram (a more general\nconcept). This allows us to bound, for the first time in this general\nframework, the expected average internal -- as well as the usual external --\nregret at stage $n$ by $O(n^{-1/3})$, which is known to be optimal.\n",
          "  We study decision making in environments where the reward is only partially\nobserved, but can be modeled as a function of an action and an observed\ncontext. This setting, known as contextual bandits, encompasses a wide variety\nof applications including health-care policy and Internet advertising. A\ncentral task is evaluation of a new policy given historic data consisting of\ncontexts, actions and received rewards. The key challenge is that the past data\ntypically does not faithfully represent proportions of actions taken by a new\npolicy. Previous approaches rely either on models of rewards or models of the\npast policy. The former are plagued by a large bias whereas the latter have a\nlarge variance.\n  In this work, we leverage the strength and overcome the weaknesses of the two\napproaches by applying the doubly robust technique to the problems of policy\nevaluation and optimization. We prove that this approach yields accurate value\nestimates when we have either a good (but not necessarily consistent) model of\nrewards or a good (but not necessarily consistent) model of past policy.\nExtensive empirical comparison demonstrates that the doubly robust approach\nuniformly improves over existing techniques, achieving both lower variance in\nvalue estimation and better policies. As such, we expect the doubly robust\napproach to become common practice.\n",
          "  A natural optimization model that formulates many online resource allocation\nand revenue management problems is the online linear program (LP) in which the\nconstraint matrix is revealed column by column along with the corresponding\nobjective coefficient. In such a model, a decision variable has to be set each\ntime a column is revealed without observing the future inputs and the goal is\nto maximize the overall objective function. In this paper, we provide a\nnear-optimal algorithm for this general class of online problems under the\nassumption of random order of arrival and some mild conditions on the size of\nthe LP right-hand-side input. Specifically, our learning-based algorithm works\nby dynamically updating a threshold price vector at geometric time intervals,\nwhere the dual prices learned from the revealed columns in the previous period\nare used to determine the sequential decisions in the current period. Due to\nthe feature of dynamic learning, the competitiveness of our algorithm improves\nover the past study of the same problem. We also present a worst-case example\nshowing that the performance of our algorithm is near-optimal.\n",
          "  We consider a multi-round auction setting motivated by pay-per-click auctions\nfor Internet advertising. In each round the auctioneer selects an advertiser\nand shows her ad, which is then either clicked or not. An advertiser derives\nvalue from clicks; the value of a click is her private information. Initially,\nneither the auctioneer nor the advertisers have any information about the\nlikelihood of clicks on the advertisements. The auctioneer's goal is to design\na (dominant strategies) truthful mechanism that (approximately) maximizes the\nsocial welfare.\n  If the advertisers bid their true private values, our problem is equivalent\nto the \"multi-armed bandit problem\", and thus can be viewed as a strategic\nversion of the latter. In particular, for both problems the quality of an\nalgorithm can be characterized by \"regret\", the difference in social welfare\nbetween the algorithm and the benchmark which always selects the same \"best\"\nadvertisement. We investigate how the design of multi-armed bandit algorithms\nis affected by the restriction that the resulting mechanism must be truthful.\nWe find that truthful mechanisms have certain strong structural properties --\nessentially, they must separate exploration from exploitation -- and they incur\nmuch higher regret than the optimal multi-armed bandit algorithms. Moreover, we\nprovide a truthful mechanism which (essentially) matches our lower bound on\nregret.\n",
          "  The multi-armed bandit problem is a popular model for studying\nexploration/exploitation trade-off in sequential decision problems. Many\nalgorithms are now available for this well-studied problem. One of the earliest\nalgorithms, given by W. R. Thompson, dates back to 1933. This algorithm,\nreferred to as Thompson Sampling, is a natural Bayesian algorithm. The basic\nidea is to choose an arm to play according to its probability of being the best\narm. Thompson Sampling algorithm has experimentally been shown to be close to\noptimal. In addition, it is efficient to implement and exhibits several\ndesirable properties such as small regret for delayed feedback. However,\ntheoretical understanding of this algorithm was quite limited. In this paper,\nfor the first time, we show that Thompson Sampling algorithm achieves\nlogarithmic expected regret for the multi-armed bandit problem. More precisely,\nfor the two-armed bandit problem, the expected regret in time $T$ is\n$O(\\frac{\\ln T}{\\Delta} + \\frac{1}{\\Delta^3})$. And, for the $N$-armed bandit\nproblem, the expected regret in time $T$ is $O([(\\sum_{i=2}^N\n\\frac{1}{\\Delta_i^2})^2] \\ln T)$. Our bounds are optimal but for the dependence\non $\\Delta_i$ and the constant factors in big-Oh.\n",
          "  We consider the multi-armed bandit problems in which a player aims to accrue\nreward by sequentially playing a given set of arms with unknown reward\nstatistics. In the classic work, policies were proposed to achieve the optimal\nlogarithmic regret order for some special classes of light-tailed reward\ndistributions, e.g., Auer et al.'s UCB1 index policy for reward distributions\nwith finite support. In this paper, we extend Auer et al.'s UCB1 index policy\nto achieve the optimal logarithmic regret order for all light-tailed (or\nequivalently, locally sub-Gaussian) reward distributions defined by the (local)\nexistence of the moment-generating function.\n",
          "  We consider bandit problems involving a large (possibly infinite) collection\nof arms, in which the expected reward of each arm is a linear function of an\n$r$-dimensional random vector $\\mathbf{Z} \\in \\mathbb{R}^r$, where $r \\geq 2$.\nThe objective is to minimize the cumulative regret and Bayes risk. When the set\nof arms corresponds to the unit sphere, we prove that the regret and Bayes risk\nis of order $\\Theta(r \\sqrt{T})$, by establishing a lower bound for an\narbitrary policy, and showing that a matching upper bound is obtained through a\npolicy that alternates between exploration and exploitation phases. The\nphase-based policy is also shown to be effective if the set of arms satisfies a\nstrong convexity condition. For the case of a general set of arms, we describe\na near-optimal policy whose regret and Bayes risk admit upper bounds of the\nform $O(r \\sqrt{T} \\log^{3/2} T)$.\n",
          "  We provide the first algorithm for online bandit linear optimization whose\nregret after T rounds is of order sqrt{Td ln N} on any finite class X of N\nactions in d dimensions, and of order d*sqrt{T} (up to log factors) when X is\ninfinite. These bounds are not improvable in general. The basic idea utilizes\ntools from convex geometry to construct what is essentially an optimal\nexploration basis. We also present an application to a model of linear bandits\nwith expert advice. Interestingly, these results show that bandit linear\noptimization with expert advice in d dimensions is no more difficult (in terms\nof the achievable regret) than the online d-armed bandit problem with expert\nadvice (where EXP4 is optimal).\n",
          "  We discuss multi-task online learning when a decision maker has to deal\nsimultaneously with M tasks. The tasks are related, which is modeled by\nimposing that the M-tuple of actions taken by the decision maker needs to\nsatisfy certain constraints. We give natural examples of such restrictions and\nthen discuss a general class of tractable constraints, for which we introduce\ncomputationally efficient ways of selecting actions, essentially by reducing to\nan on-line shortest path problem. We briefly discuss \"tracking\" and \"bandit\"\nversions of the problem and extend the model in various ways, including\nnon-additive global losses and uncountably infinite sets of tasks.\n",
          "  We consider the classical multi-armed bandit problem with Markovian rewards.\nWhen played an arm changes its state in a Markovian fashion while it remains\nfrozen when not played. The player receives a state-dependent reward each time\nit plays an arm. The number of states and the state transition probabilities of\nan arm are unknown to the player. The player's objective is to maximize its\nlong-term total reward by learning the best arm over time. We show that under\ncertain conditions on the state transition probabilities of the arms, a sample\nmean based index policy achieves logarithmic regret uniformly over the total\nnumber of trials. The result shows that sample mean based index policies can be\napplied to learning problems under the rested Markovian bandit model without\nloss of optimality in the order. Moreover, comparision between Anantharam's\nindex policy and UCB shows that by choosing a small exploration parameter UCB\ncan have a smaller regret than Anantharam's index policy.\n",
          "  We consider a retailer selling a single product with limited on-hand\ninventory over a finite selling season. Customer demand arrives according to a\nPoisson process, the rate of which is influenced by a single action taken by\nthe retailer (such as price adjustment, sales commission, advertisement\nintensity, etc.). The relationship between the action and the demand rate is\nnot known in advance. However, the retailer is able to learn the optimal action\n\"on the fly\" as she maximizes her total expected revenue based on the observed\ndemand reactions.\n  Using the pricing problem as an example, we propose a dynamic\n\"learning-while-doing\" algorithm that only involves function value estimation\nto achieve a near-optimal performance. Our algorithm employs a series of\nshrinking price intervals and iteratively tests prices within that interval\nusing a set of carefully chosen parameters. We prove that the convergence rate\nof our algorithm is among the fastest of all possible algorithms in terms of\nasymptotic \"regret\" (the relative loss comparing to the full information\noptimal solution). Our result closes the performance gaps between parametric\nand non-parametric learning and between a post-price mechanism and a\ncustomer-bidding mechanism. Important managerial insight from this research is\nthat the values of information on both the parametric form of the demand\nfunction as well as each customer's exact reservation price are less important\nthan prior literature suggests. Our results also suggest that firms would be\nbetter off to perform dynamic learning and action concurrently rather than\nsequentially.\n",
          "  We present a set of high-probability inequalities that control the\nconcentration of weighted averages of multiple (possibly uncountably many)\nsimultaneously evolving and interdependent martingales. Our results extend the\nPAC-Bayesian analysis in learning theory from the i.i.d. setting to martingales\nopening the way for its application to importance weighted sampling,\nreinforcement learning, and other interactive learning domains, as well as many\nother domains in probability theory and statistics, where martingales are\nencountered.\n  We also present a comparison inequality that bounds the expectation of a\nconvex function of a martingale difference sequence shifted to the [0,1]\ninterval by the expectation of the same function of independent Bernoulli\nvariables. This inequality is applied to derive a tighter analog of\nHoeffding-Azuma's inequality.\n",
          "  We study the problem of learning a most biased coin among a set of coins by\ntossing the coins adaptively. The goal is to minimize the number of tosses\nuntil we identify a coin i* whose posterior probability of being most biased is\nat least 1-delta for a given delta. Under a particular probabilistic model, we\ngive an optimal algorithm, i.e., an algorithm that minimizes the expected\nnumber of future tosses. The problem is closely related to finding the best arm\nin the multi-armed bandit problem using adaptive strategies. Our algorithm\nemploys an optimal adaptive strategy -- a strategy that performs the best\npossible action at each step after observing the outcomes of all previous coin\ntosses. Consequently, our algorithm is also optimal for any starting history of\noutcomes. To our knowledge, this is the first algorithm that employs an optimal\nadaptive strategy under a Bayesian setting for this problem. Our proof of\noptimality employs tools from the field of Markov games.\n",
          "  We address online linear optimization problems when the possible actions of\nthe decision maker are represented by binary vectors. The regret of the\ndecision maker is the difference between her realized loss and the best loss\nshe would have achieved by picking, in hindsight, the best possible action. Our\ngoal is to understand the magnitude of the best possible (minimax) regret. We\nstudy the problem under three different assumptions for the feedback the\ndecision maker receives: full information, and the partial information models\nof the so-called \"semi-bandit\" and \"bandit\" problems. Combining the Mirror\nDescent algorithm and the INF (Implicitely Normalized Forecaster) strategy, we\nare able to prove optimal bounds for the semi-bandit case. We also recover the\noptimal bounds for the full information setting. In the bandit case we discuss\nexisting results in light of a new lower bound, and suggest a conjecture on the\noptimal regret in that case. Finally we also prove that the standard\nexponentially weighted average forecaster is provably suboptimal in the setting\nof online combinatorial optimization.\n",
          "  We provide a sound and consistent foundation for the use of \\emph{nonrandom}\nexploration data in \"contextual bandit\" or \"partially labeled\" settings where\nonly the value of a chosen action is learned.\n  The primary challenge in a variety of settings is that the exploration\npolicy, in which \"offline\" data is logged, is not explicitly known. Prior\nsolutions here require either control of the actions during the learning\nprocess, recorded random exploration, or actions chosen obliviously in a\nrepeated manner. The techniques reported here lift these restrictions, allowing\nthe learning of a policy for choosing actions given features from historical\ndata where no randomization occurred or was logged.\n  We empirically verify our solution on two reasonably sized sets of real-world\ndata obtained from Yahoo!.\n",
          "  Multi-armed bandit problems are the most basic examples of sequential\ndecision problems with an exploration-exploitation trade-off. This is the\nbalance between staying with the option that gave highest payoffs in the past\nand exploring new options that might give higher payoffs in the future.\nAlthough the study of bandit problems dates back to the Thirties,\nexploration-exploitation trade-offs arise in several modern applications, such\nas ad placement, website optimization, and packet routing. Mathematically, a\nmulti-armed bandit is defined by the payoff process associated with each\noption. In this survey, we focus on two extreme cases in which the analysis of\nregret is particularly simple and elegant: i.i.d. payoffs and adversarial\npayoffs. Besides the basic setting of finitely many actions, we also analyze\nsome of the most important variants and extensions, such as the contextual\nbandit model.\n",
          "  In a multi-armed bandit (MAB) problem, an online algorithm makes a sequence\nof choices. In each round it chooses from a time-invariant set of alternatives\nand receives the payoff associated with this alternative. While the case of\nsmall strategy sets is by now well-understood, a lot of recent work has focused\non MAB problems with exponentially or infinitely large strategy sets, where one\nneeds to assume extra structure in order to make the problem tractable. In\nparticular, recent literature considered information on similarity between\narms.\n  We consider similarity information in the setting of \"contextual bandits\", a\nnatural extension of the basic MAB problem where before each round an algorithm\nis given the \"context\" -- a hint about the payoffs in this round. Contextual\nbandits are directly motivated by placing advertisements on webpages, one of\nthe crucial problems in sponsored search. A particularly simple way to\nrepresent similarity information in the contextual bandit setting is via a\n\"similarity distance\" between the context-arm pairs which gives an upper bound\non the difference between the respective expected payoffs.\n  Prior work on contextual bandits with similarity uses \"uniform\" partitions of\nthe similarity space, which is potentially wasteful. We design more efficient\nalgorithms that are based on adaptive partitions adjusted to \"popular\" context\nand \"high-payoff\" arms.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_bandit_bandits_optimal",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_bandit_bandits_optimal"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.217426776885986,
          6.814554214477539,
          6.8992085456848145,
          6.5719990730285645,
          6.523046493530273,
          6.44511604309082,
          6.749324798583984,
          6.742337703704834,
          6.8046722412109375,
          6.491743087768555,
          6.54335880279541,
          6.755589485168457,
          6.894334316253662,
          6.547276496887207,
          6.627110958099365,
          6.992329120635986,
          7.1828460693359375,
          6.634571075439453,
          6.743387699127197,
          6.98471212387085,
          6.532349109649658,
          6.895391464233398,
          6.638985633850098,
          6.672518253326416,
          6.521522045135498,
          6.798276901245117,
          6.327239513397217,
          6.669669151306152,
          7.007324695587158,
          6.61906099319458,
          6.971968650817871,
          6.850592613220215,
          6.965388774871826,
          7.051621437072754,
          6.882059574127197,
          6.820894718170166,
          7.014387130737305,
          6.900407791137695,
          6.650894641876221,
          6.329971790313721,
          6.768492698669434,
          6.909244060516357,
          7.119222640991211,
          6.939728260040283,
          6.599278450012207,
          6.533260822296143,
          7.082108974456787,
          6.3959059715271,
          6.749639511108398,
          7.053256511688232,
          6.3680524826049805,
          6.572047710418701,
          6.7483954429626465,
          6.705793380737305,
          6.75610876083374
         ],
         "y": [
          7.467226982116699,
          7.496527671813965,
          7.558148384094238,
          7.89863920211792,
          7.987895965576172,
          7.828725337982178,
          7.7462968826293945,
          7.626818656921387,
          7.679019927978516,
          7.469182014465332,
          8.191267013549805,
          7.681103229522705,
          7.9521636962890625,
          7.934441566467285,
          8.043469429016113,
          7.6034088134765625,
          7.330051898956299,
          8.148112297058105,
          7.515394687652588,
          7.540895938873291,
          7.886807918548584,
          7.64381742477417,
          7.766902446746826,
          7.9486284255981445,
          7.823136329650879,
          7.814131259918213,
          8.180827140808105,
          8.080475807189941,
          7.484194755554199,
          8.099788665771484,
          7.5109734535217285,
          7.51988410949707,
          7.576589107513428,
          7.303476333618164,
          7.502676963806152,
          7.689697742462158,
          7.4593706130981445,
          7.785191535949707,
          7.595341205596924,
          8.216914176940918,
          7.705578327178955,
          7.518099784851074,
          7.359133720397949,
          7.55150032043457,
          7.924555778503418,
          8.073816299438477,
          7.300248146057129,
          8.181400299072266,
          7.434785842895508,
          7.396718978881836,
          8.290899276733398,
          7.538117408752441,
          7.671433925628662,
          7.704862594604492,
          7.726644515991211
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  In response to a 1997 problem of M. Vidyasagar, we state a necessary and\nsufficient condition for distribution-free PAC learnability of a concept class\n$\\mathscr C$ under the family of all non-atomic (diffuse) measures on the\ndomain $\\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis\ndimension of $\\mathscr C$ is a sufficient, but no longer necessary, condition.\nBesides, learnability of $\\mathscr C$ under non-atomic measures does not imply\nthe uniform Glivenko-Cantelli property with regard to non-atomic measures. Our\nlearnability criterion is stated in terms of a combinatorial parameter\n$\\VC({\\mathscr C}\\,{\\mathrm{mod}}\\,\\omega_1)$ which we call the VC dimension of\n$\\mathscr C$ modulo countable sets. The new parameter is obtained by\n``thickening up'' single points in the definition of VC dimension to\nuncountable ``clusters''. Equivalently, $\\VC(\\mathscr C\\modd\\omega_1)\\leq d$ if\nand only if every countable subclass of $\\mathscr C$ has VC dimension $\\leq d$\noutside a countable subset of $\\Omega$. The new parameter can be also expressed\nas the classical VC dimension of $\\mathscr C$ calculated on a suitable subset\nof a compactification of $\\Omega$. We do not make any measurability assumptions\non $\\mathscr C$, assuming instead the validity of Martin's Axiom (MA).\n",
          "  The method of stable random projections is a tool for efficiently computing\nthe $l_\\alpha$ distances using low memory, where $0<\\alpha \\leq 2$ is a tuning\nparameter. The method boils down to a statistical estimation task and various\nestimators have been proposed, based on the geometric mean, the harmonic mean,\nand the fractional power etc.\n  This study proposes the optimal quantile estimator, whose main operation is\nselecting, which is considerably less expensive than taking fractional power,\nthe main operation in previous estimators. Our experiments report that the\noptimal quantile estimator is nearly one order of magnitude more\ncomputationally efficient than previous estimators. For large-scale learning\ntasks in which storing and computing pairwise distances is a serious\nbottleneck, this estimator should be desirable.\n  In addition to its computational advantages, the optimal quantile estimator\nexhibits nice theoretical properties. It is more accurate than previous\nestimators when $\\alpha>1$. We derive its theoretical error bounds and\nestablish the explicit (i.e., no hidden constants) sample complexity bound.\n",
          "  By reformulating a learning process of a set system L as a game between\nTeacher and Learner, we define the order type of L to be the order type of the\ngame tree, if the tree is well-founded. The features of the order type of L\n(dim L in symbol) are (1) We can represent any well-quasi-order (wqo for short)\nby the set system L of the upper-closed sets of the wqo such that the maximal\norder type of the wqo is equal to dim L. (2) dim L is an upper bound of the\nmind-change complexity of L. dim L is defined iff L has a finite elasticity (fe\nfor short), where, according to computational learning theory, if an indexed\nfamily of recursive languages has fe then it is learnable by an algorithm from\npositive data. Regarding set systems as subspaces of Cantor spaces, we prove\nthat fe of set systems is preserved by any continuous function which is\nmonotone with respect to the set-inclusion. By it, we prove that finite\nelasticity is preserved by various (nondeterministic) language operators\n(Kleene-closure, shuffle-closure, union, product, intersection,. . ..) The\nmonotone continuous functions represent nondeterministic computations. If a\nmonotone continuous function has a computation tree with each node followed by\nat most n immediate successors and the order type of a set system L is\n{\\alpha}, then the direct image of L is a set system of order type at most\nn-adic diagonal Ramsey number of {\\alpha}. Furthermore, we provide an\norder-type-preserving contravariant embedding from the category of quasi-orders\nand finitely branching simulations between them, into the complete category of\nsubspaces of Cantor spaces and monotone continuous functions having Girard's\nlinearity between them. Keyword: finite elasticity, shuffle-closure\n",
          "  The problem of statistical learning is to construct a predictor of a random\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\npredictors are drawn from some specified class, and the goal is to approach\nasymptotically the performance (expected loss) of the best predictor in the\nclass. We consider the setting in which one has perfect observation of the\n$X$-part of the sample, while the $Y$-part has to be communicated at some\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\n$X$-values. Under suitable regularity conditions on the admissible predictors,\nthe underlying family of probability distributions and the loss function, we\ngive an information-theoretic characterization of achievable predictor\nperformance in terms of conditional distortion-rate functions. The ideas are\nillustrated on the example of nonparametric regression in Gaussian noise.\n",
          "  Exchangeable random variables form an important and well-studied\ngeneralization of i.i.d. variables, however simple examples show that no\nnontrivial concept or function classes are PAC learnable under general\nexchangeable data inputs $X_1,X_2,\\ldots$. Inspired by the work of Berti and\nRigo on a Glivenko--Cantelli theorem for exchangeable inputs, we propose a new\nparadigm, adequate for learning from exchangeable data: predictive PAC\nlearnability. A learning rule $\\mathcal L$ for a function class $\\mathscr F$ is\npredictive PAC if for every $\\e,\\delta>0$ and each function $f\\in {\\mathscr\nF}$, whenever $\\abs{\\sigma}\\geq s(\\delta,\\e)$, we have with confidence\n$1-\\delta$ that the expected difference between $f(X_{n+1})$ and the image of\n$f\\vert\\sigma$ under $\\mathcal L$ does not exceed $\\e$ conditionally on\n$X_1,X_2,\\ldots,X_n$. Thus, instead of learning the function $f$ as such, we\nare learning to a given accuracy $\\e$ the predictive behaviour of $f$ at the\nfuture points $X_i(\\omega)$, $i>n$ of the sample path. Using de Finetti's\ntheorem, we show that if a universally separable function class $\\mathscr F$ is\ndistribution-free PAC learnable under i.i.d. inputs, then it is\ndistribution-free predictive PAC learnable under exchangeable inputs, with a\nslightly worse sample complexity.\n",
          "  We information-theoretically reformulate two measures of capacity from\nstatistical learning theory: empirical VC-entropy and empirical Rademacher\ncomplexity. We show these capacity measures count the number of hypotheses\nabout a dataset that a learning algorithm falsifies when it finds the\nclassifier in its repertoire minimizing empirical risk. It then follows from\nthat the future performance of predictors on unseen data is controlled in part\nby how many hypotheses the learner falsifies. As a corollary we show that\nempirical VC-entropy quantifies the message length of the true hypothesis in\nthe optimal code of a particular probability distribution, the so-called actual\nrepertoire.\n",
          "  Since its introduction by Valiant in 1984, PAC learning of DNF expressions\nremains one of the central problems in learning theory. We consider this\nproblem in the setting where the underlying distribution is uniform, or more\ngenerally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed\nthat in this setting a DNF expression can be efficiently approximated from its\n\"heavy\" low-degree Fourier coefficients alone. This is in contrast to previous\napproaches where boosting was used and thus Fourier coefficients of the target\nfunction modified by various distributions were needed. This property is\ncrucial for learning of DNF expressions over smoothed product distributions, a\nlearning model introduced by Kalai et al. (2009) and inspired by the seminal\nsmoothed analysis model of Spielman and Teng (2001).\n  We introduce a new approach to learning (or approximating) a polynomial\nthreshold functions which is based on creating a function with range [-1,1]\nthat approximately agrees with the unknown function on low-degree Fourier\ncoefficients. We then describe conditions under which this is sufficient for\nlearning polynomial threshold functions. Our approach yields a new, simple\nalgorithm for approximating any polynomial-size DNF expression from its \"heavy\"\nlow-degree Fourier coefficients alone. Our algorithm greatly simplifies the\nproof of learnability of DNF expressions over smoothed product distributions.\nWe also describe an application of our algorithm to learning monotone DNF\nexpressions over product distributions. Building on the work of Servedio\n(2001), we give an algorithm that runs in time $\\poly((s \\cdot\n\\log{(s/\\eps)})^{\\log{(s/\\eps)}}, n)$, where $s$ is the size of the target DNF\nexpression and $\\eps$ is the accuracy. This improves on $\\poly((s \\cdot\n\\log{(ns/\\eps)})^{\\log{(s/\\eps)} \\cdot \\log{(1/\\eps)}}, n)$ bound of Servedio\n(2001).\n",
          "  A $k$-modal probability distribution over the discrete domain $\\{1,...,n\\}$\nis one whose histogram has at most $k$ \"peaks\" and \"valleys.\" Such\ndistributions are natural generalizations of monotone ($k=0$) and unimodal\n($k=1$) probability distributions, which have been intensively studied in\nprobability theory and statistics.\n  In this paper we consider the problem of \\emph{learning} (i.e., performing\ndensity estimation of) an unknown $k$-modal distribution with respect to the\n$L_1$ distance. The learning algorithm is given access to independent samples\ndrawn from an unknown $k$-modal distribution $p$, and it must output a\nhypothesis distribution $\\widehat{p}$ such that with high probability the total\nvariation distance between $p$ and $\\widehat{p}$ is at most $\\epsilon.$ Our\nmain goal is to obtain \\emph{computationally efficient} algorithms for this\nproblem that use (close to) an information-theoretically optimal number of\nsamples.\n  We give an efficient algorithm for this problem that runs in time\n$\\mathrm{poly}(k,\\log(n),1/\\epsilon)$. For $k \\leq \\tilde{O}(\\log n)$, the\nnumber of samples used by our algorithm is very close (within an\n$\\tilde{O}(\\log(1/\\epsilon))$ factor) to being information-theoretically\noptimal. Prior to this work computationally efficient algorithms were known\nonly for the cases $k=0,1$ \\cite{Birge:87b,Birge:97}.\n  A novel feature of our approach is that our learning algorithm crucially uses\na new algorithm for \\emph{property testing of probability distributions} as a\nkey subroutine. The learning algorithm uses the property tester to efficiently\ndecompose the $k$-modal distribution into $k$ (near-)monotone distributions,\nwhich are easier to learn.\n",
          "  We prove a new structural lemma for partial Boolean functions $f$, which we\ncall the seed lemma for DNF. Using the lemma, we give the first subexponential\nalgorithm for proper learning of DNF in Angluin's Equivalence Query (EQ) model.\nThe algorithm has time and query complexity $2^{(\\tilde{O}{\\sqrt{n}})}$, which\nis optimal. We also give a new result on certificates for DNF-size, a simple\nalgorithm for properly PAC-learning DNF, and new results on EQ-learning $\\log\nn$-term DNF and decision trees.\n",
          "  Let X be randomly chosen from {-1,1}^n, and let Y be randomly chosen from the\nstandard spherical Gaussian on R^n. For any (possibly unbounded) polytope P\nformed by the intersection of k halfspaces, we prove that\n  |Pr [X belongs to P] - Pr [Y belongs to P]| < log^{8/5}k * Delta, where Delta\nis a parameter that is small for polytopes formed by the intersection of\n\"regular\" halfspaces (i.e., halfspaces with low influence). The novelty of our\ninvariance principle is the polylogarithmic dependence on k. Previously, only\nbounds that were at least linear in k were known. We give two important\napplications of our main result: (1) A polylogarithmic in k bound on the\nBoolean noise sensitivity of intersections of k \"regular\" halfspaces (previous\nwork gave bounds linear in k). (2) A pseudorandom generator (PRG) with seed\nlength O((log n)*poly(log k,1/delta)) that delta-fools all polytopes with k\nfaces with respect to the Gaussian distribution. We also obtain PRGs with\nsimilar parameters that fool polytopes formed by intersection of regular\nhalfspaces over the hypercube. Using our PRG constructions, we obtain the first\ndeterministic quasi-polynomial time algorithms for approximately counting the\nnumber of solutions to a broad class of integer programs, including dense\ncovering problems and contingency tables.\n",
          "  The problem of joint universal source coding and modeling, treated in the\ncontext of lossless codes by Rissanen, was recently generalized to fixed-rate\nlossy coding of finitely parametrized continuous-alphabet i.i.d. sources. We\nextend these results to variable-rate lossy block coding of stationary ergodic\nsources and show that, for bounded metric distortion measures, any finitely\nparametrized family of stationary sources satisfying suitable mixing,\nsmoothness and Vapnik-Chervonenkis learnability conditions admits universal\nschemes for joint lossy source coding and identification. We also give several\nexplicit examples of parametric sources satisfying the regularity conditions.\n",
          "  Counting is among the most fundamental operations in computing. For example,\ncounting the pth frequency moment has been a very active area of research, in\ntheoretical computer science, databases, and data mining. When p=1, the task\n(i.e., counting the sum) can be accomplished using a simple counter.\n  Compressed Counting (CC) is proposed for efficiently computing the pth\nfrequency moment of a data stream signal A_t, where 0<p<=2. CC is applicable if\nthe streaming data follow the Turnstile model, with the restriction that at the\ntime t for the evaluation, A_t[i]>= 0, which includes the strict Turnstile\nmodel as a special case. For natural data streams encountered in practice, this\nrestriction is minor.\n  The underly technique for CC is what we call skewed stable random\nprojections, which captures the intuition that, when p=1 a simple counter\nsuffices, and when p = 1+/\\Delta with small \\Delta, the sample complexity of a\ncounter system should be low (continuously as a function of \\Delta). We show at\nsmall \\Delta the sample complexity (number of projections) k = O(1/\\epsilon)\ninstead of O(1/\\epsilon^2).\n  Compressed Counting can serve a basic building block for other tasks in\nstatistics and computing, for example, estimation entropies of data streams,\nparameter estimations using the method of moments and maximum likelihood.\n  Finally, another contribution is an algorithm for approximating the\nlogarithmic norm, \\sum_{i=1}^D\\log A_t[i], and logarithmic distance. The\nlogarithmic distance is useful in machine learning practice with heavy-tailed\ndata.\n",
          "  We give the first non-trivial upper bounds on the average sensitivity and\nnoise sensitivity of polynomial threshold functions. More specifically, for a\nBoolean function f on n variables equal to the sign of a real, multivariate\npolynomial of total degree d we prove\n  1) The average sensitivity of f is at most O(n^{1-1/(4d+6)}) (we also give a\ncombinatorial proof of the bound O(n^{1-1/2^d}).\n  2) The noise sensitivity of f with noise rate \\delta is at most\nO(\\delta^{1/(4d+6)}).\n  Previously, only bounds for the linear case were known. Along the way we show\nnew structural theorems about random restrictions of polynomial threshold\nfunctions obtained via hypercontractivity. These structural results may be of\nindependent interest as they provide a generic template for transforming\nproblems related to polynomial threshold functions defined on the Boolean\nhypercube to polynomial threshold functions defined in Gaussian space.\n",
          "  We show that the disagreement coefficient of certain smooth hypothesis\nclasses is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby\nanswering a question posed in \\cite{friedman09}.\n",
          "  We consider the problem of PAC-learning decision trees, i.e., learning a\ndecision tree over the n-dimensional hypercube from independent random labeled\nexamples. Despite significant effort, no polynomial-time algorithm is known for\nlearning polynomial-sized decision trees (even trees of any super-constant\nsize), even when examples are assumed to be drawn from the uniform distribution\non {0,1}^n. We give an algorithm that learns arbitrary polynomial-sized\ndecision trees for {\\em most product distributions}. In particular, consider a\nrandom product distribution where the bias of each bit is chosen independently\nand uniformly from, say, [.49,.51]. Then with high probability over the\nparameters of the product distribution and the random examples drawn from it,\nthe algorithm will learn any tree. More generally, in the spirit of smoothed\nanalysis, we consider an arbitrary product distribution whose parameters are\nspecified only up to a [-c,c] accuracy (perturbation), for an arbitrarily small\npositive constant c.\n",
          "  Bayes statistics and statistical physics have the common mathematical\nstructure, where the log likelihood function corresponds to the random\nHamiltonian. Recently, it was discovered that the asymptotic learning curves in\nBayes estimation are subject to a universal law, even if the log likelihood\nfunction can not be approximated by any quadratic form. However, it is left\nunknown what mathematical property ensures such a universal law. In this paper,\nwe define a renormalizable condition of the statistical estimation problem, and\nshow that, under such a condition, the asymptotic learning curves are ensured\nto be subject to the universal law, even if the true distribution is\nunrealizable and singular for a statistical model. Also we study a\nnonrenormalizable case, in which the learning curves have the different\nasymptotic behaviors from the universal law.\n",
          "  We consider the problem of learning an unknown product distribution $X$ over\n$\\{0,1\\}^n$ using samples $f(X)$ where $f$ is a \\emph{known} transformation\nfunction. Each choice of a transformation function $f$ specifies a learning\nproblem in this framework.\n  Information-theoretic arguments show that for every transformation function\n$f$ the corresponding learning problem can be solved to accuracy $\\eps$, using\n$\\tilde{O}(n/\\eps^2)$ examples, by a generic algorithm whose running time may\nbe exponential in $n.$ We show that this learning problem can be\ncomputationally intractable even for constant $\\eps$ and rather simple\ntransformation functions. Moreover, the above sample complexity bound is nearly\noptimal for the general problem, as we give a simple explicit linear\ntransformation function $f(x)=w \\cdot x$ with integer weights $w_i \\leq n$ and\nprove that the corresponding learning problem requires $\\Omega(n)$ samples.\n  As our main positive result we give a highly efficient algorithm for learning\na sum of independent unknown Bernoulli random variables, corresponding to the\ntransformation function $f(x)= \\sum_{i=1}^n x_i$. Our algorithm learns to\n$\\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\\eps)$ number of\nsamples that is independent of $n.$ We also give an efficient algorithm that\nuses $\\log n \\cdot \\poly(1/\\eps)$ samples but has running time that is only\n$\\poly(\\log n, 1/\\eps).$\n",
          "  Statistical query (SQ) learning model of Kearns (1993) is a natural\nrestriction of the PAC learning model in which a learning algorithm is allowed\nto obtain estimates of statistical properties of the examples but cannot see\nthe examples themselves. We describe a new and simple characterization of the\nquery complexity of learning in the SQ learning model. Unlike the previously\nknown bounds on SQ learning our characterization preserves the accuracy and the\nefficiency of learning. The preservation of accuracy implies that that our\ncharacterization gives the first characterization of SQ learning in the\nagnostic learning framework. The preservation of efficiency is achieved using a\nnew boosting technique and allows us to derive a new approach to the design of\nevolutionary algorithms in Valiant's (2006) model of evolvability. We use this\napproach to demonstrate the existence of a large class of monotone evolutionary\nlearning algorithms based on square loss performance estimation. These results\ndiffer significantly from the few known evolutionary algorithms and give\nevidence that evolvability in Valiant's model is a more versatile phenomenon\nthan there had been previous reason to suspect.\n",
          "  The problem of statistical learning is to construct an accurate predictor of\na random variable as a function of a correlated random variable on the basis of\nan i.i.d. training sample from their joint distribution. Allowable predictors\nare constrained to lie in some specified class, and the goal is to approach\nasymptotically the performance of the best predictor in the class. We consider\ntwo settings in which the learning agent only has access to rate-limited\ndescriptions of the training data, and present information-theoretic bounds on\nthe predictor performance achievable in the presence of these communication\nconstraints. Our proofs do not assume any separation structure between\ncompression and learning and rely on a new class of operational criteria\nspecifically tailored to joint design of encoders and learning algorithms in\nrate-constrained settings.\n",
          "  We begin this report by describing the Probably Approximately Correct (PAC)\nmodel for learning a concept class, consisting of subsets of a domain, and a\nfunction class, consisting of functions from the domain to the unit interval.\nTwo combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its\ngeneralization, the Fat Shattering dimension of scale e, are explained and a\nfew examples of their calculations are given with proofs. We then explain\nSauer's Lemma, which involves the VC dimension and is used to prove the\nequivalence of a concept class being distribution-free PAC learnable and it\nhaving finite VC dimension.\n  As the main new result of our research, we explore the construction of a new\nfunction class, obtained by forming compositions with a continuous logic\nconnective, a uniformly continuous function from the unit hypercube to the unit\ninterval, from a collection of function classes. Vidyasagar had proved that\nsuch a composition function class has finite Fat Shattering dimension of all\nscales if the classes in the original collection do; however, no estimates of\nthe dimension were known. Using results by Mendelson-Vershynin and Talagrand,\nwe bound the Fat Shattering dimension of scale e of this new function class in\nterms of the Fat Shattering dimensions of the collection's classes.\n  We conclude this report by providing a few open questions and future research\ntopics involving the PAC learning model.\n",
          "  Hardness results for maximum agreement problems have close connections to\nhardness results for proper learning in computational learning theory. In this\npaper we prove two hardness results for the problem of finding a low degree\npolynomial threshold function (PTF) which has the maximum possible agreement\nwith a given set of labeled examples in $\\R^n \\times \\{-1,1\\}.$ We prove that\nfor any constants $d\\geq 1, \\eps > 0$,\n  {itemize}\n  Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a\ndegree-$d$ PTF that is consistent with a $(\\half + \\eps)$ fraction of a given\nset of labeled examples in $\\R^n \\times \\{-1,1\\}$, even if there exists a\ndegree-$d$ PTF that is consistent with a $1-\\eps$ fraction of the examples.\n  It is $\\NP$-hard to find a degree-2 PTF that is consistent with a $(\\half +\n\\eps)$ fraction of a given set of labeled examples in $\\R^n \\times \\{-1,1\\}$,\neven if there exists a halfspace (degree-1 PTF) that is consistent with a $1 -\n\\eps$ fraction of the examples.\n  {itemize}\n  These results immediately imply the following hardness of learning results:\n(i) Assuming the Unique Games Conjecture, there is no better-than-trivial\nproper learning algorithm that agnostically learns degree-$d$ PTFs under\narbitrary distributions; (ii) There is no better-than-trivial learning\nalgorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e.\ndegree-1 PTFs) under arbitrary distributions.\n",
          "  Information distance is a parameter-free similarity measure based on\ncompression, used in pattern recognition, data mining, phylogeny, clustering,\nand classification. The notion of information distance is extended from pairs\nto multiples (finite lists). We study maximal overlap, metricity, universality,\nminimal overlap, additivity, and normalized information distance in multiples.\nWe use the theoretical notion of Kolmogorov complexity which for practical\npurposes is approximated by the length of the compressed version of the file\ninvolved, using a real-world compression program.\n  {\\em Index Terms}-- Information distance, multiples, pattern recognition,\ndata mining, similarity, Kolmogorov complexity\n",
          "  Valiant's (2007) model of evolvability models the evolutionary process of\nacquiring useful functionality as a restricted form of learning from random\nexamples. Linear threshold functions and their various subclasses, such as\nconjunctions and decision lists, play a fundamental role in learning theory and\nhence their evolvability has been the primary focus of research on Valiant's\nframework (2007). One of the main open problems regarding the model is whether\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\n2008). We show that the answer is negative. Our proof is based on a new\ncombinatorial parameter of a concept class that lower-bounds the complexity of\nlearning from correlations.\n  We contrast the lower bound with a proof that linear threshold functions\nhaving a non-negligible margin on the data points are evolvable\ndistribution-independently via a simple mutation algorithm. Our algorithm\nrelies on a non-linear loss function being used to select the hypotheses\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\nevolvability requires that the loss function satisfies several mild conditions\nthat are, for example, satisfied by the quadratic loss function studied in\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\nproperty of our evolution algorithm is monotonicity, that is the algorithm\nguarantees evolvability without any decreases in performance. Previously,\nmonotone evolvability was only shown for conjunctions with quadratic loss\n(Feldman, 2009) or when the distribution on the domain is severely restricted\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\n",
          "  We consider the question of the stability of evolutionary algorithms to\ngradual changes, or drift, in the target concept. We define an algorithm to be\nresistant to drift if, for some inverse polynomial drift rate in the target\nfunction, it converges to accuracy 1 -- \\epsilon , with polynomial resources,\nand then stays within that accuracy indefinitely, except with probability\n\\epsilon , at any one time. We show that every evolution algorithm, in the\nsense of Valiant (2007; 2009), can be converted using the Correlational Query\ntechnique of Feldman (2008), into such a drift resistant algorithm. For certain\nevolutionary algorithms, such as for Boolean conjunctions, we give bounds on\nthe rates of drift that they can resist. We develop some new evolution\nalgorithms that are resistant to significant drift. In particular, we give an\nalgorithm for evolving linear separators over the spherically symmetric\ndistribution that is resistant to a drift rate of O(\\epsilon /n), and another\nalgorithm over the more general product normal distributions that resists a\nsmaller drift rate.\n  The above translation result can be also interpreted as one on the robustness\nof the notion of evolvability itself under changes of definition. As a second\nresult in that direction we show that every evolution algorithm can be\nconverted to a quasi-monotonic one that can evolve from any starting point\nwithout the performance ever dipping significantly below that of the starting\npoint. This permits the somewhat unnatural feature of arbitrary performance\ndegradations to be removed from several known robustness translations.\n",
          "  Consider a class $\\mH$ of binary functions $h: X\\to\\{-1, +1\\}$ on a finite\ninterval $X=[0, B]\\subset \\Real$. Define the {\\em sample width} of $h$ on a\nfinite subset (a sample) $S\\subset X$ as $\\w_S(h) \\equiv \\min_{x\\in S}\n|\\w_h(x)|$, where $\\w_h(x) = h(x) \\max\\{a\\geq 0: h(z)=h(x), x-a\\leq z\\leq\nx+a\\}$. Let $\\mathbb{S}_\\ell$ be the space of all samples in $X$ of cardinality\n$\\ell$ and consider sets of wide samples, i.e., {\\em hypersets} which are\ndefined as $A_{\\beta, h} = \\{S\\in \\mathbb{S}_\\ell: \\w_{S}(h) \\geq \\beta\\}$.\nThrough an application of the Sauer-Shelah result on the density of sets an\nupper estimate is obtained on the growth function (or trace) of the class\n$\\{A_{\\beta, h}: h\\in\\mH\\}$, $\\beta>0$, i.e., on the number of possible\ndichotomies obtained by intersecting all hypersets with a fixed collection of\nsamples $S\\in\\mathbb{S}_\\ell$ of cardinality $m$. The estimate is\n$2\\sum_{i=0}^{2\\lfloor B/(2\\beta)\\rfloor}{m-\\ell\\choose i}$.\n",
          "  We prove that the class of functions g:{-1,+1}^n -> {-1,+1} that only depend\non an unknown subset of k<<n variables (so-called k-juntas) is agnostically\nlearnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},\nand log(1/delta). In other words, there is an algorithm with the claimed\nrunning time that, given epsilon, delta > 0 and access to a random walk on\n{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -> {-1,+1}, finds with\nprobability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,\nwhere opt(f) denotes the distance of a closest k-junta to f.\n",
          "  A fundamental result of statistical learnig theory states that a concept\nclass is PAC learnable if and only if it is a uniform Glivenko-Cantelli class\nif and only if the VC dimension of the class is finite. However, the theorem is\nonly valid under special assumptions of measurability of the class, in which\ncase the PAC learnability even becomes consistent. Otherwise, there is a\nclassical example, constructed under the Continuum Hypothesis by Dudley and\nDurst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a\nconcept class of VC dimension one which is neither uniform Glivenko-Cantelli\nnor consistently PAC learnable. We show that, rather surprisingly, under an\nadditional set-theoretic hypothesis which is much milder than the Continuum\nHypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC\ndimension for every concept class.\n",
          "  This paper focuses on the relation between computational learning theory and\nresource-bounded dimension. We intend to establish close connections between\nthe learnability/nonlearnability of a concept class and its corresponding size\nin terms of effective dimension, which will allow the use of powerful dimension\ntechniques in computational learning and viceversa, the import of learning\nresults into complexity via dimension. Firstly, we obtain a tight result on the\ndimension of online mistake-bound learnable classes. Secondly, in relation with\nPAC learning, we show that the polynomial-space dimension of PAC learnable\nclasses of concepts is zero. This provides a hypothesis on effective dimension\nthat implies the inherent unpredictability of concept classes (the classes that\nverify this property are classes not efficiently PAC learnable using any\nhypothesis). Thirdly, in relation to space dimension of classes that are\nlearnable by membership query algorithms, the main result proves that\npolynomial-space dimension of concept classes learnable by a membership-query\nalgorithm is zero.\n",
          "  The Sample Compression Conjecture of Littlestone & Warmuth has remained\nunsolved for over two decades. This paper presents a systematic geometric\ninvestigation of the compression of finite maximum concept classes. Simple\narrangements of hyperplanes in Hyperbolic space, and Piecewise-Linear\nhyperplane arrangements, are shown to represent maximum classes, generalizing\nthe corresponding Euclidean result. A main result is that PL arrangements can\nbe swept by a moving hyperplane to unlabeled d-compress any finite maximum\nclass, forming a peeling scheme as conjectured by Kuzmin & Warmuth. A corollary\nis that some d-maximal classes cannot be embedded into any maximum class of VC\ndimension d+k, for any constant k. The construction of the PL sweeping involves\nPachner moves on the one-inclusion graph, corresponding to moves of a\nhyperplane across the intersection of d other hyperplanes. This extends the\nwell known Pachner moves for triangulations to cubical complexes.\n",
          "  In the constraint satisfaction problem ($CSP$), the aim is to find an\nassignment of values to a set of variables subject to specified constraints. In\nthe minimum cost homomorphism problem ($MinHom$), one is additionally given\nweights $c_{va}$ for every variable $v$ and value $a$, and the aim is to find\nan assignment $f$ to the variables that minimizes $\\sum_{v} c_{vf(v)}$. Let\n$MinHom(\\Gamma)$ denote the $MinHom$ problem parameterized by the set of\npredicates allowed for constraints. $MinHom(\\Gamma)$ is related to many\nwell-studied combinatorial optimization problems, and concrete applications can\nbe found in, for instance, defence logistics and machine learning. We show that\n$MinHom(\\Gamma)$ can be studied by using algebraic methods similar to those\nused for CSPs. With the aid of algebraic techniques, we classify the\ncomputational complexity of $MinHom(\\Gamma)$ for all choices of $\\Gamma$. Our\nresult settles a general dichotomy conjecture previously resolved only for\ncertain classes of directed graphs, [Gutin, Hell, Rafiey, Yeo, European J. of\nCombinatorics, 2008].\n",
          "  A sequence $x_1,\\dots,x_n,\\dots$ of discrete-valued observations is generated\naccording to some unknown probabilistic law (measure) $\\mu$. After observing\neach outcome, one is required to give conditional probabilities of the next\nobservation. The realizable case is when the measure $\\mu$ belongs to an\narbitrary but known class $\\mathcal C$ of process measures. The non-realizable\ncase is when $\\mu$ is completely arbitrary, but the prediction performance is\nmeasured with respect to a given set $\\mathcal C$ of process measures. We are\ninterested in the relations between these problems and between their solutions,\nas well as in characterizing the cases when a solution exists and finding these\nsolutions. We show that if the quality of prediction is measured using the\ntotal variation distance, then these problems coincide, while if it is measured\nusing the expected average KL divergence, then they are different. For some of\nthe formalizations we also show that when a solution exists, it can be obtained\nas a Bayes mixture over a countable subset of $\\mathcal C$. We also obtain\nseveral characterization of those sets $\\mathcal C$ for which solutions to the\nconsidered problems exist. As an illustration to the general results obtained,\nwe show that a solution to the non-realizable case of the sequence prediction\nproblem exists for the set of all finite-memory processes, but does not exist\nfor the set of all stationary processes.\n  It should be emphasized that the framework is completely general: the\nprocesses measures considered are not required to be i.i.d., mixing,\nstationary, or to belong to any parametric family.\n",
          "  The Minimum Description Length (MDL) principle selects the model that has the\nshortest code for data plus model. We show that for a countable class of\nmodels, MDL predictions are close to the true distribution in a strong sense.\nThe result is completely general. No independence, ergodicity, stationarity,\nidentifiability, or other assumption on the model class need to be made. More\nformally, we show that for any countable class of models, the distributions\nselected by MDL (or MAP) asymptotically predict (merge with) the true measure\nin the class in total variation distance. Implications for non-i.i.d. domains\nlike time-series forecasting, discriminative learning, and reinforcement\nlearning are discussed.\n",
          "  By reformulating a learning process of a set system L as a game between\nTeacher (presenter of data) and Learner (updater of the abstract independent\nset), we define the order type dim L of L to be the order type of the game\ntree. The theory of this new order type and continuous, monotone function\nbetween set systems corresponds to the theory of well quasi-orderings (WQOs).\nAs Nash-Williams developed the theory of WQOs to the theory of better\nquasi-orderings (BQOs), we introduce a set system that has order type and\ncorresponds to a BQO. We prove that the class of set systems corresponding to\nBQOs is closed by any monotone function. In (Shinohara and Arimura. \"Inductive\ninference of unbounded unions of pattern languages from positive data.\"\nTheoretical Computer Science, pp. 191-209, 2000), for any set system L, they\nconsidered the class of arbitrary (finite) unions of members of L. From\nviewpoint of WQOs and BQOs, we characterize the set systems L such that the\nclass of arbitrary (finite) unions of members of L has order type. The\ncharacterization shows that the order structure of the set system L with\nrespect to the set-inclusion is not important for the resulting set system\nhaving order type. We point out continuous, monotone function of set systems is\nsimilar to positive reduction to Jockusch-Owings' weakly semirecursive sets.\n",
          "  We consider a basic problem in unsupervised learning: learning an unknown\n\\emph{Poisson Binomial Distribution}. A Poisson Binomial Distribution (PBD)\nover $\\{0,1,\\dots,n\\}$ is the distribution of a sum of $n$ independent\nBernoulli random variables which may have arbitrary, potentially non-equal,\nexpectations. These distributions were first studied by S. Poisson in 1837\n\\cite{Poisson:37} and are a natural $n$-parameter generalization of the\nfamiliar Binomial Distribution. Surprisingly, prior to our work this basic\nlearning problem was poorly understood, and known results for it were far from\noptimal.\n  We essentially settle the complexity of the learning problem for this basic\nclass of distributions. As our first main result we give a highly efficient\nalgorithm which learns to $\\eps$-accuracy (with respect to the total variation\ndistance) using $\\tilde{O}(1/\\eps^3)$ samples \\emph{independent of $n$}. The\nrunning time of the algorithm is \\emph{quasilinear} in the size of its input\ndata, i.e., $\\tilde{O}(\\log(n)/\\eps^3)$ bit-operations. (Observe that each draw\nfrom the distribution is a $\\log(n)$-bit string.) Our second main result is a\n{\\em proper} learning algorithm that learns to $\\eps$-accuracy using\n$\\tilde{O}(1/\\eps^2)$ samples, and runs in time $(1/\\eps)^{\\poly (\\log\n(1/\\eps))} \\cdot \\log n$. This is nearly optimal, since any algorithm {for this\nproblem} must use $\\Omega(1/\\eps^2)$ samples. We also give positive and\nnegative results for some extensions of this learning problem to weighted sums\nof independent Bernoulli random variables.\n",
          "  We prove the following strong hardness result for learning: Given a\ndistribution of labeled examples from the hypercube such that there exists a\nmonomial consistent with $(1-\\eps)$ of the examples, it is NP-hard to find a\nhalfspace that is correct on $(1/2+\\eps)$ of the examples, for arbitrary\nconstants $\\eps > 0$. In learning theory terms, weak agnostic learning of\nmonomials is hard, even if one is allowed to output a hypothesis from the much\nbigger concept class of halfspaces. This hardness result subsumes a long line\nof previous results, including two recent hardness results for the proper\nlearning of monomials and halfspaces. As an immediate corollary of our result\nwe show that weak agnostic learning of decision lists is NP-hard.\n  Our techniques are quite different from previous hardness proofs for\nlearning. We define distributions on positive and negative examples for\nmonomials whose first few moments match. We use the invariance principle to\nargue that regular halfspaces (all of whose coefficients have small absolute\nvalue relative to the total $\\ell_2$ norm) cannot distinguish between\ndistributions whose first few moments match. For highly non-regular subspaces,\nwe use a structural lemma from recent work on fooling halfspaces to argue that\nthey are ``junta-like'' and one can zero out all but the top few coefficients\nwithout affecting the performance of the halfspace. The top few coefficients\nform the natural list decoding of a halfspace in the context of dictatorship\ntests/Label Cover reductions.\n  We note that unlike previous invariance principle based proofs which are only\nknown to give Unique-Games hardness, we are able to reduce from a version of\nLabel Cover problem that is known to be NP-hard. This has inspired follow-up\nwork on bypassing the Unique Games conjecture in some optimal geometric\ninapproximability results.\n",
          "  A standard assumption in machine learning is the exchangeability of data,\nwhich is equivalent to assuming that the examples are generated from the same\nprobability distribution independently. This paper is devoted to testing the\nassumption of exchangeability on-line: the examples arrive one by one, and\nafter receiving each example we would like to have a valid measure of the\ndegree to which the assumption of exchangeability has been falsified. Such\nmeasures are provided by exchangeability martingales. We extend known\ntechniques for constructing exchangeability martingales and show that our new\nmethod is competitive with the martingales introduced before. Finally we\ninvestigate the performance of our testing method on two benchmark datasets,\nUSPS and Statlog Satellite data; for the former, the known techniques give\nsatisfactory results, but for the latter our new more flexible method becomes\nnecessary.\n",
          "  The concept of overfitting in model selection is explained and demonstrated\nwith an example. After providing some background information on information\ntheory and Kolmogorov complexity, we provide a short explanation of Minimum\nDescription Length and error minimization. We conclude with a discussion of the\ntypical features of overfitting in model selection.\n",
          "  We show that Boolean functions expressible as monotone disjunctive normal\nforms are PAC-evolvable under a uniform distribution on the Boolean cube if the\nhypothesis size is allowed to remain fixed. We further show that this result is\ninsufficient to prove the PAC-learnability of monotone Boolean functions,\nthereby demonstrating a counter-example to a recent claim to the contrary. We\nfurther discuss scenarios wherein evolvability and learnability will coincide\nas well as scenarios under which they differ. The implications of the latter\ncase on the prospects of learning in complex hypothesis spaces is briefly\nexamined.\n",
          "  We study the problem of partitioning a small sample of $n$ individuals from a\nmixture of $k$ product distributions over a Boolean cube $\\{0, 1\\}^K$ according\nto their distributions. Each distribution is described by a vector of allele\nfrequencies in $\\R^K$. Given two distributions, we use $\\gamma$ to denote the\naverage $\\ell_2^2$ distance in frequencies across $K$ dimensions, which\nmeasures the statistical divergence between them. We study the case assuming\nthat bits are independently distributed across $K$ dimensions. This work\ndemonstrates that, for a balanced input instance for $k = 2$, a certain\ngraph-based optimization function returns the correct partition with high\nprobability, where a weighted graph $G$ is formed over $n$ individuals, whose\npairwise hamming distances between their corresponding bit vectors define the\nedge weights, so long as $K = \\Omega(\\ln n/\\gamma)$ and $Kn = \\tilde\\Omega(\\ln\nn/\\gamma^2)$. The function computes a maximum-weight balanced cut of $G$, where\nthe weight of a cut is the sum of the weights across all edges in the cut. This\nresult demonstrates a nice property in the high-dimensional feature space: one\ncan trade off the number of features that are required with the size of the\nsample to accomplish certain tasks like clustering.\n",
          "  A Boolean function is called read-once over a basis B if it can be expressed\nby a formula over B where no variable appears more than once. A checking test\nfor a read-once function f over B depending on all its variables is a set of\ninput vectors distinguishing f from all other read-once functions of the same\nvariables. We show that every read-once function f over B has a checking test\ncontaining O(n^l) vectors, where n is the number of relevant variables of f and\nl is the largest arity of functions in B. For some functions, this bound cannot\nbe improved by more than a constant factor. The employed technique involves\nreconstructing f from its l-variable projections and provides a stronger form\nof Kuznetsov's classic theorem on read-once representations.\n",
          "  The entropy/influence conjecture, raised by Friedgut and Kalai in 1996, seeks\nto relate two different measures of concentration of the Fourier coefficients\nof a Boolean function. Roughly saying, it claims that if the Fourier spectrum\nis \"smeared out\", then the Fourier coefficients are concentrated on \"high\"\nlevels. In this note we generalize the conjecture to biased product measures on\nthe discrete cube, and prove a variant of the conjecture for functions with an\nextremely low Fourier weight on the \"high\" levels.\n",
          "  Solomonoff's central result on induction is that the posterior of a universal\nsemimeasure M converges rapidly and with probability 1 to the true sequence\ngenerating posterior mu, if the latter is computable. Hence, M is eligible as a\nuniversal sequence predictor in case of unknown mu. Despite some nearby results\nand proofs in the literature, the stronger result of convergence for all\n(Martin-Loef) random sequences remained open. Such a convergence result would\nbe particularly interesting and natural, since randomness can be defined in\nterms of M itself. We show that there are universal semimeasures M which do not\nconverge for all random sequences, i.e. we give a partial negative answer to\nthe open problem. We also provide a positive answer for some non-universal\nsemimeasures. We define the incomputable measure D as a mixture over all\ncomputable measures and the enumerable semimeasure W as a mixture over all\nenumerable nearly-measures. We show that W converges to D and D to mu on all\nrandom sequences. The Hellinger distance measuring closeness of two\ndistributions plays a central role.\n",
          "  For each $p \\in (0,2]$, we present a randomized algorithm that returns an\n$\\epsilon$-approximation of the $p$th frequency moment of a data stream $F_p =\n\\sum_{i = 1}^n \\abs{f_i}^p$. The algorithm requires space $O(\\epsilon^{-2} \\log\n(mM)(\\log n))$ and processes each stream update using time $O((\\log n) (\\log\n\\epsilon^{-1}))$. It is nearly optimal in terms of space (lower bound\n$O(\\epsilon^{-2} \\log (mM))$ as well as time and is the first algorithm with\nthese properties. The technique separates heavy hitters from the remaining\nitems in the stream using an appropriate threshold and estimates the\ncontribution of the heavy hitters and the light elements to $F_p$ separately. A\nkey component is the design of an unbiased estimator for $\\abs{f_i}^p$ whose\ndata structure has low update time and low variance.\n",
          "  Statistical modeling of nuclear data provides a novel approach to nuclear\nsystematics complementary to established theoretical and phenomenological\napproaches based on quantum theory. Continuing previous studies in which global\nstatistical modeling is pursued within the general framework of machine\nlearning theory, we implement advances in training algorithms designed to\nimproved generalization, in application to the problem of reproducing and\npredicting the halflives of nuclear ground states that decay 100% by the beta^-\nmode. More specifically, fully-connected, multilayer feedforward artificial\nneural network models are developed using the Levenberg-Marquardt optimization\nalgorithm together with Bayesian regularization and cross-validation. The\npredictive performance of models emerging from extensive computer experiments\nis compared with that of traditional microscopic and phenomenological models as\nwell as with the performance of other learning systems, including earlier\nneural network models as well as the support vector machines recently applied\nto the same problem. In discussing the results, emphasis is placed on\npredictions for nuclei that are far from the stability line, and especially\nthose involved in the r-process nucleosynthesis. It is found that the new\nstatistical models can match or even surpass the predictive performance of\nconventional models for beta-decay systematics and accordingly should provide a\nvaluable additional tool for exploring the expanding nuclear landscape.\n",
          "  There are (at least) three approaches to quantifying information. The first,\nalgorithmic information or Kolmogorov complexity, takes events as strings and,\ngiven a universal Turing machine, quantifies the information content of a\nstring as the length of the shortest program producing it. The second, Shannon\ninformation, takes events as belonging to ensembles and quantifies the\ninformation resulting from observing the given event in terms of the number of\nalternate events that have been ruled out. The third, statistical learning\ntheory, has introduced measures of capacity that control (in part) the expected\nrisk of classifiers. These capacities quantify the expectations regarding\nfuture data that learning algorithms embed into classifiers.\n  This note describes a new method of quantifying information, effective\ninformation, that links algorithmic information to Shannon information, and\nalso links both to capacities arising in statistical learning theory. After\nintroducing the measure, we show that it provides a non-universal analog of\nKolmogorov complexity. We then apply it to derive basic capacities in\nstatistical learning theory: empirical VC-entropy and empirical Rademacher\ncomplexity. A nice byproduct of our approach is an interpretation of the\nexplanatory power of a learning algorithm in terms of the number of hypotheses\nit falsifies, counted in two different ways for the two capacities. We also\ndiscuss how effective information relates to information gain, Shannon and\nmutual information.\n",
          "  We consider the problem of choosing a density estimate from a set of\ndistributions F, minimizing the L1-distance to an unknown distribution\n(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the\nproblem: Scheffe tournament winner and minimum distance estimate. The Scheffe\ntournament estimate requires fewer computations than the minimum distance\nestimate, but has strictly weaker guarantees than the latter.\n  We focus on the computational aspect of density estimation. We present two\nalgorithms, both with the same guarantee as the minimum distance estimate. The\nfirst one, a modification of the minimum distance estimate, uses the same\nnumber (quadratic in |F|) of computations as the Scheffe tournament. The second\none, called ``efficient minimum loss-weight estimate,'' uses only a linear\nnumber of computations, assuming that F is preprocessed.\n  We also give examples showing that the guarantees of the algorithms cannot be\nimproved and explore randomized algorithms for density estimation.\n",
          "  Machine learning is used to approximate density functionals. For the model\nproblem of the kinetic energy of non-interacting fermions in 1d, mean absolute\nerrors below 1 kcal/mol on test densities similar to the training set are\nreached with fewer than 100 training densities. A predictor identifies if a\ntest density is within the interpolation region. Via principal component\nanalysis, a projected functional derivative finds highly accurate\nself-consistent densities. Challenges for application of our method to real\nelectronic structure problems are discussed.\n",
          "  We give a deterministic, polynomial-time algorithm for approximately counting\nthe number of {0,1}-solutions to any instance of the knapsack problem. On an\ninstance of length n with total weight W and accuracy parameter eps, our\nalgorithm produces a (1 + eps)-multiplicative approximation in time poly(n,log\nW,1/eps). We also give algorithms with identical guarantees for general integer\nknapsack, the multidimensional knapsack problem (with a constant number of\nconstraints) and for contingency tables (with a constant number of rows).\nPreviously, only randomized approximation schemes were known for these problems\ndue to work by Morris and Sinclair and work by Dyer.\n  Our algorithms work by constructing small-width, read-once branching programs\nfor approximating the underlying solution space under a carefully chosen\ndistribution. As a byproduct of this approach, we obtain new query algorithms\nfor learning functions of k halfspaces with respect to the uniform distribution\non {0,1}^n. The running time of our algorithm is polynomial in the accuracy\nparameter eps. Previously even for the case of k=2, only algorithms with an\nexponential dependence on eps were known.\n",
          "  We consider the problem of boosting the accuracy of weak learning algorithms\nin the agnostic learning framework of Haussler (1992) and Kearns et al. (1992).\nKnown algorithms for this problem (Ben-David et al., 2001; Gavinsky, 2002;\nKalai et al., 2008) follow the same strategy as boosting algorithms in the PAC\nmodel: the weak learner is executed on the same target function but over\ndifferent distributions on the domain. We demonstrate boosting algorithms for\nthe agnostic learning framework that only modify the distribution on the labels\nof the points (or, equivalently, modify the target function). This allows\nboosting a distribution-specific weak agnostic learner to a strong agnostic\nlearner with respect to the same distribution.\n  When applied to the weak agnostic parity learning algorithm of Goldreich and\nLevin (1989) our algorithm yields a simple PAC learning algorithm for DNF and\nan agnostic learning algorithm for decision trees over the uniform distribution\nusing membership queries. These results substantially simplify Jackson's famous\nDNF learning algorithm (1994) and the recent result of Gopalan et al. (2008).\n  We also strengthen the connection to hard-core set constructions discovered\nby Klivans and Servedio (1999) by demonstrating that hard-core set\nconstructions that achieve the optimal hard-core set size (given by Holenstein\n(2005) and Barak et al. (2009)) imply distribution-specific agnostic boosting\nalgorithms. Conversely, our boosting algorithm gives a simple hard-core set\nconstruction with an (almost) optimal hard-core set size.\n",
          "  We show that the learning sample complexity of a sigmoidal neural network\nconstructed by Sontag (1992) required to achieve a given misclassification\nerror under a fixed purely atomic distribution can grow arbitrarily fast: for\nany prescribed rate of growth there is an input distribution having this rate\nas the sample complexity, and the bound is asymptotically tight. The rate can\nbe superexponential, a non-recursive function, etc. We further observe that\nSontag's ANN is not Glivenko-Cantelli under any input distribution having a\nnon-atomic part.\n",
          "  We provide asymptotically sharp bounds for the Gaussian surface area and the\nGaussian noise sensitivity of polynomial threshold functions. In particular we\nshow that if $f$ is a degree-$d$ polynomial threshold function, then its\nGaussian sensitivity at noise rate $\\epsilon$ is less than some quantity\nasymptotic to $\\frac{d\\sqrt{2\\epsilon}}{\\pi}$ and the Gaussian surface area is\nat most $\\frac{d}{\\sqrt{2\\pi}}$. Furthermore these bounds are asymptotically\ntight as $\\epsilon\\to 0$ and $f$ the threshold function of a product of $d$\ndistinct homogeneous linear functions.\n",
          "  We study the problem of learning k-juntas given access to examples drawn from\na number of different product distributions. Thus we wish to learn a function f\n: {-1,1}^n -> {-1,1} that depends on k (unknown) coordinates. While the best\nknown algorithms for the general problem of learning a k-junta require running\ntime of n^k * poly(n,2^k), we show that given access to k different product\ndistributions with biases separated by \\gamma>0, the functions may be learned\nin time poly(n,2^k,\\gamma^{-k}). More generally, given access to t <= k\ndifferent product distributions, the functions may be learned in time n^{k/t} *\npoly(n,2^k,\\gamma^{-k}). Our techniques involve novel results in Fourier\nanalysis relating Fourier expansions with respect to different biases and a\ngeneralization of Russo's formula.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_learnability_learnable_learning",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_learnability_learnable_learning"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.751434803009033,
          3.7630326747894287,
          3.7867212295532227,
          3.692324638366699,
          3.8530211448669434,
          3.5252435207366943,
          3.9790806770324707,
          3.8271560668945312,
          3.9908785820007324,
          4.067481994628906,
          1.3600058555603027,
          3.8334691524505615,
          4.060622215270996,
          3.6496188640594482,
          3.975215435028076,
          3.7551939487457275,
          3.815721273422241,
          4.026028156280518,
          3.6461846828460693,
          3.743001699447632,
          3.950045108795166,
          3.2747933864593506,
          3.954941511154175,
          4.1909308433532715,
          3.842146396636963,
          4.01093053817749,
          3.7012155055999756,
          3.69185471534729,
          3.737184762954712,
          4.012052059173584,
          3.817708730697632,
          3.8892557621002197,
          3.7791337966918945,
          3.7593438625335693,
          3.981003761291504,
          3.8735191822052,
          3.4487853050231934,
          3.7778818607330322,
          3.862248659133911,
          3.9788434505462646,
          3.965240716934204,
          3.82643985748291,
          3.8318710327148438,
          3.754856586456299,
          3.4319205284118652,
          3.9228339195251465,
          3.7776846885681152,
          4.017640590667725,
          4.011127948760986,
          3.6026055812835693,
          4.216411590576172,
          3.965200662612915,
          3.7876744270324707
         ],
         "y": [
          7.7127227783203125,
          8.322639465332031,
          7.776127815246582,
          8.153316497802734,
          7.871879577636719,
          8.009466171264648,
          7.9474663734436035,
          8.263629913330078,
          7.876136779785156,
          8.120875358581543,
          11.095620155334473,
          8.232327461242676,
          8.013787269592285,
          7.781243324279785,
          7.970452785491943,
          7.189150333404541,
          8.196039199829102,
          7.948343276977539,
          8.120035171508789,
          7.754892826080322,
          8.063451766967773,
          7.693284034729004,
          7.91611909866333,
          7.954696178436279,
          8.277260780334473,
          7.995500564575195,
          7.730830192565918,
          7.8060455322265625,
          7.806875228881836,
          8.078812599182129,
          7.505098342895508,
          7.742283344268799,
          7.6866135597229,
          8.244317054748535,
          8.070000648498535,
          8.186436653137207,
          7.7451958656311035,
          7.746028900146484,
          8.237213134765625,
          7.841155052185059,
          7.719187259674072,
          7.52384614944458,
          8.276074409484863,
          6.991204261779785,
          7.97508430480957,
          8.305163383483887,
          7.096123218536377,
          8.077529907226562,
          7.9017415046691895,
          7.892223834991455,
          8.035029411315918,
          7.978760719299316,
          7.97029447555542
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  It is now well known that decentralised optimisation can be formulated as a\npotential game, and game-theoretical learning algorithms can be used to find an\noptimum. One of the most common learning techniques in game theory is\nfictitious play. However fictitious play is founded on an implicit assumption\nthat opponents' strategies are stationary. We present a novel variation of\nfictitious play that allows the use of a more realistic model of opponent\nstrategy. It uses a heuristic approach, from the online streaming data\nliterature, to adaptively update the weights assigned to recently observed\nactions. We compare the results of the proposed algorithm with those of\nstochastic and geometric fictitious play in a simple strategic form game, a\nvehicle target assignment game and a disaster management problem. In all the\ntests the rate of convergence of the proposed algorithm was similar or better\nthan the variations of fictitious play we compared it with. The new algorithm\ntherefore improves the performance of game-theoretical learning in\ndecentralised optimisation.\n",
          "  We study two-player security games which can be viewed as sequences of\nnonzero-sum matrix games played by an Attacker and a Defender. The evolution of\nthe game is based on a stochastic fictitious play process, where players do not\nhave access to each other's payoff matrix. Each has to observe the other's\nactions up to present and plays the action generated based on the best response\nto these observations. In a regular fictitious play process, each player makes\na maximum likelihood estimate of her opponent's mixed strategy, which results\nin a time-varying update based on the previous estimate and current action. In\nthis paper, we explore an alternative scheme for frequency update, whose mean\ndynamic is instead time-invariant. We examine convergence properties of the\nmean dynamic of the fictitious play process with such an update scheme, and\nestablish local stability of the equilibrium point when both players are\nrestricted to two actions. We also propose an adaptive algorithm based on this\ntime-invariant frequency update.\n",
          "  In this paper, we consider uplink transmissions involving multiple users\ncommunicating with a base station over a fading channel. We assume that the\nbase station does not coordinate the transmissions of the users and hence the\nusers employ random access communication. The situation is modeled as a\nnon-cooperative repeated game with incomplete information. Each user attempts\nto minimize its long term power consumption subject to a minimum rate\nrequirement. We propose a two timescale stochastic gradient algorithm (TTSGA)\nfor tuning the users' transmission probabilities. The algorithm includes a\n'waterfilling threshold update mechanism' that ensures that the rate\nconstraints are satisfied. We prove that under the algorithm, the users'\ntransmission probabilities converge to a Nash equilibrium. Moreover, we also\nprove that the rate constraints are satisfied; this is also demonstrated using\nsimulation studies.\n",
          "  In wireless access network optimization, today's main challenges reside in\ntraffic offload and in the improvement of both capacity and coverage networks.\nThe operators are interested in solving their localized coverage and capacity\nproblems in areas where the macro network signal is not able to serve the\ndemand for mobile data. Thus, the major issue for operators is to find the best\nsolution at reasonable expanses. The femto cell seems to be the answer to this\nproblematic. In this work (This work is supported by the COMET project AWARE.\nhttp://www.ftw.at/news/project-start-for-aware-ftw), we focus on the problem of\nsharing femto access between a same mobile operator's customers. This problem\ncan be modeled as a game where service requesters customers (SRCs) and service\nproviders customers (SPCs) are the players.\n  This work addresses the sharing femto access problem considering only one SPC\nusing game theory tools. We consider that SRCs are static and have some similar\nand regular connection behavior. We also note that the SPC and each SRC have a\nsoftware embedded respectively on its femto access, user equipment (UE).\n  After each connection requested by a SRC, its software will learn the\nstrategy increasing its gain knowing that no information about the other SRCs\nstrategies is given. The following article presents a distributed learning\nalgorithm with incomplete information running in SRCs software. We will then\nanswer the following questions for a game with $N$ SRCs and one SPC: how many\nconnections are necessary for each SRC in order to learn the strategy\nmaximizing its gain? Does this algorithm converge to a stable state? If yes,\ndoes this state a Nash Equilibrium and is there any way to optimize the\nlearning process duration time triggered by SRCs software?\n",
          "  The fundamental problem of multiple secondary users contending for\nopportunistic spectrum access over multiple channels in cognitive radio\nnetworks has been formulated recently as a decentralized multi-armed bandit\n(D-MAB) problem. In a D-MAB problem there are $M$ users and $N$ arms (channels)\nthat each offer i.i.d. stochastic rewards with unknown means so long as they\nare accessed without collision. The goal is to design a decentralized online\nlearning policy that incurs minimal regret, defined as the difference between\nthe total expected rewards accumulated by a model-aware genie, and that\nobtained by all users applying the policy. We make two contributions in this\npaper. First, we consider the setting where the users have a prioritized\nranking, such that it is desired for the $K$-th-ranked user to learn to access\nthe arm offering the $K$-th highest mean reward. For this problem, we present\nthe first distributed policy that yields regret that is uniformly logarithmic\nover time without requiring any prior assumption about the mean rewards.\nSecond, we consider the case when a fair access policy is required, i.e., it is\ndesired for all users to experience the same mean reward. For this problem, we\npresent a distributed policy that yields order-optimal regret scaling with\nrespect to the number of users and arms, better than previously proposed\npolicies in the literature. Both of our distributed policies make use of an\ninnovative modification of the well known UCB1 policy for the classic\nmulti-armed bandit problem that allows a single user to learn how to play the\narm that yields the $K$-th largest mean reward.\n",
          "  We formulate and study a decentralized multi-armed bandit (MAB) problem.\nThere are M distributed players competing for N independent arms. Each arm,\nwhen played, offers i.i.d. reward according to a distribution with an unknown\nparameter. At each time, each player chooses one arm to play without exchanging\nobservations or any information with other players. Players choosing the same\narm collide, and, depending on the collision model, either no one receives\nreward or the colliding players share the reward in an arbitrary way. We show\nthat the minimum system regret of the decentralized MAB grows with time at the\nsame logarithmic order as in the centralized counterpart where players act\ncollectively as a single entity by exchanging observations and making decisions\njointly. A decentralized policy is constructed to achieve this optimal order\nwhile ensuring fairness among players and without assuming any pre-agreement or\ninformation exchange among players. Based on a Time Division Fair Sharing\n(TDFS) of the M best arms, the proposed policy is constructed and its order\noptimality is proven under a general reward model. Furthermore, the basic\nstructure of the TDFS policy can be used with any order-optimal single-player\npolicy to achieve order optimality in the decentralized setting. We also\nestablish a lower bound on the system regret growth rate for a general class of\ndecentralized polices, to which the proposed policy belongs. This problem finds\npotential applications in cognitive radio networks, multi-channel communication\nsystems, multi-agent systems, web search and advertising, and social networks.\n",
          "  In this paper, we propose a systematic solution to the problem of scheduling\ndelay-sensitive media data for transmission over time-varying wireless\nchannels. We first formulate the dynamic scheduling problem as a Markov\ndecision process (MDP) that explicitly considers the users' heterogeneous\nmultimedia data characteristics (e.g. delay deadlines, distortion impacts and\ndependencies etc.) and time-varying channel conditions, which are not\nsimultaneously considered in state-of-the-art packet scheduling algorithms.\nThis formulation allows us to perform foresighted decisions to schedule\nmultiple data units for transmission at each time in order to optimize the\nlong-term utilities of the multimedia applications. The heterogeneity of the\nmedia data enables us to express the transmission priorities between the\ndifferent data units as a priority graph, which is a directed acyclic graph\n(DAG). This priority graph provides us with an elegant structure to decompose\nthe multi-data unit foresighted decision at each time into multiple single-data\nunit foresighted decisions which can be performed sequentially, from the high\npriority data units to the low priority data units, thereby significantly\nreducing the computation complexity. When the statistical knowledge of the\nmultimedia data characteristics and channel conditions is unknown a priori, we\ndevelop a low-complexity online learning algorithm to update the value\nfunctions which capture the impact of the current decision on the future\nutility. The simulation results show that the proposed solution significantly\noutperforms existing state-of-the-art scheduling solutions.\n",
          "  We consider the adaptive shortest-path routing problem in wireless networks\nunder unknown and stochastically varying link states. In this problem, we aim\nto optimize the quality of communication between a source and a destination\nthrough adaptive path selection. Due to the randomness and uncertainties in the\nnetwork dynamics, the quality of each link varies over time according to a\nstochastic process with unknown distributions. After a path is selected for\ncommunication, the aggregated quality of all links on this path (e.g., total\npath delay) is observed. The quality of each individual link is not observable.\nWe formulate this problem as a multi-armed bandit with dependent arms. We show\nthat by exploiting arm dependencies, a regret polynomial with network size can\nbe achieved while maintaining the optimal logarithmic order with time. This is\nin sharp contrast with the exponential regret order with network size offered\nby a direct application of the classic MAB policies that ignore arm\ndependencies. Furthermore, our results are obtained under a general model of\nlink-quality distributions (including heavy-tailed distributions) and find\napplications in cognitive radio and ad hoc networks with unknown and dynamic\ncommunication environments.\n",
          "  Learning algorithms are essential for the applications of game theory in a\nnetworking environment. In dynamic and decentralized settings where the\ntraffic, topology and channel states may vary over time and the communication\nbetween agents is impractical, it is important to formulate and study games of\nincomplete information and fully distributed learning algorithms which for each\nagent requires a minimal amount of information regarding the remaining agents.\nIn this paper, we address this major challenge and introduce heterogeneous\nlearning schemes in which each agent adopts a distinct learning pattern in the\ncontext of games with incomplete information. We use stochastic approximation\ntechniques to show that the heterogeneous learning schemes can be studied in\nterms of their deterministic ordinary differential equation (ODE) counterparts.\nDepending on the learning rates of the players, these ODEs could be different\nfrom the standard replicator dynamics, (myopic) best response (BR) dynamics,\nlogit dynamics, and fictitious play dynamics. We apply the results to a class\nof security games in which the attacker and the defender adopt different\nlearning schemes due to differences in their rationality levels and the\ninformation they acquire.\n",
          "  In this paper, we consider a queue-aware distributive resource control\nalgorithm for two-hop MIMO cooperative systems. We shall illustrate that relay\nbuffering is an effective way to reduce the intrinsic half-duplex penalty in\ncooperative systems. The complex interactions of the queues at the source node\nand the relays are modeled as an average-cost infinite horizon Markov Decision\nProcess (MDP). The traditional approach solving this MDP problem involves\ncentralized control with huge complexity. To obtain a distributive and low\ncomplexity solution, we introduce a linear structure which approximates the\nvalue function of the associated Bellman equation by the sum of per-node value\nfunctions. We derive a distributive two-stage two-winner auction-based control\npolicy which is a function of the local CSI and local QSI only. Furthermore, to\nestimate the best fit approximation parameter, we propose a distributive online\nstochastic learning algorithm using stochastic approximation theory. Finally,\nwe establish technical conditions for almost-sure convergence and show that\nunder heavy traffic, the proposed low complexity distributive control is global\noptimal.\n",
          "  We consider an opportunistic spectrum access (OSA) problem where the\ntime-varying condition of each channel (e.g., as a result of random fading or\ncertain primary users' activities) is modeled as an arbitrary finite-state\nMarkov chain. At each instance of time, a (secondary) user probes a channel and\ncollects a certain reward as a function of the state of the channel (e.g., good\nchannel condition results in higher data rate for the user). Each channel has\npotentially different state space and statistics, both unknown to the user, who\ntries to learn which one is the best as it goes and maximizes its usage of the\nbest channel. The objective is to construct a good online learning algorithm so\nas to minimize the difference between the user's performance in total rewards\nand that of using the best channel (on average) had it known which one is the\nbest from a priori knowledge of the channel statistics (also known as the\nregret). This is a classic exploration and exploitation problem and results\nabound when the reward processes are assumed to be iid. Compared to prior work,\nthe biggest difference is that in our case the reward process is assumed to be\nMarkovian, of which iid is a special case. In addition, the reward processes\nare restless in that the channel conditions will continue to evolve independent\nof the user's actions. This leads to a restless bandit problem, for which there\nexists little result on either algorithms or performance bounds in this\nlearning context to the best of our knowledge. In this paper we introduce an\nalgorithm that utilizes regenerative cycles of a Markov chain and computes a\nsample-mean based index policy, and show that under mild conditions on the\nstate transition probabilities of the Markov chains this algorithm achieves\nlogarithmic regret uniformly over time, and that this regret bound is also\noptimal.\n",
          "  Cross-layer optimization solutions have been proposed in recent years to\nimprove the performance of network users operating in a time-varying,\nerror-prone wireless environment. However, these solutions often rely on ad-hoc\noptimization approaches, which ignore the different environmental dynamics\nexperienced at various layers by a user and violate the layered network\narchitecture of the protocol stack by requiring layers to provide access to\ntheir internal protocol parameters to other layers. This paper presents a new\ntheoretic foundation for cross-layer optimization, which allows each layer to\nmake autonomous decisions individually, while maximizing the utility of the\nwireless user by optimally determining what information needs to be exchanged\namong layers. Hence, this cross-layer framework does not change the current\nlayered architecture. Specifically, because the wireless user interacts with\nthe environment at various layers of the protocol stack, the cross-layer\noptimization problem is formulated as a layered Markov decision process (MDP)\nin which each layer adapts its own protocol parameters and exchanges\ninformation (messages) with other layers in order to cooperatively maximize the\nperformance of the wireless user. The message exchange mechanism for\ndetermining the optimal cross-layer transmission strategies has been designed\nfor both off-line optimization and on-line dynamic adaptation. We also show\nthat many existing cross-layer optimization algorithms can be formulated as\nsimplified, sub-optimal, versions of our layered MDP framework.\n",
          "  We study the problem of allocating multiple users to a set of wireless\nchannels in a decentralized manner when the channel quali- ties are\ntime-varying and unknown to the users, and accessing the same channel by\nmultiple users leads to reduced quality due to interference. In such a setting\nthe users not only need to learn the inherent channel quality and at the same\ntime the best allocations of users to channels so as to maximize the social\nwelfare. Assuming that the users adopt a certain online learning algorithm, we\ninvestigate under what conditions the socially optimal allocation is\nachievable. In particular we examine the effect of different levels of\nknowledge the users may have and the amount of communications and cooperation.\nThe general conclusion is that when the cooperation of users decreases and the\nuncertainty about channel payoffs increases it becomes harder to achieve the\nsocially opti- mal allocation.\n",
          "  We consider the design of cognitive Medium Access Control (MAC) protocols\nenabling an unlicensed (secondary) transmitter-receiver pair to communicate\nover the idle periods of a set of licensed channels, i.e., the primary network.\nThe objective is to maximize data throughput while maintaining the\nsynchronization between secondary users and avoiding interference with licensed\n(primary) users. No statistical information about the primary traffic is\nassumed to be available a-priori to the secondary user. We investigate two\ndistinct sensing scenarios. In the first, the secondary transmitter is capable\nof sensing all the primary channels, whereas it senses one channel only in the\nsecond scenario. In both cases, we propose MAC protocols that efficiently learn\nthe statistics of the primary traffic online. Our simulation results\ndemonstrate that the proposed blind protocols asymptotically achieve the\nthroughput obtained when prior knowledge of primary traffic statistics is\navailable.\n",
          "  In this paper, we propose a general cross-layer optimization framework in\nwhich we explicitly consider both the heterogeneous and dynamically changing\ncharacteristics of delay-sensitive applications and the underlying time-varying\nnetwork conditions. We consider both the independently decodable data units\n(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured\nby a directed acyclic graph (DAG). We first formulate the cross-layer design as\na non-linear constrained optimization problem by assuming complete knowledge of\nthe application characteristics and the underlying network conditions. The\nconstrained cross-layer optimization is decomposed into several cross-layer\noptimization subproblems for each DU and two master problems. The proposed\ndecomposition method determines the necessary message exchanges between layers\nfor achieving the optimal cross-layer solution. However, the attributes (e.g.\ndistortion impact, delay deadline etc) of future DUs as well as the network\nconditions are often unknown in the considered real-time applications. The\nimpact of current cross-layer actions on the future DUs can be characterized by\na state-value function in the Markov decision process (MDP) framework. Based on\nthe dynamic programming solution to the MDP, we develop a low-complexity\ncross-layer optimization algorithm using online learning for each DU\ntransmission. This online algorithm can be implemented in real-time in order to\ncope with unknown source characteristics, network dynamics and resource\nconstraints. Our numerical results demonstrate the efficiency of the proposed\nonline algorithm.\n",
          "  The problem of opportunistic spectrum access in cognitive radio networks has\nbeen recently formulated as a non-Bayesian restless multi-armed bandit problem.\nIn this problem, there are N arms (corresponding to channels) and one player\n(corresponding to a secondary user). The state of each arm evolves as a\nfinite-state Markov chain with unknown parameters. At each time slot, the\nplayer can select K < N arms to play and receives state-dependent rewards\n(corresponding to the throughput obtained given the activity of primary users).\nThe objective is to maximize the expected total rewards (i.e., total\nthroughput) obtained over multiple plays. The performance of an algorithm for\nsuch a multi-armed bandit problem is measured in terms of regret, defined as\nthe difference in expected reward compared to a model-aware genie who always\nplays the best K arms. In this paper, we propose a new continuous exploration\nand exploitation (CEE) algorithm for this problem. When no information is\navailable about the dynamics of the arms, CEE is the first algorithm to\nguarantee near-logarithmic regret uniformly over time. When some bounds\ncorresponding to the stationary state distributions and the state-dependent\nrewards are known, we show that CEE can be easily modified to achieve\nlogarithmic regret over time. In contrast, prior algorithms require additional\ninformation concerning bounds on the second eigenvalues of the transition\nmatrices in order to guarantee logarithmic regret. Finally, we show through\nnumerical simulations that CEE is more efficient than prior algorithms.\n",
          "  Water-filling is the term for the classic solution to the problem of\nallocating constrained power to a set of parallel channels to maximize the\ntotal data-rate. It is used widely in practice, for example, for power\nallocation to sub-carriers in multi-user OFDM systems such as WiMax. The\nclassic water-filling algorithm is deterministic and requires perfect knowledge\nof the channel gain to noise ratios. In this paper we consider how to do power\nallocation over stochastically time-varying (i.i.d.) channels with unknown gain\nto noise ratio distributions. We adopt an online learning framework based on\nstochastic multi-armed bandits. We consider two variations of the problem, one\nin which the goal is to find a power allocation to maximize $\\sum\\limits_i\n\\mathbb{E}[\\log(1 + SNR_i)]$, and another in which the goal is to find a power\nallocation to maximize $\\sum\\limits_i \\log(1 + \\mathbb{E}[SNR_i])$. For the\nfirst problem, we propose a \\emph{cognitive water-filling} algorithm that we\ncall CWF1. We show that CWF1 obtains a regret (defined as the cumulative gap\nover time between the sum-rate obtained by a distribution-aware genie and this\npolicy) that grows polynomially in the number of channels and logarithmically\nin time, implying that it asymptotically achieves the optimal time-averaged\nrate that can be obtained when the gain distributions are known. For the second\nproblem, we present an algorithm called CWF2, which is, to our knowledge, the\nfirst algorithm in the literature on stochastic multi-armed bandits to exploit\nnon-linear dependencies between the arms. We prove that the number of times\nCWF2 picks the incorrect power allocation is bounded by a function that is\npolynomial in the number of channels and logarithmic in time, implying that its\nfrequency of incorrect allocation tends to zero.\n",
          "  We consider the dynamics of Q-learning in two-player two-action games with a\nBoltzmann exploration mechanism. For any non-zero exploration rate the dynamics\nis dissipative, which guarantees that agent strategies converge to rest points\nthat are generally different from the game's Nash Equlibria (NE). We provide a\ncomprehensive characterization of the rest point structure for different games,\nand examine the sensitivity of this structure with respect to the noise due to\nexploration. Our results indicate that for a class of games with multiple NE\nthe asymptotic behavior of learning dynamics can undergo drastic changes at\ncritical exploration rates. Furthermore, we demonstrate that for certain games\nwith a single NE, it is possible to have additional rest points (not\ncorresponding to any NE) that persist for a finite range of the exploration\nrates and disappear when the exploration rates of both players tend to zero.\n",
          "  We study the problem of dynamic spectrum sensing and access in cognitive\nradio systems as a partially observed Markov decision process (POMDP). A group\nof cognitive users cooperatively tries to exploit vacancies in primary\n(licensed) channels whose occupancies follow a Markovian evolution. We first\nconsider the scenario where the cognitive users have perfect knowledge of the\ndistribution of the signals they receive from the primary users. For this\nproblem, we obtain a greedy channel selection and access policy that maximizes\nthe instantaneous reward, while satisfying a constraint on the probability of\ninterfering with licensed transmissions. We also derive an analytical universal\nupper bound on the performance of the optimal policy. Through simulation, we\nshow that our scheme achieves good performance relative to the upper bound and\nimproved performance relative to an existing scheme.\n  We then consider the more practical scenario where the exact distribution of\nthe signal from the primary is unknown. We assume a parametric model for the\ndistribution and develop an algorithm that can learn the true distribution,\nstill guaranteeing the constraint on the interference probability. We show that\nthis algorithm outperforms the naive design that assumes a worst case value for\nthe parameter. We also provide a proof for the convergence of the learning\nalgorithm.\n",
          "  For a large multi-hop wireless network, nodes are preferable to make\ndistributed and localized link-scheduling decisions with only interactions\namong a small number of neighbors. However, for a slowly decaying channel and\ndensely populated interferers, a small size neighborhood often results in\nnontrivial link outages and is thus insufficient for making optimal scheduling\ndecisions. A question arises how to deal with the information outside a\nneighborhood in distributed link-scheduling. In this work, we develop joint\napproximation of information and distributed link scheduling. We first apply\nmachine learning approaches to model distributed link-scheduling with complete\ninformation. We then characterize the information outside a neighborhood in\nform of residual interference as a random loss variable. The loss variable is\nfurther characterized by either a Mean Field approximation or a normal\ndistribution based on the Lyapunov central limit theorem. The approximated\ninformation outside a neighborhood is incorporated in a factor graph. This\nresults in joint approximation and distributed link-scheduling in an iterative\nfashion. Link-scheduling decisions are first made at each individual node based\non the approximated loss variables. Loss variables are then updated and used\nfor next link-scheduling decisions. The algorithm repeats between these two\nphases until convergence. Interactive iterations among these variables are\nimplemented with a message-passing algorithm over a factor graph. Simulation\nresults show that using learned information outside a neighborhood jointly with\ndistributed link-scheduling reduces the outage probability close to zero even\nfor a small neighborhood.\n",
          "  In this paper we study the online learning problem involving rested and\nrestless multiarmed bandits with multiple plays. The system consists of a\nsingle player/user and a set of K finite-state discrete-time Markov chains\n(arms) with unknown state spaces and statistics. At each time step the player\ncan play M arms. The objective of the user is to decide for each step which M\nof the K arms to play over a sequence of trials so as to maximize its long term\nreward. The restless multiarmed bandit is particularly relevant to the\napplication of opportunistic spectrum access (OSA), where a (secondary) user\nhas access to a set of K channels, each of time-varying condition as a result\nof random fading and/or certain primary users' activities.\n",
          "  In this paper, we propose a two-timescale delay-optimal dynamic clustering\nand power allocation design for downlink network MIMO systems. The dynamic\nclustering control is adaptive to the global queue state information (GQSI)\nonly and computed at the base station controller (BSC) over a longer time\nscale. On the other hand, the power allocations of all the BSs in one cluster\nare adaptive to both intra-cluster channel state information (CCSI) and\nintra-cluster queue state information (CQSI), and computed at the cluster\nmanager (CM) over a shorter time scale. We show that the two-timescale\ndelay-optimal control can be formulated as an infinite-horizon average cost\nConstrained Partially Observed Markov Decision Process (CPOMDP). By exploiting\nthe special problem structure, we shall derive an equivalent Bellman equation\nin terms of Pattern Selection Q-factor to solve the CPOMDP. To address the\ndistributive requirement and the issue of exponential memory requirement and\ncomputational complexity, we approximate the Pattern Selection Q-factor by the\nsum of Per-cluster Potential functions and propose a novel distributive online\nlearning algorithm to estimate the Per-cluster Potential functions (at each CM)\nas well as the Lagrange multipliers (LM) (at each BS). We show that the\nproposed distributive online learning algorithm converges almost surely (with\nprobability 1). By exploiting the birth-death structure of the queue dynamics,\nwe further decompose the Per-cluster Potential function into sum of Per-cluster\nPer-user Potential functions and formulate the instantaneous power allocation\nas a Per-stage QSI-aware Interference Game played among all the CMs. We also\npropose a QSI-aware Simultaneous Iterative Water-filling Algorithm (QSIWFA) and\nshow that it can achieve the Nash Equilibrium (NE).\n",
          "  In this article, a survey of several important equilibrium concepts for\ndecentralized networks is presented. The term decentralized is used here to\nrefer to scenarios where decisions (e.g., choosing a power allocation policy)\nare taken autonomously by devices interacting with each other (e.g., through\nmutual interference). The iterative long-term interaction is characterized by\nstable points of the wireless network called equilibria. The interest in these\nequilibria stems from the relevance of network stability and the fact that they\ncan be achieved by letting radio devices to repeatedly interact over time. To\nachieve these equilibria, several learning techniques, namely, the best\nresponse dynamics, fictitious play, smoothed fictitious play, reinforcement\nlearning algorithms, and regret matching, are discussed in terms of information\nrequirements and convergence properties. Most of the notions introduced here,\nfor both equilibria and learning schemes, are illustrated by a simple case\nstudy, namely, an interference channel with two transmitter-receiver pairs.\n",
          "  In this paper, spectrum access in cognitive radio networks is modeled as a\nrepeated auction game subject to monitoring and entry costs. For secondary\nusers, sensing costs are incurred as the result of primary users' activity.\nFurthermore, each secondary user pays the cost of transmissions upon successful\nbidding for a channel. Knowledge regarding other secondary users' activity is\nlimited due to the distributed nature of the network. The resulting formulation\nis thus a dynamic game with incomplete information. In this paper, an efficient\nbidding learning algorithm is proposed based on the outcome of past\ntransactions. As demonstrated through extensive simulations, the proposed\ndistributed scheme outperforms a myopic one-stage algorithm, and can achieve a\ngood balance between efficiency and fairness.\n",
          "  Despite the conventional wisdom that proactive security is superior to\nreactive security, we show that reactive security can be competitive with\nproactive security as long as the reactive defender learns from past attacks\ninstead of myopically overreacting to the last attack. Our game-theoretic model\nfollows common practice in the security literature by making worst-case\nassumptions about the attacker: we grant the attacker complete knowledge of the\ndefender's strategy and do not require the attacker to act rationally. In this\nmodel, we bound the competitive ratio between a reactive defense algorithm\n(which is inspired by online learning theory) and the best fixed proactive\ndefense. Additionally, we show that, unlike proactive defenses, this reactive\nstrategy is robust to a lack of information about the attacker's incentives and\nknowledge.\n",
          "  In this paper,we consider the restless bandit problem, which is one of the\nmost well-studied generalizations of the celebrated stochastic multi-armed\nbandit problem in decision theory. However, it is known be PSPACE-Hard to\napproximate to any non-trivial factor. Thus the optimality is very difficult to\nobtain due to its high complexity. A natural method is to obtain the greedy\npolicy considering its stability and simplicity. However, the greedy policy\nwill result in the optimality loss for its intrinsic myopic behavior generally.\nIn this paper, by analyzing one class of so-called standard reward function, we\nestablish the closed-form condition about the discounted factor \\beta such that\nthe optimality of the greedy policy is guaranteed under the discounted expected\nreward criterion, especially, the condition \\beta = 1 indicating the optimality\nof the greedy policy under the average accumulative reward criterion. Thus, the\nstandard form of reward function can easily be used to judge the optimality of\nthe greedy policy without any complicated calculation. Some examples in\ncognitive radio networks are presented to verify the effectiveness of the\nmathematical result in judging the optimality of the greedy policy.\n",
          "  This paper presents a method for automated healing as part of off-line\nautomated troubleshooting. The method combines statistical learning with\nconstraint optimization. The automated healing aims at locally optimizing radio\nresource management (RRM) or system parameters of cells with poor performance\nin an iterative manner. The statistical learning processes the data using\nLogistic Regression (LR) to extract closed form (functional) relations between\nKey Performance Indicators (KPIs) and Radio Resource Management (RRM)\nparameters. These functional relations are then processed by an optimization\nengine which proposes new parameter values. The advantage of the proposed\nformulation is the small number of iterations required by the automated healing\nmethod to converge, making it suitable for off-line implementation. The\nproposed method is applied to heal an Inter-Cell Interference Coordination\n(ICIC) process in a 3G Long Term Evolution (LTE) network which is based on\nsoft-frequency reuse scheme. Numerical simulations illustrate the benefits of\nthe proposed approach.\n",
          "  In this paper, we address the problem of global transmit power minimization\nin a self-congiguring network where radio devices are subject to operate at a\nminimum signal to interference plus noise ratio (SINR) level. We model the\nnetwork as a parallel Gaussian interference channel and we introduce a fully\ndecentralized algorithm (based on trial and error) able to statistically\nachieve a congiguration where the performance demands are met. Contrary to\nexisting solutions, our algorithm requires only local information and can learn\nstable and efficient working points by using only one bit feedback. We model\nthe network under two different game theoretical frameworks: normal form and\nsatisfaction form. We show that the converging points correspond to equilibrium\npoints, namely Nash and satisfaction equilibrium. Similarly, we provide\nsufficient conditions for the algorithm to converge in both formulations.\nMoreover, we provide analytical results to estimate the algorithm's\nperformance, as a function of the network parameters. Finally, numerical\nresults are provided to validate our theoretical conclusions. Keywords:\nLearning, power control, trial and error, Nash equilibrium, spectrum sharing.\n",
          "  In this paper, we consider the distributive queue-aware power and subband\nallocation design for a delay-optimal OFDMA uplink system with one base\nstation, $K$ users and $N_F$ independent subbands. Each mobile has an uplink\nqueue with heterogeneous packet arrivals and delay requirements. We model the\nproblem as an infinite horizon average reward Markov Decision Problem (MDP)\nwhere the control actions are functions of the instantaneous Channel State\nInformation (CSI) as well as the joint Queue State Information (QSI). To\naddress the distributive requirement and the issue of exponential memory\nrequirement and computational complexity, we approximate the subband allocation\nQ-factor by the sum of the per-user subband allocation Q-factor and derive a\ndistributive online stochastic learning algorithm to estimate the per-user\nQ-factor and the Lagrange multipliers (LM) simultaneously and determine the\ncontrol actions using an auction mechanism. We show that under the proposed\nauction mechanism, the distributive online learning converges almost surely\n(with probability 1). For illustration, we apply the proposed distributive\nstochastic learning framework to an application example with exponential packet\nsize distribution. We show that the delay-optimal power control has the {\\em\nmulti-level water-filling} structure where the CSI determines the instantaneous\npower allocation and the QSI determines the water-level. The proposed algorithm\nhas linear signaling overhead and computational complexity $\\mathcal O(KN)$,\nwhich is desirable from an implementation perspective.\n",
          "  We consider a class of fully stochastic and fully distributed algorithms,\nthat we prove to learn equilibria in games.\n  Indeed, we consider a family of stochastic distributed dynamics that we prove\nto converge weakly (in the sense of weak convergence for probabilistic\nprocesses) towards their mean-field limit, i.e an ordinary differential\nequation (ODE) in the general case. We focus then on a class of stochastic\ndynamics where this ODE turns out to be related to multipopulation replicator\ndynamics.\n  Using facts known about convergence of this ODE, we discuss the convergence\nof the initial stochastic dynamics: For general games, there might be\nnon-convergence, but when convergence of the ODE holds, considered stochastic\nalgorithms converge towards Nash equilibria. For games admitting Lyapunov\nfunctions, that we call Lyapunov games, the stochastic dynamics converge. We\nprove that any ordinal potential game, and hence any potential game is a\nLyapunov game, with a multiaffine Lyapunov function. For Lyapunov games with a\nmultiaffine Lyapunov function, we prove that this Lyapunov function is a\nsuper-martingale over the stochastic dynamics. This leads a way to provide\nbounds on their time of convergence by martingale arguments. This applies in\nparticular for many classes of games that have been considered in literature,\nincluding several load balancing game scenarios and congestion games.\n",
          "  In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are\n$N$ arms, with rewards on all arms evolving at each time as Markov chains with\nknown parameters. A player seeks to activate $K \\geq 1$ arms at each time in\norder to maximize the expected total reward obtained over multiple plays. RMAB\nis a challenging problem that is known to be PSPACE-hard in general. We\nconsider in this work the even harder non-Bayesian RMAB, in which the\nparameters of the Markov chain are assumed to be unknown \\emph{a priori}. We\ndevelop an original approach to this problem that is applicable when the\ncorresponding Bayesian problem has the structure that, depending on the known\nparameter values, the optimal solution is one of a prescribed finite set of\npolicies. In such settings, we propose to learn the optimal policy for the\nnon-Bayesian RMAB by employing a suitable meta-policy which treats each policy\nfrom this finite set as an arm in a different non-Bayesian multi-armed bandit\nproblem for which a single-arm selection policy is optimal. We demonstrate this\napproach by developing a novel sensing policy for opportunistic spectrum access\nover unknown dynamic channels. We prove that our policy achieves\nnear-logarithmic regret (the difference in expected reward compared to a\nmodel-aware genie), which leads to the same average reward that can be achieved\nby the optimal policy under a known model. This is the first such result in the\nliterature for a non-Bayesian RMAB. For our proof, we also develop a novel\ngeneralization of the Chernoff-Hoeffding bound.\n",
          "  In this paper, we propose a distributed reinforcement learning (RL) technique\ncalled distributed power control using Q-learning (DPC-Q) to manage the\ninterference caused by the femtocells on macro-users in the downlink. The DPC-Q\nleverages Q-Learning to identify the sub-optimal pattern of power allocation,\nwhich strives to maximize femtocell capacity, while guaranteeing macrocell\ncapacity level in an underlay cognitive setting. We propose two different\napproaches for the DPC-Q algorithm: namely, independent, and cooperative. In\nthe former, femtocells learn independently from each other while in the latter,\nfemtocells share some information during learning in order to enhance their\nperformance. Simulation results show that the independent approach is capable\nof mitigating the interference generated by the femtocells on macro-users.\nMoreover, the results show that cooperation enhances the performance of the\nfemtocells in terms of speed of convergence, fairness and aggregate femtocell\ncapacity.\n",
          "  In this paper, we consider the problem of real-time transmission scheduling\nover time-varying channels. We first formulate the transmission scheduling\nproblem as a Markov decision process (MDP) and systematically unravel the\nstructural properties (e.g. concavity in the state-value function and\nmonotonicity in the optimal scheduling policy) exhibited by the optimal\nsolutions. We then propose an online learning algorithm which preserves these\nstructural properties and achieves -optimal solutions for an arbitrarily small\n. The advantages of the proposed online method are that: (i) it does not\nrequire a priori knowledge of the traffic arrival and channel statistics and\n(ii) it adaptively approximates the state-value functions using piece-wise\nlinear functions and has low storage and computation complexity. We also extend\nthe proposed low-complexity online learning solution to the prioritized data\ntransmission. The simulation results demonstrate that the proposed method\nachieves significantly better utility (or delay)-energy trade-offs when\ncomparing to existing state-of-art online optimization methods.\n",
          "  In this paper, we consider delay-optimal power and subcarrier allocation\ndesign for OFDMA systems with $N_F$ subcarriers, $K$ mobiles and one base\nstation. There are $K$ queues at the base station for the downlink traffic to\nthe $K$ mobiles with heterogeneous packet arrivals and delay requirements. We\nshall model the problem as a $K$-dimensional infinite horizon average reward\nMarkov Decision Problem (MDP) where the control actions are assumed to be a\nfunction of the instantaneous Channel State Information (CSI) as well as the\njoint Queue State Information (QSI). This problem is challenging because it\ncorresponds to a stochastic Network Utility Maximization (NUM) problem where\ngeneral solution is still unknown. We propose an {\\em online stochastic value\niteration} solution using {\\em stochastic approximation}. The proposed power\ncontrol algorithm, which is a function of both the CSI and the QSI, takes the\nform of multi-level water-filling. We prove that under two mild conditions in\nTheorem 1 (One is the stepsize condition. The other is the condition on\naccessibility of the Markov Chain, which can be easily satisfied in most of the\ncases we are interested.), the proposed solution converges to the optimal\nsolution almost surely (with probability 1) and the proposed framework offers a\npossible solution to the general stochastic NUM problem. By exploiting the\nbirth-death structure of the queue dynamics, we obtain a reduced complexity\ndecomposed solution with linear $\\mathcal{O}(KN_F)$ complexity and\n$\\mathcal{O}(K)$ memory requirement.\n",
          "  This paper introduces a machine learning based collaborative multi-band\nspectrum sensing policy for cognitive radios. The proposed sensing policy\nguides secondary users to focus the search of unused radio spectrum to those\nfrequencies that persistently provide them high data rate. The proposed policy\nis based on machine learning, which makes it adaptive with the temporally and\nspatially varying radio spectrum. Furthermore, there is no need for dynamic\nmodeling of the primary activity since it is implicitly learned over time.\nEnergy efficiency is achieved by minimizing the number of assigned sensors per\neach subband under a constraint on miss detection probability. It is important\nto control the missed detections because they cause collisions with primary\ntransmissions and lead to retransmissions at both the primary and secondary\nuser. Simulations show that the proposed machine learning based sensing policy\nimproves the overall throughput of the secondary network and improves the\nenergy efficiency while controlling the miss detection probability.\n",
          "  This paper suggests the use of intelligent network-aware processing agents in\nwireless local area network drivers to generate metrics for bandwidth\nestimation based on real-time channel statistics to enable wireless multimedia\napplication adaptation. Various configurations in the wireless digital home are\nstudied and the experimental results with performance variations are presented.\n",
          "  In a dynamic heterogeneous environment, such as pervasive and ubiquitous\ncomputing, context-aware adaptation is a key concept to meet the varying\nrequirements of different users. Connectivity is an important context source\nthat can be utilized for optimal management of diverse networking resources.\nApplication QoS (Quality of service) is another important issue that should be\ntaken into consideration for design of a context-aware system. This paper\npresents connectivity from the view point of context awareness, identifies\nvarious relevant raw connectivity contexts, and discusses how high-level\ncontext information can be abstracted from the raw context information.\nFurther, rich context information is utilized in various policy representation\nwith respect to user profile and preference, application characteristics,\ndevice capability, and network QoS conditions. Finally, a context-aware\nend-to-end evaluation algorithm is presented for adaptive connectivity\nmanagement in a multi-access wireless network. Unlike the currently existing\nalgorithms, the proposed algorithm takes into account user QoS parameters, and\ntherefore, it is more practical.\n",
          "  The new model that we present in this paper is introduced in the context of\nguaranteed QoS and resources management in the inter-domain routing framework.\nThis model, called the stock model, is based on a reverse cascade approach and\nis applied in a distributed context. So transit providers have to learn the\nright capacities to buy and to stock and, therefore learning theory is applied\nthrough an iterative process. We show that transit providers manage to learn\nhow to strategically choose their capacities on each route in order to maximize\ntheir benefits, despite the very incomplete information. Finally, we provide\nand analyse some simulation results given by the application of the model in a\nsimple case where the model quickly converges to a stable state.\n",
          "  We introduce in this paper a new algorithm for Multi-Armed Bandit (MAB)\nproblems. A machine learning paradigm popular within Cognitive Network related\ntopics (e.g., Spectrum Sensing and Allocation). We focus on the case where the\nrewards are exponentially distributed, which is common when dealing with\nRayleigh fading channels. This strategy, named Multiplicative Upper Confidence\nBound (MUCB), associates a utility index to every available arm, and then\nselects the arm with the highest index. For every arm, the associated index is\nequal to the product of a multiplicative factor by the sample mean of the\nrewards collected by this arm. We show that the MUCB policy has a low\ncomplexity and is order optimal.\n",
          "  We consider the task of opportunistic channel access in a primary system\ncomposed of independent Gilbert-Elliot channels where the secondary (or\nopportunistic) user does not dispose of a priori information regarding the\nstatistical characteristics of the system. It is shown that this problem may be\ncast into the framework of model-based learning in a specific class of\nPartially Observed Markov Decision Processes (POMDPs) for which we introduce an\nalgorithm aimed at striking an optimal tradeoff between the exploration (or\nestimation) and exploitation requirements. We provide finite horizon regret\nbounds for this algorithm as well as a numerical evaluation of its performance\nin the single channel model as well as in the case of stochastically identical\nchannels.\n",
          "  We consider the problem of distributed convergence to efficient outcomes in\ncoordination games through dynamics based on aspiration learning. Under\naspiration learning, a player continues to play an action as long as the\nrewards received exceed a specified aspiration level. Here, the aspiration\nlevel is a fading memory average of past rewards, and these levels also are\nsubject to occasional random perturbations. A player becomes dissatisfied\nwhenever a received reward is less than the aspiration level, in which case the\nplayer experiments with a probability proportional to the degree of\ndissatisfaction. Our first contribution is the characterization of the\nasymptotic behavior of the induced Markov chain of the iterated process in\nterms of an equivalent finite-state Markov chain. We then characterize\nexplicitly the behavior of the proposed aspiration learning in a generalized\nversion of coordination games, examples of which include network formation and\ncommon-pool games. In particular, we show that in generic coordination games\nthe frequency at which an efficient action profile is played can be made\narbitrarily large. Although convergence to efficient outcomes is desirable, in\nseveral coordination games, such as common-pool games, attainability of fair\noutcomes, i.e., sequences of plays at which players experience highly rewarding\nreturns with the same frequency, might also be of special interest. To this\nend, we demonstrate through analysis and simulations that aspiration learning\nalso establishes fair outcomes in all symmetric coordination games, including\ncommon-pool games.\n",
          "  In our previous work, we proposed a systematic cross-layer framework for\ndynamic multimedia systems, which allows each layer to make autonomous and\nforesighted decisions that maximize the system's long-term performance, while\nmeeting the application's real-time delay constraints. The proposed solution\nsolved the cross-layer optimization offline, under the assumption that the\nmultimedia system's probabilistic dynamics were known a priori. In practice,\nhowever, these dynamics are unknown a priori and therefore must be learned\nonline. In this paper, we address this problem by allowing the multimedia\nsystem layers to learn, through repeated interactions with each other, to\nautonomously optimize the system's long-term performance at run-time. We\npropose two reinforcement learning algorithms for optimizing the system under\ndifferent design constraints: the first algorithm solves the cross-layer\noptimization in a centralized manner, and the second solves it in a\ndecentralized manner. We analyze both algorithms in terms of their required\ncomputation, memory, and inter-layer communication overheads. After noting that\nthe proposed reinforcement learning algorithms learn too slowly, we introduce a\ncomplementary accelerated learning algorithm that exploits partial knowledge\nabout the system's dynamics in order to dramatically improve the system's\nperformance. In our experiments, we demonstrate that decentralized learning can\nperform as well as centralized learning, while enabling the layers to act\nautonomously. Additionally, we show that existing application-independent\nreinforcement learning algorithms, and existing myopic learning algorithms\ndeployed in multimedia systems, perform significantly worse than our proposed\napplication-aware and foresighted learning methods.\n",
          "  We consider the problem of energy-efficient point-to-point transmission of\ndelay-sensitive data (e.g. multimedia data) over a fading channel. Existing\nresearch on this topic utilizes either physical-layer centric solutions, namely\npower-control and adaptive modulation and coding (AMC), or system-level\nsolutions based on dynamic power management (DPM); however, there is currently\nno rigorous and unified framework for simultaneously utilizing both\nphysical-layer centric and system-level techniques to achieve the minimum\npossible energy consumption, under delay constraints, in the presence of\nstochastic and a priori unknown traffic and channel conditions. In this report,\nwe propose such a framework. We formulate the stochastic optimization problem\nas a Markov decision process (MDP) and solve it online using reinforcement\nlearning. The advantages of the proposed online method are that (i) it does not\nrequire a priori knowledge of the traffic arrival and channel statistics to\ndetermine the jointly optimal power-control, AMC, and DPM policies; (ii) it\nexploits partial information about the system so that less information needs to\nbe learned than when using conventional reinforcement learning algorithms; and\n(iii) it obviates the need for action exploration, which severely limits the\nadaptation speed and run-time performance of conventional reinforcement\nlearning algorithms. Our results show that the proposed learning algorithms can\nconverge up to two orders of magnitude faster than a state-of-the-art learning\nalgorithm for physical layer power-control and up to three orders of magnitude\nfaster than conventional reinforcement learning algorithms.\n",
          "  In a sensor network, in practice, the communication among sensors is subject\nto:(1) errors or failures at random times; (3) costs; and(2) constraints since\nsensors and networks operate under scarce resources, such as power, data rate,\nor communication. The signal-to-noise ratio (SNR) is usually a main factor in\ndetermining the probability of error (or of communication failure) in a link.\nThese probabilities are then a proxy for the SNR under which the links operate.\nThe paper studies the problem of designing the topology, i.e., assigning the\nprobabilities of reliable communication among sensors (or of link failures) to\nmaximize the rate of convergence of average consensus, when the link\ncommunication costs are taken into account, and there is an overall\ncommunication budget constraint. To consider this problem, we address a number\nof preliminary issues: (1) model the network as a random topology; (2)\nestablish necessary and sufficient conditions for mean square sense (mss) and\nalmost sure (a.s.) convergence of average consensus when network links fail;\nand, in particular, (3) show that a necessary and sufficient condition for both\nmss and a.s. convergence is for the algebraic connectivity of the mean graph\ndescribing the network topology to be strictly positive. With these results, we\nformulate topology design, subject to random link failures and to a\ncommunication cost constraint, as a constrained convex optimization problem to\nwhich we apply semidefinite programming techniques. We show by an extensive\nnumerical study that the optimal design improves significantly the convergence\nspeed of the consensus algorithm and can achieve the asymptotic performance of\na non-random network at a fraction of the communication cost.\n",
          "  In this paper, we model the various wireless users in a cognitive radio\nnetwork as a collection of selfish, autonomous agents that strategically\ninteract in order to acquire the dynamically available spectrum opportunities.\nOur main focus is on developing solutions for wireless users to successfully\ncompete with each other for the limited and time-varying spectrum\nopportunities, given the experienced dynamics in the wireless network. We\ncategorize these dynamics into two types: one is the disturbance due to the\nenvironment (e.g. wireless channel conditions, source traffic characteristics,\netc.) and the other is the impact caused by competing users. To analyze the\ninteractions among users given the environment disturbance, we propose a\ngeneral stochastic framework for modeling how the competition among users for\nspectrum opportunities evolves over time. At each stage of the dynamic resource\nallocation, a central spectrum moderator auctions the available resources and\nthe users strategically bid for the required resources. The joint bid actions\naffect the resource allocation and hence, the rewards and future strategies of\nall users. Based on the observed resource allocation and corresponding rewards\nfrom previous allocations, we propose a best response learning algorithm that\ncan be deployed by wireless users to improve their bidding policy at each\nstage. The simulation results show that by deploying the proposed best response\nlearning algorithm, the wireless users can significantly improve their own\nperformance in terms of both the packet loss rate and the incurred cost for the\nused resources.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_bandit_reward_optimal",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_bandit_reward_optimal"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.677240371704102,
          7.671177864074707,
          8.195735931396484,
          8.207174301147461,
          7.966210842132568,
          7.637863636016846,
          8.3418607711792,
          8.026938438415527,
          7.735714435577393,
          8.278619766235352,
          7.990264892578125,
          8.328314781188965,
          8.050725936889648,
          8.067362785339355,
          8.351099967956543,
          7.82692289352417,
          7.999490737915039,
          7.594069957733154,
          8.048360824584961,
          8.206716537475586,
          7.812440395355225,
          8.285743713378906,
          8.030854225158691,
          8.061288833618164,
          7.63364839553833,
          7.783748149871826,
          8.221807479858398,
          8.039036750793457,
          8.261004447937012,
          7.774788856506348,
          7.6549506187438965,
          8.086307525634766,
          8.2667236328125,
          8.309656143188477,
          8.146161079406738,
          8.363533973693848,
          8.390486717224121,
          8.089369773864746,
          7.921666622161865,
          7.901926517486572,
          7.649017333984375,
          8.230624198913574,
          8.315247535705566,
          8.138728141784668,
          8.098493576049805,
          8.037091255187988
         ],
         "y": [
          6.672999858856201,
          6.706974983215332,
          6.88906717300415,
          6.907257556915283,
          6.9512834548950195,
          6.958860874176025,
          7.031639099121094,
          7.080493450164795,
          6.648488521575928,
          7.0544867515563965,
          6.929126262664795,
          7.031235694885254,
          6.864344120025635,
          6.887848377227783,
          7.036902904510498,
          7.024519920349121,
          7.003537178039551,
          6.530937671661377,
          6.894675254821777,
          7.082696914672852,
          6.957563400268555,
          7.026680946350098,
          6.839822292327881,
          6.867753505706787,
          6.698014259338379,
          7.053637981414795,
          7.004653453826904,
          6.845625877380371,
          7.017149925231934,
          6.678681373596191,
          7.010138988494873,
          6.870317459106445,
          7.023499011993408,
          7.041936874389648,
          6.918323993682861,
          7.051652908325195,
          7.042646408081055,
          6.978527069091797,
          7.012351036071777,
          6.989871025085449,
          6.694002151489258,
          6.986813068389893,
          6.99780797958374,
          7.0812788009643555,
          6.8897175788879395,
          6.928129196166992
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Structured classification tasks such as sequence labeling and dependency\nparsing have seen much interest by the Natural Language Processing and the\nmachine learning communities. Several online learning algorithms were adapted\nfor structured tasks such as Perceptron, Passive- Aggressive and the recently\nintroduced Confidence-Weighted learning . These online algorithms are easy to\nimplement, fast to train and yield state-of-the-art performance. However,\nunlike probabilistic models like Hidden Markov Model and Conditional random\nfields, these methods generate models that output merely a prediction with no\nadditional information regarding confidence in the correctness of the output.\nIn this work we fill the gap proposing few alternatives to compute the\nconfidence in the output of non-probabilistic algorithms.We show how to compute\nconfidence estimates in the prediction such that the confidence reflects the\nprobability that the word is labeled correctly. We then show how to use our\nmethods to detect mislabeled words, trade recall for precision and active\nlearning. We evaluate our methods on four noun-phrase chunking and named entity\nrecognition sequence labeling tasks, and on dependency parsing for 14\nlanguages.\n",
          "  PRISM is an extension of Prolog with probabilistic predicates and built-in\nsupport for expectation-maximization learning. Constraint Handling Rules (CHR)\nis a high-level programming language based on multi-headed multiset rewrite\nrules.\n  In this paper, we introduce a new probabilistic logic formalism, called\nCHRiSM, based on a combination of CHR and PRISM. It can be used for high-level\nrapid prototyping of complex statistical models by means of \"chance rules\". The\nunderlying PRISM system can then be used for several probabilistic inference\ntasks, including probability computation and parameter learning. We define the\nCHRiSM language in terms of syntax and operational semantics, and illustrate it\nwith examples. We define the notion of ambiguous programs and define a\ndistribution semantics for unambiguous programs. Next, we describe an\nimplementation of CHRiSM, based on CHR(PRISM). We discuss the relation between\nCHRiSM and other probabilistic logic programming languages, in particular PCHR.\nFinally we identify potential application domains.\n",
          "  It is a high-quality algorithm for hierarchical clustering of large software\nsource code. This effectively allows to break the complexity of tens of\nmillions lines of source code, so that a human software engineer can comprehend\na software system at high level by means of looking at its architectural\ndiagram that is reconstructed automatically from the source code of the\nsoftware system. The architectural diagram shows a tree of subsystems having\nOOP classes in its leaves (in the other words, a nested software\ndecomposition). The tool reconstructs the missing\n(inconsistent/incomplete/inexistent) architectural documentation for a software\nsystem from its source code. This facilitates software maintenance: change\nrequests can be performed substantially faster. Simply speaking, this unique\ntool allows to lift the comprehensible grain of object-oriented software\nsystems from OOP class-level to subsystem-level. It is estimated that a\ncommercial tool, developed on the basis of this work, will reduce software\nmaintenance expenses 10 times on the current needs, and will allow to implement\nnext-generation software systems which are currently too complex to be within\nthe range of human comprehension, therefore can't yet be designed or\nimplemented. Implemented prototype in Open Source:\nhttp://sourceforge.net/p/insoar/code-0/1/tree/\n",
          "  Thanks to the Eslo1 (\"Enqu\\^ete sociolinguistique d'Orl\\'eans\", i.e.\n\"Sociolinguistic Inquiery of Orl\\'eans\") campain, a large oral corpus has been\ngathered and transcribed in a textual format. The purpose of the work presented\nhere is to associate a morpho-syntactic label to each unit of this corpus. To\nthis aim, we have first studied the specificities of the necessary labels, and\ntheir various possible levels of description. This study has led to a new\noriginal hierarchical structuration of labels. Then, considering that our new\nset of labels was different from the one used in every available software, and\nthat these softwares usually do not fit for oral data, we have built a new\nlabeling tool by a Machine Learning approach, from data labeled by Cordial and\ncorrected by hand. We have applied linear CRF (Conditional Random Fields)\ntrying to take the best possible advantage of the linguistic knowledge that was\nused to define the set of labels. We obtain an accuracy between 85 and 90%,\ndepending of the parameters used.\n",
          "  Analogical reasoning depends fundamentally on the ability to learn and\ngeneralize about relations between objects. We develop an approach to\nrelational learning which, given a set of pairs of objects\n$\\mathbf{S}=\\{A^{(1)}:B^{(1)},A^{(2)}:B^{(2)},\\ldots,A^{(N)}:B ^{(N)}\\}$,\nmeasures how well other pairs A:B fit in with the set $\\mathbf{S}$. Our work\naddresses the following question: is the relation between objects A and B\nanalogous to those relations found in $\\mathbf{S}$? Such questions are\nparticularly relevant in information retrieval, where an investigator might\nwant to search for analogous pairs of objects that match the query set of\ninterest. There are many ways in which objects can be related, making the task\nof measuring analogies very challenging. Our approach combines a similarity\nmeasure on function spaces with Bayesian analysis to produce a ranking. It\nrequires data containing features of the objects of interest and a link matrix\nspecifying which relationships exist; no further attributes of such\nrelationships are necessary. We illustrate the potential of our method on text\nanalysis and information networks. An application on discovering functional\ninteractions between pairs of proteins is discussed in detail, where we show\nthat our approach can work in practice even if a small set of protein pairs is\nprovided.\n",
          "  The recognition, involvement, and description of main actors influences the\nstory line of the whole text. This is of higher importance as the text per se\nrepresents a flow of words and expressions that once it is read it is lost. In\nthis respect, the understanding of a text and moreover on how the actor exactly\nbehaves is not only a major concern: as human beings try to store a given input\non short-term memory while associating diverse aspects and actors with\nincidents, the following approach represents a virtual architecture, where\ncollocations are concerned and taken as the associative completion of the\nactors' acting. Once that collocations are discovered, they become managed in\nseparated memory blocks broken down by the actors. As for human beings, the\nmemory blocks refer to associative mind-maps. We then present several priority\nfunctions to represent the actual temporal situation inside a mind-map to\nenable the user to reconstruct the recent events from the discovered temporal\nresults.\n",
          "  Pattern learning in an important problem in Natural Language Processing\n(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved\nto be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)\nshowed great advantages on other tasks, such as machine translation. In this\narticle, we first formalize EPL, and then show that the probability given by an\nEPL model is constant-factor approximation of the probability given by an\nensemble method that integrates exponential number of models obtained with\nvarious segmentations of the training data. This work for the first time\nprovides theoretical justification for the widely used EPL algorithm in NLP,\nwhich was previously viewed as a flawed heuristic method. Better understanding\nof EPL may lead to improved pattern learning algorithms in future.\n",
          "  Nowadays, supervised learning is commonly used in many domains. Indeed, many\nworks propose to learn new knowledge from examples that translate the expected\nbehaviour of the considered system. A key issue of supervised learning concerns\nthe description language used to represent the examples. In this paper, we\npropose a method to evaluate the feature set used to describe them. Our method\nis based on the computation of the consistency of the example base. We carried\nout a case study in the domain of geomatic in order to evaluate the sets of\nmeasures used to characterise geographic objects. The case study shows that our\nmethod allows to give relevant evaluations of measure sets.\n",
          "  This article presents a model which is capable of learning and abstracting\nnew concepts based on comparing observations and finding the resemblance\nbetween the observations. In the model, the new observations are compared with\nthe templates which have been derived from the previous experiences. In the\nfirst stage, the objects are first represented through a geometric description\nwhich is used for finding the object boundaries and a descriptor which is\ninspired by the human visual system and then they are fed into the model. Next,\nthe new observations are identified through comparing them with the\npreviously-learned templates and are used for producing new templates. The\ncomparisons are made based on measures like Euclidean or correlation distance.\nThe new template is created by applying onion-pealing algorithm. The algorithm\nconsecutively uses convex hulls which are made by the points representing the\nobjects. If the new observation is remarkably similar to one of the observed\ncategories, it is no longer utilized in creating a new template. The existing\ntemplates are used to provide a description of the new observation. This\ndescription is provided in the templates space. Each template represents a\ndimension of the feature space. The degree of the resemblance each template\nbears to each object indicates the value associated with the object in that\ndimension of the templates space. In this way, the description of the new\nobservation becomes more accurate and detailed as the time passes and the\nexperiences increase. We have used this model for learning and recognizing the\nnew polygons in the polygon space. Representing the polygons was made possible\nthrough employing a geometric method and a method inspired by human visual\nsystem. Various implementations of the model have been compared. The evaluation\nresults of the model prove its efficiency in learning and deriving new\ntemplates.\n",
          "  Many AI researchers and cognitive scientists have argued that analogy is the\ncore of cognition. The most influential work on computational modeling of\nanalogy-making is Structure Mapping Theory (SMT) and its implementation in the\nStructure Mapping Engine (SME). A limitation of SME is the requirement for\ncomplex hand-coded representations. We introduce the Latent Relation Mapping\nEngine (LRME), which combines ideas from SME and Latent Relational Analysis\n(LRA) in order to remove the requirement for hand-coded representations. LRME\nbuilds analogical mappings between lists of words, using a large corpus of raw\ntext to automatically discover the semantic relations among the words. We\nevaluate LRME on a set of twenty analogical mapping problems, ten based on\nscientific analogies and ten based on common metaphors. LRME achieves\nhuman-level performance on the twenty problems. We compare LRME with a variety\nof alternative approaches and find that they are not able to reach the same\nlevel of performance.\n",
          "  In this paper we propose a use-case-driven iterative design methodology for\nnormative frameworks, also called virtual institutions, which are used to\ngovern open systems. Our computational model represents the normative framework\nas a logic program under answer set semantics (ASP). By means of an inductive\nlogic programming approach, implemented using ASP, it is possible to synthesise\nnew rules and revise the existing ones. The learning mechanism is guided by the\ndesigner who describes the desired properties of the framework through use\ncases, comprising (i) event traces that capture possible scenarios, and (ii) a\nstate that describes the desired outcome. The learning process then proposes\nadditional rules, or changes to current rules, to satisfy the constraints\nexpressed in the use cases. Thus, the contribution of this paper is a process\nfor the elaboration and revision of a normative framework by means of a\nsemi-automatic and iterative process driven from specifications of\n(un)desirable behaviour. The process integrates a novel and general methodology\nfor theory revision based on ASP.\n",
          "  Many real world problems can be expressed as optimisation problems. Solving\nthis kind of problems means to find, among all possible solutions, the one that\nmaximises an evaluation function. One approach to solve this kind of problem is\nto use an informed search strategy. The principle of this kind of strategy is\nto use problem-specific knowledge beyond the definition of the problem itself\nto find solutions more efficiently than with an uninformed strategy. This kind\nof strategy demands to define problem-specific knowledge (heuristics). The\nefficiency and the effectiveness of systems based on it directly depend on the\nused knowledge quality. Unfortunately, acquiring and maintaining such knowledge\ncan be fastidious. The objective of the work presented in this paper is to\npropose an automatic knowledge revision approach for systems based on an\ninformed tree search strategy. Our approach consists in analysing the system\nexecution logs and revising knowledge based on these logs by modelling the\nrevision problem as a knowledge space exploration problem. We present an\nexperiment we carried out in an application domain where informed search\nstrategies are often used: cartographic generalisation.\n",
          "  The contribution of this paper is to provide a semantic model (using soft\nconstraints) of the words used by web-users to describe objects in a language\ngame; a game in which one user describes a selected object of those composing\nthe scene, and another user has to guess which object has been described. The\ngiven description needs to be non ambiguous and accurate enough to allow other\nusers to guess the described shape correctly.\n  To build these semantic models the descriptions need to be analyzed to\nextract the syntax and words' classes used. We have modeled the meaning of\nthese descriptions using soft constraints as a way for grounding the meaning.\n  The descriptions generated by the system took into account the context of the\nobject to avoid ambiguous descriptions, and allowed users to guess the\ndescribed object correctly 72% of the times.\n",
          "  An explanation for the acquisition of word-object mappings is the associative\nlearning in a cross-situational scenario. Here we present analytical results of\nthe performance of a simple associative learning algorithm for acquiring a\none-to-one mapping between $N$ objects and $N$ words based solely on the\nco-occurrence between objects and words. In particular, a learning trial in our\nlearning scenario consists of the presentation of $C + 1 < N$ objects together\nwith a target word, which refers to one of the objects in the context. We find\nthat the learning times are distributed exponentially and the learning rates\nare given by $\\ln{[\\frac{N(N-1)}{C + (N-1)^{2}}]}$ in the case the $N$ target\nwords are sampled randomly and by $\\frac{1}{N} \\ln [\\frac{N-1}{C}] $ in the\ncase they follow a deterministic presentation sequence. This learning\nperformance is much superior to those exhibited by humans and more realistic\nlearning algorithms in cross-situational experiments. We show that introduction\nof discrimination limitations using Weber's law and forgetting reduce the\nperformance of the associative algorithm to the human level.\n",
          "  Nous pr\\'esentons dans cette contribution une approche \\`a la fois symbolique\net probabiliste permettant d'extraire l'information sur la segmentation du\nsignal de parole \\`a partir d'information prosodique. Nous utilisons pour ce\nfaire des grammaires probabilistes poss\\'edant une structure hi\\'erarchique\nminimale. La phase de construction des grammaires ainsi que leur pouvoir de\npr\\'ediction sont \\'evalu\\'es qualitativement ainsi que quantitativement.\n  -----\n  Methodologically oriented, the present work sketches an approach for prosodic\ninformation retrieval and speech segmentation, based on both symbolic and\nprobabilistic information. We have recourse to probabilistic grammars, within\nwhich we implement a minimal hierarchical structure. Both the stages of\nprobabilistic grammar building and its testing in prediction are explored and\nquantitatively and qualitatively evaluated.\n",
          "  The past few years have seen a surge of interest in the field of\nprobabilistic logic learning and statistical relational learning. In this\nendeavor, many probabilistic logics have been developed. ProbLog is a recent\nprobabilistic extension of Prolog motivated by the mining of large biological\nnetworks. In ProbLog, facts can be labeled with probabilities. These facts are\ntreated as mutually independent random variables that indicate whether these\nfacts belong to a randomly sampled program. Different kinds of queries can be\nposed to ProbLog programs. We introduce algorithms that allow the efficient\nexecution of these queries, discuss their implementation on top of the\nYAP-Prolog system, and evaluate their performance in the context of large\nnetworks of biological entities.\n",
          "  A database of objects discovered in houses in the Roman city of Pompeii\nprovides a unique view of ordinary life in an ancient city. Experts have used\nthis collection to study the structure of Roman households, exploring the\ndistribution and variability of tasks in architectural spaces, but such\napproaches are necessarily affected by modern cultural assumptions. In this\nstudy we present a data-driven approach to household archeology, treating it as\nan unsupervised labeling problem. This approach scales to large data sets and\nprovides a more objective complement to human interpretation.\n",
          "  We propose a unified neural network architecture and learning algorithm that\ncan be applied to various natural language processing tasks including:\npart-of-speech tagging, chunking, named entity recognition, and semantic role\nlabeling. This versatility is achieved by trying to avoid task-specific\nengineering and therefore disregarding a lot of prior knowledge. Instead of\nexploiting man-made input features carefully optimized for each task, our\nsystem learns internal representations on the basis of vast amounts of mostly\nunlabeled training data. This work is then used as a basis for building a\nfreely available tagging system with good performance and minimal computational\nrequirements.\n",
          "  Formal Concept Analysis (FCA) begins from a context, given as a binary\nrelation between some objects and some attributes, and derives a lattice of\nconcepts, where each concept is given as a set of objects and a set of\nattributes, such that the first set consists of all objects that satisfy all\nattributes in the second, and vice versa. Many applications, though, provide\ncontexts with quantitative information, telling not just whether an object\nsatisfies an attribute, but also quantifying this satisfaction. Contexts in\nthis form arise as rating matrices in recommender systems, as occurrence\nmatrices in text analysis, as pixel intensity matrices in digital image\nprocessing, etc. Such applications have attracted a lot of attention, and\nseveral numeric extensions of FCA have been proposed. We propose the framework\nof proximity sets (proxets), which subsume partially ordered sets (posets) as\nwell as metric spaces. One feature of this approach is that it extracts from\nquantified contexts quantified concepts, and thus allows full use of the\navailable information. Another feature is that the categorical approach allows\nanalyzing any universal properties that the classical FCA and the new versions\nmay have, and thus provides structural guidance for aligning and combining the\napproaches.\n",
          "  It has been argued that analogy is the core of cognition. In AI research,\nalgorithms for analogy are often limited by the need for hand-coded high-level\nrepresentations as input. An alternative approach is to use high-level\nperception, in which high-level representations are automatically generated\nfrom raw data. Analogy perception is the process of recognizing analogies using\nhigh-level perception. We present PairClass, an algorithm for analogy\nperception that recognizes lexical proportional analogies using representations\nthat are automatically generated from a large corpus of raw textual data. A\nproportional analogy is an analogy of the form A:B::C:D, meaning \"A is to B as\nC is to D\". A lexical proportional analogy is a proportional analogy with\nwords, such as carpenter:wood::mason:stone. PairClass represents the semantic\nrelations between two words using a high-dimensional feature vector, in which\nthe elements are based on frequencies of patterns in the corpus. PairClass\nrecognizes analogies by applying standard supervised machine learning\ntechniques to the feature vectors. We show how seven different tests of word\ncomprehension can be framed as problems of analogy perception and we then apply\nPairClass to the seven resulting sets of analogy perception problems. We\nachieve competitive results on all seven tests. This is the first time a\nuniform approach has handled such a range of tests of word comprehension.\n",
          "  Many real world problems can be defined as optimisation problems in which the\naim is to maximise an objective function. The quality of obtained solution is\ndirectly linked to the pertinence of the used objective function. However,\ndesigning such function, which has to translate the user needs, is usually\nfastidious. In this paper, a method to help user objective functions designing\nis proposed. Our approach, which is highly interactive, is based on man machine\ndialogue and more particularly on the comparison of problem instance solutions\nby the user. We propose an experiment in the domain of cartographic\ngeneralisation that shows promising results.\n",
          "  Many databases store data in relational format, with different types of\nentities and information about links between the entities. The field of\nstatistical-relational learning (SRL) has developed a number of new statistical\nmodels for such data. In this paper we focus on learning class-level or\nfirst-order dependencies, which model the general database statistics over\nattributes of linked objects and links (e.g., the percentage of A grades given\nin computer science classes). Class-level statistical relationships are\nimportant in themselves, and they support applications like policy making,\nstrategic planning, and query optimization. Most current SRL methods find\nclass-level dependencies, but their main task is to support instance-level\npredictions about the attributes or links of specific entities. We focus only\non class-level prediction, and describe algorithms for learning class-level\nmodels that are orders of magnitude faster for this task. Our algorithms learn\nBayes nets with relational structure, leveraging the efficiency of single-table\nnonrelational Bayes net learners. An evaluation of our methods on three data\nsets shows that they are computationally feasible for realistic table sizes,\nand that the learned structures represent the statistical information in the\ndatabases well. After learning compiles the database statistics into a Bayes\nnet, querying these statistics via Bayes net inference is faster than with SQL\nqueries, and does not depend on the size of the database.\n",
          "  Most image-search approaches today are based on the text based tags\nassociated with the images which are mostly human generated and are subject to\nvarious kinds of errors. The results of a query to the image database thus can\noften be misleading and may not satisfy the requirements of the user. In this\nwork we propose our approach to automate this tagging process of images, where\nimage results generated can be fine filtered based on a probabilistic tagging\nmechanism. We implement a tool which helps to automate the tagging process by\nmaintaining a training database, wherein the system is trained to identify\ncertain set of input images, the results generated from which are used to\ncreate a probabilistic tagging mechanism. Given a certain set of segments in an\nimage it calculates the probability of presence of particular keywords. This\nprobability table is further used to generate the candidate tags for input\nimages.\n",
          "  We present an algorithmic framework for learning multiple related tasks. Our\nframework exploits a form of prior knowledge that relates the output spaces of\nthese tasks. We present PAC learning results that analyze the conditions under\nwhich such learning is possible. We present results on learning a shallow\nparser and named-entity recognition system that exploits our framework, showing\nconsistent improvements over baseline methods.\n",
          "  We develop, analyze, and evaluate a novel, supervised, specific-to-general\nlearner for a simple temporal logic and use the resulting algorithm to learn\nvisual event definitions from video sequences. First, we introduce a simple,\npropositional, temporal, event-description language called AMA that is\nsufficiently expressive to represent many events yet sufficiently restrictive\nto support learning. We then give algorithms, along with lower and upper\ncomplexity bounds, for the subsumption and generalization problems for AMA\nformulas. We present a positive-examples--only specific-to-general learning\nmethod based on these algorithms. We also present a polynomial-time--computable\n``syntactic'' subsumption test that implies semantic subsumption without being\nequivalent to it. A generalization algorithm based on syntactic subsumption can\nbe used in place of semantic generalization to improve the asymptotic\ncomplexity of the resulting learning algorithm. Finally, we apply this\nalgorithm to the task of learning relational event definitions from video and\nshow that it yields definitions that are competitive with hand-coded ones.\n",
          "  Computers understand very little of the meaning of human language. This\nprofoundly limits our ability to give instructions to computers, the ability of\ncomputers to explain their actions to us, and the ability of computers to\nanalyse and process text. Vector space models (VSMs) of semantics are beginning\nto address these limits. This paper surveys the use of VSMs for semantic\nprocessing of text. We organize the literature on VSMs according to the\nstructure of the matrix in a VSM. There are currently three broad classes of\nVSMs, based on term-document, word-context, and pair-pattern matrices, yielding\nthree classes of applications. We survey a broad range of applications in these\nthree categories and we take a detailed look at a specific open source project\nin each category. Our goal in this survey is to show the breadth of\napplications of VSMs for semantics, to provide a new perspective on VSMs for\nthose who are already familiar with the area, and to provide pointers into the\nliterature for those who are less familiar with the field.\n",
          "  Mediation is an important method in dispute resolution. We implement a case\nbased reasoning approach to mediation integrating analogical and commonsense\nreasoning components that allow an artificial mediation agent to satisfy\nrequirements expected from a human mediator, in particular: utilizing\nexperience with cases in different domains; and structurally transforming the\nset of issues for a better solution. We utilize a case structure based on\nontologies reflecting the perceptions of the parties in dispute. The analogical\nreasoning component, employing the Structure Mapping Theory from psychology,\nprovides a flexibility to respond innovatively in unusual circumstances, in\ncontrast with conventional approaches confined into specialized problem\ndomains. We aim to build a mediation case base incorporating real world\ninstances ranging from interpersonal or intergroup disputes to international\nconflicts.\n",
          "  Automated generalisation has known important improvements these last few\nyears. However, an issue that still deserves more study concerns the automatic\nevaluation of generalised data. Indeed, many automated generalisation systems\nrequire the utilisation of an evaluation function to automatically assess\ngeneralisation outcomes. In this paper, we propose a new approach dedicated to\nthe design of such a function. This approach allows an imperfectly defined\nevaluation function to be revised through a man-machine dialogue. The user\ngives its preferences to the system by comparing generalisation outcomes.\nMachine Learning techniques are then used to improve the evaluation function.\nAn experiment carried out on buildings shows that our approach significantly\nimproves generalisation evaluation functions defined by users.\n",
          "  We participated, in the Article Classification and the Interaction Method\nsubtasks (ACT and IMT, respectively) of the Protein-Protein Interaction task of\nthe BioCreative III Challenge. For the ACT, we pursued an extensive testing of\navailable Named Entity Recognition and dictionary tools, and used the most\npromising ones to extend our Variable Trigonometric Threshold linear\nclassifier. For the IMT, we experimented with a primarily statistical approach,\nas opposed to employing a deeper natural language processing strategy. Finally,\nwe also studied the benefits of integrating the method extraction approach that\nwe have used for the IMT into the ACT pipeline. For the ACT, our linear article\nclassifier leads to a ranking and classification performance significantly\nhigher than all the reported submissions. For the IMT, our results are\ncomparable to those of other systems, which took very different approaches. For\nthe ACT, we show that the use of named entity recognition tools leads to a\nsubstantial improvement in the ranking and classification of articles relevant\nto protein-protein interaction. Thus, we show that our substantially expanded\nlinear classifier is a very competitive classifier in this domain. Moreover,\nthis classifier produces interpretable surfaces that can be understood as\n\"rules\" for human understanding of the classification. In terms of the IMT\ntask, in contrast to other participants, our approach focused on identifying\nsentences that are likely to bear evidence for the application of a PPI\ndetection method, rather than on classifying a document as relevant to a\nmethod. As BioCreative III did not perform an evaluation of the evidence\nprovided by the system, we have conducted a separate assessment; the evaluators\nagree that our tool is indeed effective in detecting relevant evidence for PPI\ndetection methods.\n",
          "  The generation of meaningless \"words\" matching certain statistical and/or\nlinguistic criteria is frequently needed for experimental purposes in\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\nthe Cognitive Neuroscience literatue. The process for building nonwords\nsometimes has to be based on linguistic units such as syllables or morphemes,\nresulting in a numerical explosion of combinations when the size of the\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\nto generate nonwords of variables size. The approach builds pseudowords by\nusing a modified Metaheuristic algorithm based on a local search procedure\nenhanced by a feedback-based scheme. Experimental results show that the new\nalgorithm is a practical and effective tool for nonword generation.\n",
          "  A plausible definition of \"reasoning\" could be \"algebraically manipulating\npreviously acquired knowledge in order to answer a new question\". This\ndefinition covers first-order logical inference or probabilistic inference. It\nalso includes much simpler manipulations commonly used to build large learning\nsystems. For instance, we can build an optical character recognition system by\nfirst training a character segmenter, an isolated character recognizer, and a\nlanguage model, using appropriate labeled training sets. Adequately\nconcatenating these modules and fine tuning the resulting system can be viewed\nas an algebraic operation in a space of models. The resulting model answers a\nnew question, that is, converting the image of a text page into a computer\nreadable text.\n  This observation suggests a conceptual continuity between algebraically rich\ninference systems, such as logical or probabilistic inference, and simple\nmanipulations, such as the mere concatenation of trainable learning systems.\nTherefore, instead of trying to bridge the gap between machine learning systems\nand sophisticated \"all-purpose\" inference mechanisms, we can instead\nalgebraically enrich the set of manipulations applicable to training systems,\nand build reasoning capabilities from the ground up.\n",
          "  Cross-document coreference, the problem of resolving entity mentions across\nmulti-document collections, is crucial to automated knowledge base construction\nand data mining tasks. However, the scarcity of large labeled data sets has\nhindered supervised machine learning research for this task. In this paper we\ndevelop and demonstrate an approach based on ``distantly-labeling'' a data set\nfrom which we can train a discriminative cross-document coreference model. In\nparticular we build a dataset of more than a million people mentions extracted\nfrom 3.5 years of New York Times articles, leverage Wikipedia for distant\nlabeling with a generative model (and measure the reliability of such\nlabeling); then we train and evaluate a conditional random field coreference\nmodel that has factors on cross-document entities as well as mention-pairs.\nThis coreference model obtains high accuracy in resolving mentions and entities\nthat are not present in the training data, indicating applicability to\nnon-Wikipedia data. Given the large amount of data, our work is also an\nexercise demonstrating the scalability of our approach.\n",
          "  Scenarios for the emergence or bootstrap of a lexicon involve the repeated\ninteraction between at least two agents who must reach a consensus on how to\nname N objects using H words. Here we consider minimal models of two types of\nlearning algorithms: cross-situational learning, in which the individuals\ndetermine the meaning of a word by looking for something in common across all\nobserved uses of that word, and supervised operant conditioning learning, in\nwhich there is strong feedback between individuals about the intended meaning\nof the words. Despite the stark differences between these learning schemes, we\nshow that they yield the same communication accuracy in the realistic limits of\nlarge N and H, which coincides with the result of the classical occupancy\nproblem of randomly assigning N objects to H words.\n",
          "  A dictionary defines words in terms of other words. Definitions can tell you\nthe meanings of words you don't know, but only if you know the meanings of the\ndefining words. How many words do you need to know (and which ones) in order to\nbe able to learn all the rest from definitions? We reduced dictionaries to\ntheir \"grounding kernels\" (GKs), about 10% of the dictionary, from which all\nthe other words could be defined. The GK words turned out to have\npsycholinguistic correlates: they were learned at an earlier age and more\nconcrete than the rest of the dictionary. But one can compress still more: the\nGK turns out to have internal structure, with a strongly connected \"kernel\ncore\" (KC) and a surrounding layer, from which a hierarchy of definitional\ndistances can be derived, all the way out to the periphery of the full\ndictionary. These definitional distances, too, are correlated with\npsycholinguistic variables (age of acquisition, concreteness, imageability,\noral and written frequency) and hence perhaps with the \"mental lexicon\" in each\nof our heads.\n",
          "  This report outlines an approach to learning generative models from data. We\nexpress models as probabilistic programs, which allows us to capture abstract\npatterns within the examples. By choosing our language for programs to be an\nextension of the algebraic data type of the examples, we can begin with a\nprogram that generates all and only the examples. We then introduce greater\nabstraction, and hence generalization, incrementally to the extent that it\nimproves the posterior probability of the examples given the program. Motivated\nby previous approaches to model merging and program induction, we search for\nsuch explanatory abstractions using program transformations. We consider two\ntypes of transformation: Abstraction merges common subexpressions within a\nprogram into new functions (a form of anti-unification). Deargumentation\nsimplifies functions by reducing the number of arguments. We demonstrate that\nthis approach finds key patterns in the domain of nested lists, including\nparameterized sub-functions and stochastic recursion.\n",
          "  In this paper, we propose a technique to extract constrained formal concepts.\n",
          "  Music prediction tasks range from predicting tags given a song or clip of\naudio, predicting the name of the artist, or predicting related songs given a\nsong, clip, artist name or tag. That is, we are interested in every semantic\nrelationship between the different musical concepts in our database. In\nrealistically sized databases, the number of songs is measured in the hundreds\nof thousands or more, and the number of artists in the tens of thousands or\nmore, providing a considerable challenge to standard machine learning\ntechniques. In this work, we propose a method that scales to such datasets\nwhich attempts to capture the semantic similarities between the database items\nby modeling audio, artist names, and tags in a single low-dimensional semantic\nspace. This choice of space is learnt by optimizing the set of prediction tasks\nof interest jointly using multi-task learning. Our method both outperforms\nbaseline methods and, in comparison to them, is faster and consumes less\nmemory. We then demonstrate how our method learns an interpretable model, where\nthe semantic space captures well the similarities of interest.\n",
          "  This paper introduces a named entity recognition approach in textual corpus.\nThis Named Entity (NE) can be a named: location, person, organization, date,\ntime, etc., characterized by instances. A NE is found in texts accompanied by\ncontexts: words that are left or right of the NE. The work mainly aims at\nidentifying contexts inducing the NE's nature. As such, The occurrence of the\nword \"President\" in a text, means that this word or context may be followed by\nthe name of a president as President \"Obama\". Likewise, a word preceded by the\nstring \"footballer\" induces that this is the name of a footballer. NE\nrecognition may be viewed as a classification method, where every word is\nassigned to a NE class, regarding the context. The aim of this study is then to\nidentify and classify the contexts that are most relevant to recognize a NE,\nthose which are frequently found with the NE. A learning approach using\ntraining corpus: web documents, constructed from learning examples is then\nsuggested. Frequency representations and modified tf-idf representations are\nused to calculate the context weights associated to context frequency, learning\nexample frequency, and document frequency in the corpus.\n",
          "  Recognizing analogies, synonyms, antonyms, and associations appear to be four\ndistinct tasks, requiring distinct NLP algorithms. In the past, the four tasks\nhave been treated independently, using a wide variety of algorithms. These four\nsemantic classes, however, are a tiny sample of the full range of semantic\nphenomena, and we cannot afford to create ad hoc algorithms for each semantic\nphenomenon; we need to seek a unified approach. We propose to subsume a broad\nrange of phenomena under analogies. To limit the scope of this paper, we\nrestrict our attention to the subsumption of synonyms, antonyms, and\nassociations. We introduce a supervised corpus-based machine learning algorithm\nfor classifying analogous word pairs, and we show that it can solve\nmultiple-choice SAT analogy questions, TOEFL synonym questions, ESL\nsynonym-antonym questions, and similar-associated-both questions from cognitive\npsychology.\n",
          "  Building rules on top of ontologies is the ultimate goal of the logical layer\nof the Semantic Web. To this aim an ad-hoc mark-up language for this layer is\ncurrently under discussion. It is intended to follow the tradition of hybrid\nknowledge representation and reasoning systems such as $\\mathcal{AL}$-log that\nintegrates the description logic $\\mathcal{ALC}$ and the function-free Horn\nclausal language \\textsc{Datalog}. In this paper we consider the problem of\nautomating the acquisition of these rules for the Semantic Web. We propose a\ngeneral framework for rule induction that adopts the methodological apparatus\nof Inductive Logic Programming and relies on the expressive and deductive power\nof $\\mathcal{AL}$-log. The framework is valid whatever the scope of induction\n(description vs. prediction) is. Yet, for illustrative purposes, we also\ndiscuss an instantiation of the framework which aims at description and turns\nout to be useful in Ontology Refinement.\n  Keywords: Inductive Logic Programming, Hybrid Knowledge Representation and\nReasoning Systems, Ontologies, Semantic Web.\n  Note: To appear in Theory and Practice of Logic Programming (TPLP)\n",
          "  We participated in three of the protein-protein interaction subtasks of the\nSecond BioCreative Challenge: classification of abstracts relevant for\nprotein-protein interaction (IAS), discovery of protein pairs (IPS) and text\npassages characterizing protein interaction (ISS) in full text documents. We\napproached the abstract classification task with a novel, lightweight linear\nmodel inspired by spam-detection techniques, as well as an uncertainty-based\nintegration scheme. We also used a Support Vector Machine and the Singular\nValue Decomposition on the same features for comparison purposes. Our approach\nto the full text subtasks (protein pair and passage identification) includes a\nfeature expansion method based on word-proximity networks. Our approach to the\nabstract classification task (IAS) was among the top submissions for this task\nin terms of the measures of performance used in the challenge evaluation\n(accuracy, F-score and AUC). We also report on a web-tool we produced using our\napproach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Our\napproach to the full text tasks resulted in one of the highest recall rates as\nwell as mean reciprocal rank of correct passages. Our approach to abstract\nclassification shows that a simple linear model, using relatively few features,\nis capable of generalizing and uncovering the conceptual nature of\nprotein-protein interaction from the bibliome. Since the novel approach is\nbased on a very lightweight linear model, it can be easily ported and applied\nto similar problems. In full text problems, the expansion of word features with\nword-proximity networks is shown to be useful, though the need for some\nimprovements is discussed.\n",
          "  We present and study an agent-based model of T-Cell cross-regulation in the\nadaptive immune system, which we apply to binary classification. Our method\nexpands an existing analytical model of T-cell cross-regulation (Carneiro et\nal. in Immunol Rev 216(1):48-68, 2007) that was used to study the\nself-organizing dynamics of a single population of T-Cells in interaction with\nan idealized antigen presenting cell capable of presenting a single antigen.\nWith agent-based modeling we are able to study the self-organizing dynamics of\nmultiple populations of distinct T-cells which interact via antigen presenting\ncells that present hundreds of distinct antigens. Moreover, we show that such\nself-organizing dynamics can be guided to produce an effective binary\nclassification of antigens, which is competitive with existing machine learning\nmethods when applied to biomedical text classification. More specifically, here\nwe test our model on a dataset of publicly available full-text biomedical\narticles provided by the BioCreative challenge (Krallinger in The biocreative\nii. 5 challenge overview, p 19, 2009). We study the robustness of our model's\nparameter configurations, and show that it leads to encouraging results\ncomparable to state-of-the-art classifiers. Our results help us understand both\nT-cell cross-regulation as a general principle of guided self-organization, as\nwell as its applicability to document classification. Therefore, we show that\nour bio-inspired algorithm is a promising novel method for biomedical article\nclassification and for binary document classification in general.\n",
          "  Data mining allows the exploration of sequences of phenomena, whereas one\nusually tends to focus on isolated phenomena or on the relation between two\nphenomena. It offers invaluable tools for theoretical analyses and exploration\nof the structure of sentences, texts, dialogues, and speech. We report here the\nresults of an attempt at using it for inspecting sequences of verbs from French\naccounts of road accidents. This analysis comes from an original approach of\nunsupervised training allowing the discovery of the structure of sequential\ndata. The entries of the analyzer were only made of the verbs appearing in the\nsentences. It provided a classification of the links between two successive\nverbs into four distinct clusters, allowing thus text segmentation. We give\nhere an interpretation of these clusters by applying a statistical analysis to\nindependent semantic annotations.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_corpus_classification_semantic",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_corpus_classification_semantic"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.6315480470657349,
          1.1128034591674805,
          1.5822373628616333,
          1.5158662796020508,
          1.281417727470398,
          1.1794304847717285,
          1.594188928604126,
          0.9874619841575623,
          0.9975549578666687,
          1.228674054145813,
          1.056165337562561,
          0.7866833209991455,
          1.0685731172561646,
          1.4659779071807861,
          1.658869981765747,
          1.1496721506118774,
          0.9610893130302429,
          1.8758721351623535,
          1.1024609804153442,
          1.2871736288070679,
          0.9721876382827759,
          1.4803221225738525,
          1.9838862419128418,
          1.6643961668014526,
          1.596533179283142,
          1.1397536993026733,
          1.1894773244857788,
          0.9715343713760376,
          1.4575425386428833,
          1.4576901197433472,
          1.588989019393921,
          1.6532306671142578,
          1.484184741973877,
          1.4297890663146973,
          1.6049656867980957,
          1.0409865379333496,
          1.8824819326400757,
          1.4829235076904297,
          1.2998756170272827,
          1.0255423784255981,
          1.3637580871582031,
          1.3669936656951904,
          1.61844003200531,
          1.355330228805542
         ],
         "y": [
          6.415247917175293,
          6.400338172912598,
          6.804248809814453,
          6.2809271812438965,
          6.055486679077148,
          6.036287307739258,
          6.445141792297363,
          6.5339436531066895,
          6.623554706573486,
          6.0261712074279785,
          6.386024475097656,
          6.449514865875244,
          6.334667205810547,
          6.180044651031494,
          6.223598957061768,
          6.333739280700684,
          6.558319568634033,
          6.566012859344482,
          6.328002452850342,
          6.086491584777832,
          6.49232816696167,
          6.077732563018799,
          6.6732635498046875,
          6.513124942779541,
          6.547487258911133,
          6.021038055419922,
          6.128951072692871,
          6.534789562225342,
          6.483195781707764,
          6.195323467254639,
          6.64793062210083,
          6.53074836730957,
          6.233641147613525,
          6.200689792633057,
          6.742164611816406,
          6.3516106605529785,
          6.63682746887207,
          6.351774215698242,
          6.084993362426758,
          6.41654109954834,
          6.4778618812561035,
          6.433811664581299,
          6.336997985839844,
          6.376293182373047
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  In this paper we propose a framework for solving constrained online convex\noptimization problem. Our motivation stems from the observation that most\nalgorithms proposed for online convex optimization require a projection onto\nthe convex set $\\mathcal{K}$ from which the decisions are made. While for\nsimple shapes (e.g. Euclidean ball) the projection is straightforward, for\narbitrary complex sets this is the main computational challenge and may be\ninefficient in practice. In this paper, we consider an alternative online\nconvex optimization problem. Instead of requiring decisions belong to\n$\\mathcal{K}$ for all rounds, we only require that the constraints which define\nthe set $\\mathcal{K}$ be satisfied in the long run. We show that our framework\ncan be utilized to solve a relaxed version of online learning with side\nconstraints addressed in \\cite{DBLP:conf/colt/MannorT06} and\n\\cite{DBLP:conf/aaai/KvetonYTM08}. By turning the problem into an online\nconvex-concave optimization problem, we propose an efficient algorithm which\nachieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret bound and\n$\\tilde{\\mathcal{O}}(T^{3/4})$ bound for the violation of constraints. Then we\nmodify the algorithm in order to guarantee that the constraints are satisfied\nin the long run. This gain is achieved at the price of getting\n$\\tilde{\\mathcal{O}}(T^{3/4})$ regret bound. Our second algorithm is based on\nthe Mirror Prox method \\citep{nemirovski-2005-prox} to solve variational\ninequalities which achieves $\\tilde{\\mathcal{\\mathcal{O}}}(T^{2/3})$ bound for\nboth regret and the violation of constraints when the domain $\\K$ can be\ndescribed by a finite number of linear constraints. Finally, we extend the\nresult to the setting where we only have partial access to the convex set\n$\\mathcal{K}$ and propose a multipoint bandit feedback algorithm with the same\nbounds in expectation as our first algorithm.\n",
          "  We consider the problem of online estimation of a real-valued signal\ncorrupted by oblivious zero-mean noise using linear estimators. The estimator\nis required to iteratively predict the underlying signal based on the current\nand several last noisy observations, and its performance is measured by the\nmean-square-error. We describe and analyze an algorithm for this task which: 1.\nAchieves logarithmic adaptive regret against the best linear filter in\nhindsight. This bound is assyptotically tight, and resolves the question of\nMoon and Weissman [1]. 2. Runs in linear time in terms of the number of filter\ncoefficients. Previous constructions required at least quadratic time.\n",
          "  We analyze and evaluate an online gradient descent algorithm with adaptive\nper-coordinate adjustment of learning rates. Our algorithm can be thought of as\nan online version of batch gradient descent with a diagonal preconditioner.\nThis approach leads to regret bounds that are stronger than those of standard\nonline gradient descent for general online convex optimization problems.\nExperimentally, we show that our algorithm is competitive with state-of-the-art\nalgorithms for large scale machine learning problems.\n",
          "  We propose a general method called truncated gradient to induce sparsity in\nthe weights of online learning algorithms with convex loss functions. This\nmethod has several essential properties: The degree of sparsity is continuous\n-- a parameter controls the rate of sparsification from no sparsification to\ntotal sparsification. The approach is theoretically motivated, and an instance\nof it can be regarded as an online counterpart of the popular\n$L_1$-regularization method in the batch setting. We prove that small rates of\nsparsification result in only small additional regret with respect to typical\nonline learning guarantees. The approach works well empirically. We apply the\napproach to several datasets and find that for datasets with large numbers of\nfeatures, substantial sparsity is discoverable.\n",
          "  In this work we study parallelization of online learning, a core primitive in\nmachine learning. In a parallel environment all known approaches for parallel\nonline learning lead to delayed updates, where the model is updated using\nout-of-date information. In the worst case, or when examples are temporally\ncorrelated, delay can have a very adverse effect on the learning algorithm.\nHere, we analyze and present preliminary empirical results on a set of learning\narchitectures based on a feature sharding approach that present various\ntradeoffs between delay, degree of parallelism, representation power and\nempirical performance.\n",
          "  We consider the unconstrained optimization problem whose objective function\nis composed of a smooth and a non-smooth conponents where the smooth component\nis the expectation a random function. This type of problem arises in some\ninteresting applications in machine learning. We propose a stochastic gradient\ndescent algorithm for this class of optimization problem. When the non-smooth\ncomponent has a particular structure, we propose another stochastic gradient\ndescent algorithm by incorporating a smoothing method into our first algorithm.\nThe proofs of the convergence rates of these two algorithms are given and we\nshow the numerical performance of our algorithm by applying them to regularized\nlinear regression problems with different sets of synthetic data.\n",
          "  Nesterov's accelerated gradient methods (AGM) have been successfully applied\nin many machine learning areas. However, their empirical performance on\ntraining max-margin models has been inferior to existing specialized solvers.\nIn this paper, we first extend AGM to strongly convex and composite objective\nfunctions with Bregman style prox-functions. Our unifying framework covers both\nthe $\\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant\nadaptively, and bounds the duality gap. Then we demonstrate various ways to\napply this framework of methods to a wide range of machine learning problems.\nEmphasis will be given on their rate of convergence and how to efficiently\ncompute the gradient and optimize the models. The experimental results show\nthat with our extensions AGM outperforms state-of-the-art solvers on max-margin\nmodels.\n",
          "  Cyclic coordinate descent is a classic optimization method that has witnessed\na resurgence of interest in machine learning. Reasons for this include its\nsimplicity, speed and stability, as well as its competitive performance on\n$\\ell_1$ regularized smooth optimization problems. Surprisingly, very little is\nknown about its finite time convergence behavior on these problems. Most\nexisting results either just prove convergence or provide asymptotic rates. We\nfill this gap in the literature by proving $O(1/k)$ convergence rates (where\n$k$ is the iteration counter) for two variants of cyclic coordinate descent\nunder an isotonicity assumption. Our analysis proceeds by comparing the\nobjective values attained by the two variants with each other, as well as with\nthe gradient descent algorithm. We show that the iterates generated by the\ncyclic coordinate descent methods remain better than those of gradient descent\nuniformly over time.\n",
          "  Stochastic gradient descent is a simple approach to find the local minima of\na cost function whose evaluations are corrupted by noise. In this paper, we\ndevelop a procedure extending stochastic gradient descent algorithms to the\ncase where the function is defined on a Riemannian manifold. We prove that, as\nin the Euclidian case, the gradient descent algorithm converges to a critical\npoint of the cost function. The algorithm has numerous potential applications,\nand is illustrated here by four examples. In particular a novel gossip\nalgorithm on the set of covariance matrices is derived and tested numerically.\n",
          "  We introduce new online and batch algorithms that are robust to data with\nmissing features, a situation that arises in many practical applications. In\nthe online setup, we allow for the comparison hypothesis to change as a\nfunction of the subset of features that is observed on any given round,\nextending the standard setting where the comparison hypothesis is fixed\nthroughout. In the batch setup, we present a convex relation of a non-convex\nproblem to jointly estimate an imputation function, used to fill in the values\nof missing features, along with the classification hypothesis. We prove regret\nbounds in the online setting and Rademacher complexity bounds for the batch\ni.i.d. setting. The algorithms are tested on several UCI datasets, showing\nsuperior performance over baselines.\n",
          "  This report considers how to inject external candidate solutions into the\nCMA-ES algorithm. The injected solutions might stem from a gradient or a Newton\nstep, a surrogate model optimizer or any other oracle or search mechanism. They\ncan also be the result of a repair mechanism, for example to render infeasible\nsolutions feasible. Only small modifications to the CMA-ES are necessary to\nturn injection into a reliable and effective method: too long steps need to be\ntightly renormalized. The main objective of this report is to reveal this\nsimple mechanism. Depending on the source of the injected solutions,\ninteresting variants of CMA-ES arise. When the best-ever solution is always\n(re-)injected, an elitist variant of CMA-ES with weighted multi-recombination\narises. When \\emph{all} solutions are injected from an \\emph{external} source,\nthe resulting algorithm might be viewed as \\emph{adaptive encoding} with\nstep-size control. In first experiments, injected solutions of very good\nquality lead to a convergence speed twice as fast as on the (simple) sphere\nfunction without injection. This means that we observe an impressive speed-up\non otherwise difficult to solve functions. Single bad injected solutions on the\nother hand do no significant harm.\n",
          "  In this paper, we consider the problem of preserving privacy in the online\nlearning setting. We study the problem in the online convex programming (OCP)\nframework---a popular online learning setting with several interesting\ntheoretical and practical implications---while using differential privacy as\nthe formal privacy measure. For this problem, we distill two critical\nattributes that a private OCP algorithm should have in order to provide\nreasonable privacy as well as utility guarantees: 1) linearly decreasing\nsensitivity, i.e., as new data points arrive their effect on the learning model\ndecreases, 2) sub-linear regret bound---regret bound is a popular\ngoodness/utility measure of an online learning algorithm.\n  Given an OCP algorithm that satisfies these two conditions, we provide a\ngeneral framework to convert the given algorithm into a privacy preserving OCP\nalgorithm with good (sub-linear) regret. We then illustrate our approach by\nconverting two popular online learning algorithms into their differentially\nprivate variants while guaranteeing sub-linear regret ($O(\\sqrt{T})$). Next, we\nconsider the special case of online linear regression problems, a practically\nimportant class of online learning problems, for which we generalize an\napproach by Dwork et al. to provide a differentially private algorithm with\njust $O(\\log^{1.5} T)$ regret. Finally, we show that our online learning\nframework can be used to provide differentially private algorithms for offline\nlearning as well. For the offline learning problem, our approach obtains better\nerror bounds as well as can handle larger class of problems than the existing\nstate-of-the-art methods Chaudhuri et al.\n",
          "  In this dissertation we study statistical and online learning problems from\nan optimization viewpoint.The dissertation is divided into two parts :\n  I. We first consider the question of learnability for statistical learning\nproblems in the general learning setting. The question of learnability is well\nstudied and fully characterized for binary classification and for real valued\nsupervised learning problems using the theory of uniform convergence. However\nwe show that for the general learning setting uniform convergence theory fails\nto characterize learnability. To fill this void we use stability of learning\nalgorithms to fully characterize statistical learnability in the general\nsetting. Next we consider the problem of online learning. Unlike the\nstatistical learning framework there is a dearth of generic tools that can be\nused to establish learnability and rates for online learning problems in\ngeneral. We provide online analogs to classical tools from statistical learning\ntheory like Rademacher complexity, covering numbers, etc. We further use these\ntools to fully characterize learnability for online supervised learning\nproblems.\n  II. In the second part, for general classes of convex learning problems, we\nprovide appropriate mirror descent (MD) updates for online and statistical\nlearning of these problems. Further, we show that the the MD is near optimal\nfor online convex learning and for most cases, is also near optimal for\nstatistical convex learning. We next consider the problem of convex\noptimization and show that oracle complexity can be lower bounded by the so\ncalled fat-shattering dimension of the associated linear class. Thus we\nestablish a strong connection between offline convex optimization problems and\nstatistical learning problems. We also show that for a large class of high\ndimensional optimization problems, MD is in fact near optimal even for convex\noptimization.\n",
          "  We propose a first-order method for stochastic strongly convex optimization\nthat attains $O(1/n)$ rate of convergence, analysis show that the proposed\nmethod is simple, easily to implement, and in worst case, asymptotically four\ntimes faster than its peers. We derive this method from several intuitive\nobservations that are generalized from existing first order optimization\nmethods.\n",
          "  We consider the problem of online linear regression on arbitrary\ndeterministic sequences when the ambient dimension d can be much larger than\nthe number of time rounds T. We introduce the notion of sparsity regret bound,\nwhich is a deterministic online counterpart of recent risk bounds derived in\nthe stochastic setting under a sparsity scenario. We prove such regret bounds\nfor an online-learning algorithm called SeqSEW and based on exponential\nweighting and data-driven truncation. In a second part we apply a\nparameter-free version of this algorithm to the stochastic setting (regression\nmodel with random design). This yields risk bounds of the same flavor as in\nDalalyan and Tsybakov (2011) but which solve two questions left open therein.\nIn particular our risk bounds are adaptive (up to a logarithmic factor) to the\nunknown variance of the noise if the latter is Gaussian. We also address the\nregression model with fixed design.\n",
          "  We show that for a general class of convex online learning problems, Mirror\nDescent can always achieve a (nearly) optimal regret guarantee.\n",
          "  We study online learning when individual instances are corrupted by\nadversarially chosen random noise. We assume the noise distribution is unknown,\nand may change over time with no restriction other than having zero mean and\nbounded variance. Our technique relies on a family of unbiased estimators for\nnon-linear functions, which may be of independent interest. We show that a\nvariant of online gradient descent can learn functions in any dot-product\n(e.g., polynomial) or Gaussian kernel space with any analytic convex loss\nfunction. Our variant uses randomized estimates that need to query a random\nnumber of noisy copies of each instance, where with high probability this\nnumber is upper bounded by a constant. Allowing such multiple queries cannot be\navoided: Indeed, we show that online learning is in general impossible when\nonly one noisy copy of each instance can be accessed.\n",
          "  Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve\nstate-of-the-art performance on a variety of machine learning tasks. Several\nresearchers have recently proposed schemes to parallelize SGD, but all require\nperformance-destroying memory locking and synchronization. This work aims to\nshow using novel theoretical analysis, algorithms, and implementation that SGD\ncan be implemented without any locking. We present an update scheme called\nHOGWILD! which allows processors access to shared memory with the possibility\nof overwriting each other's work. We show that when the associated optimization\nproblem is sparse, meaning most gradient updates only modify small parts of the\ndecision variable, then HOGWILD! achieves a nearly optimal rate of convergence.\nWe demonstrate experimentally that HOGWILD! outperforms alternative schemes\nthat use locking by an order of magnitude.\n",
          "  The standard model of online prediction deals with serial processing of\ninputs by a single processor. However, in large-scale online prediction\nproblems, where inputs arrive at a high rate, an increasingly common necessity\nis to distribute the computation across several processors. A non-trivial\nchallenge is to design distributed algorithms for online prediction, which\nmaintain good regret guarantees. In \\cite{DMB}, we presented the DMB algorithm,\nwhich is a generic framework to convert any serial gradient-based online\nprediction algorithm into a distributed algorithm. Moreover, its regret\nguarantee is asymptotically optimal for smooth convex loss functions and\nstochastic inputs. On the flip side, it is fragile to many types of failures\nthat are common in distributed environments. In this companion paper, we\npresent variants of the DMB algorithm, which are resilient to many types of\nnetwork failures, and tolerant to varying performance of the computing nodes.\n",
          "  We show a principled way of deriving online learning algorithms from a\nminimax analysis. Various upper bounds on the minimax value, previously thought\nto be non-constructive, are shown to yield algorithms. This allows us to\nseamlessly recover known methods and to derive new ones. Our framework also\ncaptures such \"unorthodox\" methods as Follow the Perturbed Leader and the R^2\nforecaster. We emphasize that understanding the inherent complexity of the\nlearning problem leads to the development of algorithms.\n  We define local sequential Rademacher complexities and associated algorithms\nthat allow us to obtain faster rates in online learning, similarly to\nstatistical learning theory. Based on these localized complexities we build a\ngeneral adaptive method that can take advantage of the suboptimality of the\nobserved sequence.\n  We present a number of new algorithms, including a family of randomized\nmethods that use the idea of a \"random playout\". Several new versions of the\nFollow-the-Perturbed-Leader algorithms are presented, as well as methods based\non the Littlestone's dimension, efficient methods for matrix completion with\ntrace norm, and algorithms for the problems of transductive learning and\nprediction with static experts.\n",
          "  We study the generalization performance of online learning algorithms trained\non samples coming from a dependent source of data. We show that the\ngeneralization error of any stable online algorithm concentrates around its\nregret--an easily computable statistic of the online performance of the\nalgorithm--when the underlying ergodic process is $\\beta$- or $\\phi$-mixing. We\nshow high probability error bounds assuming the loss function is convex, and we\nalso establish sharp convergence rates and deviation bounds for strongly convex\nlosses and several linear prediction problems such as linear and logistic\nregression, least-squares SVM, and boosting on dependent data. In addition, our\nresults have straightforward applications to stochastic optimization with\ndependent data, and our analysis requires only martingale convergence\narguments; we need not rely on more powerful statistical tools such as\nempirical process theory.\n",
          "  Stochastic gradient descent (SGD) is a simple and popular method to solve\nstochastic optimization problems which arise in machine learning. For strongly\nconvex problems, its convergence rate was known to be O(\\log(T)/T), by running\nSGD for T iterations and returning the average point. However, recent results\nshowed that using a different algorithm, one can get an optimal O(1/T) rate.\nThis might lead one to believe that standard SGD is suboptimal, and maybe\nshould even be replaced as a method of choice. In this paper, we investigate\nthe optimality of SGD in a stochastic setting. We show that for smooth\nproblems, the algorithm attains the optimal O(1/T) rate. However, for\nnon-smooth problems, the convergence rate with averaging might really be\n\\Omega(\\log(T)/T), and this is not just an artifact of the analysis. On the\nflip side, we show that a simple modification of the averaging step suffices to\nrecover the O(1/T) rate, and no other change of the algorithm is necessary. We\nalso present experimental results which support our findings, and point out\nopen problems.\n",
          "  We study the non-smooth optimization problems in machine learning, where both\nthe loss function and the regularizer are non-smooth functions. Previous\nstudies on efficient empirical loss minimization assume either a smooth loss\nfunction or a strongly convex regularizer, making them unsuitable for\nnon-smooth optimization. We develop a simple yet efficient method for a family\nof non-smooth optimization problems where the dual form of the loss function is\nbilinear in primal and dual variables. We cast a non-smooth optimization\nproblem into a minimax optimization problem, and develop a primal dual prox\nmethod that solves the minimax optimization problem at a rate of $O(1/T)$\n{assuming that the proximal step can be efficiently solved}, significantly\nfaster than a standard subgradient descent method that has an $O(1/\\sqrt{T})$\nconvergence rate. Our empirical study verifies the efficiency of the proposed\nmethod for various non-smooth optimization problems that arise ubiquitously in\nmachine learning by comparing it to the state-of-the-art first order methods.\n",
          "  In batch learning, stability together with existence and uniqueness of the\nsolution corresponds to well-posedness of Empirical Risk Minimization (ERM)\nmethods; recently, it was proved that CV_loo stability is necessary and\nsufficient for generalization and consistency of ERM. In this note, we\nintroduce CV_on stability, which plays a similar note in online learning. We\nshow that stochastic gradient descent (SDG) with the usual hypotheses is CVon\nstable and we then discuss the implications of CV_on stability for convergence\nof SGD.\n",
          "  We establish an excess risk bound of O(H R_n^2 + R_n \\sqrt{H L*}) for\nempirical risk minimization with an H-smooth loss function and a hypothesis\nclass with Rademacher complexity R_n, where L* is the best risk achievable by\nthe hypothesis class. For typical hypothesis classes where R_n = \\sqrt{R/n},\nthis translates to a learning rate of O(RH/n) in the separable (L*=0) case and\nO(RH/n + \\sqrt{L^* RH/n}) more generally. We also provide similar guarantees\nfor online and stochastic convex optimization with a smooth non-negative\nobjective.\n",
          "  The cross-entropy method is a simple but efficient method for global\noptimization. In this paper we provide two online variants of the basic CEM,\ntogether with a proof of convergence.\n",
          "  In this paper, we focus on the question of the extent to which online\nlearning can benefit from distributed computing. We focus on the setting in\nwhich $N$ agents online-learn cooperatively, where each agent only has access\nto its own data. We propose a generic data-distributed online learning\nmeta-algorithm. We then introduce the Distributed Weighted Majority and\nDistributed Online Mirror Descent algorithms, as special cases. We show, using\nboth theoretical analysis and experiments, that compared to a single agent:\ngiven the same computation time, these distributed algorithms achieve smaller\ngeneralization errors; and given the same generalization errors, they can be\n$N$ times faster.\n",
          "  We propose a new stochastic gradient method for optimizing the sum of a\nfinite set of smooth functions, where the sum is strongly convex. While\nstandard stochastic gradient methods converge at sublinear rates for this\nproblem, the proposed method incorporates a memory of previous gradient values\nin order to achieve a linear convergence rate. In a machine learning context,\nnumerical experiments indicate that the new algorithm can dramatically\noutperform standard algorithms, both in terms of optimizing the training error\nand reducing the test error quickly.\n",
          "  We introduce a new online convex optimization algorithm that adaptively\nchooses its regularization function based on the loss functions observed so\nfar. This is in contrast to previous algorithms that use a fixed regularization\nfunction such as L2-squared, and modify it only via a single time-dependent\nparameter. Our algorithm's regret bounds are worst-case optimal, and for\ncertain realistic classes of loss functions they are much better than existing\nbounds. These bounds are problem-dependent, which means they can exploit the\nstructure of the actual problem instance. Critically, however, our algorithm\ndoes not need to know this structure in advance. Rather, we prove competitive\nguarantees that show the algorithm provides a bound within a constant factor of\nthe best possible bound (of a certain functional form) in hindsight.\n",
          "  We study the problem of online regression. We prove a theoretical bound on\nthe square loss of Ridge Regression. We do not make any assumptions about input\nvectors or outcomes. We also show that Bayesian Ridge Regression can be thought\nof as an online algorithm competing with all the Gaussian linear experts.\n",
          "  For large scale learning problems, it is desirable if we can obtain the\noptimal model parameters by going through the data in only one pass. Polyak and\nJuditsky (1992) showed that asymptotically the test performance of the simple\naverage of the parameters obtained by stochastic gradient descent (SGD) is as\ngood as that of the parameters which minimize the empirical cost. However, to\nour knowledge, despite its optimal asymptotic convergence rate, averaged SGD\n(ASGD) received little attention in recent research on large scale learning.\nOne possible reason is that it may take a prohibitively large number of\ntraining samples for ASGD to reach its asymptotic region for most real\nproblems. In this paper, we present a finite sample analysis for the method of\nPolyak and Juditsky (1992). Our analysis shows that it indeed usually takes a\nhuge number of samples for ASGD to reach its asymptotic region for improperly\nchosen learning rate. More importantly, based on our analysis, we propose a\nsimple way to properly set learning rate so that it takes a reasonable amount\nof data for ASGD to reach its asymptotic region. We compare ASGD using our\nproposed learning rate with other well known algorithms for training large\nscale linear classifiers. The experiments clearly show the superiority of ASGD.\n",
          "  With the explosion of the size of digital dataset, the limiting factor for\ndecomposition algorithms is the \\emph{number of passes} over the input, as the\ninput is often stored out-of-core or even off-site. Moreover, we're only\ninterested in algorithms that operate in \\emph{constant memory} w.r.t. to the\ninput size, so that arbitrarily large input can be processed. In this paper, we\npresent a practical comparison of two such algorithms: a distributed method\nthat operates in a single pass over the input vs. a streamed two-pass\nstochastic algorithm. The experiments track the effect of distributed\ncomputing, oversampling and memory trade-offs on the accuracy and performance\nof the two algorithms. To ensure meaningful results, we choose the input to be\na real dataset, namely the whole of the English Wikipedia, in the application\nsettings of Latent Semantic Analysis.\n",
          "  The paper deals with on-line regression settings with signals belonging to a\nBanach lattice. Our algorithms work in a semi-online setting where all the\ninputs are known in advance and outcomes are unknown and given step by step. We\napply the Aggregating Algorithm to construct a prediction method whose\ncumulative loss over all the input vectors is comparable with the cumulative\nloss of any linear functional on the Banach lattice. As a by-product we get an\nalgorithm that takes signals from an arbitrary domain. Its cumulative loss is\ncomparable with the cumulative loss of any predictor function from Besov and\nTriebel-Lizorkin spaces. We describe several applications of our setting.\n",
          "  We study three families of online convex optimization algorithms:\nfollow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual\naveraging (RDA), and composite-objective mirror descent. We first prove\nequivalence theorems that show all of these algorithms are instantiations of a\ngeneral FTRL update. This provides theoretical insight on previous experimental\nobservations. In particular, even though the FOBOS composite mirror descent\nalgorithm handles L1 regularization explicitly, it has been observed that RDA\nis even more effective at producing sparsity. Our results demonstrate that\nFOBOS uses subgradient approximations to the L1 penalty from previous rounds,\nleading to less sparsity than RDA, which handles the cumulative penalty in\nclosed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,\nand outperforms both on a large, real-world dataset.\n  Our second contribution is a unified analysis which produces regret bounds\nthat match (up to logarithmic terms) or improve the best previously known\nbounds. This analysis also extends these algorithms in two important ways: we\nsupport a more general type of composite objective and we analyze implicit\nupdates, which replace the subgradient approximation of the current loss\nfunction with an exact optimization.\n",
          "  This paper derives an identity connecting the square loss of ridge regression\nin on-line mode with the loss of the retrospectively best regressor. Some\ncorollaries about the properties of the cumulative loss of on-line ridge\nregression are also obtained.\n",
          "  Stability is a general notion that quantifies the sensitivity of a learning\nalgorithm's output to small change in the training dataset (e.g. deletion or\nreplacement of a single training sample). Such conditions have recently been\nshown to be more powerful to characterize learnability in the general learning\nsetting under i.i.d. samples where uniform convergence is not necessary for\nlearnability, but where stability is both sufficient and necessary for\nlearnability. We here show that similar stability conditions are also\nsufficient for online learnability, i.e. whether there exists a learning\nalgorithm such that under any sequence of examples (potentially chosen\nadversarially) produces a sequence of hypotheses that has no regret in the\nlimit with respect to the best hypothesis in hindsight. We introduce online\nstability, a stability condition related to uniform-leave-one-out stability in\nthe batch setting, that is sufficient for online learnability. In particular we\nshow that popular classes of online learners, namely algorithms that fall in\nthe category of Follow-the-(Regularized)-Leader, Mirror Descent, gradient-based\nmethods and randomized algorithms like Weighted Majority and Hedge, are\nguaranteed to have no regret if they have such online stability property. We\nprovide examples that suggest the existence of an algorithm with such stability\ncondition might in fact be necessary for online learnability. For the more\nrestricted binary classification setting, we establish that such stability\ncondition is in fact both sufficient and necessary. We also show that for a\nlarge class of online learnable problems in the general learning setting,\nnamely those with a notion of sub-exponential covering, no-regret online\nalgorithms that have such stability condition exists.\n",
          "  Mini-batch algorithms have been proposed as a way to speed-up stochastic\nconvex optimization problems. We study how such algorithms can be improved\nusing accelerated gradient methods. We provide a novel analysis, which shows\nhow standard gradient methods may sometimes be insufficient to obtain a\nsignificant speed-up and propose a novel accelerated gradient algorithm, which\ndeals with this deficiency, enjoys a uniformly superior guarantee and works\nwell in practice.\n",
          "  Many online, i.e., time-adaptive, inverse problems in signal processing and\nmachine learning fall under the wide umbrella of the asymptotic minimization of\na sequence of non-negative, convex, and continuous functions. To incorporate\na-priori knowledge into the design, the asymptotic minimization task is usually\nconstrained on a fixed closed convex set, which is dictated by the available\na-priori information. To increase versatility towards the usage of the\navailable information, the present manuscript extends the Adaptive Projected\nSubgradient Method (APSM) by introducing an algorithmic scheme which\nincorporates a-priori knowledge in the design via a sequence of strongly\nattracting quasi-nonexpansive mappings in a real Hilbert space. In such a way,\nthe benefits offered to online learning tasks by the proposed method unfold in\ntwo ways: 1) the rich class of quasi-nonexpansive mappings provides a plethora\nof ways to cast a-priori knowledge, and 2) by introducing a sequence of such\nmappings, the proposed scheme is able to capture the time-varying nature of\na-priori information. The convergence properties of the algorithm are studied,\nseveral special cases of the method with wide applicability are shown, and the\npotential of the proposed scheme is demonstrated by considering an increasingly\nimportant, nowadays, online sparse system/signal recovery task.\n",
          "  Online prediction methods are typically presented as serial algorithms\nrunning on a single processor. However, in the age of web-scale prediction\nproblems, it is increasingly common to encounter situations where a single\nprocessor cannot keep up with the high rate at which inputs arrive. In this\nwork, we present the \\emph{distributed mini-batch} algorithm, a method of\nconverting many serial gradient-based online prediction algorithms into\ndistributed algorithms. We prove a regret bound for this method that is\nasymptotically optimal for smooth convex loss functions and stochastic inputs.\nMoreover, our analysis explicitly takes into account communication latencies\nbetween nodes in the distributed environment. We show how our method can be\nused to solve the closely-related distributed stochastic optimization problem,\nachieving an asymptotically linear speed-up over multiple processors. Finally,\nwe demonstrate the merits of our approach on a web-scale online prediction\nproblem.\n",
          "  This manuscripts contains the proofs for \"A Primal-Dual Message-Passing\nAlgorithm for Approximated Large Scale Structured Prediction\".\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_optimal_learning_learnability",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_optimal_learning_learnability"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.156333923339844,
          5.0835490226745605,
          5.069742679595947,
          5.013638019561768,
          4.955358028411865,
          4.13896369934082,
          3.850417375564575,
          3.895571231842041,
          4.24735689163208,
          4.95655632019043,
          4.892646312713623,
          5.450169563293457,
          5.184429168701172,
          4.159748554229736,
          5.2466511726379395,
          5.3023834228515625,
          5.061944484710693,
          4.888586044311523,
          5.213435649871826,
          5.67765474319458,
          5.118525505065918,
          4.158410549163818,
          3.885547637939453,
          4.981985569000244,
          5.105738162994385,
          3.7891645431518555,
          5.233161449432373,
          4.145408630371094,
          5.149033069610596,
          5.152765274047852,
          4.676426410675049,
          4.966473579406738,
          5.315109729766846,
          5.110252857208252,
          5.110195159912109,
          5.145979881286621,
          4.148754119873047,
          3.9142377376556396,
          5.077773571014404,
          4.969645977020264,
          4.814993381500244
         ],
         "y": [
          8.935883522033691,
          8.801359176635742,
          9.016486167907715,
          9.007086753845215,
          9.175836563110352,
          9.572321891784668,
          9.66433048248291,
          9.661261558532715,
          9.440790176391602,
          9.011351585388184,
          8.830446243286133,
          9.16967487335205,
          8.777302742004395,
          9.583385467529297,
          8.595741271972656,
          8.868846893310547,
          8.80593490600586,
          9.18773078918457,
          9.009267807006836,
          8.601954460144043,
          8.728793144226074,
          9.577615737915039,
          9.664777755737305,
          8.759929656982422,
          8.763360977172852,
          8.8270263671875,
          9.009435653686523,
          9.582808494567871,
          8.90985107421875,
          8.810696601867676,
          9.204819679260254,
          9.22642993927002,
          8.711118698120117,
          8.93848991394043,
          8.877116203308105,
          8.76988410949707,
          9.591649055480957,
          9.65915298461914,
          9.105118751525879,
          8.953749656677246,
          9.084720611572266
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  The use of L1 regularisation for sparse learning has generated immense\nresearch interest, with successful application in such diverse areas as signal\nacquisition, image coding, genomics and collaborative filtering. While existing\nwork highlights the many advantages of L1 methods, in this paper we find that\nL1 regularisation often dramatically underperforms in terms of predictive\nperformance when compared with other methods for inferring sparsity. We focus\non unsupervised latent variable models, and develop L1 minimising factor\nmodels, Bayesian variants of \"L1\", and Bayesian models with a stronger L0-like\nsparsity induced through spike-and-slab distributions. These spike-and-slab\nBayesian factor models encourage sparsity while accounting for uncertainty in a\nprincipled manner and avoiding unnecessary shrinkage of non-zero values. We\ndemonstrate on a number of data sets that in practice spike-and-slab Bayesian\nmethods outperform L1 minimisation, even on a computational budget. We thus\nhighlight the need to re-assess the wide use of L1 methods in sparsity-reliant\napplications, particularly when we care about generalising to previously unseen\ndata, and provide an alternative that, over many varying conditions, provides\nimproved generalisation performance.\n",
          "  Volterra and polynomial regression models play a major role in nonlinear\nsystem identification and inference tasks. Exciting applications ranging from\nneuroscience to genome-wide association analysis build on these models with the\nadditional requirement of parsimony. This requirement has high interpretative\nvalue, but unfortunately cannot be met by least-squares based or kernel\nregression methods. To this end, compressed sampling (CS) approaches, already\nsuccessful in linear regression settings, can offer a viable alternative. The\nviability of CS for sparse Volterra and polynomial models is the core theme of\nthis work. A common sparse regression task is initially posed for the two\nmodels. Building on (weighted) Lasso-based schemes, an adaptive RLS-type\nalgorithm is developed for sparse polynomial regressions. The identifiability\nof polynomial models is critically challenged by dimensionality. However,\nfollowing the CS principle, when these models are sparse, they could be\nrecovered by far fewer measurements. To quantify the sufficient number of\nmeasurements for a given level of sparsity, restricted isometry properties\n(RIP) are investigated in commonly met polynomial regression settings,\ngeneralizing known results for their linear counterparts. The merits of the\nnovel (weighted) adaptive CS algorithms to sparse polynomial modeling are\nverified through synthetic as well as real data tests for genotype-phenotype\nanalysis.\n",
          "  We propose Shotgun, a parallel coordinate descent algorithm for minimizing\nL1-regularized losses. Though coordinate descent seems inherently sequential,\nwe prove convergence bounds for Shotgun which predict linear speedups, up to a\nproblem-dependent limit. We present a comprehensive empirical study of Shotgun\nfor Lasso and sparse logistic regression. Our theoretical predictions on the\npotential for parallelism closely match behavior on real data. Shotgun\noutperforms other published solvers on a range of large problems, proving to be\none of the most scalable algorithms for L1.\n",
          "  Sparse linear regression -- finding an unknown vector from linear\nmeasurements -- is now known to be possible with fewer samples than variables,\nvia methods like the LASSO. We consider the multiple sparse linear regression\nproblem, where several related vectors -- with partially shared support sets --\nhave to be recovered. A natural question in this setting is whether one can use\nthe sharing to further decrease the overall number of samples required. A line\nof recent research has studied the use of \\ell_1/\\ell_q norm\nblock-regularizations with q>1 for such problems; however these could actually\nperform worse in sample complexity -- vis a vis solving each problem separately\nignoring sharing -- depending on the level of sharing.\n  We present a new method for multiple sparse linear regression that can\nleverage support and parameter overlap when it exists, but not pay a penalty\nwhen it does not. A very simple idea: we decompose the parameters into two\ncomponents and regularize these differently. We show both theoretically and\nempirically, our method strictly and noticeably outperforms both \\ell_1 or\n\\ell_1/\\ell_q methods, over the entire range of possible overlaps (except at\nboundary cases, where we match the best method). We also provide theoretical\nguarantees that the method performs well under high-dimensional scaling.\n",
          "  The graphical lasso \\citep{FHT2007a} is an algorithm for learning the\nstructure in an undirected Gaussian graphical model, using $\\ell_1$\nregularization to control the number of zeros in the precision matrix\n${\\B\\Theta}={\\B\\Sigma}^{-1}$ \\citep{BGA2008,yuan_lin_07}. The {\\texttt R}\npackage \\GL\\ \\citep{FHT2007a} is popular, fast, and allows one to efficiently\nbuild a path of models for different values of the tuning parameter.\nConvergence of \\GL\\ can be tricky; the converged precision matrix might not be\nthe inverse of the estimated covariance, and occasionally it fails to converge\nwith warm starts. In this paper we explain this behavior, and propose new\nalgorithms that appear to outperform \\GL.\n  By studying the \"normal equations\" we see that, \\GL\\ is solving the {\\em\ndual} of the graphical lasso penalized likelihood, by block coordinate ascent;\na result which can also be found in \\cite{BGA2008}.\n  In this dual, the target of estimation is $\\B\\Sigma$, the covariance matrix,\nrather than the precision matrix $\\B\\Theta$. We propose similar primal\nalgorithms \\PGL\\ and \\DPGL, that also operate by block-coordinate descent,\nwhere $\\B\\Theta$ is the optimization target. We study all of these algorithms,\nand in particular different approaches to solving their coordinate\nsub-problems. We conclude that \\DPGL\\ is superior from several points of view.\n",
          "  It is a challenging task to select correlated variables in a high dimensional\nspace. To address this challenge, the elastic net has been developed and\nsuccessfully applied to many applications. Despite its great success, the\nelastic net does not explicitly use correlation information embedded in data to\nselect correlated variables. To overcome this limitation, we present a novel\nBayesian hybrid model, the EigenNet, that uses the eigenstructures of data to\nguide variable selection. Specifically, it integrates a sparse conditional\nclassification model with a generative model capturing variable correlations in\na principled Bayesian framework. We reparameterize the hybrid model in the\neigenspace to avoid overfiting and to increase the computational efficiency of\nits MCMC sampler. Furthermore, we provide an alternative view to the EigenNet\nfrom a regularization perspective: the EigenNet has an adaptive\neigenspace-based composite regularizer, which naturally generalizes the\n$l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and\nreal data show that the EigenNet significantly outperforms the lasso, the\nelastic net, and the Bayesian lasso in terms of prediction accuracy, especially\nwhen the number of training samples is smaller than the number of variables.\n",
          "  The group Lasso is an extension of the Lasso for feature selection on\n(predefined) non-overlapping groups of features. The non-overlapping group\nstructure limits its applicability in practice. There have been several recent\nattempts to study a more general formulation, where groups of features are\ngiven, potentially with overlaps between the groups. The resulting optimization\nis, however, much more challenging to solve due to the group overlaps. In this\npaper, we consider the efficient optimization of the overlapping group Lasso\npenalized problem. We reveal several key properties of the proximal operator\nassociated with the overlapping group Lasso, and compute the proximal operator\nby solving the smooth and convex dual problem, which allows the use of the\ngradient descent type of algorithms for the optimization. We have performed\nempirical evaluations using the breast cancer gene expression data set, which\nconsists of 8,141 genes organized into (overlapping) gene sets. Experimental\nresults demonstrate the efficiency and effectiveness of the proposed algorithm.\n",
          "  We study a norm for structured sparsity which leads to sparse linear\npredictors whose supports are unions of prede ned overlapping groups of\nvariables. We call the obtained formulation latent group Lasso, since it is\nbased on applying the usual group Lasso penalty on a set of latent variables. A\ndetailed analysis of the norm and its properties is presented and we\ncharacterize conditions under which the set of groups associated with latent\nvariables are correctly identi ed. We motivate and discuss the delicate choice\nof weights associated to each group, and illustrate this approach on simulated\ndata and on the problem of breast cancer prognosis from gene expression data.\n",
          "  We consider the problem of estimating the parameters of a Gaussian or binary\ndistribution in such a way that the resulting undirected graphical model is\nsparse. Our approach is to solve a maximum likelihood problem with an added\nl_1-norm penalty term. The problem as formulated is convex but the memory\nrequirements and complexity of existing interior point methods are prohibitive\nfor problems with more than tens of nodes. We present two new algorithms for\nsolving problems with at least a thousand nodes in the Gaussian case. Our first\nalgorithm uses block coordinate descent, and can be interpreted as recursive\nl_1-norm penalized regression. Our second algorithm, based on Nesterov's first\norder method, yields a complexity estimate with a better dependence on problem\nsize than existing interior point methods. Using a log determinant relaxation\nof the log partition function (Wainwright & Jordan (2006)), we show that these\nsame algorithms can be used to solve an approximate sparse maximum likelihood\nproblem for the binary case. We test our algorithms on synthetic data, as well\nas on gene expression and senate voting records data.\n",
          "  Joint sparsity offers powerful structural cues for feature selection,\nespecially for variables that are expected to demonstrate a \"grouped\" behavior.\nSuch behavior is commonly modeled via group-lasso, multitask lasso, and related\nmethods where feature selection is effected via mixed-norms. Several mixed-norm\nbased sparse models have received substantial attention, and for some cases\nefficient algorithms are also available. Surprisingly, several constrained\nsparse models seem to be lacking scalable algorithms. We address this\ndeficiency by presenting batch and online (stochastic-gradient) optimization\nmethods, both of which rely on efficient projections onto mixed-norm balls. We\nillustrate our methods by applying them to the multitask lasso. We conclude by\nmentioning some open problems.\n",
          "  We consider the least-square regression problem with regularization by a\nblock 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger\nthan one. This problem, referred to as the group Lasso, extends the usual\nregularization by the 1-norm where all spaces have dimension one, where it is\ncommonly referred to as the Lasso. In this paper, we study the asymptotic model\nconsistency of the group Lasso. We derive necessary and sufficient conditions\nfor the consistency of group Lasso under practical assumptions, such as model\nmisspecification. When the linear predictors and Euclidean norms are replaced\nby functions and reproducing kernel Hilbert norms, the problem is usually\nreferred to as multiple kernel learning and is commonly used for learning from\nheterogeneous data sources and for non linear variable selection. Using tools\nfrom functional analysis, and in particular covariance operators, we extend the\nconsistency results to this infinite dimensional case and also propose an\nadaptive scheme to obtain a consistent model estimate, even when the necessary\ncondition required for the non adaptive scheme is not satisfied.\n",
          "  We consider the least-square linear regression problem with regularization by\nthe $\\ell^1$-norm, a problem usually referred to as the Lasso. In this paper,\nwe first present a detailed asymptotic analysis of model consistency of the\nLasso in low-dimensional settings. For various decays of the regularization\nparameter, we compute asymptotic equivalents of the probability of correct\nmodel selection. For a specific rate decay, we show that the Lasso selects all\nthe variables that should enter the model with probability tending to one\nexponentially fast, while it selects all other variables with strictly positive\nprobability. We show that this property implies that if we run the Lasso for\nseveral bootstrapped replications of a given sample, then intersecting the\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\nThis novel variable selection procedure, referred to as the Bolasso, is\nextended to high-dimensional settings by a provably consistent two-step\nprocedure.\n",
          "  It is difficult to find the optimal sparse solution of a manifold learning\nbased dimensionality reduction algorithm. The lasso or the elastic net\npenalized manifold learning based dimensionality reduction is not directly a\nlasso penalized least square problem and thus the least angle regression (LARS)\n(Efron et al. \\cite{LARS}), one of the most popular algorithms in sparse\nlearning, cannot be applied. Therefore, most current approaches take indirect\nways or have strict settings, which can be inconvenient for applications. In\nthis paper, we proposed the manifold elastic net or MEN for short. MEN\nincorporates the merits of both the manifold learning based dimensionality\nreduction and the sparse learning based dimensionality reduction. By using a\nseries of equivalent transformations, we show MEN is equivalent to the lasso\npenalized least square problem and thus LARS is adopted to obtain the optimal\nsparse solution of MEN. In particular, MEN has the following advantages for\nsubsequent classification: 1) the local geometry of samples is well preserved\nfor low dimensional data representation, 2) both the margin maximization and\nthe classification error minimization are considered for sparse projection\ncalculation, 3) the projection matrix of MEN improves the parsimony in\ncomputation, 4) the elastic net penalty reduces the over-fitting problem, and\n5) the projection matrix of MEN can be interpreted psychologically and\nphysiologically. Experimental evidence on face recognition over various popular\ndatasets suggests that MEN is superior to top level dimensionality reduction\nalgorithms.\n",
          "  This paper studies the outlier detection problem from the point of view of\npenalized regressions. Our regression model adds one mean shift parameter for\neach of the $n$ data points. We then apply a regularization favoring a sparse\nvector of mean shift parameters. The usual $L_1$ penalty yields a convex\ncriterion, but we find that it fails to deliver a robust estimator. The $L_1$\npenalty corresponds to soft thresholding. We introduce a thresholding (denoted\nby $\\Theta$) based iterative procedure for outlier detection ($\\Theta$-IPOD). A\nversion based on hard thresholding correctly identifies outliers on some hard\ntest problems. We find that $\\Theta$-IPOD is much faster than iteratively\nreweighted least squares for large data because each iteration costs at most\n$O(np)$ (and sometimes much less) avoiding an $O(np^2)$ least squares estimate.\nWe describe the connection between $\\Theta$-IPOD and $M$-estimators. Our\nproposed method has one tuning parameter with which to both identify outliers\nand estimate regression coefficients. A data-dependent choice can be made based\non BIC. The tuned $\\Theta$-IPOD shows outstanding performance in identifying\noutliers in various situations in comparison to other existing approaches. This\nmethodology extends to high-dimensional modeling with $p\\gg n$, if both the\ncoefficient vector and the outlier pattern are sparse.\n",
          "  In multi-label learning, each sample is associated with several labels.\nExisting works indicate that exploring correlations between labels improve the\nprediction performance. However, embedding the label correlations into the\ntraining process significantly increases the problem size. Moreover, the\nmapping of the label structure in the feature space is not clear. In this\npaper, we propose a novel multi-label learning method \"Structured Decomposition\n+ Group Sparsity (SDGS)\". In SDGS, we learn a feature subspace for each label\nfrom the structured decomposition of the training data, and predict the labels\nof a new sample from its group sparse representation on the multi-subspace\nobtained from the structured decomposition. In particular, in the training\nstage, we decompose the data matrix $X\\in R^{n\\times p}$ as\n$X=\\sum_{i=1}^kL^i+S$, wherein the rows of $L^i$ associated with samples that\nbelong to label $i$ are nonzero and consist a low-rank matrix, while the other\nrows are all-zeros, the residual $S$ is a sparse matrix. The row space of $L_i$\nis the feature subspace corresponding to label $i$. This decomposition can be\nefficiently obtained via randomized optimization. In the prediction stage, we\nestimate the group sparse representation of a new sample on the multi-subspace\nvia group \\emph{lasso}. The nonzero representation coefficients tend to\nconcentrate on the subspaces of labels that the sample belongs to, and thus an\neffective prediction can be obtained. We evaluate SDGS on several real datasets\nand compare it with popular methods. Results verify the effectiveness and\nefficiency of SDGS.\n",
          "  We consider a class of learning problems regularized by a structured\nsparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over\ngroups of variables. Whereas much effort has been put in developing fast\noptimization techniques when the groups are disjoint or embedded in a\nhierarchy, we address here the case of general overlapping groups. To this end,\nwe present two different strategies: On the one hand, we show that the proximal\noperator associated with a sum of l_infinity-norms can be computed exactly in\npolynomial time by solving a quadratic min-cost flow problem, allowing the use\nof accelerated proximal gradient methods. On the other hand, we use proximal\nsplitting techniques, and address an equivalent formulation with\nnon-overlapping groups, but in higher dimension and with additional\nconstraints. We propose efficient and scalable algorithms exploiting these two\nstrategies, which are significantly faster than alternative approaches. We\nillustrate these methods with several problems such as CUR matrix\nfactorization, multi-task learning of tree-structured dictionaries, background\nsubtraction in video sequences, image denoising with wavelets, and topographic\ndictionary learning of natural image patches.\n",
          "  We derive a novel norm that corresponds to the tightest convex relaxation of\nsparsity combined with an $\\ell_2$ penalty. We show that this new {\\em\n$k$-support norm} provides a tighter relaxation than the elastic net and is\nthus a good replacement for the Lasso or the elastic net in sparse prediction\nproblems. Through the study of the $k$-support norm, we also bound the\nlooseness of the elastic net, thus shedding new light on it and providing\njustification for its use.\n",
          "  Lasso, or $\\ell^1$ regularized least squares, has been explored extensively\nfor its remarkable sparsity properties. It is shown in this paper that the\nsolution to Lasso, in addition to its sparsity, has robustness properties: it\nis the solution to a robust optimization problem. This has two important\nconsequences. First, robustness provides a connection of the regularizer to a\nphysical property, namely, protection from noise. This allows a principled\nselection of the regularizer, and in particular, generalizations of Lasso that\nalso yield convex optimization problems are obtained by considering different\nuncertainty sets.\n  Secondly, robustness can itself be used as an avenue to exploring different\nproperties of the solution. In particular, it is shown that robustness of the\nsolution explains why the solution is sparse. The analysis as well as the\nspecific results obtained differ from standard sparsity results, providing\ndifferent geometric intuition. Furthermore, it is shown that the robust\noptimization formulation is related to kernel density estimation, and based on\nthis approach, a proof that Lasso is consistent is given using robustness\ndirectly. Finally, a theorem saying that sparsity and algorithmic stability\ncontradict each other, and hence Lasso is not stable, is presented.\n",
          "  We describe a fast method to eliminate features (variables) in l1 -penalized\nleast-square regression (or LASSO) problems. The elimination of features leads\nto a potentially substantial reduction in running time, specially for large\nvalues of the penalty parameter. Our method is not heuristic: it only\neliminates features that are guaranteed to be absent after solving the LASSO\nproblem. The feature elimination step is easy to parallelize and can test each\nfeature for elimination independently. Moreover, the computational effort of\nour method is negligible compared to that of solving the LASSO problem -\nroughly it is the same as single gradient step. Our method extends the scope of\nexisting LASSO algorithms to treat larger data sets, previously out of their\nreach. We show how our method can be extended to general l1 -penalized convex\nproblems and present preliminary results for the Sparse Support Vector Machine\nand Logistic Regression problems.\n",
          "  We study a generalized framework for structured sparsity. It extends the\nwell-known methods of Lasso and Group Lasso by incorporating additional\nconstraints on the variables as part of a convex optimization problem. This\nframework provides a straightforward way of favouring prescribed sparsity\npatterns, such as orderings, contiguous regions and overlapping groups, among\nothers. Existing optimization methods are limited to specific constraint sets\nand tend to not scale well with sample size and dimensionality. We propose a\nnovel first order proximal method, which builds upon results on fixed points\nand successive approximations. The algorithm can be applied to a general class\nof conic and norm constraints sets and relies on a proximity operator\nsubproblem which can be computed explicitly. Experiments on different\nregression problems demonstrate the efficiency of the optimization algorithm\nand its scalability with the size of the problem. They also demonstrate state\nof the art statistical performance, which improves over Lasso and StructOMP.\n",
          "  Sparse learning has recently received increasing attention in many areas\nincluding machine learning, statistics, and applied mathematics. The mixed-norm\nregularization based on the L1/Lq norm with q > 1 is attractive in many\napplications of regression and classification in that it facilitates group\nsparsity in the model. The resulting optimization problem is, however,\nchallenging to solve due to the structure of the L1/Lq -regularization.\nExisting work deals with special cases including q = 2,infinity, and they\ncannot be easily extended to the general case. In this paper, we propose an\nefficient algorithm based on the accelerated gradient method for solving the\nL1/Lq -regularized problem, which is applicable for all values of q larger than\n1, thus significantly extending existing work. One key building block of the\nproposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our\ntheoretical analysis reveals the key properties of EP1q and illustrates why\nEP1q for the general q is significantly more challenging to solve than the\nspecial cases. Based on our theoretical analysis, we develop an efficient\nalgorithm for EP1q by solving two zero finding problems. Experimental results\ndemonstrate the efficiency of the proposed algorithm.\n",
          "  A wide class of regularization problems in machine learning and statistics\nemploy a regularization term which is obtained by composing a simple convex\nfunction \\omega with a linear transformation. This setting includes Group Lasso\nmethods, the Fused Lasso and other total variation methods, multi-task learning\nmethods and many more. In this paper, we present a general approach for\ncomputing the proximity operator of this class of regularizers, under the\nassumption that the proximity operator of the function \\omega is known in\nadvance. Our approach builds on a recent line of research on optimal first\norder optimization methods and uses fixed point iterations for numerically\ncomputing the proximity operator. It is more general than current approaches\nand, as we show with numerical simulations, computationally more efficient than\navailable first order methods which do not achieve the optimal rate. In\nparticular, our method outperforms state of the art O(1/T) methods for\noverlapping Group Lasso and matches optimal O(1/T^2) methods for the Fused\nLasso and tree structured Group Lasso.\n",
          "  We consider the problem of learning a structured multi-task regression, where\nthe output consists of multiple responses that are related by a graph and the\ncorrelated response variables are dependent on the common inputs in a sparse\nbut synergistic manner. Previous methods such as l1/l2-regularized multi-task\nregression assume that all of the output variables are equally related to the\ninputs, although in many real-world problems, outputs are related in a complex\nmanner. In this paper, we propose graph-guided fused lasso (GFlasso) for\nstructured multi-task regression that exploits the graph structure over the\noutput variables. We introduce a novel penalty function based on fusion penalty\nto encourage highly correlated outputs to share a common set of relevant\ninputs. In addition, we propose a simple yet efficient proximal-gradient method\nfor optimizing GFlasso that can also be applied to any optimization problems\nwith a convex smooth loss and the general class of fusion penalty defined on\narbitrary graph structures. By exploiting the structure of the non-smooth\n''fusion penalty'', our method achieves a faster convergence rate than the\nstandard first-order method, sub-gradient method, and is significantly more\nscalable than the widely adopted second-order cone-programming and\nquadratic-programming formulations. In addition, we provide an analysis of the\nconsistency property of the GFlasso model. Experimental results not only\ndemonstrate the superiority of GFlasso over the standard lasso but also show\nthe efficiency and scalability of our proximal-gradient method.\n",
          "  Sparse estimation methods are aimed at using or obtaining parsimonious\nrepresentations of data or models. They were first dedicated to linear variable\nselection but numerous extensions have now emerged such as structured sparsity\nor kernel selection. It turns out that many of the related estimation problems\ncan be cast as convex optimization problems by regularizing the empirical risk\nwith appropriate non-smooth norms. The goal of this paper is to present from a\ngeneral perspective optimization tools and techniques dedicated to such\nsparsity-inducing penalties. We cover proximal methods, block-coordinate\ndescent, reweighted $\\ell_2$-penalized techniques, working-set and homotopy\nmethods, as well as non-convex formulations and extensions, and provide an\nextensive set of experiments to compare various algorithms from a computational\npoint of view.\n",
          "  We study the problem of estimating high-dimensional regression models\nregularized by a structured sparsity-inducing penalty that encodes prior\nstructural information on either the input or output variables. We consider two\nwidely adopted types of penalties of this kind as motivating examples: (1) the\ngeneral overlapping-group-lasso penalty, generalized from the group-lasso\npenalty; and (2) the graph-guided-fused-lasso penalty, generalized from the\nfused-lasso penalty. For both types of penalties, due to their nonseparability\nand nonsmoothness, developing an efficient optimization method remains a\nchallenging problem. In this paper we propose a general optimization approach,\nthe smoothing proximal gradient (SPG) method, which can solve structured sparse\nregression problems with any smooth convex loss under a wide spectrum of\nstructured sparsity-inducing penalties. Our approach combines a smoothing\ntechnique with an effective proximal gradient method. It achieves a convergence\nrate significantly faster than the standard first-order methods, subgradient\nmethods, and is much more scalable than the most widely used interior-point\nmethods. The efficiency and scalability of our method are demonstrated on both\nsimulation experiments and real genetic data sets.\n",
          "  Using the $\\ell_1$-norm to regularize the estimation of the parameter vector\nof a linear model leads to an unstable estimator when covariates are highly\ncorrelated. In this paper, we introduce a new penalty function which takes into\naccount the correlation of the design matrix to stabilize the estimation. This\nnorm, called the trace Lasso, uses the trace norm, which is a convex surrogate\nof the rank, of the selected covariates as the criterion of model complexity.\nWe analyze the properties of our norm, describe an optimization algorithm based\non reweighted least-squares, and illustrate the behavior of this norm on\nsynthetic data, showing that it is more adapted to strong correlations than\ncompeting methods such as the elastic net.\n",
          "  rdering of regression or classification coefficients occurs in many\nreal-world applications. Fused Lasso exploits this ordering by explicitly\nregularizing the differences between neighboring coefficients through an\n$\\ell_1$ norm regularizer. However, due to nonseparability and nonsmoothness of\nthe regularization term, solving the fused Lasso problem is computationally\ndemanding. Existing solvers can only deal with problems of small or medium\nsize, or a special case of the fused Lasso problem in which the predictor\nmatrix is identity matrix. In this paper, we propose an iterative algorithm\nbased on split Bregman method to solve a class of large-scale fused Lasso\nproblems, including a generalized fused Lasso and a fused Lasso support vector\nclassifier. We derive our algorithm using augmented Lagrangian method and prove\nits convergence properties. The performance of our method is tested on both\nartificial data and real-world applications including proteomic data from mass\nspectrometry and genomic data from array CGH. We demonstrate that our method is\nmany times faster than the existing solvers, and show that it is especially\nefficient for large p, small n problems.\n",
          "  We consider the least-square linear regression problem with regularization by\nthe l1-norm, a problem usually referred to as the Lasso. In this paper, we\npresent a detailed asymptotic analysis of model consistency of the Lasso. For\nvarious decays of the regularization parameter, we compute asymptotic\nequivalents of the probability of correct model selection (i.e., variable\nselection). For a specific rate decay, we show that the Lasso selects all the\nvariables that should enter the model with probability tending to one\nexponentially fast, while it selects all other variables with strictly positive\nprobability. We show that this property implies that if we run the Lasso for\nseveral bootstrapped replications of a given sample, then intersecting the\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\nThis novel variable selection algorithm, referred to as the Bolasso, is\ncompared favorably to other linear regression methods on synthetic data and\ndatasets from the UCI machine learning repository.\n",
          "  We present a data dependent generalization bound for a large class of\nregularized algorithms which implement structured sparsity constraints. The\nbound can be applied to standard squared-norm regularization, the Lasso, the\ngroup Lasso, some versions of the group Lasso with overlapping groups, multiple\nkernel learning and other regularization schemes. In all these cases\ncompetitive results are obtained. A novel feature of our bound is that it can\nbe applied in an infinite dimensional setting such as the Lasso in a separable\nHilbert space or multiple kernel learning with a countable number of kernels.\n",
          "  We study the problem of learning high dimensional regression models\nregularized by a structured-sparsity-inducing penalty that encodes prior\nstructural information on either input or output sides. We consider two widely\nadopted types of such penalties as our motivating examples: 1) overlapping\ngroup lasso penalty, based on the l1/l2 mixed-norm penalty, and 2) graph-guided\nfusion penalty. For both types of penalties, due to their non-separability,\ndeveloping an efficient optimization method has remained a challenging problem.\nIn this paper, we propose a general optimization approach, called smoothing\nproximal gradient method, which can solve the structured sparse regression\nproblems with a smooth convex loss and a wide spectrum of\nstructured-sparsity-inducing penalties. Our approach is based on a general\nsmoothing technique of Nesterov. It achieves a convergence rate faster than the\nstandard first-order method, subgradient method, and is much more scalable than\nthe most widely used interior-point method. Numerical results are reported to\ndemonstrate the efficiency and scalability of the proposed method.\n",
          "  We consider a class of learning problems that involve a structured\nsparsity-inducing norm defined as the sum of $\\ell_\\infty$-norms over groups of\nvariables. Whereas a lot of effort has been put in developing fast optimization\nmethods when the groups are disjoint or embedded in a specific hierarchical\nstructure, we address here the case of general overlapping groups. To this end,\nwe show that the corresponding optimization problem is related to network flow\noptimization. More precisely, the proximal problem associated with the norm we\nconsider is dual to a quadratic min-cost flow problem. We propose an efficient\nprocedure which computes its solution exactly in polynomial time. Our algorithm\nscales up to millions of variables, and opens up a whole new range of\napplications for structured sparse models. We present several experiments on\nimage and video data, demonstrating the applicability and scalability of our\napproach for various problems.\n",
          "  In this paper, we present a new variational method for sparse regression\nusing $L_0$ regularization. The variational parameters appear in the\napproximate model in a way that is similar to Breiman's Garrote model. We refer\nto this method as the variational Garrote (VG). We show that the combination of\nthe variational approximation and $L_0$ regularization has the effect of making\nthe problem effectively of maximal rank even when the number of samples is\nsmall compared to the number of variables. The VG is compared numerically with\nthe Lasso method, ridge regression and the recently introduced paired mean\nfield method (PMF) (M. Titsias & M. L\\'azaro-Gredilla., NIPS 2012). Numerical\nresults show that the VG and PMF yield more accurate predictions and more\naccurately reconstruct the true model than the other methods. It is shown that\nthe VG finds correct solutions when the Lasso solution is inconsistent due to\nlarge input correlations. Globally, VG is significantly faster than PMF and\ntends to perform better as the problems become denser and in problems with\nstrongly correlated inputs. The naive implementation of the VG scales cubic\nwith the number of features. By introducing Lagrange multipliers we obtain a\ndual formulation of the problem that scales cubic in the number of samples, but\nclose to linear in the number of features.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_lasso_regularization_regularized",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_lasso_regularization_regularized"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.474805235862732,
          1.9248223304748535,
          2.1221625804901123,
          2.023590087890625,
          1.9158192873001099,
          1.8788257837295532,
          2.004915714263916,
          1.99439537525177,
          2.008383274078369,
          1.9250212907791138,
          2.1912522315979004,
          2.094421148300171,
          1.861894965171814,
          2.080488443374634,
          1.8361263275146484,
          1.9213114976882935,
          1.7795279026031494,
          2.0114262104034424,
          2.0566012859344482,
          2.031249523162842,
          2.0054688453674316,
          2.0492405891418457,
          1.977354884147644,
          1.9437439441680908,
          1.9780606031417847,
          2.003039598464966,
          2.0350000858306885,
          2.126371383666992,
          2.0231592655181885,
          1.989655613899231,
          1.8136357069015503,
          1.968047022819519,
          1.9703068733215332
         ],
         "y": [
          10.42932415008545,
          10.421928405761719,
          10.401792526245117,
          10.375749588012695,
          10.727364540100098,
          10.380481719970703,
          10.437915802001953,
          10.418310165405273,
          10.597433090209961,
          10.39236068725586,
          10.308121681213379,
          10.46146011352539,
          10.424694061279297,
          10.442669868469238,
          10.28069019317627,
          10.485873222351074,
          10.657472610473633,
          10.550431251525879,
          10.345254898071289,
          10.440528869628906,
          10.420492172241211,
          10.44844913482666,
          10.335684776306152,
          10.482115745544434,
          10.420663833618164,
          10.726347923278809,
          10.443485260009766,
          10.469279289245605,
          10.427562713623047,
          10.425562858581543,
          10.355088233947754,
          10.455632209777832,
          10.449694633483887
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Multilabel classification is a relatively recent subfield of machine\nlearning. Unlike to the classical approach, where instances are labeled with\nonly one category, in multilabel classification, an arbitrary number of\ncategories is chosen to label an instance. Due to the problem complexity (the\nsolution is one among an exponential number of alternatives), a very common\nsolution (the binary method) is frequently used, learning a binary classifier\nfor every category, and combining them all afterwards. The assumption taken in\nthis solution is not realistic, and in this work we give examples where the\ndecisions for all the labels are not taken independently, and thus, a\nsupervised approach should learn those existing relationships among categories\nto make a better classification. Therefore, we show here a generic methodology\nthat can improve the results obtained by a set of independent probabilistic\nbinary classifiers, by using a combination procedure with a classifier trained\non the co-occurrences of the labels. We show an exhaustive experimentation in\nthree different standard corpora of labeled documents (Reuters-21578,\nOhsumed-23 and RCV1), which present noticeable improvements in all of them,\nwhen using our methodology, in three probabilistic base classifiers.\n",
          "  We consider the problem of function estimation in the case where the data\ndistribution may shift between training and test time, and additional\ninformation about it may be available at test time. This relates to popular\nscenarios such as covariate shift, concept drift, transfer learning and\nsemi-supervised learning. This working paper discusses how these tasks could be\ntackled depending on the kind of changes of the distributions. It argues that\nknowledge of an underlying causal direction can facilitate several of these\ntasks.\n",
          "  The standard training method of Conditional Random Fields (CRFs) is very slow\nfor large-scale applications. As an alternative, piecewise training divides the\nfull graph into pieces, trains them independently, and combines the learned\nweights at test time. In this paper, we present \\emph{separate} training for\nundirected models based on the novel Co-occurrence Rate Factorization (CR-F).\nSeparate training is a local training method. In contrast to MEMMs, separate\ntraining is unaffected by the label bias problem. Experiments show that\nseparate training (i) is unaffected by the label bias problem; (ii) reduces the\ntraining time from weeks to seconds; and (iii) obtains competitive results to\nthe standard and piecewise training on linear-chain CRFs.\n",
          "  This work explores the effects of relevant and irrelevant boolean variables\non the accuracy of classifiers. The analysis uses the assumption that the\nvariables are conditionally independent given the class, and focuses on a\nnatural family of learning algorithms for such sources when the relevant\nvariables have a small advantage over random guessing. The main result is that\nalgorithms relying predominately on irrelevant variables have error\nprobabilities that quickly go to 0 in situations where algorithms that limit\nthe use of irrelevant variables have errors bounded below by a positive\nconstant. We also show that accurate learning is possible even when there are\nso few examples that one cannot determine with high confidence whether or not\nany individual variable is relevant.\n",
          "  Semi-supervised support vector machines (S3VMs) are a kind of popular\napproaches which try to improve learning performance by exploiting unlabeled\ndata. Though S3VMs have been found helpful in many situations, they may\ndegenerate performance and the resultant generalization ability may be even\nworse than using the labeled data only. In this paper, we try to reduce the\nchance of performance degeneration of S3VMs. Our basic idea is that, rather\nthan exploiting all unlabeled data, the unlabeled instances should be selected\nsuch that only the ones which are very likely to be helpful are exploited,\nwhile some highly risky unlabeled instances are avoided. We propose the\nS3VM-\\emph{us} method by using hierarchical clustering to select the unlabeled\ninstances. Experiments on a broad range of data sets over eighty-eight\ndifferent settings show that the chance of performance degeneration of\nS3VM-\\emph{us} is much smaller than that of existing S3VMs.\n",
          "  A bag-of-words based probabilistic classifier is trained using regularized\nlogistic regression to detect vandalism in the English Wikipedia. Isotonic\nregression is used to calibrate the class membership probabilities. Learning\ncurve, reliability, ROC, and cost analysis are performed.\n",
          "  The most basic assumption used in statistical learning theory is that\ntraining data and test data are drawn from the same underlying distribution.\nUnfortunately, in many applications, the \"in-domain\" test data is drawn from a\ndistribution that is related, but not identical, to the \"out-of-domain\"\ndistribution of the training data. We consider the common case in which labeled\nout-of-domain data is plentiful, but labeled in-domain data is scarce. We\nintroduce a statistical formulation of this problem in terms of a simple\nmixture model and present an instantiation of this framework to maximum entropy\nclassifiers and their linear chain counterparts. We present efficient inference\nalgorithms for this special case based on the technique of conditional\nexpectation maximization. Our experimental results show that our approach leads\nto improved performance on three real world tasks on four different data sets\nfrom the natural language processing domain.\n",
          "  This work deals with the problem of classifying uncertain data. With this aim\nthe Uncertain Nearest Neighbor (UNN) rule is here introduced, which represents\nthe generalization of the deterministic nearest neighbor rule to the case in\nwhich uncertain objects are available. The UNN rule relies on the concept of\nnearest neighbor class, rather than on that of nearest neighbor object. The\nnearest neighbor class of a test object is the class that maximizes the\nprobability of providing its nearest neighbor. It is provided evidence that the\nformer concept is much more powerful than the latter one in the presence of\nuncertainty, in that it correctly models the right semantics of the nearest\nneighbor decision rule when applied to the uncertain scenario. An effective and\nefficient algorithm to perform uncertain nearest neighbor classification of a\ngeneric (un)certain test object is designed, based on properties that greatly\nreduce the temporal cost associated with nearest neighbor class probability\ncomputation. Experimental results are presented, showing that the UNN rule is\neffective and efficient in classifying uncertain data.\n",
          "  We describe Information Forests, an approach to classification that\ngeneralizes Random Forests by replacing the splitting criterion of non-leaf\nnodes from a discriminative one -- based on the entropy of the label\ndistribution -- to a generative one -- based on maximizing the information\ndivergence between the class-conditional distributions in the resulting\npartitions. The basic idea consists of deferring classification until a measure\nof \"classification confidence\" is sufficiently high, and instead breaking down\nthe data so as to maximize this measure. In an alternative interpretation,\nInformation Forests attempt to partition the data into subsets that are \"as\ninformative as possible\" for the purpose of the task, which is to classify the\ndata. Classification confidence, or informative content of the subsets, is\nquantified by the Information Divergence. Our approach relates to active\nlearning, semi-supervised learning, mixed generative/discriminative learning.\n",
          "  Learning algorithms normally assume that there is at most one annotation or\nlabel per data point. However, in some scenarios, such as medical diagnosis and\non-line collaboration,multiple annotations may be available. In either case,\nobtaining labels for data points can be expensive and time-consuming (in some\ncircumstances ground-truth may not exist). Semi-supervised learning approaches\nhave shown that utilizing the unlabeled data is often beneficial in these\ncases. This paper presents a probabilistic semi-supervised model and algorithm\nthat allows for learning from both unlabeled and labeled data in the presence\nof multiple annotators. We assume that it is known what annotator labeled which\ndata points. The proposed approach produces annotator models that allow us to\nprovide (1) estimates of the true label and (2) annotator variable expertise\nfor both labeled and unlabeled data. We provide numerical comparisons under\nvarious scenarios and with respect to standard semi-supervised learning.\nExperiments showed that the presented approach provides clear advantages over\nmulti-annotator methods that do not use the unlabeled data and over methods\nthat do not use multi-labeler information.\n",
          "  In conventional supervised pattern recognition tasks, model selection is\ntypically accomplished by minimizing the classification error rate on a set of\nso-called development data, subject to ground-truth labeling by human experts\nor some other means. In the context of speech processing systems and other\nlarge-scale practical applications, however, such labeled development data are\ntypically costly and difficult to obtain. This article proposes an alternative\nsemi-supervised framework for likelihood-based model selection that leverages\nunlabeled data by using trained classifiers representing each model to\nautomatically generate putative labels. The errors that result from this\nautomatic labeling are shown to be amenable to results from robust statistics,\nwhich in turn provide for minimax-optimal censored likelihood ratio tests that\nrecover the nonparametric sign test as a limiting case. This approach is then\nvalidated experimentally using a state-of-the-art automatic speech recognition\nsystem to select between candidate word pronunciations using unlabeled speech\ndata that only potentially contain instances of the words under test. Results\nprovide supporting evidence for the utility of this approach, and suggest that\nit may also find use in other applications of machine learning.\n",
          "  We present an approach to semi-supervised learning based on an exponential\nfamily characterization. Our approach generalizes previous work on coupled\npriors for hybrid generative/discriminative models. Our model is more flexible\nand natural than previous approaches. Experimental results on several data sets\nshow that our approach also performs better in practice.\n",
          "  There has been increased interest in devising learning techniques that\ncombine unlabeled data with labeled data ? i.e. semi-supervised learning.\nHowever, to the best of our knowledge, no study has been performed across\nvarious techniques and different types and amounts of labeled and unlabeled\ndata. Moreover, most of the published work on semi-supervised learning\ntechniques assumes that the labeled and unlabeled data come from the same\ndistribution. It is possible for the labeling process to be associated with a\nselection bias such that the distributions of data points in the labeled and\nunlabeled sets are different. Not correcting for such bias can result in biased\nfunction approximation with potentially poor performance. In this paper, we\npresent an empirical study of various semi-supervised learning techniques on a\nvariety of datasets. We attempt to answer various questions such as the effect\nof independence or relevance amongst features, the effect of the size of the\nlabeled and unlabeled sets and the effect of noise. We also investigate the\nimpact of sample-selection bias on the semi-supervised learning techniques\nunder study and implement a bivariate probit technique particularly designed to\ncorrect for such bias.\n",
          "  We address the problems of multi-domain and single-domain regression based on\ndistinct and unpaired labeled training sets for each of the domains and a large\nunlabeled training set from all domains. We formulate these problems as a\nBayesian estimation with partial knowledge of statistical relations. We propose\na worst-case design strategy and study the resulting estimators. Our analysis\nexplicitly accounts for the cardinality of the labeled sets and includes the\nspecial cases in which one of the labeled sets is very large or, in the other\nextreme, completely missing. We demonstrate our estimators in the context of\nremoving expressions from facial images and in the context of audio-visual word\nrecognition, and provide comparisons to several recently proposed multi-modal\nlearning algorithms.\n",
          "  We present an algorithm, called the Offset Tree, for learning to make\ndecisions in situations where the payoff of only one choice is observed, rather\nthan all choices. The algorithm reduces this setting to binary classification,\nallowing one to reuse of any existing, fully supervised binary classification\nalgorithm in this partial information setting. We show that the Offset Tree is\nan optimal reduction to binary classification. In particular, it has regret at\nmost $(k-1)$ times the regret of the binary classifier it uses (where $k$ is\nthe number of choices), and no reduction to binary classification can do\nbetter. This reduction is also computationally optimal, both at training and\ntest time, requiring just $O(\\log_2 k)$ work to train on an example or make a\nprediction.\n  Experiments with the Offset Tree show that it generally performs better than\nseveral alternative approaches.\n",
          "  For a classification problem described by the joint density $P(\\omega,x)$,\nmodels of $P(\\omega\\eq\\omega'|x,x')$ (the ``Bayesian similarity measure'') have\nbeen shown to be an optimal similarity measure for nearest neighbor\nclassification. This paper analyzes demonstrates several additional properties\nof that conditional distribution. The paper first shows that we can\nreconstruct, up to class labels, the class posterior distribution $P(\\omega|x)$\ngiven $P(\\omega\\eq\\omega'|x,x')$, gives a procedure for recovering the class\nlabels, and gives an asymptotically Bayes-optimal classification procedure. It\nalso shows, given such an optimal similarity measure, how to construct a\nclassifier that outperforms the nearest neighbor classifier and achieves\nBayes-optimal classification rates. The paper then analyzes Bayesian similarity\nin a framework where a classifier faces a number of related classification\ntasks (multitask learning) and illustrates that reconstruction of the class\nposterior distribution is not possible in general. Finally, the paper\nidentifies a distinct class of classification problems using\n$P(\\omega\\eq\\omega'|x,x')$ and shows that using $P(\\omega\\eq\\omega'|x,x')$ to\nsolve those problems is the Bayes optimal solution.\n",
          "  Ordinal regression is commonly formulated as a multi-class problem with\nordinal constraints. The challenge of designing accurate classifiers for\nordinal regression generally increases with the number of classes involved, due\nto the large number of labeled patterns that are needed. The availability of\nordinal class labels, however, is often costly to calibrate or difficult to\nobtain. Unlabeled patterns, on the other hand, often exist in much greater\nabundance and are freely available. To take benefits from the abundance of\nunlabeled patterns, we present a novel transductive learning paradigm for\nordinal regression in this paper, namely Transductive Ordinal Regression (TOR).\nThe key challenge of the present study lies in the precise estimation of both\nthe ordinal class label of the unlabeled data and the decision functions of the\nordinal classes, simultaneously. The core elements of the proposed TOR include\nan objective function that caters to several commonly used loss functions\ncasted in transductive settings, for general ordinal regression. A label\nswapping scheme that facilitates a strictly monotonic decrease in the objective\nfunction value is also introduced. Extensive numerical studies on commonly used\nbenchmark datasets including the real world sentiment prediction problem are\nthen presented to showcase the characteristics and efficacies of the proposed\ntransductive ordinal regression. Further, comparisons to recent\nstate-of-the-art ordinal regression methods demonstrate the introduced\ntransductive learning paradigm for ordinal regression led to the robust and\nimproved performance.\n",
          "  Multi-instance learning attempts to learn from a training set consisting of\nlabeled bags each containing many unlabeled instances. Previous studies\ntypically treat the instances in the bags as independently and identically\ndistributed. However, the instances in a bag are rarely independent, and\ntherefore a better performance can be expected if the instances are treated in\nan non-i.i.d. way that exploits the relations among instances. In this paper,\nwe propose a simple yet effective multi-instance learning method, which regards\neach bag as a graph and uses a specific kernel to distinguish the graphs by\nconsidering the features of the nodes as well as the features of the edges that\nconvey some relations among instances. The effectiveness of the proposed method\nis validated by experiments.\n",
          "  Leveraging the power of increasing amounts of data to analyze customer base\nfor attracting and retaining the most valuable customers is a major problem\nfacing companies in this information age. Data mining technologies extract\nhidden information and knowledge from large data stored in databases or data\nwarehouses, thereby supporting the corporate decision making process. CRM uses\ndata mining (one of the elements of CRM) techniques to interact with customers.\nThis study investigates the use of a technique, semi-supervised learning, for\nthe management and analysis of customer-related data warehouse and information.\nThe idea of semi-supervised learning is to learn not only from the labeled\ntraining data, but to exploit also the structural information in additionally\navailable unlabeled data. The proposed semi-supervised method is a model by\nmeans of a feed-forward neural network trained by a back propagation algorithm\n(multi-layer perceptron) in order to predict the category of an unknown\ncustomer (potential customers). In addition, this technique can be used with\nRapid Miner tools for both labeled and unlabeled data.\n",
          "  We propose a novel hybrid loss for multiclass and structured prediction\nproblems that is a convex combination of log loss for Conditional Random Fields\n(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We\nprovide a sufficient condition for when the hybrid loss is Fisher consistent\nfor classification. This condition depends on a measure of dominance between\nlabels - specifically, the gap in per observation probabilities between the\nmost likely labels. We also prove Fisher consistency is necessary for\nparametric consistency when learning models such as CRFs.\n  We demonstrate empirically that the hybrid loss typically performs as least\nas well as - and often better than - both of its constituent losses on variety\nof tasks. In doing so we also provide an empirical comparison of the efficacy\nof probabilistic and margin based approaches to multiclass and structured\nprediction and the effects of label dominance on these results.\n",
          "  In Bayesian machine learning, conjugate priors are popular, mostly due to\nmathematical convenience. In this paper, we show that there are deeper reasons\nfor choosing a conjugate prior. Specifically, we formulate the conjugate prior\nin the form of Bregman divergence and show that it is the inherent geometry of\nconjugate priors that makes them appropriate and intuitive. This geometric\ninterpretation allows one to view the hyperparameters of conjugate priors as\nthe {\\it effective} sample points, thus providing additional intuition. We use\nthis geometric understanding of conjugate priors to derive the hyperparameters\nand expression of the prior used to couple the generative and discriminative\ncomponents of a hybrid model for semi-supervised learning.\n",
          "  We consider the task of learning a classifier from the feature space\n$\\mathcal{X}$ to the set of classes $\\mathcal{Y} = \\{0, 1\\}$, when the features\ncan be partitioned into class-conditionally independent feature sets\n$\\mathcal{X}_1$ and $\\mathcal{X}_2$. We show the surprising fact that the\nclass-conditional independence can be used to represent the original learning\ntask in terms of 1) learning a classifier from $\\mathcal{X}_2$ to\n$\\mathcal{X}_1$ and 2) learning the class-conditional distribution of the\nfeature set $\\mathcal{X}_1$. This fact can be exploited for semi-supervised\nlearning because the former task can be accomplished purely from unlabeled\nsamples. We present experimental evaluation of the idea in two real world\napplications.\n",
          "  Semisupervised learning has emerged as a popular framework for improving\nmodeling accuracy while controlling labeling cost. Based on an extension of\nstochastic composite likelihood we quantify the asymptotic accuracy of\ngenerative semi-supervised learning. In doing so, we complement\ndistribution-free analysis by providing an alternative framework to measure the\nvalue associated with different labeling policies and resolve the fundamental\nquestion of how much data to label and in what manner. We demonstrate our\napproach with both simulation studies and real world experiments using naive\nBayes for text classification and MRFs and CRFs for structured prediction in\nNLP.\n",
          "  Semisupervised methods are techniques for using labeled data\n$(X_1,Y_1),\\ldots,(X_n,Y_n)$ together with unlabeled data $X_{n+1},\\ldots,X_N$\nto make predictions. These methods invoke some assumptions that link the\nmarginal distribution $P_X$ of X to the regression function f(x). For example,\nit is common to assume that f is very smooth over high density regions of\n$P_X$. Many of the methods are ad-hoc and have been shown to work in specific\nexamples but are lacking a theoretical foundation. We provide a minimax\nframework for analyzing semisupervised methods. In particular, we study methods\nbased on metrics that are sensitive to the distribution $P_X$. Our model\nincludes a parameter $\\alpha$ that controls the strength of the semisupervised\nassumption. We then use the data to adapt to $\\alpha$.\n",
          "  Collecting large labeled data sets is a laborious and expensive task, whose\nscaling up requires division of the labeling workload between many teachers.\nWhen the number of classes is large, miscorrespondences between the labels\ngiven by the different teachers are likely to occur, which, in the extreme\ncase, may reach total inconsistency. In this paper we describe how globally\nconsistent labels can be obtained, despite the absence of teacher coordination,\nand discuss the possible efficiency of this process in terms of human labor. We\ndefine a notion of label efficiency, measuring the ratio between the number of\nglobally consistent labels obtained and the number of labels provided by\ndistributed teachers. We show that the efficiency depends critically on the\nratio alpha between the number of data instances seen by a single teacher, and\nthe number of classes. We suggest several algorithms for the distributed\nlabeling problem, and analyze their efficiency as a function of alpha. In\naddition, we provide an upper bound on label efficiency for the case of\ncompletely uncoordinated teachers, and show that efficiency approaches 0 as the\nratio between the number of labels each teacher provides and the number of\nclasses drops (i.e. alpha goes to 0).\n",
          "  We describe an approach to domain adaptation that is appropriate exactly in\nthe case when one has enough ``target'' data to do slightly better than just\nusing only ``source'' data. Our approach is incredibly simple, easy to\nimplement as a preprocessing step (10 lines of Perl!) and outperforms\nstate-of-the-art approaches on a range of datasets. Moreover, it is trivially\nextended to a multi-domain adaptation problem, where one has data from a\nvariety of different domains.\n",
          "  Probabilistic generative modeling of data distributions can potentially\nexploit hidden information which is useful for discriminative classification.\nThis observation has motivated the development of approaches that couple\ngenerative and discriminative models for classification. In this paper, we\npropose a new approach to couple generative and discriminative models in an\nunified framework based on PAC-Bayes risk theory. We first derive the\nmodel-parameter-independent stochastic feature mapping from a practical MAP\nclassifier operating on generative models. Then we construct a linear\nstochastic classifier equipped with the feature mapping, and derive the\nexplicit PAC-Bayes risk bounds for such classifier for both supervised and\nsemi-supervised learning. Minimizing the risk bound, using an EM-like iterative\nprocedure, results in a new posterior over hidden variables (E-step) and the\nupdate rules of model parameters (M-step). The derivation of the posterior is\nalways feasible due to the way of equipping feature mapping and the explicit\nform of bounding risk. The derived posterior allows the tuning of generative\nmodels and subsequently the feature mappings for better classification. The\nderived update rules of the model parameters are same to those of the uncoupled\nmodels as the feature mapping is model-parameter-independent. Our experiments\nshow that the coupling between data modeling generative model and the\ndiscriminative classifier via a stochastic feature mapping in this framework\nleads to a general classification tool with state-of-the-art performance.\n",
          "  Many popular linear classifiers, such as logistic regression, boosting, or\nSVM, are trained by optimizing a margin-based risk function. Traditionally,\nthese risk functions are computed based on a labeled dataset. We develop a\nnovel technique for estimating such risks using only unlabeled data and the\nmarginal label distribution. We prove that the proposed risk estimator is\nconsistent on high-dimensional datasets and demonstrate it on synthetic and\nreal-world data. In particular, we show how the estimate is used for evaluating\nclassifiers in transfer learning, and for training classifiers with no labeled\ndata whatsoever.\n",
          "  Conditional Random Fields (CRFs) constitute a popular and efficient approach\nfor supervised sequence labelling. CRFs can cope with large description spaces\nand can integrate some form of structural dependency between labels. In this\ncontribution, we address the issue of efficient feature selection for CRFs\nbased on imposing sparsity through an L1 penalty. We first show how sparsity of\nthe parameter set can be exploited to significantly speed up training and\nlabelling. We then introduce coordinate descent parameter update schemes for\nCRFs with L1 regularization. We finally provide some empirical comparisons of\nthe proposed approach with state-of-the-art CRF training strategies. In\nparticular, it is shown that the proposed approach is able to take profit of\nthe sparsity to speed up processing and hence potentially handle larger\ndimensional models.\n",
          "  A significant challenge to make learning techniques more suitable for general\npurpose use is to move beyond i) complete supervision, ii) low dimensional\ndata, iii) a single task and single view per instance. Solving these challenges\nallows working with \"Big Data\" problems that are typically high dimensional\nwith multiple (but possibly incomplete) labelings and views. While other work\nhas addressed each of these problems separately, in this paper we show how to\naddress them together, namely semi-supervised dimension reduction for\nmulti-task and multi-view learning (SSDR-MML), which performs optimization for\ndimension reduction and label inference in semi-supervised setting. The\nproposed framework is designed to handle both multi-task and multi-view\nlearning settings, and can be easily adapted to many useful applications.\nInformation obtained from all tasks and views is combined via reconstruction\nerrors in a linear fashion that can be efficiently solved using an alternating\noptimization scheme. Our formulation has a number of advantages. We explicitly\nmodel the information combining mechanism as a data structure (a\nweight/nearest-neighbor matrix) which allows investigating fundamental\nquestions in multi-task and multi-view learning. We address one such question\nby presenting a general measure to quantify the success of simultaneous\nlearning of multiple tasks or from multiple views. We show that our SSDR-MML\napproach can outperform many state-of-the-art baseline methods and demonstrate\nthe effectiveness of connecting dimension reduction and learning.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_supervised_labeling_classification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_supervised_labeling_classification"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.9159250259399414,
          2.2266037464141846,
          1.8932864665985107,
          2.626899003982544,
          1.6520808935165405,
          1.8051337003707886,
          1.8806045055389404,
          2.035748243331909,
          1.9002708196640015,
          1.6947697401046753,
          1.757560133934021,
          1.936682105064392,
          1.8261346817016602,
          1.8973817825317383,
          2.6875364780426025,
          2.0168261528015137,
          1.5105581283569336,
          1.9204126596450806,
          1.5563634634017944,
          2.0964746475219727,
          1.9944688081741333,
          1.948574423789978,
          1.8742883205413818,
          1.939589023590088,
          2.1056509017944336,
          1.8127609491348267,
          1.9037100076675415,
          1.906578779220581,
          1.853076696395874,
          1.8603302240371704,
          1.9345425367355347
         ],
         "y": [
          7.4655914306640625,
          7.493185997009277,
          7.567783832550049,
          7.518228530883789,
          7.700681686401367,
          7.844283103942871,
          7.576960563659668,
          7.974979877471924,
          7.665432929992676,
          7.589668273925781,
          7.705611228942871,
          7.74737548828125,
          7.608292579650879,
          7.556591510772705,
          7.658658027648926,
          7.9402031898498535,
          7.69641637802124,
          7.4097185134887695,
          7.6090407371521,
          7.917337894439697,
          7.701073169708252,
          7.705747127532959,
          7.575154781341553,
          7.731303691864014,
          7.444164752960205,
          6.620481967926025,
          7.713613510131836,
          7.850399017333984,
          7.432987689971924,
          7.4608154296875,
          7.616059303283691
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Minimizing the rank of a matrix subject to affine constraints is a\nfundamental problem with many important applications in machine learning and\nstatistics. In this paper we propose a simple and fast algorithm SVP (Singular\nValue Projection) for rank minimization with affine constraints (ARMP) and show\nthat SVP recovers the minimum rank solution for affine constraints that satisfy\nthe \"restricted isometry property\" and show robustness of our method to noise.\nOur results improve upon a recent breakthrough by Recht, Fazel and Parillo\n(RFP07) and Lee and Bresler (LB09) in three significant ways:\n  1) our method (SVP) is significantly simpler to analyze and easier to\nimplement,\n  2) we give recovery guarantees under strictly weaker isometry assumptions\n  3) we give geometric convergence guarantees for SVP even in presense of noise\nand, as demonstrated empirically, SVP is significantly faster on real-world and\nsynthetic problems.\n  In addition, we address the practically important problem of low-rank matrix\ncompletion (MCP), which can be seen as a special case of ARMP. We empirically\ndemonstrate that our algorithm recovers low-rank incoherent matrices from an\nalmost optimal number of uniformly sampled entries. We make partial progress\ntowards proving exact recovery and provide some intuition for the strong\nperformance of SVP applied to matrix completion by showing a more restricted\nisometry property. Our algorithm outperforms existing methods, such as those of\n\\cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completion\nproblem by an order of magnitude and is also significantly more robust to\nnoise.\n",
          "  Suppose a given observation matrix can be decomposed as the sum of a low-rank\nmatrix and a sparse matrix (outliers), and the goal is to recover these\nindividual components from the observed sum. Such additive decompositions have\napplications in a variety of numerical problems including system\nidentification, latent variable graphical modeling, and principal components\nanalysis. We study conditions under which recovering such a decomposition is\npossible via a combination of $\\ell_1$ norm and trace norm minimization. We are\nspecifically interested in the question of how many outliers are allowed so\nthat convex programming can still achieve accurate recovery, and we obtain\nstronger recovery guarantees than previous studies. Moreover, we do not assume\nthat the spatial pattern of outliers is random, which stands in contrast to\nrelated analyses under such assumptions via matrix completion.\n",
          "  Given a matrix M of low-rank, we consider the problem of reconstructing it\nfrom noisy observations of a small, random subset of its entries. The problem\narises in a variety of applications, from collaborative filtering (the `Netflix\nproblem') to structure-from-motion and positioning. We study a low complexity\nalgorithm introduced by Keshavan et al.(2009), based on a combination of\nspectral techniques and manifold optimization, that we call here OptSpace. We\nprove performance guarantees that are order-optimal in a number of\ncircumstances.\n",
          "  The paper addresses the problem of low-rank trace norm minimization. We\npropose an algorithm that alternates between fixed-rank optimization and\nrank-one updates. The fixed-rank optimization is characterized by an efficient\nfactorization that makes the trace norm differentiable in the search space and\nthe computation of duality gap numerically tractable. The search space is\nnonlinear but is equipped with a particular Riemannian structure that leads to\nefficient computations. We present a second-order trust-region algorithm with a\nguaranteed quadratic rate of convergence. Overall, the proposed optimization\nscheme converges super-linearly to the global solution while maintaining\ncomplexity that is linear in the number of rows and columns of the matrix. To\ncompute a set of solutions efficiently for a grid of regularization parameters\nwe propose a predictor-corrector approach that outperforms the naive\nwarm-restart approach on the fixed-rank quotient manifold. The performance of\nthe proposed algorithm is illustrated on problems of low-rank matrix completion\nand multivariate linear regression.\n",
          "  We address the problem of minimizing a convex function over the space of\nlarge matrices with low rank. While this optimization problem is hard in\ngeneral, we propose an efficient greedy algorithm and derive its formal\napproximation guarantees. Each iteration of the algorithm involves\n(approximately) finding the left and right singular vectors corresponding to\nthe largest singular value of a certain matrix, which can be calculated in\nlinear time. This leads to an algorithm which can scale to large matrices\narising in several applications such as matrix completion for collaborative\nfiltering and robust low rank matrix approximation.\n",
          "  When data is sampled from an unknown subspace, principal component analysis\n(PCA) provides an effective way to estimate the subspace and hence reduce the\ndimension of the data. At the heart of PCA is the Eckart-Young-Mirsky theorem,\nwhich characterizes the best rank k approximation of a matrix. In this paper,\nwe prove a generalization of the Eckart-Young-Mirsky theorem under all\nunitarily invariant norms. Using this result, we obtain closed-form solutions\nfor a set of rank/norm regularized problems, and derive closed-form solutions\nfor a general class of subspace clustering problems (where data is modelled by\nunions of unknown subspaces). From these results we obtain new theoretical\ninsights and promising experimental results.\n",
          "  Truncated Singular Value Decomposition (SVD) calculates the closest rank-$k$\napproximation of a given input matrix. Selecting the appropriate rank $k$\ndefines a critical model order choice in most applications of SVD. To obtain a\nprincipled cut-off criterion for the spectrum, we convert the underlying\noptimization problem into a noisy channel coding problem. The optimal\napproximation capacity of this channel controls the appropriate strength of\nregularization to suppress noise. In simulation experiments, this information\ntheoretic method to determine the optimal rank competes with state-of-the art\nmodel selection techniques.\n",
          "  The statistical leverage scores of a matrix $A$ are the squared row-norms of\nthe matrix containing its (top) left singular vectors and the coherence is the\nlargest leverage score. These quantities are of interest in recently-popular\nproblems such as matrix completion and Nystr\\\"{o}m-based low-rank matrix\napproximation as well as in large-scale statistical data analysis applications\nmore generally; moreover, they are of interest since they define the key\nstructural nonuniformity that must be dealt with in developing fast randomized\nmatrix algorithms. Our main result is a randomized algorithm that takes as\ninput an arbitrary $n \\times d$ matrix $A$, with $n \\gg d$, and that returns as\noutput relative-error approximations to all $n$ of the statistical leverage\nscores. The proposed algorithm runs (under assumptions on the precise values of\n$n$ and $d$) in $O(n d \\log n)$ time, as opposed to the $O(nd^2)$ time required\nby the na\\\"{i}ve algorithm that involves computing an orthogonal basis for the\nrange of $A$. Our analysis may be viewed in terms of computing a relative-error\napproximation to an underconstrained least-squares approximation problem, or,\nrelatedly, it may be viewed as an application of Johnson-Lindenstrauss type\nideas. Several practically-important extensions of our basic result are also\ndescribed, including the approximation of so-called cross-leverage scores, the\nextension of these ideas to matrices with $n \\approx d$, and the extension to\nstreaming environments.\n",
          "  The problem of completing a low-rank matrix from a subset of its entries is\noften encountered in the analysis of incomplete data sets exhibiting an\nunderlying factor model with applications in collaborative filtering, computer\nvision and control. Most recent work had been focused on constructing efficient\nalgorithms for exact or approximate recovery of the missing matrix entries and\nproving lower bounds for the number of known entries that guarantee a\nsuccessful recovery with high probability. A related problem from both the\nmathematical and algorithmic point of view is the distance geometry problem of\nrealizing points in a Euclidean space from a given subset of their pairwise\ndistances. Rigidity theory answers basic questions regarding the uniqueness of\nthe realization satisfying a given partial set of distances. We observe that\nbasic ideas and tools of rigidity theory can be adapted to determine uniqueness\nof low-rank matrix completion, where inner products play the role that\ndistances play in rigidity theory. This observation leads to an efficient\nrandomized algorithm for testing both local and global unique completion.\nCrucial to our analysis is a new matrix, which we call the completion matrix,\nthat serves as the analogue of the rigidity matrix.\n",
          "  In this paper we consider general rank minimization problems with rank\nappearing in either objective function or constraint. We first establish that a\nclass of special rank minimization problems has closed-form solutions. Using\nthis result, we then propose penalty decomposition methods for general rank\nminimization problems in which each subproblem is solved by a block coordinate\ndescend method. Under some suitable assumptions, we show that any accumulation\npoint of the sequence generated by the penalty decomposition methods satisfies\nthe first-order optimality conditions of a nonlinear reformulation of the\nproblems. Finally, we test the performance of our methods by applying them to\nthe matrix completion and nearest low-rank correlation matrix problems. The\ncomputational results demonstrate that our methods are generally comparable or\nsuperior to the existing methods in terms of solution quality.\n",
          "  Singular Value Decomposition (and Principal Component Analysis) is one of the\nmost widely used techniques for dimensionality reduction: successful and\nefficiently computable, it is nevertheless plagued by a well-known,\nwell-documented sensitivity to outliers. Recent work has considered the setting\nwhere each point has a few arbitrarily corrupted components. Yet, in\napplications of SVD or PCA such as robust collaborative filtering or\nbioinformatics, malicious agents, defective genes, or simply corrupted or\ncontaminated experiments may effectively yield entire points that are\ncompletely corrupted.\n  We present an efficient convex optimization-based algorithm we call Outlier\nPursuit, that under some mild assumptions on the uncorrupted points (satisfied,\ne.g., by the standard generative assumption in PCA problems) recovers the exact\noptimal low-dimensional subspace, and identifies the corrupted points. Such\nidentification of corrupted points that do not conform to the low-dimensional\napproximation, is of paramount interest in bioinformatics and financial\napplications, and beyond. Our techniques involve matrix decomposition using\nnuclear norm minimization, however, our results, setup, and approach,\nnecessarily differ considerably from the existing line of work in matrix\ncompletion and matrix decomposition, since we develop an approach to recover\nthe correct column space of the uncorrupted matrix, rather than the exact\nmatrix itself. In any problem where one seeks to recover a structure rather\nthan the exact initial matrices, techniques developed thus far relying on\ncertificates of optimality, will fail. We present an important extension of\nthese methods, that allows the treatment of such problems.\n",
          "  We show that matrix completion with trace-norm regularization can be\nsignificantly hurt when entries of the matrix are sampled non-uniformly. We\nintroduce a weighted version of the trace-norm regularizer that works well also\nwith non-uniform sampling. Our experimental results demonstrate that the\nweighted trace-norm regularization indeed yields significant gains on the\n(highly non-uniformly sampled) Netflix dataset.\n",
          "  Let M be a random (alpha n) x n matrix of rank r<<n, and assume that a\nuniformly random subset E of its entries is observed. We describe an efficient\nalgorithm that reconstructs M from |E| = O(rn) observed entries with relative\nroot mean square error RMSE <= C(rn/|E|)^0.5 . Further, if r=O(1), M can be\nreconstructed exactly from |E| = O(n log(n)) entries. These results apply\nbeyond random matrices to general low-rank incoherent matrices.\n  This settles (in the case of bounded rank) a question left open by Candes and\nRecht and improves over the guarantees for their reconstruction algorithm. The\ncomplexity of our algorithm is O(|E|r log(n)), which opens the way to its use\nfor massive data sets. In the process of proving these statements, we obtain a\ngeneralization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek\non the spectrum of sparse random matrices.\n",
          "  We consider the problem of approximately reconstructing a partially-observed,\napproximately low-rank matrix. This problem has received much attention lately,\nmostly using the trace-norm as a surrogate to the rank. Here we study low-rank\nmatrix reconstruction using both the trace-norm, as well as the less-studied\nmax-norm, and present reconstruction guarantees based on existing analysis on\nthe Rademacher complexity of the unit balls of these norms. We show how these\nare superior in several ways to recently published guarantees based on\nspecialized analysis.\n",
          "  We consider the dimensionality-reduction problem (finding a subspace\napproximation of observed data) for contaminated data in the high dimensional\nregime, where the number of observations is of the same magnitude as the number\nof variables of each observation, and the data set contains some (arbitrarily)\ncorrupted observations. We propose a High-dimensional Robust Principal\nComponent Analysis (HR-PCA) algorithm that is tractable, robust to contaminated\npoints, and easily kernelizable. The resulting subspace has a bounded deviation\nfrom the desired one, achieves maximal robustness -- a breakdown point of 50%\nwhile all existing algorithms have a breakdown point of zero, and unlike\nordinary PCA algorithms, achieves optimality in the limit case where the\nproportion of corrupted points goes to zero.\n",
          "  A general framework based on Gaussian models and a MAP-EM algorithm is\nintroduced in this paper for solving matrix/table completion problems. The\nnumerical experiments with the standard and challenging movie ratings data show\nthat the proposed approach, based on probably one of the simplest probabilistic\nmodels, leads to the results in the same ballpark as the state-of-the-art, at a\nlower computational cost.\n",
          "  This paper considers the problem of completing a matrix with many missing\nentries under the assumption that the columns of the matrix belong to a union\nof multiple low-rank subspaces. This generalizes the standard low-rank matrix\ncompletion problem to situations in which the matrix rank can be quite high or\neven full rank. Since the columns belong to a union of subspaces, this problem\nmay also be viewed as a missing-data version of the subspace clustering\nproblem. Let X be an n x N matrix whose (complete) columns lie in a union of at\nmost k subspaces, each of rank <= r < n, and assume N >> kn. The main result of\nthe paper shows that under mild assumptions each column of X can be perfectly\nrecovered with high probability from an incomplete version so long as at least\nCrNlog^2(n) entries of X are observed uniformly at random, with C>1 a constant\ndepending on the usual incoherence conditions, the geometrical arrangement of\nsubspaces, and the distribution of columns over the subspaces. The result is\nillustrated with numerical experiments and an application to Internet distance\nmatrix completion and topology identification.\n",
          "  We analyze a class of estimators based on convex relaxation for solving\nhigh-dimensional matrix decomposition problems. The observations are noisy\nrealizations of a linear transformation $\\mathfrak{X}$ of the sum of an\napproximately) low rank matrix $\\Theta^\\star$ with a second matrix\n$\\Gamma^\\star$ endowed with a complementary form of low-dimensional structure;\nthis set-up includes many statistical models of interest, including factor\nanalysis, multi-task regression, and robust covariance estimation. We derive a\ngeneral theorem that bounds the Frobenius norm error for an estimate of the\npair $(\\Theta^\\star, \\Gamma^\\star)$ obtained by solving a convex optimization\nproblem that combines the nuclear norm with a general decomposable regularizer.\nOur results utilize a \"spikiness\" condition that is related to but milder than\nsingular vector incoherence. We specialize our general result to two cases that\nhave been studied in past work: low rank plus an entrywise sparse matrix, and\nlow rank plus a columnwise sparse matrix. For both models, our theory yields\nnon-asymptotic Frobenius error bounds for both deterministic and stochastic\nnoise matrices, and applies to matrices $\\Theta^\\star$ that can be exactly or\napproximately low rank, and matrices $\\Gamma^\\star$ that can be exactly or\napproximately sparse. Moreover, for the case of stochastic noise matrices and\nthe identity observation operator, we establish matching lower bounds on the\nminimax error. The sharpness of our predictions is confirmed by numerical\nsimulations.\n",
          "  We study the calibration process in circular ultrasound tomography devices\nwhere the sensor positions deviate from the circumference of a perfect circle.\nThis problem arises in a variety of applications in signal processing ranging\nfrom breast imaging to sensor network localization. We introduce a novel method\nof calibration/localization based on the time-of-flight (ToF) measurements\nbetween sensors when the enclosed medium is homogeneous. In the presence of all\nthe pairwise ToFs, one can easily estimate the sensor positions using\nmulti-dimensional scaling (MDS) method. In practice however, due to the\ntransitional behaviour of the sensors and the beam form of the transducers, the\nToF measurements for close-by sensors are unavailable. Further, random\nmalfunctioning of the sensors leads to random missing ToF measurements. On top\nof the missing entries, in practice an unknown time delay is also added to the\nmeasurements. In this work, we incorporate the fact that a matrix defined from\nall the ToF measurements is of rank at most four. In order to estimate the\nmissing ToFs, we apply a state-of-the-art low-rank matrix completion algorithm,\nOPTSPACE . To find the correct positions of the sensors (our ultimate goal) we\nthen apply MDS. We show analytic bounds on the overall error of the whole\nprocess in the presence of noise and hence deduce its robustness. Finally, we\nconfirm the functionality of our method in practice by simulations mimicking\nthe measurements of a circular ultrasound tomography device.\n",
          "  Low-rank matrix approximations are often used to help scale standard machine\nlearning algorithms to large-scale problems. Recently, matrix coherence has\nbeen used to characterize the ability to extract global information from a\nsubset of matrix entries in the context of these low-rank approximations and\nother sampling-based algorithms, e.g., matrix com- pletion, robust PCA. Since\ncoherence is defined in terms of the singular vectors of a matrix and is\nexpensive to compute, the practical significance of these results largely\nhinges on the following question: Can we efficiently and accurately estimate\nthe coherence of a matrix? In this paper we address this question. We propose a\nnovel algorithm for estimating coherence from a small number of columns,\nformally analyze its behavior, and derive a new coherence-based matrix\napproximation bound based on this analysis. We then present extensive\nexperimental results on synthetic and real datasets that corroborate our\nworst-case theoretical analysis, yet provide strong support for the use of our\nproposed algorithm whenever low-rank approximation is being considered. Our\nalgorithm efficiently and accurately estimates matrix coherence across a wide\nrange of datasets, and these coherence estimates are excellent predictors of\nthe effectiveness of sampling-based matrix approximation on a case-by-case\nbasis.\n",
          "  Regularization by the sum of singular values, also referred to as the trace\nnorm, is a popular technique for estimating low rank rectangular matrices. In\nthis paper, we extend some of the consistency results of the Lasso to provide\nnecessary and sufficient conditions for rank consistency of trace norm\nminimization with the square loss. We also provide an adaptive version that is\nrank consistent even when the necessary condition for the non adaptive version\nis not fulfilled.\n",
          "  In this work we address the subspace recovery problem. Given a set of data\nsamples (vectors) approximately drawn from a union of multiple subspaces, our\ngoal is to segment the samples into their respective subspaces and correct the\npossible errors as well. To this end, we propose a novel method termed Low-Rank\nRepresentation (LRR), which seeks the lowest-rank representation among all the\ncandidates that can represent the data samples as linear combinations of the\nbases in a given dictionary. It is shown that LRR well solves the subspace\nrecovery problem: when the data is clean, we prove that LRR exactly captures\nthe true subspace structures; for the data contaminated by outliers, we prove\nthat under certain conditions LRR can exactly recover the row space of the\noriginal data and detect the outlier as well; for the data corrupted by\narbitrary errors, LRR can also approximately recover the row space with\ntheoretical guarantees. Since the subspace membership is provably determined by\nthe row space, these further imply that LRR can perform robust subspace\nsegmentation and error correction, in an efficient way.\n",
          "  Higher-order tensor decompositions are analogous to the familiar Singular\nValue Decomposition (SVD), but they transcend the limitations of matrices\n(second-order tensors). SVD is a powerful tool that has achieved impressive\nresults in information retrieval, collaborative filtering, computational\nlinguistics, computational vision, and other fields. However, SVD is limited to\ntwo-dimensional arrays of data (two modes), and many potential applications\nhave three or more modes, which require higher-order tensor decompositions.\nThis paper evaluates four algorithms for higher-order tensor decomposition:\nHigher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal\nIteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We\nmeasure the time (elapsed run time), space (RAM and disk space requirements),\nand fit (tensor reconstruction accuracy) of the four algorithms, under a\nvariety of conditions. We find that standard implementations of HO-SVD and HOOI\ndo not scale up to larger tensors, due to increasing RAM requirements. We\nrecommend HOOI for tensors that are small enough for the available RAM and MP\nfor larger tensors.\n",
          "  The common task in matrix completion (MC) and robust principle component\nanalysis (RPCA) is to recover a low-rank matrix from a given data matrix. These\nproblems gained great attention from various areas in applied sciences\nrecently, especially after the publication of the pioneering works of Cand`es\net al.. One fundamental result in MC and RPCA is that nuclear norm based convex\noptimizations lead to the exact low-rank matrix recovery under suitable\nconditions. In this paper, we extend this result by showing that strongly\nconvex optimizations can guarantee the exact low-rank matrix recovery as well.\nThe result in this paper not only provides sufficient conditions under which\nthe strongly convex models lead to the exact low-rank matrix recovery, but also\nguides us on how to choose suitable parameters in practical algorithms.\n",
          "  Recovery of low-rank matrices has recently seen significant activity in many\nareas of science and engineering, motivated by recent theoretical results for\nexact reconstruction guarantees and interesting practical applications. A\nnumber of methods have been developed for this recovery problem. However, a\nprincipled method for choosing the unknown target rank is generally not\nprovided. In this paper, we present novel recovery algorithms for estimating\nlow-rank matrices in matrix completion and robust principal component analysis\nbased on sparse Bayesian learning (SBL) principles. Starting from a matrix\nfactorization formulation and enforcing the low-rank constraint in the\nestimates as a sparsity constraint, we develop an approach that is very\neffective in determining the correct rank while providing high recovery\nperformance. We provide connections with existing methods in other similar\nproblems and empirical results and comparisons with current state-of-the-art\nmethods that illustrate the effectiveness of this approach.\n",
          "  This paper discusses clustering and latent semantic indexing (LSI) aspects of\nthe singular value decomposition (SVD). The purpose of this paper is twofold.\nThe first is to give an explanation on how and why the singular vectors can be\nused in clustering. And the second is to show that the two seemingly unrelated\nSVD aspects actually originate from the same source: related vertices tend to\nbe more clustered in the graph representation of lower rank approximate matrix\nusing the SVD than in the original semantic graph. Accordingly, the SVD can\nimprove retrieval performance of an information retrieval system since queries\nmade to the approximate matrix can retrieve more relevant documents and filter\nout more irrelevant documents than the same queries made to the original\nmatrix. By utilizing this fact, we will devise an LSI algorithm that mimicks\nSVD capability in clustering related vertices. Convergence analysis shows that\nthe algorithm is convergent and produces a unique solution for each input.\nExperimental results using some standard datasets in LSI research show that\nretrieval performances of the algorithm are comparable to the SVD's. In\naddition, the algorithm is more practical and easier to use because there is no\nneed to determine decomposition rank which is crucial in driving retrieval\nperformance of the SVD.\n",
          "  We consider a problem of significant practical importance, namely, the\nreconstruction of a low-rank data matrix from a small subset of its entries.\nThis problem appears in many areas such as collaborative filtering, computer\nvision and wireless sensor networks. In this paper, we focus on the matrix\ncompletion problem in the case when the observed samples are corrupted by\nnoise. We compare the performance of three state-of-the-art matrix completion\nalgorithms (OptSpace, ADMiRA and FPCA) on a single simulation platform and\npresent numerical results. We show that in practice these efficient algorithms\ncan be used to reconstruct real data matrices, as well as randomly generated\nmatrices, accurately.\n",
          "  Motivated by the philosophy and phenomenal success of compressed sensing, the\nproblem of reconstructing a matrix from a sampling of its entries has attracted\nmuch attention recently. Such a problem can be viewed as an\ninformation-theoretic variant of the well-studied matrix completion problem,\nand the main objective is to design an efficient algorithm that can reconstruct\na matrix by inspecting only a small number of its entries. Although this is an\nimpossible task in general, Cand\\`es and co-authors have recently shown that\nunder a so-called incoherence assumption, a rank $r$ $n\\times n$ matrix can be\nreconstructed using semidefinite programming (SDP) after one inspects\n$O(nr\\log^6n)$ of its entries. In this paper we propose an alternative approach\nthat is much more efficient and can reconstruct a larger class of matrices by\ninspecting a significantly smaller number of the entries. Specifically, we\nfirst introduce a class of so-called stable matrices and show that it includes\nall those that satisfy the incoherence assumption. Then, we propose a\nrandomized basis pursuit (RBP) algorithm and show that it can reconstruct a\nstable rank $r$ $n\\times n$ matrix after inspecting $O(nr\\log n)$ of its\nentries. Our sampling bound is only a logarithmic factor away from the\ninformation-theoretic limit and is essentially optimal. Moreover, the runtime\nof the RBP algorithm is bounded by $O(nr^2\\log n+n^2r)$, which compares very\nfavorably with the $\\Omega(n^4r^2\\log^{12}n)$ runtime of the SDP-based\nalgorithm. Perhaps more importantly, our algorithm will provide an exact\nreconstruction of the input matrix in polynomial time. By contrast, the\nSDP-based algorithm can only provide an approximate one in polynomial time.\n",
          "  We consider the problem of reconstructing a low-rank matrix from a small\nsubset of its entries. In this paper, we describe the implementation of an\nefficient algorithm called OptSpace, based on singular value decomposition\nfollowed by local manifold optimization, for solving the low-rank matrix\ncompletion problem. It has been shown that if the number of revealed entries is\nlarge enough, the output of singular value decomposition gives a good estimate\nfor the original matrix, so that local optimization reconstructs the correct\nmatrix with high probability. We present numerical results which show that this\nalgorithm can reconstruct the low rank matrix exactly from a very small subset\nof its entries. We further study the robustness of the algorithm with respect\nto noise, and its performance on actual collaborative filtering datasets.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_matrix_matrices_minimization",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_matrix_matrices_minimization"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.4203093647956848,
          0.5431928038597107,
          0.260627418756485,
          0.37534669041633606,
          0.23147571086883545,
          0.40782180428504944,
          0.36711689829826355,
          0.4585108757019043,
          0.1848456859588623,
          0.34573981165885925,
          0.40368011593818665,
          0.1652185022830963,
          0.48030751943588257,
          0.43716689944267273,
          0.4531511664390564,
          0.15179817378520966,
          0.24452607333660126,
          0.6113947629928589,
          0.31135159730911255,
          0.5108003616333008,
          0.4041074216365814,
          0.3521219789981842,
          0.3563029170036316,
          0.46170008182525635,
          0.4833776652812958,
          -0.011759094893932343,
          0.27265140414237976,
          0.6918998956680298,
          0.1494368016719818,
          0.3629041910171509
         ],
         "y": [
          10.992606163024902,
          10.935081481933594,
          11.033169746398926,
          10.969932556152344,
          11.01360034942627,
          10.880067825317383,
          10.94902229309082,
          10.972319602966309,
          11.050772666931152,
          10.976689338684082,
          10.862401962280273,
          11.055770874023438,
          11.095292091369629,
          11.046640396118164,
          10.824114799499512,
          11.075352668762207,
          11.034194946289062,
          10.972480773925781,
          11.060179710388184,
          10.925466537475586,
          10.859308242797852,
          10.905025482177734,
          10.872551918029785,
          10.905242919921875,
          10.976542472839355,
          10.429908752441406,
          11.03232479095459,
          11.180959701538086,
          11.052434921264648,
          10.963428497314453
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This paper presents a framework aimed at monitoring the behavior of aircraft\nin a given airspace. Nominal trajectories are determined and learned using data\ndriven methods. Standard procedures are used by air traffic controllers (ATC)\nto guide aircraft, ensure the safety of the airspace, and to maximize the\nrunway occupancy. Even though standard procedures are used by ATC, the control\nof the aircraft remains with the pilots, leading to a large variability in the\nflight patterns observed. Two methods to identify typical operations and their\nvariability from recorded radar tracks are presented. This knowledge base is\nthen used to monitor the conformance of current operations against operations\npreviously identified as standard. A tool called AirTrajectoryMiner is\npresented, aiming at monitoring the instantaneous health of the airspace, in\nreal time. The airspace is \"healthy\" when all aircraft are flying according to\nthe nominal procedures. A measure of complexity is introduced, measuring the\nconformance of current flight to nominal flight patterns. When an aircraft does\nnot conform, the complexity increases as more attention from ATC is required to\nensure a safe separation between aircraft.\n",
          "  Topic models have proven to be a useful tool for discovering latent\nstructures in document collections. However, most document collections often\ncome as temporal streams and thus several aspects of the latent structure such\nas the number of topics, the topics' distribution and popularity are\ntime-evolving. Several models exist that model the evolution of some but not\nall of the above aspects. In this paper we introduce infinite dynamic topic\nmodels, iDTM, that can accommodate the evolution of all the aforementioned\naspects. Our model assumes that documents are organized into epochs, where the\ndocuments within each epoch are exchangeable but the order between the\ndocuments is maintained across epochs. iDTM allows for unbounded number of\ntopics: topics can die or be born at any epoch, and the representation of each\ntopic can evolve according to a Markovian dynamics. We use iDTM to analyze the\nbirth and evolution of topics in the NIPS community and evaluated the efficacy\nof our model on both simulated and real datasets with favorable outcome.\n",
          "  Latent Dirichlet allocation (LDA) is a widely-used probabilistic topic\nmodeling paradigm, and recently finds many applications in computer vision and\ncomputational biology. In this paper, we propose a fast and accurate batch\nalgorithm, active belief propagation (ABP), for training LDA. Usually batch LDA\nalgorithms require repeated scanning of the entire corpus and searching the\ncomplete topic space. To process massive corpora having a large number of\ntopics, the training iteration of batch LDA algorithms is often inefficient and\ntime-consuming. To accelerate the training speed, ABP actively scans the subset\nof corpus and searches the subset of topic space for topic modeling, therefore\nsaves enormous training time in each iteration. To ensure accuracy, ABP selects\nonly those documents and topics that contribute to the largest residuals within\nthe residual belief propagation (RBP) framework. On four real-world corpora,\nABP performs around $10$ to $100$ times faster than state-of-the-art batch LDA\nalgorithms with a comparable topic modeling accuracy.\n",
          "  Latent Dirichlet Allocation models discrete data as a mixture of discrete\ndistributions, using Dirichlet beliefs over the mixture weights. We study a\nvariation of this concept, in which the documents' mixture weight beliefs are\nreplaced with squashed Gaussian distributions. This allows documents to be\nassociated with elements of a Hilbert space, admitting kernel topic models\n(KTM), modelling temporal, spatial, hierarchical, social and other structure\nbetween documents. The main challenge is efficient approximate inference on the\nlatent Gaussian. We present an approximate algorithm cast around a Laplace\napproximation in a transformed basis. The KTM can also be interpreted as a type\nof Gaussian process latent variable model, or as a topic model conditional on\ndocument features, uncovering links between earlier work in these areas.\n",
          "  Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model\nfor probabilistic topic modeling, which attracts worldwide interests and\ntouches on many important applications in text mining, computer vision and\ncomputational biology. This paper introduces a topic modeling toolbox (TMBP)\nbased on the belief propagation (BP) algorithms. TMBP toolbox is implemented by\nMEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing\ntopic modeling packages, the novelty of this toolbox lies in the BP algorithms\nfor learning LDA-based topic models. The current version includes BP algorithms\nfor latent Dirichlet allocation (LDA), author-topic models (ATM), relational\ntopic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project\nand more BP-based algorithms for various topic models will be added in the near\nfuture. Interested users may also extend BP algorithms for learning more\ncomplicated topic models. The source codes are freely available under the GNU\nGeneral Public Licence, Version 1.0 at https://mloss.org/software/view/399/.\n",
          "  Frequent episode discovery is a popular framework for pattern discovery in\nevent streams. An episode is a partially ordered set of nodes with each node\nassociated with an event type. Efficient (and separate) algorithms exist for\nepisode discovery when the associated partial order is total (serial episode)\nand trivial (parallel episode). In this paper, we propose efficient algorithms\nfor discovering frequent episodes with general partial orders. These algorithms\ncan be easily specialized to discover serial or parallel episodes. Also, the\nalgorithms are flexible enough to be specialized for mining in the space of\ncertain interesting subclasses of partial orders. We point out that there is an\ninherent combinatorial explosion in frequent partial order mining and most\nimportantly, frequency alone is not a sufficient measure of interestingness. We\npropose a new interestingness measure for general partial order episodes and a\ndiscovery method based on this measure, for filtering out uninteresting partial\norders. Simulations demonstrate the effectiveness of our algorithms.\n",
          "  This paper studies the topic modeling problem of tagged documents and images.\nHigher-order relations among tagged documents and images are major and\nubiquitous characteristics, and play positive roles in extracting reliable and\ninterpretable topics. In this paper, we propose the tag-topic models (TTM) to\ndepict such higher-order topic structural dependencies within the Markov random\nfield (MRF) framework. First, we use the novel factor graph representation of\nlatent Dirichlet allocation (LDA)-based topic models from the MRF perspective,\nand present an efficient loopy belief propagation (BP) algorithm for\napproximate inference and parameter estimation. Second, we propose the factor\nhypergraph representation of TTM, and focus on both pairwise and higher-order\nrelation modeling among tagged documents and images. Efficient loopy BP\nalgorithm is developed to learn TTM, which encourages the topic labeling\nsmoothness among tagged documents and images. Extensive experimental results\nconfirm the incorporation of higher-order relations to be effective in\nenhancing the overall topic modeling performance, when compared with current\nstate-of-the-art topic models, in many text and image mining tasks of broad\ninterests such as word and link prediction, document classification, and tag\nrecommendation.\n",
          "  In this paper, we study CPU utilization time patterns of several Map-Reduce\napplications. After extracting running patterns of several applications, the\npatterns with their statistical information are saved in a reference database\nto be later used to tweak system parameters to efficiently execute unknown\napplications in future. To achieve this goal, CPU utilization patterns of new\napplications along with its statistical information are compared with the\nalready known ones in the reference database to find/predict their most\nprobable execution patterns. Because of different patterns lengths, the Dynamic\nTime Warping (DTW) is utilized for such comparison; a statistical analysis is\nthen applied to DTWs' outcomes to select the most suitable candidates.\nMoreover, under a hypothesis, another algorithm is proposed to classify\napplications under similar CPU utilization patterns. Three widely used text\nprocessing applications (WordCount, Distributed Grep, and Terasort) and another\napplication (Exim Mainlog parsing) are used to evaluate our hypothesis in\ntweaking system parameters in executing similar applications. Results were very\npromising and showed effectiveness of our approach on 5-node Map-Reduce\nplatform\n",
          "  This paper presents the current state of a work in progress, whose objective\nis to better understand the effects of factors that significantly influence the\nperformance of Latent Semantic Analysis (LSA). A difficult task, which consists\nin answering (French) biology Multiple Choice Questions, is used to test the\nsemantic properties of the truncated singular space and to study the relative\ninfluence of main parameters. A dedicated software has been designed to fine\ntune the LSA semantic space for the Multiple Choice Questions task. With\noptimal parameters, the performances of our simple model are quite surprisingly\nequal or superior to those of 7th and 8th grades students. This indicates that\nsemantic spaces were quite good despite their low dimensions and the small\nsizes of training data sets. Besides, we present an original entropy global\nweighting of answers' terms of each question of the Multiple Choice Questions\nwhich was necessary to achieve the model's success.\n",
          "  We study the problem of estimating the time delay between two signals\nrepresenting delayed, irregularly sampled and noisy versions of the same\nunderlying pattern. We propose and demonstrate an evolutionary algorithm for\nthe (hyper)parameter estimation of a kernel-based technique in the context of\nan astronomical problem, namely estimating the time delay between two\ngravitationally lensed signals from a distant quasar. Mixed types (integer and\nreal) are used to represent variables within the evolutionary algorithm. We\ntest the algorithm on several artificial data sets, and also on real\nastronomical observations of quasar Q0957+561. By carrying out a statistical\nanalysis of the results we present a detailed comparison of our method with the\nmost popular methods for time delay estimation in astrophysics. Our method\nyields more accurate and more stable time delay estimates: for Q0957+561, we\nobtain 419.6 days for the time delay between images A and B. Our methodology\ncan be readily applied to current state-of-the-art optical monitoring data in\nastronomy, but can also be applied in other disciplines involving similar time\nseries data.\n",
          "  Mining information from logs is an old and still active research topic. In\nrecent years, with the rapid emerging of cloud computing, log mining becomes\nincreasingly important to industry. This paper focus on one major mission of\nlog mining: anomaly detection, and proposes a novel method for mining abnormal\nsequences from large logs. Different from previous anomaly detection systems\nwhich based on statistics, probabilities and Markov assumption, our approach\nmeasures the strangeness of a sequence using compression. It first trains a\ngrammar about normal behaviors using grammar-based compression, then measures\nthe information quantities and densities of questionable sequences according to\nincrementation of grammar length. We have applied our approach on mining some\nreal bugs from fine grained execution logs. We have also tested its ability on\nintrusion detection using some publicity available system call traces. The\nexperiments show that our method successfully selects the strange sequences\nwhich related to bugs or attacking.\n",
          "  As a major source for information on virtually any topic, Wikipedia serves an\nimportant role in public dissemination and consumption of knowledge. As a\nresult, it presents tremendous potential for people to promulgate their own\npoints of view; such efforts may be more subtle than typical vandalism. In this\npaper, we introduce new behavioral metrics to quantify the level of controversy\nassociated with a particular user: a Controversy Score (C-Score) based on the\namount of attention the user focuses on controversial pages, and a Clustered\nControversy Score (CC-Score) that also takes into account topical clustering.\nWe show that both these measures are useful for identifying people who try to\n\"push\" their points of view, by showing that they are good predictors of which\neditors get blocked. The metrics can be used to triage potential POV pushers.\nWe apply this idea to a dataset of users who requested promotion to\nadministrator status and easily identify some editors who significantly changed\ntheir behavior upon becoming administrators. At the same time, such behavior is\nnot rampant. Those who are promoted to administrator status tend to have more\nstable behavior than comparable groups of prolific editors. This suggests that\nthe Adminship process works well, and that the Wikipedia community is not\noverwhelmed by users who become administrators to promote their own points of\nview.\n",
          "  We present sparse topical coding (STC), a non-probabilistic formulation of\ntopic models for discovering latent representations of large collections of\ndata. Unlike probabilistic topic models, STC relaxes the normalization\nconstraint of admixture proportions and the constraint of defining a normalized\nlikelihood function. Such relaxations make STC amenable to: 1) directly control\nthe sparsity of inferred representations by using sparsity-inducing\nregularizers; 2) be seamlessly integrated with a convex error function (e.g.,\nSVM hinge loss) for supervised learning; and 3) be efficiently learned with a\nsimply structured coordinate descent algorithm. Our results demonstrate the\nadvantages of STC and supervised MedSTC on identifying topical meanings of\nwords and improving classification accuracy and time efficiency.\n",
          "  The objective of change-point detection is to discover abrupt property\nchanges lying behind time-series data. In this paper, we present a novel\nstatistical change-point detection algorithm based on non-parametric divergence\nestimation between time-series samples from two retrospective segments. Our\nmethod uses the relative Pearson divergence as a divergence measure, and it is\naccurately and efficiently estimated by a method of direct density-ratio\nestimation. Through experiments on artificial and real-world datasets including\nhuman-activity sensing, speech, and Twitter messages, we demonstrate the\nusefulness of the proposed method.\n",
          "  Topic Modeling is an approach used for automatic comprehension and\nclassification of data in a variety of settings, and perhaps the canonical\napplication is in uncovering thematic structure in a corpus of documents. A\nnumber of foundational works both in machine learning and in theory have\nsuggested a probabilistic model for documents, whereby documents arise as a\nconvex combination of (i.e. distribution on) a small number of topic vectors,\neach topic vector being a distribution on words (i.e. a vector of\nword-frequencies). Similar models have since been used in a variety of\napplication areas; the Latent Dirichlet Allocation or LDA model of Blei et al.\nis especially popular.\n  Theoretical studies of topic modeling focus on learning the model's\nparameters assuming the data is actually generated from it. Existing approaches\nfor the most part rely on Singular Value Decomposition(SVD), and consequently\nhave one of two limitations: these works need to either assume that each\ndocument contains only one topic, or else can only recover the span of the\ntopic vectors instead of the topic vectors themselves.\n  This paper formally justifies Nonnegative Matrix Factorization(NMF) as a main\ntool in this context, which is an analog of SVD where all vectors are\nnonnegative. Using this tool we give the first polynomial-time algorithm for\nlearning topic models without the above two limitations. The algorithm uses a\nfairly mild assumption about the underlying topic matrix called separability,\nwhich is usually found to hold in real-life data. A compelling feature of our\nalgorithm is that it generalizes to models that incorporate topic-topic\ncorrelations, such as the Correlated Topic Model and the Pachinko Allocation\nModel.\n  We hope that this paper will motivate further theoretical results that use\nNMF as a replacement for SVD - just as NMF has come to replace SVD in many\napplications.\n",
          "  We present a solution to the problem of understanding a system that produces\na sequence of temporally ordered observations. Our solution is based on\ngenerating and interpreting a set of temporal decision rules. A temporal\ndecision rule is a decision rule that can be used to predict or retrodict the\nvalue of a decision attribute, using condition attributes that are observed at\ntimes other than the decision attribute's time of observation. A rule set,\nconsisting of a set of temporal decision rules with the same decision\nattribute, can be interpreted by our Temporal Investigation Method for\nEnregistered Record Sequences (TIMERS) to signify an instantaneous, an acausal\nor a possibly causal relationship between the condition attributes and the\ndecision attribute. We show the effectiveness of our method, by describing a\nnumber of experiments with both synthetic and real temporal data.\n",
          "  Detecting changes in high-dimensional time series is difficult because it\ninvolves the comparison of probability densities that need to be estimated from\nfinite samples. In this paper, we present the first feature extraction method\ntailored to change point detection, which is based on an extended version of\nStationary Subspace Analysis. We reduce the dimensionality of the data to the\nmost non-stationary directions, which are most informative for detecting state\nchanges in the time series. In extensive simulations on synthetic data we show\nthat the accuracy of three change point detection algorithms is significantly\nincreased by a prior feature extraction step. These findings are confirmed in\nan application to industrial fault monitoring.\n",
          "  We present a probabilistic model of events in continuous time in which each\nevent triggers a Poisson process of successor events. The ensemble of observed\nevents is thereby modeled as a superposition of Poisson processes. Efficient\ninference is feasible under this model with an EM algorithm. Moreover, the EM\nalgorithm can be implemented as a distributed algorithm, permitting the model\nto be applied to very large datasets. We apply these techniques to the modeling\nof Twitter messages and the revision history of Wikipedia.\n",
          "  In this paper, we describe our approach to the Wikipedia Participation\nChallenge which aims to predict the number of edits a Wikipedia editor will\nmake in the next 5 months. The best submission from our team, \"zeditor\",\nachieved 41.7% improvement over WMF's baseline predictive model and the final\nrank of 3rd place among 96 teams. An interesting characteristic of our approach\nis that only temporal dynamics features (i.e., how the number of edits changes\nin recent periods, etc.) are used in a self-supervised learning framework,\nwhich makes it easy to be generalised to other application domains.\n",
          "  In information retrieval, a fundamental goal is to transform a document into\nconcepts that are representative of its content. The term \"representative\" is\nin itself challenging to define, and various tasks require different\ngranularities of concepts. In this paper, we aim to model concepts that are\nsparse over the vocabulary, and that flexibly adapt their content based on\nother relevant semantic information such as textual structure or associated\nimage features. We explore a Bayesian nonparametric model based on nested beta\nprocesses that allows for inferring an unknown number of strictly sparse\nconcepts. The resulting model provides an inherently different representation\nof concepts than a standard LDA (or HDP) based topic model, and allows for\ndirect incorporation of semantic features. We demonstrate the utility of this\nrepresentation on multilingual blog data and the Congressional Record.\n",
          "  Engine assembly is a complex and heavily automated distributed-control\nprocess, with large amounts of faults data logged everyday. We describe an\napplication of temporal data mining for analyzing fault logs in an engine\nassembly plant. Frequent episode discovery framework is a model-free method\nthat can be used to deduce (temporal) correlations among events from the logs\nin an efficient manner. In addition to being theoretically elegant and\ncomputationally efficient, frequent episodes are also easy to interpret in the\nform actionable recommendations. Incorporation of domain-specific information\nis critical to successful application of the method for analyzing fault logs in\nthe manufacturing domain. We show how domain-specific knowledge can be\nincorporated using heuristic rules that act as pre-filters and post-filters to\nfrequent episode discovery. The system described here is currently being used\nin one of the engine assembly plants of General Motors and is planned for\nadaptation in other plants. To the best of our knowledge, this paper presents\nthe first real, large-scale application of temporal data mining in the\nmanufacturing domain. We believe that the ideas presented in this paper can\nhelp practitioners engineer tools for analysis in other similar or related\napplication domains as well.\n",
          "  Models of bags of words typically assume topic mixing so that the words in a\nsingle bag come from a limited number of topics. We show here that many sets of\nbag of words exhibit a very different pattern of variation than the patterns\nthat are efficiently captured by topic mixing. In many cases, from one bag of\nwords to the next, the words disappear and new ones appear as if the theme\nslowly and smoothly shifted across documents (providing that the documents are\nsomehow ordered). Examples of latent structure that describe such ordering are\neasily imagined. For example, the advancement of the date of the news stories\nis reflected in a smooth change over the theme of the day as certain evolving\nnews stories fall out of favor and new events create new stories. Overlaps\namong the stories of consecutive days can be modeled by using windows over\nlinearly arranged tight distributions over words. We show here that such\nstrategy can be extended to multiple dimensions and cases where the ordering of\ndata is not readily obvious. We demonstrate that this way of modeling\ncovariation in word occurrences outperforms standard topic models in\nclassification and prediction tasks in applications in biology, text modeling\nand computer vision.\n",
          "  We introduce Gaussian Process Topic Models (GPTMs), a new family of topic\nmodels which can leverage a kernel among documents while extracting correlated\ntopics. GPTMs can be considered a systematic generalization of the Correlated\nTopic Models (CTMs) using ideas from Gaussian Process (GP) based embedding.\nSince GPTMs work with both a topic covariance matrix and a document kernel\nmatrix, learning GPTMs involves a novel component-solving a suitable Sylvester\nequation capturing both topic and document dependencies. The efficacy of GPTMs\nis demonstrated with experiments evaluating the quality of both topic modeling\nand embedding.\n",
          "  Unlike static documents, version controlled documents are continuously edited\nby one or more authors. Such collaborative revision process makes traditional\nmodeling and visualization techniques inappropriate. In this paper we propose a\nnew representation based on local space-time smoothing that captures important\nrevision patterns. We demonstrate the applicability of our framework using\nexperiments on synthetic and real-world data.\n",
          "  Most Web page classification models typically apply the bag of words (BOW)\nmodel to represent the feature space. The original BOW representation, however,\nis unable to recognize semantic relationships between terms. One possible\nsolution is to apply the topic model approach based on the Latent Dirichlet\nAllocation algorithm to cluster the term features into a set of latent topics.\nTerms assigned into the same topic are semantically related. In this paper, we\npropose a novel hierarchical classification method based on a topic model and\nby integrating additional term features from neighboring pages. Our\nhierarchical classification method consists of two phases: (1) feature\nrepresentation by using a topic model and integrating neighboring pages, and\n(2) hierarchical Support Vector Machines (SVM) classification model constructed\nfrom a confusion matrix. From the experimental results, the approach of using\nthe proposed hierarchical SVM model by integrating current page with\nneighboring pages via the topic model yielded the best performance with the\naccuracy equal to 90.33% and the F1 measure of 90.14%; an improvement of 5.12%\nand 5.13% over the original SVM model, respectively.\n",
          "  In real life, media information has time attributes either implicitly or\nexplicitly known as temporal data. This paper investigates the usefulness of\napplying Bayesian classification to an interval encoded temporal database with\nprioritized items. The proposed method performs temporal mining by encoding the\ndatabase with weighted items which prioritizes the items according to their\nimportance from the user perspective. Naive Bayesian classification helps in\nmaking the resulting temporal rules more effective. The proposed priority based\ntemporal mining (PBTM) method added with classification aids in solving\nproblems in a well informed and systematic manner. The experimental results are\nobtained from the complaints database of the telecommunications system, which\nshows the feasibility of this method of classification based temporal mining.\n",
          "  Detection of emerging topics are now receiving renewed interest motivated by\nthe rapid growth of social networks. Conventional term-frequency-based\napproaches may not be appropriate in this context, because the information\nexchanged are not only texts but also images, URLs, and videos. We focus on the\nsocial aspects of theses networks. That is, the links between users that are\ngenerated dynamically intentionally or unintentionally through replies,\nmentions, and retweets. We propose a probability model of the mentioning\nbehaviour of a social network user, and propose to detect the emergence of a\nnew topic from the anomaly measured through the model. We combine the proposed\nmention anomaly score with a recently proposed change-point detection technique\nbased on the Sequentially Discounting Normalized Maximum Likelihood (SDNML), or\nwith Kleinberg's burst model. Aggregating anomaly scores from hundreds of\nusers, we show that we can detect emerging topics only based on the\nreply/mention relationships in social network posts. We demonstrate our\ntechnique in a number of real data sets we gathered from Twitter. The\nexperiments show that the proposed mention-anomaly-based approaches can detect\nnew topics at least as early as the conventional term-frequency-based approach,\nand sometimes much earlier when the keyword is ill-defined.\n",
          "  Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model\nfor probabilistic topic modeling, which attracts worldwide interests and\ntouches on many important applications in text mining, computer vision and\ncomputational biology. This paper represents LDA as a factor graph within the\nMarkov random field (MRF) framework, which enables the classic loopy belief\npropagation (BP) algorithm for approximate inference and parameter estimation.\nAlthough two commonly-used approximate inference methods, such as variational\nBayes (VB) and collapsed Gibbs sampling (GS), have gained great successes in\nlearning LDA, the proposed BP is competitive in both speed and accuracy as\nvalidated by encouraging experimental results on four large-scale document data\nsets. Furthermore, the BP algorithm has the potential to become a generic\nlearning scheme for variants of LDA-based topic models. To this end, we show\nhow to learn two typical variants of LDA-based topic models, such as\nauthor-topic models (ATM) and relational topic models (RTM), using BP based on\nthe factor graph representation.\n",
          "  We investigate the problem of learning a topic model - the well-known Latent\nDirichlet Allocation - in a distributed manner, using a cluster of C processors\nand dividing the corpus to be learned equally among them. We propose a simple\napproximated method that can be tuned, trading speed for accuracy according to\nthe task at hand. Our approach is asynchronous, and therefore suitable for\nclusters of heterogenous machines.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_topics_topic_corpus",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "12_topics_topic_corpus"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.6512367725372314,
          0.7697345614433289,
          0.7135133147239685,
          0.7128669619560242,
          0.7070196270942688,
          1.586983323097229,
          0.72477787733078,
          1.6247811317443848,
          1.1207689046859741,
          0.057729680091142654,
          1.5901058912277222,
          0.8075252771377563,
          0.7176789045333862,
          -0.1796082705259323,
          0.7082735896110535,
          1.6612188816070557,
          -0.07974051684141159,
          0.776383638381958,
          0.8237597942352295,
          0.7122199535369873,
          1.6185964345932007,
          0.7545875906944275,
          0.6968669891357422,
          0.8310810923576355,
          0.693525493144989,
          1.6539692878723145,
          0.7769292593002319,
          0.7127436995506287,
          0.7128961682319641,
          0.8847732543945312
         ],
         "y": [
          4.907029151916504,
          5.35184907913208,
          5.318225383758545,
          5.321706295013428,
          5.313126087188721,
          4.934076309204102,
          5.318060874938965,
          4.9855055809021,
          5.91631555557251,
          7.854290962219238,
          4.984017848968506,
          5.433022499084473,
          5.350990295410156,
          7.535184860229492,
          5.330783367156982,
          4.891697883605957,
          7.644164085388184,
          5.324703693389893,
          5.424702167510986,
          5.338110446929932,
          4.934544086456299,
          5.341272354125977,
          5.306951999664307,
          5.354538440704346,
          5.365673065185547,
          4.892965793609619,
          5.336897850036621,
          5.318465709686279,
          5.309580326080322,
          5.504774570465088
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  We consider the problem of high-dimensional Gaussian graphical model\nselection. We identify a set of graphs for which an efficient estimation\nalgorithm exists, and this algorithm is based on thresholding of empirical\nconditional covariances. Under a set of transparent conditions, we establish\nstructural consistency (or sparsistency) for the proposed algorithm, when the\nnumber of samples n=omega(J_{min}^{-2} log p), where p is the number of\nvariables and J_{min} is the minimum (absolute) edge potential of the graphical\nmodel. The sufficient conditions for sparsistency are based on the notion of\nwalk-summability of the model and the presence of sparse local vertex\nseparators in the underlying graph. We also derive novel non-asymptotic\nnecessary conditions on the number of samples required for sparsistency.\n",
          "  This work describes a method of approximating matrix permanents efficiently\nusing belief propagation. We formulate a probability distribution whose\npartition function is exactly the permanent, then use Bethe free energy to\napproximate this partition function. After deriving some speedups to standard\nbelief propagation, the resulting algorithm requires $(n^2)$ time per\niteration. Finally, we demonstrate the advantages of using this approximation.\n",
          "  It is known that fixed points of loopy belief propagation (BP) correspond to\nstationary points of the Bethe variational problem, where we minimize the Bethe\nfree energy subject to normalization and marginalization constraints.\nUnfortunately, this does not entirely explain BP because BP is a dual rather\nthan primal algorithm to solve the Bethe variational problem -- beliefs are\ninfeasible before convergence. Thus, we have no better understanding of BP than\nas an algorithm to seek for a common zero of a system of non-linear functions,\nnot explicitly related to each other. In this theoretical paper, we show that\nthese functions are in fact explicitly related -- they are the partial\nderivatives of a single function of reparameterizations. That means, BP seeks\nfor a stationary point of a single function, without any constraints. This\nfunction has a very natural form: it is a linear combination of local\nlog-partition functions, exactly as the Bethe entropy is the same linear\ncombination of local entropies.\n",
          "  The maximum a posteriori (MAP) configuration of binary variable models with\nsubmodular graph-structured energy functions can be found efficiently and\nexactly by graph cuts. Max-product belief propagation (MP) has been shown to be\nsuboptimal on this class of energy functions by a canonical counterexample\nwhere MP converges to a suboptimal fixed point (Kulesza & Pereira, 2008).\n  In this work, we show that under a particular scheduling and damping scheme,\nMP is equivalent to graph cuts, and thus optimal. We explain the apparent\ncontradiction by showing that with proper scheduling and damping, MP always\nconverges to an optimal fixed point. Thus, the canonical counterexample only\nshows the suboptimality of MP with a particular suboptimal choice of schedule\nand damping. With proper choices, MP is optimal.\n",
          "  In this paper, we consider the coherent theory of (epistemic) uncertainty of\nWalley, in which beliefs are represented through sets of probability\ndistributions, and we focus on the problem of modeling prior ignorance about a\ncategorical random variable. In this setting, it is a known result that a state\nof prior ignorance is not compatible with learning. To overcome this problem,\nanother state of beliefs, called \\emph{near-ignorance}, has been proposed.\nNear-ignorance resembles ignorance very closely, by satisfying some principles\nthat can arguably be regarded as necessary in a state of ignorance, and allows\nlearning to take place. What this paper does, is to provide new and substantial\nevidence that also near-ignorance cannot be really regarded as a way out of the\nproblem of starting statistical inference in conditions of very weak beliefs.\nThe key to this result is focusing on a setting characterized by a variable of\ninterest that is \\emph{latent}. We argue that such a setting is by far the most\ncommon case in practice, and we provide, for the case of categorical latent\nvariables (and general \\emph{manifest} variables) a condition that, if\nsatisfied, prevents learning to take place under prior near-ignorance. This\ncondition is shown to be easily satisfied even in the most common statistical\nproblems. We regard these results as a strong form of evidence against the\npossibility to adopt a condition of prior near-ignorance in real statistical\nproblems.\n",
          "  Walley's Imprecise Dirichlet Model (IDM) for categorical i.i.d. data extends\nthe classical Dirichlet model to a set of priors. It overcomes several\nfundamental problems which other approaches to uncertainty suffer from. Yet, to\nbe useful in practice, one needs efficient ways for computing the\nimprecise=robust sets or intervals. The main objective of this work is to\nderive exact, conservative, and approximate, robust and credible interval\nestimates under the IDM for a large class of statistical estimators, including\nthe entropy and mutual information.\n",
          "  We describe a new technique for computing lower-bounds on the minimum energy\nconfiguration of a planar Markov Random Field (MRF). Our method successively\nadds large numbers of constraints and enforces consistency over binary\nprojections of the original problem state space. These constraints are\nrepresented in terms of subproblems in a dual-decomposition framework that is\noptimized using subgradient techniques. The complete set of constraints we\nconsider enforces cycle consistency over the original graph. In practice we\nfind that the method converges quickly on most problems with the addition of a\nfew subproblems and outperforms existing methods for some interesting classes\nof hard potentials.\n",
          "  Max-product belief propagation is a local, iterative algorithm to find the\nmode/MAP estimate of a probability distribution. While it has been successfully\nemployed in a wide variety of applications, there are relatively few\ntheoretical guarantees of convergence and correctness for general loopy graphs\nthat may have many short cycles. Of these, even fewer provide exact ``necessary\nand sufficient'' characterizations.\n  In this paper we investigate the problem of using max-product to find the\nmaximum weight matching in an arbitrary graph with edge weights. This is done\nby first constructing a probability distribution whose mode corresponds to the\noptimal matching, and then running max-product. Weighted matching can also be\nposed as an integer program, for which there is an LP relaxation. This\nrelaxation is not always tight. In this paper we show that \\begin{enumerate}\n\\item If the LP relaxation is tight, then max-product always converges, and\nthat too to the correct answer. \\item If the LP relaxation is loose, then\nmax-product does not converge. \\end{enumerate} This provides an exact,\ndata-dependent characterization of max-product performance, and a precise\nconnection to LP relaxation, which is a well-studied optimization technique.\nAlso, since LP relaxation is known to be tight for bipartite graphs, our\nresults generalize other recent results on using max-product to find weighted\nmatchings in bipartite graphs.\n",
          "  The Bethe approximation, or loopy belief propagation algorithm is a\nsuccessful method for approximating partition functions of probabilistic models\nassociated with a graph. Chertkov and Chernyak derived an interesting formula\ncalled Loop Series Expansion, which is an expansion of the partition function.\nThe main term of the series is the Bethe approximation while other terms are\nlabeled by subgraphs called generalized loops. In our recent paper, we derive\nthe loop series expansion in form of a polynomial with coefficients positive\nintegers, and extend the result to the expansion of marginals. In this paper,\nwe give more clear derivation for the results and discuss the properties of the\npolynomial which is introduced in the paper.\n",
          "  We address the problem of learning the parameters in graphical models when\ninference is intractable. A common strategy in this case is to replace the\npartition function with its Bethe approximation. We show that there exists a\nregime of empirical marginals where such Bethe learning will fail. By failure\nwe mean that the empirical marginals cannot be recovered from the approximated\nmaximum likelihood parameters (i.e., moment matching is not achieved). We\nprovide several conditions on empirical marginals that yield outer and inner\nbounds on the set of Bethe learnable marginals. An interesting implication of\nour results is that there exists a large class of marginals that cannot be\nobtained as stable fixed points of belief propagation. Taken together our\nresults provide a novel approach to analyzing learning with Bethe\napproximations and highlight when it can be expected to work or fail.\n",
          "  In the context of inference with expectation constraints, we propose an\napproach based on the \"loopy belief propagation\" algorithm LBP, as a surrogate\nto an exact Markov Random Field MRF modelling. A prior information composed of\ncorrelations among a large set of N variables, is encoded into a graphical\nmodel; this encoding is optimized with respect to an approximate decoding\nprocedure LBP, which is used to infer hidden variables from an observed subset.\nWe focus on the situation where the underlying data have many different\nstatistical components, representing a variety of independent patterns.\nConsidering a single parameter family of models we show how LBP may be used to\nencode and decode efficiently such information, without solving the NP hard\ninverse problem yielding the optimal MRF. Contrary to usual practice, we work\nin the non-convex Bethe free energy minimization framework, and manage to\nassociate a belief propagation fixed point to each component of the underlying\nprobabilistic mixture. The mean field limit is considered and yields an exact\nconnection with the Hopfield model at finite temperature and steady state, when\nthe number of mixture components is proportional to the number of variables. In\naddition, we provide an enhanced learning procedure, based on a straightforward\nmulti-parameter extension of the model in conjunction with an effective\ncontinuous optimization procedure. This is performed using the stochastic\nsearch heuristic CMAES and yields a significant improvement with respect to the\nsingle parameter basic model.\n",
          "  In this paper we derive the equations for Loop Corrected Belief Propagation\non a continuous variable Gaussian model. Using the exactness of the averages\nfor belief propagation for Gaussian models, a different way of obtaining the\ncovariances is found, based on Belief Propagation on cavity graphs. We discuss\nthe relation of this loop correction algorithm to Expectation Propagation\nalgorithms for the case in which the model is no longer Gaussian, but slightly\nperturbed by nonlinear terms.\n",
          "  The typical behavior of optimal solutions to portfolio optimization problems\nwith absolute deviation and expected shortfall models using replica analysis\nwas pioneeringly estimated by S. Ciliberti and M. M\\'ezard [Eur. Phys. B. 57,\n175 (2007)]; however, they have not yet developed an approximate derivation\nmethod for finding the optimal portfolio with respect to a given return set. In\nthis study, an approximation algorithm based on belief propagation for the\nportfolio optimization problem is presented using the Bethe free energy\nformalism, and the consistency of the numerical experimental results of the\nproposed algorithm with those of replica analysis is confirmed. Furthermore,\nthe conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the\nabsolute deviation model and with the mean-variance model have the same typical\nbehavior, is verified using replica analysis and the belief propagation\nalgorithm.\n",
          "  In this paper, we address the problem of learning the structure of a pairwise\ngraphical model from samples in a high-dimensional setting. Our first main\nresult studies the sparsistency, or consistency in sparsity pattern recovery,\nproperties of a forward-backward greedy algorithm as applied to general\nstatistical models. As a special case, we then apply this algorithm to learn\nthe structure of a discrete graphical model via neighborhood estimation. As a\ncorollary of our general result, we derive sufficient conditions on the number\nof samples n, the maximum node-degree d and the problem size p, as well as\nother conditions on the model parameters, so that the algorithm recovers all\nthe edges with high probability. Our result guarantees graph selection for\nsamples scaling as n = Omega(d^2 log(p)), in contrast to existing\nconvex-optimization based algorithms that require a sample complexity of\n\\Omega(d^3 log(p)). Further, the greedy algorithm only requires a restricted\nstrong convexity condition which is typically milder than irrepresentability\nassumptions. We corroborate these results using numerical simulations at the\nend.\n",
          "  We propose a nonparametric generalization of belief propagation, Kernel\nBelief Propagation (KBP), for pairwise Markov random fields. Messages are\nrepresented as functions in a reproducing kernel Hilbert space (RKHS), and\nmessage updates are simple linear operations in the RKHS. KBP makes none of the\nassumptions commonly required in classical BP algorithms: the variables need\nnot arise from a finite domain or a Gaussian distribution, nor must their\nrelations take any particular parametric form. Rather, the relations between\nvariables are represented implicitly, and are learned nonparametrically from\ntraining data. KBP has the advantage that it may be used on any domain where\nkernels are defined (Rd, strings, groups), even where explicit parametric\nmodels are not known, or closed form expressions for the BP updates do not\nexist. The computational cost of message updates in KBP is polynomial in the\ntraining data size. We also propose a constant time approximate message update\nprocedure by representing messages using a small number of basis functions. In\nexperiments, we apply KBP to image denoising, depth prediction from still\nimages, and protein configuration prediction: KBP is faster than competing\nclassical and nonparametric approaches (by orders of magnitude, in some cases),\nwhile providing significantly more accurate results.\n",
          "  The problem of structure estimation in graphical models with latent variables\nis considered. We characterize conditions for tractable graph estimation and\ndevelop efficient methods with provable guarantees. We consider models where\nthe underlying Markov graph is locally tree-like, and the model is in the\nregime of correlation decay. For the special case of the Ising model, the\nnumber of samples $n$ required for structural consistency of our method scales\nas $n=\\Omega(\\theta_{\\min}^{-\\delta\\eta(\\eta+1)-2}\\log p)$, where p is the\nnumber of variables, $\\theta_{\\min}$ is the minimum edge potential, $\\delta$ is\nthe depth (i.e., distance from a hidden node to the nearest observed nodes),\nand $\\eta$ is a parameter which depends on the bounds on node and edge\npotentials in the Ising model. Necessary conditions for structural consistency\nunder any algorithm are derived and our method nearly matches the lower bound\non sample requirements. Further, the proposed method is practical to implement\nand provides flexibility to control the number of latent variables and the\ncycle lengths in the output graph.\n",
          "  Marginal MAP problems are notoriously difficult tasks for graphical models.\nWe derive a general variational framework for solving marginal MAP problems, in\nwhich we apply analogues of the Bethe, tree-reweighted, and mean field\napproximations. We then derive a \"mixed\" message passing algorithm and a\nconvergent alternative using CCCP to solve the BP-type approximations.\nTheoretically, we give conditions under which the decoded solution is a global\nor local optimum, and obtain novel upper bounds on solutions. Experimentally we\ndemonstrate that our algorithms outperform related approaches. We also show\nthat EM and variational EM comprise a special case of our framework.\n",
          "  We consider the problem of high-dimensional Ising (graphical) model\nselection. We propose a simple algorithm for structure estimation based on the\nthresholding of the empirical conditional variation distances. We introduce a\nnovel criterion for tractable graph families, where this method is efficient,\nbased on the presence of sparse local separators between node pairs in the\nunderlying graph. For such graphs, the proposed algorithm has a sample\ncomplexity of $n=\\Omega(J_{\\min}^{-2}\\log p)$, where $p$ is the number of\nvariables, and $J_{\\min}$ is the minimum (absolute) edge potential in the\nmodel. We also establish nonasymptotic necessary and sufficient conditions for\nstructure estimation.\n",
          "  We consider computation of permanent of a positive $(N\\times N)$ non-negative\nmatrix, $P=(P_i^j|i,j=1,\\cdots,N)$, or equivalently the problem of weighted\ncounting of the perfect matchings over the complete bipartite graph $K_{N,N}$.\nThe problem is known to be of likely exponential complexity. Stated as the\npartition function $Z$ of a graphical model, the problem allows exact Loop\nCalculus representation [Chertkov, Chernyak '06] in terms of an interior\nminimum of the Bethe Free Energy functional over non-integer doubly stochastic\nmatrix of marginal beliefs, $\\beta=(\\beta_i^j|i,j=1,\\cdots,N)$, also\ncorrespondent to a fixed point of the iterative message-passing algorithm of\nthe Belief Propagation (BP) type. Our main result is an explicit expression of\nthe exact partition function (permanent) in terms of the matrix of BP\nmarginals, $\\beta$, as $Z=\\mbox{Perm}(P)=Z_{BP}\n\\mbox{Perm}(\\beta_i^j(1-\\beta_i^j))/\\prod_{i,j}(1-\\beta_i^j)$, where $Z_{BP}$\nis the BP expression for the permanent stated explicitly in terms if $\\beta$.\nWe give two derivations of the formula, a direct one based on the Bethe Free\nEnergy and an alternative one combining the Ihara graph-$\\zeta$ function and\nthe Loop Calculus approaches. Assuming that the matrix $\\beta$ of the Belief\nPropagation marginals is calculated, we provide two lower bounds and one\nupper-bound to estimate the multiplicative term. Two complementary lower bounds\nare based on the Gurvits-van der Waerden theorem and on a relation between the\nmodified permanent and determinant respectively.\n",
          "  The problem of graphical model selection is to correctly estimate the graph\nstructure of a Markov random field given samples from the underlying\ndistribution. We analyze the information-theoretic limitations of the problem\nof graph selection for binary Markov random fields under high-dimensional\nscaling, in which the graph size $p$ and the number of edges $k$, and/or the\nmaximal node degree $d$ are allowed to increase to infinity as a function of\nthe sample size $n$. For pairwise binary Markov random fields, we derive both\nnecessary and sufficient conditions for correct graph selection over the class\n$\\mathcal{G}_{p,k}$ of graphs on $p$ vertices with at most $k$ edges, and over\nthe class $\\mathcal{G}_{p,d}$ of graphs on $p$ vertices with maximum degree at\nmost $d$. For the class $\\mathcal{G}_{p, k}$, we establish the existence of\nconstants $c$ and $c'$ such that if $\\numobs < c k \\log p$, any method has\nerror probability at least 1/2 uniformly over the family, and we demonstrate a\ngraph decoder that succeeds with high probability uniformly over the family for\nsample sizes $\\numobs > c' k^2 \\log p$. Similarly, for the class\n$\\mathcal{G}_{p,d}$, we exhibit constants $c$ and $c'$ such that for $n < c d^2\n\\log p$, any method fails with probability at least 1/2, and we demonstrate a\ngraph decoder that succeeds with high probability for $n > c' d^3 \\log p$.\n",
          "  An important part of problems in statistical physics and computer science can\nbe expressed as the computation of marginal probabilities over a Markov Random\nField. The belief propagation algorithm, which is an exact procedure to compute\nthese marginals when the underlying graph is a tree, has gained its popularity\nas an efficient way to approximate them in the more general case. In this\npaper, we focus on an aspect of the algorithm that did not get that much\nattention in the literature, which is the effect of the normalization of the\nmessages. We show in particular that, for a large class of normalization\nstrategies, it is possible to focus only on belief convergence. Following this,\nwe express the necessary and sufficient conditions for local stability of a\nfixed point in terms of the graph structure and the beliefs values at the fixed\npoint. We also explicit some connexion between the normalization constants and\nthe underlying Bethe Free Energy.\n",
          "  Latent tree graphical models are widely used in computational biology, signal\nand image processing, and network tomography. Here we design a new efficient,\nestimation procedure for latent tree models, including Gaussian and discrete,\nreversible models, that significantly improves on previous sample requirement\nbounds. Our techniques are based on a new hidden state estimator which is\nrobust to inaccuracies in estimated parameters. More precisely, we prove that\nlatent tree models can be estimated with high probability in the so-called\nKesten-Stigum regime with $O(log^2 n)$ samples where $n$ is the number of\nnodes.\n",
          "  Markov random fields are used to model high dimensional distributions in a\nnumber of applied areas. Much recent interest has been devoted to the\nreconstruction of the dependency structure from independent samples from the\nMarkov random fields. We analyze a simple algorithm for reconstructing the\nunderlying graph defining a Markov random field on $n$ nodes and maximum degree\n$d$ given observations. We show that under mild non-degeneracy conditions it\nreconstructs the generating graph with high probability using $\\Theta(d\n\\epsilon^{-2}\\delta^{-4} \\log n)$ samples where $\\epsilon,\\delta$ depend on the\nlocal interactions. For most local interaction $\\eps,\\delta$ are of order\n$\\exp(-O(d))$.\n  Our results are optimal as a function of $n$ up to a multiplicative constant\ndepending on $d$ and the strength of the local interactions. Our results seem\nto be the first results for general models that guarantee that {\\em the}\ngenerating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}\n\\epsilon^{-2}\\delta^{-4} \\log n)$ running time bound. In cases where the\nmeasure on the graph has correlation decay, the running time is $O(n^2 \\log n)$\nfor all fixed $d$. We also discuss the effect of observing noisy samples and\nshow that as long as the noise level is low, our algorithm is effective. On the\nother hand, we construct an example where large noise implies\nnon-identifiability even for generic noise and interactions. Finally, we\nbriefly show that in some simple cases, models with hidden nodes can also be\nrecovered.\n",
          "  We describe the first sub-quadratic sampling algorithm for the Multiplicative\nAttribute Graph Model (MAGM) of Kim and Leskovec (2010). We exploit the close\nconnection between MAGM and the Kronecker Product Graph Model (KPGM) of\nLeskovec et al. (2010), and show that to sample a graph from a MAGM it suffices\nto sample small number of KPGM graphs and \\emph{quilt} them together. Under a\nrestricted set of technical conditions our algorithm runs in $O((\\log_2(n))^3\n|E|)$ time, where $n$ is the number of nodes and $|E|$ is the number of edges\nin the sampled graph. We demonstrate the scalability of our algorithm via\nextensive empirical evaluation; we can sample a MAGM graph with 8 million nodes\nand 20 billion edges in under 6 hours.\n",
          "  We show that the definition of neighbor in Markov random fields as defined by\nBesag (1974) when the joint distribution of the sites is not positive is not\nwell-defined. In a random field with finite number of sites we study the\nconditions under which giving the value at extra sites will change the belief\nof an agent about one site. Also the conditions under which the information\nfrom some sites is equivalent to giving the value at all other sites is\nstudied. These concepts provide an alternative to the concept of neighbor for\ngeneral case where the positivity condition of the joint does not hold.\n",
          "  We introduce a new class of lower bounds on the log partition function of a\nMarkov random field which makes use of a reversed Jensen's inequality. In\nparticular, our method approximates the intractable distribution using a linear\ncombination of spanning trees with negative weights. This technique is a\nlower-bound counterpart to the tree-reweighted belief propagation algorithm,\nwhich uses a convex combination of spanning trees with positive weights to\nprovide corresponding upper bounds. We develop algorithms to optimize and\ntighten the lower bounds over the non-convex set of valid parameter values. Our\nalgorithm generalizes mean field approaches (including naive and structured\nmean field approximations), which it includes as a limiting case.\n",
          "  Loopy belief propagation performs approximate inference on graphical models\nwith loops. One might hope to compensate for the approximation by adjusting\nmodel parameters. Learning algorithms for this purpose have been explored\npreviously, and the claim has been made that every set of locally consistent\nmarginals can arise from belief propagation run on a graphical model. On the\ncontrary, here we show that many probability distributions have marginals that\ncannot be reached by belief propagation using any set of model parameters or\nany learning algorithm. We call such marginals `unbelievable.' This problem\noccurs whenever the Hessian of the Bethe free energy is not positive-definite\nat the target marginals. All learning algorithms for belief propagation\nnecessarily fail in these cases, producing beliefs or sets of beliefs that may\neven be worse than the pre-learning approximation. We then show that averaging\ninaccurate beliefs, each obtained from belief propagation using model\nparameters perturbed about some learned mean values, can achieve the\nunbelievable marginals.\n",
          "  We introduce a novel and efficient sampling algorithm for the Multiplicative\nAttribute Graph Model (MAGM - Kim and Leskovec (2010)}). Our algorithm is\n\\emph{strictly} more efficient than the algorithm proposed by Yun and\nVishwanathan (2012), in the sense that our method extends the \\emph{best} time\ncomplexity guarantee of their algorithm to a larger fraction of parameter\nspace. Both in theory and in empirical evaluation on sparse graphs, our new\nalgorithm outperforms the previous one. To design our algorithm, we first\ndefine a stochastic \\emph{ball-dropping process} (BDP). Although a special case\nof this process was introduced as an efficient approximate sampling algorithm\nfor the Kronecker Product Graph Model (KPGM - Leskovec et al. (2010)}), neither\n\\emph{why} such an approximation works nor \\emph{what} is the actual\ndistribution this process is sampling from has been addressed so far to the\nbest of our knowledge. Our rigorous treatment of the BDP enables us to clarify\nthe rational behind a BDP approximation of KPGM, and design an efficient\nsampling algorithm for the MAGM.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_models_propagation_markov",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "13_models_propagation_markov"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.582152843475342,
          3.4788894653320312,
          3.468367576599121,
          3.036050796508789,
          3.601278305053711,
          3.568600654602051,
          2.958094835281372,
          2.9886059761047363,
          3.4725875854492188,
          3.5257980823516846,
          3.4253199100494385,
          3.508481740951538,
          3.4616363048553467,
          2.5836644172668457,
          3.6896300315856934,
          2.665159225463867,
          3.4797310829162598,
          2.599264144897461,
          3.452197313308716,
          2.7128140926361084,
          3.452209949493408,
          2.529773235321045,
          2.7327332496643066,
          2.541067361831665,
          2.7940988540649414,
          3.505408763885498,
          3.5499396324157715,
          2.603928327560425,
          3.141695737838745
         ],
         "y": [
          5.540857791900635,
          5.974002361297607,
          5.965115547180176,
          5.999502182006836,
          6.1088948249816895,
          6.00722599029541,
          5.840745449066162,
          6.119704246520996,
          5.9625444412231445,
          5.977228164672852,
          6.012784481048584,
          5.940212249755859,
          5.966935634613037,
          5.587251663208008,
          5.692144393920898,
          5.570276737213135,
          5.972055912017822,
          5.501055717468262,
          5.9629411697387695,
          5.652536392211914,
          5.948936462402344,
          5.396241188049316,
          5.612992763519287,
          5.635131359100342,
          5.681513786315918,
          5.9695844650268555,
          5.985286235809326,
          5.656545162200928,
          5.8300089836120605
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  As the amount of online text increases, the demand for text classification to\naid the analysis and management of text is increasing. Text is cheap, but\ninformation, in the form of knowing what classes a text belongs to, is\nexpensive. Automatic classification of text can provide this information at low\ncost, but the classifiers themselves must be built with expensive human effort,\nor trained from texts which have themselves been manually classified. In this\npaper we will discuss a procedure of classifying text using the concept of\nassociation rule of data mining. Association rule mining technique has been\nused to derive feature set from pre-classified text documents. Naive Bayes\nclassifier is then used on derived features for final classification.\n",
          "  Text classification is the automated assignment of natural language texts to\npredefined categories based on their content. Text classification is the\nprimary requirement of text retrieval systems, which retrieve texts in response\nto a user query, and text understanding systems, which transform text in some\nway such as producing summaries, answering questions or extracting data. Now a\nday the demand of text classification is increasing tremendously. Keeping this\ndemand into consideration, new and updated techniques are being developed for\nthe purpose of automated text classification. This paper presents a new\nalgorithm for text classification. Instead of using words, word relation i.e.\nassociation rules is used to derive feature set from pre-classified text\ndocuments. The concept of Naive Bayes Classifier is then used on derived\nfeatures and finally a concept of Genetic Algorithm has been added for final\nclassification. A system based on the proposed algorithm has been implemented\nand tested. The experimental results show that the proposed system works as a\nsuccessful text classifier.\n",
          "  Term weighting schemes often dominate the performance of many classifiers,\nsuch as kNN, centroid-based classifier and SVMs. The widely used term weighting\nscheme in text categorization, i.e., tf.idf, is originated from information\nretrieval (IR) field. The intuition behind idf for text categorization seems\nless reasonable than IR. In this paper, we introduce inverse category frequency\n(icf) into term weighting scheme and propose two novel approaches, i.e., tf.icf\nand icf-based supervised term weighting schemes. The tf.icf adopts icf to\nsubstitute idf factor and favors terms occurring in fewer categories, rather\nthan fewer documents. And the icf-based approach combines icf and relevance\nfrequency (rf) to weight terms in a supervised way. Our cross-classifier and\ncross-corpus experiments have shown that our proposed approaches are superior\nor comparable to six supervised term weighting schemes and three traditional\nschemes in terms of macro-F1 and micro-F1.\n",
          "  In Data Mining, the usefulness of association rules is strongly limited by\nthe huge amount of delivered rules. In this paper we propose a new approach to\nprune and filter discovered rules. Using Domain Ontologies, we strengthen the\nintegration of user knowledge in the post-processing task. Furthermore, an\ninteractive and iterative framework is designed to assist the user along the\nanalyzing task. On the one hand, we represent user domain knowledge using a\nDomain Ontology over database. On the other hand, a novel technique is\nsuggested to prune and to filter discovered rules. The proposed framework was\napplied successfully over the client database provided by Nantes Habitat.\n",
          "  This paper deals with the binary classification task when the target class\nhas the lower probability of occurrence. In such situation, it is not possible\nto build a powerful classifier by using standard methods such as logistic\nregression, classification tree, discriminant analysis, etc. To overcome this\nshort-coming of these methods which yield classifiers with low sensibility, we\ntackled the classification problem here through an approach based on the\nassociation rules learning. This approach has the advantage of allowing the\nidentification of the patterns that are well correlated with the target class.\nAssociation rules learning is a well known method in the area of data-mining.\nIt is used when dealing with large database for unsupervised discovery of local\npatterns that expresses hidden relationships between input variables. In\nconsidering association rules from a supervised learning point of view, a\nrelevant set of weak classifiers is obtained from which one derives a\nclassifier that performs well.\n",
          "  In this paper, the mining of hybrid association rules with rough set approach\nis investigated as the algorithm RSHAR.The RSHAR algorithm is constituted of\ntwo steps mainly. At first, to join the participant tables into a general table\nto generate the rules which is expressing the relationship between two or more\ndomains that belong to several different tables in a database. Then we apply\nthe mapping code on selected dimension, which can be added directly into the\ninformation system as one certain attribute. To find the association rules,\nfrequent itemsets are generated in second step where candidate itemsets are\ngenerated through equivalence classes and also transforming the mapping code in\nto real dimensions. The searching method for candidate itemset is similar to\napriori algorithm. The analysis of the performance of algorithm has been\ncarried out.\n",
          "  Text classification is the process of classifying documents into predefined\ncategories based on their content. Existing supervised learning algorithms to\nautomatically classify text need sufficient documents to learn accurately. This\npaper presents a new algorithm for text classification that requires fewer\ndocuments for training. Instead of using words, word relation i.e association\nrules from these words is used to derive feature set from preclassified text\ndocuments. The concept of Naive Bayes classifier is then used on derived\nfeatures and finally only a single concept of Genetic Algorithm has been added\nfor final classification. Experimental results show that the classifier build\nthis way is more accurate than the existing text classification systems.\n",
          "  Associative Classifier is a novel technique which is the integration of\nAssociation Rule Mining and Classification. The difficult task in building\nAssociative Classifier model is the selection of relevant rules from a large\nnumber of class association rules (CARs). A very popular method of ordering\nrules for selection is based on confidence, support and antecedent size (CSA).\nOther methods are based on hybrid orderings in which CSA method is combined\nwith other measures. In the present work, we study the effect of using\ndifferent interestingness measures of Association rules in CAR rule ordering\nand selection for associative classifier.\n",
          "  Text Classification is a challenging and a red hot field in the current\nscenario and has great importance in text categorization applications. A lot of\nresearch work has been done in this field but there is a need to categorize a\ncollection of text documents into mutually exclusive categories by extracting\nthe concepts or features using supervised learning paradigm and different\nclassification algorithms. In this paper, a new Fuzzy Similarity Based Concept\nMining Model (FSCMM) is proposed to classify a set of text documents into pre -\ndefined Category Groups (CG) by providing them training and preparing on the\nsentence, document and integrated corpora levels along with feature reduction,\nambiguity removal on each level to achieve high system performance. Fuzzy\nFeature Category Similarity Analyzer (FFCSA) is used to analyze each extracted\nfeature of Integrated Corpora Feature Vector (ICFV) with the corresponding\ncategories or classes. This model uses Support Vector Machine Classifier (SVMC)\nto classify correctly the training data patterns into two groups; i. e., + 1\nand - 1, thereby producing accurate and correct results. The proposed model\nworks efficiently and effectively with great performance and high - accuracy\nresults.\n",
          "  One of the most utilized data mining tasks is the search for association\nrules. Association rules represent significant relationships between items in\ntransactions. We extend the concept of association rule to represent a much\nbroader class of associations, which we refer to as \\emph{entity-relationship\nrules.} Semantically, entity-relationship rules express associations between\nproperties of related objects. Syntactically, these rules are based on a broad\nsubclass of safe domain relational calculus queries. We propose a new\ndefinition of support and confidence for entity-relationship rules and for the\nfrequency of entity-relationship queries. We prove that the definition of\nfrequency satisfies standard probability axioms and the Apriori property.\n",
          "  The output of an association rule miner is often huge in practice. This is\nwhy several concise lossless representations have been proposed, such as the\n\"essential\" or \"representative\" rules. We revisit the algorithm given by\nKryszkiewicz (Int. Symp. Intelligent Data Analysis 2001, Springer-Verlag LNCS\n2189, 350-359) for mining representative rules. We show that its output is\nsometimes incomplete, due to an oversight in its mathematical validation. We\npropose alternative complete generators and we extend the approach to an\nexisting closure-aware basis similar to, and often smaller than, the\nrepresentative rules, namely the basis B*.\n",
          "  Recently, different works proposed a new way to mine patterns in databases\nwith pathological size. For example, experiments in genome biology usually\nprovide databases with thousands of attributes (genes) but only tens of objects\n(experiments). In this case, mining the \"transposed\" database runs through a\nsmaller search space, and the Galois connection allows to infer the closed\npatterns of the original database. We focus here on constrained pattern mining\nfor those unusual databases and give a theoretical framework for database and\nconstraint transposition. We discuss the properties of constraint transposition\nand look into classical constraints. We then address the problem of generating\nthe closed patterns of the original database satisfying the constraint,\nstarting from those mined in the \"transposed\" database. Finally, we show how to\ngenerate all the patterns satisfying the constraint from the closed ones.\n",
          "  Most of the existing information retrieval systems are based on bag of words\nmodel and are not equipped with common world knowledge. Work has been done\ntowards improving the efficiency of such systems by using intelligent\nalgorithms to generate search queries, however, not much research has been done\nin the direction of incorporating human-and-society level knowledge in the\nqueries. This paper is one of the first attempts where such information is\nincorporated into the search queries using Wikipedia semantics. The paper\npresents an essential shift from conventional token based queries to concept\nbased queries, leading to an enhanced efficiency of information retrieval\nsystems. To efficiently handle the automated query learning problem, we propose\nWikipedia-based Evolutionary Semantics (Wiki-ES) framework where concept based\nqueries are learnt using a co-evolving evolutionary procedure. Learning concept\nbased queries using an intelligent evolutionary procedure yields significant\nimprovement in performance which is shown through an extensive study using\nReuters newswire documents. Comparison of the proposed framework is performed\nwith other information retrieval systems. Concept based approach has also been\nimplemented on other information retrieval systems to justify the effectiveness\nof a transition from token based queries to concept based queries.\n",
          "  The rough-set theory proposed by Pawlak, has been widely used in dealing with\ndata classification problems. The original rough-set model is, however, quite\nsensitive to noisy data. Tzung thus proposed deals with the problem of\nproducing a set of fuzzy certain and fuzzy possible rules from quantitative\ndata with a predefined tolerance degree of uncertainty and misclassification.\nThis model allowed, which combines the variable precision rough-set model and\nthe fuzzy set theory, is thus proposed to solve this problem. This paper thus\ndeals with the problem of producing a set of fuzzy certain and fuzzy possible\nrules from incomplete quantitative data with a predefined tolerance degree of\nuncertainty and misclassification. A new method, incomplete quantitative data\nfor rough-set model and the fuzzy set theory, is thus proposed to solve this\nproblem. It first transforms each quantitative value into a fuzzy set of\nlinguistic terms using membership functions and then finding incomplete\nquantitative data with lower and the fuzzy upper approximations. It second\ncalculates the fuzzy {\\beta}-lower and the fuzzy {\\beta}-upper approximations.\nThe certain and possible rules are then generated based on these fuzzy\napproximations. These rules can then be used to classify unknown objects.\n",
          "  Association rule mining plays vital part in knowledge mining. The difficult\ntask is discovering knowledge or useful rules from the large number of rules\ngenerated for reduced support. For pruning or grouping rules, several\ntechniques are used such as rule structure cover methods, informative cover\nmethods, rule clustering, etc. Another way of selecting association rules is\nbased on interestingness measures such as support, confidence, correlation, and\nso on. In this paper, we study how rule clusters of the pattern Xi - Y are\ndistributed over different interestingness measures.\n",
          "  This paper introduces an evaluation methodologies for the e-learners'\nbehaviour that will be a feedback to the decision makers in e-learning system.\nLearner's profile plays a crucial role in the evaluation process to improve the\ne-learning process performance. The work focuses on the clustering of the\ne-learners based on their behaviour into specific categories that represent the\nlearner's profiles. The learners' classes named as regular, workers, casual,\nbad, and absent. The work may answer the question of how to return bad students\nto be regular ones. The work presented the use of different fuzzy clustering\ntechniques as fuzzy c-means and kernelized fuzzy c-means to find the learners'\ncategories and predict their profiles. The paper presents the main phases as\ndata description, preparation, features selection, and the experiments design\nusing different fuzzy clustering models. Analysis of the obtained results and\ncomparison with the real world behavior of those learners proved that there is\na match with percentage of 78%. Fuzzy clustering reflects the learners'\nbehavior more than crisp clustering. Comparison between FCM and KFCM proved\nthat the KFCM is much better than FCM in predicting the learners' behaviour.\n",
          "  Discovering pattern sets or global patterns is an attractive issue from the\npattern mining community in order to provide useful information. By combining\nlocal patterns satisfying a joint meaning, this approach produces patterns of\nhigher level and thus more useful for the data analyst than the usual local\npatterns, while reducing the number of patterns. In parallel, recent works\ninvestigating relationships between data mining and constraint programming (CP)\nshow that the CP paradigm is a nice framework to model and mine such patterns\nin a declarative and generic way. We present a constraint-based language which\nenables us to define queries addressing patterns sets and global patterns. The\nusefulness of such a declarative approach is highlighted by several examples\ncoming from the clustering based on associations. This language has been\nimplemented in the CP framework.\n",
          "  This version is ***superseded*** by a full version that can be found at\nhttp://www.itu.dk/people/pagh/papers/mining-jour.pdf, which contains stronger\ntheoretical results and fixes a mistake in the reporting of experiments.\n  Abstract: Sampling-based methods have previously been proposed for the\nproblem of finding interesting associations in data, even for low-support\nitems. While these methods do not guarantee precise results, they can be vastly\nmore efficient than approaches that rely on exact counting. However, for many\nsimilarity measures no such methods have been known. In this paper we show how\na wide variety of measures can be supported by a simple biased sampling method.\nThe method also extends to find high-confidence association rules. We\ndemonstrate theoretically that our method is superior to exact methods when the\nthreshold for \"interesting similarity/confidence\" is above the average pairwise\nsimilarity/confidence, and the average support is not too low. Our method is\nparticularly good when transactions contain many items. We confirm in\nexperiments on standard association mining benchmarks that this gives a\nsignificant speedup on real data sets (sometimes much larger than the\ntheoretical guarantees). Reductions in computation time of over an order of\nmagnitude, and significant savings in space, are observed.\n",
          "  Text Document classification aims in associating one or more predefined\ncategories based on the likelihood suggested by the training set of labeled\ndocuments. Many machine learning algorithms play a vital role in training the\nsystem with predefined categories among which Na\\\"ive Bayes has some intriguing\nfacts that it is simple, easy to implement and draws better accuracy in large\ndatasets in spite of the na\\\"ive dependence. The importance of Na\\\"ive Bayes\nMachine learning approach has felt hence the study has been taken up for text\ndocument classification and the statistical event models available. This survey\nthe various feature selection methods has been discussed and compared along\nwith the metrics related to text document classification.\n",
          "  The tasks of extracting (top-$K$) Frequent Itemsets (FI's) and Association\nRules (AR's) are fundamental primitives in data mining and database\napplications. Exact algorithms for these problems exist and are widely used,\nbut their running time is hindered by the need of scanning the entire dataset,\npossibly multiple times. High quality approximations of FI's and AR's are\nsufficient for most practical uses, and a number of recent works explored the\napplication of sampling for fast discovery of approximate solutions to the\nproblems. However, these works do not provide satisfactory performance\nguarantees on the quality of the approximation, due to the difficulty of\nbounding the probability of under- or over-sampling any one of an unknown\nnumber of frequent itemsets. In this work we circumvent this issue by applying\nthe statistical concept of \\emph{Vapnik-Chervonenkis (VC) dimension} to develop\na novel technique for providing tight bounds on the sample size that guarantees\napproximation within user-specified parameters. Our technique applies both to\nabsolute and to relative approximations of (top-$K$) FI's and AR's. The\nresulting sample size is linearly dependent on the VC-dimension of a range\nspace associated with the dataset to be mined. The main theoretical\ncontribution of this work is a proof that the VC-dimension of this range space\nis upper bounded by an easy-to-compute characteristic quantity of the dataset\nwhich we call \\emph{d-index}, and is the maximum integer $d$ such that the\ndataset contains at least $d$ transactions of length at least $d$ such that no\none of them is a superset of or equal to another. We show that this bound is\nstrict for a large class of datasets.\n",
          "  In this paper, we present the step by step knowledge acquisition process by\nchoosing a structured method through using a questionnaire as a knowledge\nacquisition tool. Here we want to depict the problem domain as, how to evaluate\nteachers performance in higher education through the use of expert system\ntechnology. The problem is how to acquire the specific knowledge for a selected\nproblem efficiently and effectively from human experts and encode it in the\nsuitable computer format. Acquiring knowledge from human experts in the process\nof expert systems development is one of the most common problems cited till\nyet. This questionnaire was sent to 87 domain experts within all public and\nprivate universities in Pakistani. Among them 25 domain experts sent their\nvaluable opinions. Most of the domain experts were highly qualified, well\nexperienced and highly responsible persons. The whole questionnaire was divided\ninto 15 main groups of factors, which were further divided into 99 individual\nquestions. These facts were analyzed further to give a final shape to the\nquestionnaire. This knowledge acquisition technique may be used as a learning\ntool for further research work.\n",
          "  The Data Mining process enables the end users to analyze, understand and use\nthe extracted knowledge in an intelligent system or to support in the\ndecision-making processes. However, many algorithms used in the process\nencounter large quantities of patterns, complicating the analysis of the\npatterns. This fact occurs with association rules, a Data Mining technique that\ntries to identify intrinsic patterns in large data sets. A method that can help\nthe analysis of the association rules is the use of taxonomies in the step of\npost-processing knowledge. In this paper, the GART algorithm is proposed, which\nuses taxonomies to generalize association rules, and the RulEE-GAR\ncomputational module, that enables the analysis of the generalized rules.\n",
          "  Now-a-days the amount of data stored in educational database increasing\nrapidly. These databases contain hidden information for improvement of\nstudents' performance. Educational data mining is used to study the data\navailable in the educational field and bring out the hidden knowledge from it.\nClassification methods like decision trees, Bayesian network etc can be applied\non the educational data for predicting the student's performance in\nexamination. This prediction will help to identify the weak students and help\nthem to score better marks. The C4.5, ID3 and CART decision tree algorithms are\napplied on engineering student's data to predict their performance in the final\nexam. The outcome of the decision tree predicted the number of students who are\nlikely to pass, fail or promoted to next year. The results provide steps to\nimprove the performance of the students who were predicted to fail or promoted.\nAfter the declaration of the results in the final examination the marks\nobtained by the students are fed into the system and the results were analyzed\nfor the next session. The comparative analysis of the results states that the\nprediction has helped the weaker students to improve and brought out betterment\nin the result.\n",
          "  In this new and current era of technology, advancements and techniques,\nefficient and effective text document classification is becoming a challenging\nand highly required area to capably categorize text documents into mutually\nexclusive categories. Fuzzy similarity provides a way to find the similarity of\nfeatures among various documents. In this paper, a technical review on various\nfuzzy similarity based models is given. These models are discussed and compared\nto frame out their use and necessity. A tour of different methodologies is\nprovided which is based upon fuzzy similarity related concerns. It shows that\nhow text and web documents are categorized efficiently into different\ncategories. Various experimental results of these models are also discussed.\nThe technical comparisons among each model's parameters are shown in the form\nof a 3-D chart. Such study and technical review provide a strong base of\nresearch work done on fuzzy similarity based text document categorization.\n",
          "  The avalanche quantity of the information developed by mankind has led to\nconcept of automation of knowledge extraction - Data Mining ([1]). This\ndirection is connected with a wide spectrum of problems - from recognition of\nthe fuzzy set to creation of search machines. Important component of Data\nMining is processing of the text information. Such problems lean on concept of\nclassification and clustering ([2]). Classification consists in definition of\nan accessory of some element (text) to one of in advance created classes.\nClustering means splitting a set of elements (texts) on clusters which quantity\nare defined by localization of elements of the given set in vicinities of these\nsome natural centers of these clusters. Realization of a problem of\nclassification initially should lean on the given postulates, basic of which -\nthe aprioristic information on primary set of texts and a measure of affinity\nof elements and classes.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_classifier_classification_classify",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "14_classifier_classification_classify"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.2804873585700989,
          0.2752895653247833,
          0.32415735721588135,
          0.35047096014022827,
          0.3419240117073059,
          0.31130191683769226,
          0.2807594835758209,
          0.31288760900497437,
          0.21538938581943512,
          0.3514205813407898,
          0.3250836730003357,
          0.4051763117313385,
          0.5326483845710754,
          0.25543856620788574,
          0.3169776499271393,
          0.07362458854913712,
          0.3570057153701782,
          0.37706801295280457,
          0.29577502608299255,
          0.36939144134521484,
          0.34955957531929016,
          0.304310142993927,
          0.17482993006706238,
          0.23898792266845703,
          0.05845789983868599,
          0.2991369366645813
         ],
         "y": [
          6.238644599914551,
          6.29878568649292,
          6.271801948547363,
          6.0447001457214355,
          6.073169231414795,
          6.027899265289307,
          6.275529384613037,
          5.971281051635742,
          6.3217058181762695,
          6.009336471557617,
          6.015563011169434,
          5.9405927658081055,
          6.401277542114258,
          6.38075590133667,
          6.011043071746826,
          6.54985237121582,
          5.997173309326172,
          5.918537139892578,
          6.276051044464111,
          5.939403057098389,
          6.561835289001465,
          6.023830890655518,
          6.6689839363098145,
          6.30535364151001,
          6.528878211975098,
          6.2020792961120605
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  The remarkable results of Foster and Vohra was a starting point for a series\nof papers which show that any sequence of outcomes can be learned (with no\nprior knowledge) using some universal randomized forecasting algorithm and\nforecast-dependent checking rules. We show that for the class of all\ncomputationally efficient outcome-forecast-based checking rules, this property\nis violated. Moreover, we present a probabilistic algorithm generating with\nprobability close to one a sequence with a subsequence which simultaneously\nmiscalibrates all partially weakly computable randomized forecasting\nalgorithms. %subsequences non-learnable by each randomized algorithm.\n  According to the Dawid's prequential framework we consider partial recursive\nrandomized algorithms.\n",
          "  We study prediction with expert advice in the setting where the losses are\naccumulated with some discounting---the impact of old losses may gradually\nvanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm\nfor Regression to this case, propose a suitable new variant of exponential\nweights algorithm, and prove respective loss bounds.\n",
          "  We introduce a new protocol for prediction with expert advice in which each\nexpert evaluates the learner's and his own performance using a loss function\nthat may change over time and may be different from the loss functions used by\nthe other experts. The learner's goal is to perform better or not much worse\nthan each expert, as evaluated by that expert, for all experts simultaneously.\nIf the loss functions used by the experts are all proper scoring rules and all\nmixable, we show that the defensive forecasting algorithm enjoys the same\nperformance guarantee as that attainable by the Aggregating Algorithm in the\nstandard setting and known to be optimal. This result is also applied to the\ncase of \"specialist\" (or \"sleeping\") experts. In this case, the defensive\nforecasting algorithm reduces to a simple modification of the Aggregating\nAlgorithm.\n",
          "  We are studying long term sequence prediction (forecasting). We approach this\nby investigating criteria for choosing a compact useful state representation.\nThe state is supposed to summarize useful information from the history. We want\na method that is asymptotically consistent in the sense it will provably\neventually only choose between alternatives that satisfy an optimality property\nrelated to the used criterion. We extend our work to the case where there is\nside information that one can take advantage of and, furthermore, we briefly\ndiscuss the active setting where an agent takes actions to achieve desirable\noutcomes.\n",
          "  In the framework of prediction with expert advice, we consider a recently\nintroduced kind of regret bounds: the bounds that depend on the effective\ninstead of nominal number of experts. In contrast to the NormalHedge bound,\nwhich mainly depends on the effective number of experts and also weakly depends\non the nominal one, we obtain a bound that does not contain the nominal number\nof experts at all. We use the defensive forecasting method and introduce an\napplication of defensive forecasting to multivalued supermartingales.\n",
          "  We provide a natural learning process in which a financial trader without a\nrisk receives a gain in case when Stock Market is inefficient. In this process,\nthe trader rationally choose his gambles using a prediction made by a\nrandomized calibrated algorithm. Our strategy is based on Dawid's notion of\ncalibration with more general changing checking rules and on some modification\nof Kakade and Foster's randomized algorithm for computing calibrated forecasts.\n",
          "  The method of defensive forecasting is applied to the problem of prediction\nwith expert advice for binary outcomes. It turns out that defensive forecasting\nis not only competitive with the Aggregating Algorithm but also handles the\ncase of \"second-guessing\" experts, whose advice depends on the learner's\nprediction; this paper assumes that the dependence on the learner's prediction\nis continuous.\n",
          "  We consider the problem of sequential prediction and provide tools to study\nthe minimax value of the associated game. Classical statistical learning theory\nprovides several useful complexity measures to study learning with i.i.d. data.\nOur proposed sequential complexities can be seen as extensions of these\nmeasures to the sequential setting. The developed theory is shown to yield\nprecise learning guarantees for the problem of sequential prediction. In\nparticular, we show necessary and sufficient conditions for online learnability\nin the setting of supervised learning. Several examples show the utility of our\nframework: we can establish learnability without having to exhibit an explicit\nonline learning algorithm.\n",
          "  In prediction with expert advice the goal is to design online prediction\nalgorithms that achieve small regret (additional loss on the whole data)\ncompared to a reference scheme. In the simplest such scheme one compares to the\nloss of the best expert in hindsight. A more ambitious goal is to split the\ndata into segments and compare to the best expert on each segment. This is\nappropriate if the nature of the data changes between segments. The standard\nfixed-share algorithm is fast and achieves small regret compared to this\nscheme.\n  Fixed share treats the experts as black boxes: there are no assumptions about\nhow they generate their predictions. But if the experts are learning, the\nfollowing question arises: should the experts learn from all data or only from\ndata in their own segment? The original algorithm naturally addresses the first\ncase. Here we consider the second option, which is more appropriate exactly\nwhen the nature of the data changes between segments. In general extending\nfixed share to this second case will slow it down by a factor of T on T\noutcomes. We show, however, that no such slowdown is necessary if the experts\nare hidden Markov models.\n",
          "  Defensive forecasting is a method of transforming laws of probability (stated\nin game-theoretic terms as strategies for Sceptic) into forecasting algorithms.\nThere are two known varieties of defensive forecasting: \"continuous\", in which\nSceptic's moves are assumed to depend on the forecasts in a (semi)continuous\nmanner and which produces deterministic forecasts, and \"randomized\", in which\nthe dependence of Sceptic's moves on the forecasts is arbitrary and\nForecaster's moves are allowed to be randomized. This note shows that the\nrandomized variety can be obtained from the continuous variety by smearing\nSceptic's moves to make them continuous.\n",
          "  In this paper the sequential prediction problem with expert advice is\nconsidered for the case where losses of experts suffered at each step cannot be\nbounded in advance. We present some modification of Kalai and Vempala algorithm\nof following the perturbed leader where weights depend on past losses of the\nexperts. New notions of a volume and a scaled fluctuation of a game are\nintroduced. We present a probabilistic algorithm protected from unrestrictedly\nlarge one-step losses. This algorithm has the optimal performance in the case\nwhen the scaled fluctuations of one-step losses of experts of the pool tend to\nzero.\n",
          "  We consider an agent interacting with an unmodeled environment. At each time,\nthe agent makes an observation, takes an action, and incurs a cost. Its actions\ncan influence future observations and costs. The goal is to minimize the\nlong-term average cost. We propose a novel algorithm, known as the active LZ\nalgorithm, for optimal control based on ideas from the Lempel-Ziv scheme for\nuniversal data compression and prediction. We establish that, under the active\nLZ algorithm, if there exists an integer $K$ such that the future is\nconditionally independent of the past given a window of $K$ consecutive actions\nand observations, then the average cost converges to the optimum. Experimental\nresults involving the game of Rock-Paper-Scissors illustrate merits of the\nalgorithm.\n",
          "  In the framework of prediction of individual sequences, sequential prediction\nmethods are to be constructed that perform nearly as well as the best expert\nfrom a given class. We consider prediction strategies that compete with the\nclass of switching strategies that can segment a given sequence into several\nblocks, and follow the advice of a different \"base\" expert in each block. As\nusual, the performance of the algorithm is measured by the regret defined as\nthe excess loss relative to the best switching strategy selected in hindsight\nfor the particular sequence to be predicted. In this paper we construct\nprediction strategies of low computational cost for the case where the set of\nbase experts is large. In particular we provide a method that can transform any\nprediction algorithm $\\A$ that is designed for the base class into a tracking\nalgorithm. The resulting tracking algorithm can take advantage of the\nprediction performance and potential computational efficiency of $\\A$ in the\nsense that it can be implemented with time and space complexity only\n$O(n^{\\gamma} \\ln n)$ times larger than that of $\\A$, where $n$ is the time\nhorizon and $\\gamma \\ge 0$ is a parameter of the algorithm. With $\\A$ properly\nchosen, our algorithm achieves a regret bound of optimal order for $\\gamma>0$,\nand only $O(\\ln n)$ times larger than the optimal order for $\\gamma=0$ for all\ntypical regret bound types we examined. For example, for predicting binary\nsequences with switching parameters under the logarithmic loss, our method\nachieves the optimal $O(\\ln n)$ regret rate with time complexity\n$O(n^{1+\\gamma}\\ln n)$ for any $\\gamma\\in (0,1)$.\n",
          "  We explore the striking mathematical connections that exist between market\nscoring rules, cost function based prediction markets, and no-regret learning.\nWe show that any cost function based prediction market can be interpreted as an\nalgorithm for the commonly studied problem of learning from expert advice by\nequating trades made in the market with losses observed by the learning\nalgorithm. If the loss of the market organizer is bounded, this bound can be\nused to derive an O(sqrt(T)) regret bound for the corresponding learning\nalgorithm. We then show that the class of markets with convex cost functions\nexactly corresponds to the class of Follow the Regularized Leader learning\nalgorithms, with the choice of a cost function in the market corresponding to\nthe choice of a regularizer in the learning problem. Finally, we show an\nequivalence between market scoring rules and prediction markets with convex\ncost functions. This implies that market scoring rules can also be interpreted\nnaturally as Follow the Regularized Leader algorithms, and may be of\nindependent interest. These connections provide new insight into how it is that\ncommonly studied markets, such as the Logarithmic Market Scoring Rule, can\naggregate opinions into accurate estimates of the likelihood of future events.\n",
          "  We study online learnability of a wide class of problems, extending the\nresults of (Rakhlin, Sridharan, Tewari, 2010) to general notions of performance\nmeasure well beyond external regret. Our framework simultaneously captures such\nwell-known notions as internal and general Phi-regret, learning with\nnon-additive global cost functions, Blackwell's approachability, calibration of\nforecasters, adaptive regret, and more. We show that learnability in all these\nsituations is due to control of the same three quantities: a martingale\nconvergence term, a term describing the ability to perform well if future is\nknown, and a generalization of sequential Rademacher complexity, studied in\n(Rakhlin, Sridharan, Tewari, 2010). Since we directly study complexity of the\nproblem instead of focusing on efficient algorithms, we are able to improve and\nextend many known results which have been previously derived via an algorithmic\nconstruction.\n",
          "  This article discusses in detail the rating system that won the kaggle\ncompetition \"Chess Ratings: Elo vs the rest of the world\". The competition\nprovided a historical dataset of outcomes for chess games, and aimed to\ndiscover whether novel approaches can predict the outcomes of future games,\nmore accurately than the well-known Elo rating system. The winning rating\nsystem, called Elo++ in the rest of the article, builds upon the Elo rating\nsystem. Like Elo, Elo++ uses a single rating per player and predicts the\noutcome of a game, by using a logistic curve over the difference in ratings of\nthe players. The major component of Elo++ is a regularization technique that\navoids overfitting these ratings. The dataset of chess games and outcomes is\nrelatively small and one has to be careful not to draw \"too many conclusions\"\nout of the limited data. Many approaches tested in the competition showed signs\nof such an overfitting. The leader-board was dominated by attempts that did a\nvery good job on a small test dataset, but couldn't generalize well on the\nprivate hold-out dataset. The Elo++ regularization takes into account the\nnumber of games per player, the recency of these games and the ratings of the\nopponents. Finally, Elo++ employs a stochastic gradient descent scheme for\ntraining the ratings, and uses only two global parameters (white's advantage\nand regularization constant) that are optimized using cross-validation.\n",
          "  The note presents a modified proof of a loss bound for the exponentially\nweighted average forecaster with time-varying potential. The regret term of the\nalgorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the\nnumber of experts and n is the number of steps.\n",
          "  We apply the method of defensive forecasting, based on the use of\ngame-theoretic supermartingales, to prediction with expert advice. In the\ntraditional setting of a countable number of experts and a finite number of\noutcomes, the Defensive Forecasting Algorithm is very close to the well-known\nAggregating Algorithm. Not only the performance guarantees but also the\npredictions are the same for these two methods of fundamentally different\nnature. We discuss also a new setting where the experts can give advice\nconditional on the learner's future decision. Both the algorithms can be\nadapted to the new setting and give the same performance guarantees as in the\ntraditional setting. Finally, we outline an application of defensive\nforecasting to a setting with several loss functions.\n",
          "  We show how models for prediction with expert advice can be defined concisely\nand clearly using hidden Markov models (HMMs); standard HMM algorithms can then\nbe used to efficiently calculate, among other things, how the expert\npredictions should be weighted according to the model. We cast many existing\nmodels as HMMs and recover the best known running times in each case. We also\ndescribe two new models: the switch distribution, which was recently developed\nto improve Bayesian/Minimum Description Length model selection, and a new\ngeneralisation of the fixed share algorithm based on run-length coding. We give\nloss bounds for all models and shed new light on their relationships.\n",
          "  The games of prediction with expert advice are considered in this paper. We\npresent some modification of Kalai and Vempala algorithm of following the\nperturbed leader for the case of unrestrictedly large one-step gains. We show\nthat in general case the cumulative gain of any probabilistic prediction\nalgorithm can be much worse than the gain of some expert of the pool.\nNevertheless, we give the lower bound for this cumulative gain in general case\nand construct a universal algorithm which has the optimal performance; we also\nprove that in case when one-step gains of experts of the pool have ``limited\ndeviations'' the performance of our algorithm is close to the performance of\nthe best expert.\n",
          "  Multi-step ahead forecasting is still an open challenge in time series\nforecasting. Several approaches that deal with this complex problem have been\nproposed in the literature but an extensive comparison on a large number of\ntasks is still missing. This paper aims to fill this gap by reviewing existing\nstrategies for multi-step ahead forecasting and comparing them in theoretical\nand practical terms. To attain such an objective, we performed a large scale\ncomparison of these different strategies using a large experimental benchmark\n(namely the 111 series from the NN5 forecasting competition). In addition, we\nconsidered the effects of deseasonalization, input variable selection, and\nforecast combination on these strategies and on multi-step ahead forecasting at\nlarge. The following three findings appear to be consistently supported by the\nexperimental results: Multiple-Output strategies are the best performing\napproaches, deseasonalization leads to uniformly improved forecast accuracy,\nand input selection is more effective when performed in conjunction with\ndeseasonalization.\n",
          "  When dealing with time series with complex non-stationarities, low\nretrospective regret on individual realizations is a more appropriate goal than\nlow prospective risk in expectation. Online learning algorithms provide\npowerful guarantees of this form, and have often been proposed for use with\nnon-stationary processes because of their ability to switch between different\nforecasters or ``experts''. However, existing methods assume that the set of\nexperts whose forecasts are to be combined are all given at the start, which is\nnot plausible when dealing with a genuinely historical or evolutionary system.\nWe show how to modify the ``fixed shares'' algorithm for tracking the best\nexpert to cope with a steadily growing set of experts, obtained by fitting new\nmodels to new data as it becomes available, and obtain regret bounds for the\ngrowing ensemble.\n",
          "  Using the game-theoretic framework for probability, Vovk and Shafer. have\nshown that it is always possible, using randomization, to make sequential\nprobability forecasts that pass any countable set of well-behaved statistical\ntests. This result generalizes work by other authors, who consider only tests\nof calbration.\n  We complement this result with a lower bound. We show that Vovk and Shafer's\nresult is valid only when the forecasts are computed with unrestrictedly\nincreasing degree of accuracy.\n  When some level of discreteness is fixed, we present a game-theoretic\ngeneralization of Oakes' example for randomized forecasting that is a test\nfailing any given method of deferministic forecasting; originally, this example\nwas presented for deterministic calibration.\n",
          "  We show that the Brier game of prediction is mixable and find the optimal\nlearning rate and substitution function for it. The resulting prediction\nalgorithm is applied to predict results of football and tennis matches. The\ntheoretical performance guarantee turns out to be rather tight on these data\nsets, especially in the case of the more extensive tennis data.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_prediction_forecasting_forecasts",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "15_prediction_forecasting_forecasts"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.827361106872559,
          6.792002201080322,
          6.823301792144775,
          6.6555562019348145,
          6.813652038574219,
          6.82297945022583,
          6.808572292327881,
          6.433969020843506,
          6.822066307067871,
          6.854572772979736,
          6.779527187347412,
          6.743702411651611,
          6.666482448577881,
          6.60670280456543,
          6.585544586181641,
          6.593814373016357,
          6.761229991912842,
          6.834234237670898,
          6.813546657562256,
          6.829220294952393,
          6.751128673553467,
          6.7869181632995605,
          6.83713960647583,
          6.627140998840332,
          6.744598388671875
         ],
         "y": [
          8.73205280303955,
          8.761673927307129,
          8.799726486206055,
          8.548592567443848,
          8.795360565185547,
          8.7320556640625,
          8.806682586669922,
          8.358811378479004,
          8.790080070495605,
          8.805403709411621,
          8.736220359802246,
          8.599571228027344,
          8.573587417602539,
          8.506919860839844,
          8.392204284667969,
          8.45434284210205,
          8.755769729614258,
          8.806239128112793,
          8.786310195922852,
          8.78801155090332,
          8.842226028442383,
          8.840743064880371,
          8.73869800567627,
          8.480722427368164,
          8.684666633605957
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Recent work in signal processing and statistics have focused on defining new\nregularization functions, which not only induce sparsity of the solution, but\nalso take into account the structure of the problem. We present in this paper a\nclass of convex penalties introduced in the machine learning community, which\ntake the form of a sum of l_2 and l_infinity-norms over groups of variables.\nThey extend the classical group-sparsity regularization in the sense that the\ngroups possibly overlap, allowing more flexibility in the group design. We\nreview efficient optimization methods to deal with the corresponding inverse\nproblems, and their application to the problem of learning dictionaries of\nnatural image patches: On the one hand, dictionary learning has indeed proven\neffective for various signal processing tasks. On the other hand, structured\nsparsity provides a natural framework for modeling dependencies between\ndictionary elements. We thus consider a structured sparse regularization to\nlearn dictionaries embedded in a particular structure, for instance a tree or a\ntwo-dimensional grid. In the latter case, the results we obtain are similar to\nthe dictionaries produced by topographic independent component analysis.\n",
          "  A large set of signals can sometimes be described sparsely using a\ndictionary, that is, every element can be represented as a linear combination\nof few elements from the dictionary. Algorithms for various signal processing\napplications, including classification, denoising and signal separation, learn\na dictionary from a set of signals to be represented. Can we expect that the\nrepresentation found by such a dictionary for a previously unseen example from\nthe same source will have L_2 error of the same magnitude as those for the\ngiven examples? We assume signals are generated from a fixed distribution, and\nstudy this questions from a statistical learning theory perspective.\n  We develop generalization bounds on the quality of the learned dictionary for\ntwo types of constraints on the coefficient selection, as measured by the\nexpected L_2 error in representation when the dictionary is used. For the case\nof l_1 regularized coefficient selection we provide a generalization bound of\nthe order of O(sqrt(np log(m lambda)/m)), where n is the dimension, p is the\nnumber of elements in the dictionary, lambda is a bound on the l_1 norm of the\ncoefficient vector and m is the number of samples, which complements existing\nresults. For the case of representing a new signal as a combination of at most\nk dictionary elements, we provide a bound of the order O(sqrt(np log(m k)/m))\nunder an assumption on the level of orthogonality of the dictionary (low Babel\nfunction). We further show that this assumption holds for most dictionaries in\nhigh dimensions in a strong probabilistic sense. Our results further yield fast\nrates of order 1/m as opposed to 1/sqrt(m) using localized Rademacher\ncomplexity. We provide similar results in a general setting using kernels with\nweak smoothness requirements.\n",
          "  The goal of predictive sparse coding is to learn a representation of examples\nas sparse linear combinations of elements from a dictionary, such that a\nlearned hypothesis linear in the new representation performs well on a\npredictive task. Predictive sparse coding algorithms recently have demonstrated\nimpressive performance on a variety of supervised tasks, but their\ngeneralization properties have not been studied. We establish the first\ngeneralization error bounds for predictive sparse coding, covering two\nsettings: 1) the overcomplete setting, where the number of features k exceeds\nthe original dimensionality d; and 2) the high or infinite-dimensional setting,\nwhere only dimension-free bounds are useful. Both learning bounds intimately\ndepend on stability properties of the learned sparse encoder, as measured on\nthe training sample. Consequently, we first present a fundamental stability\nresult for the LASSO, a result characterizing the stability of the sparse codes\nwith respect to perturbations to the dictionary. In the overcomplete setting,\nwe present an estimation error bound that decays as \\tilde{O}(sqrt(d k/m)) with\nrespect to d and k. In the high or infinite-dimensional setting, we show a\ndimension-free bound that is \\tilde{O}(sqrt(k^2 s / m)) with respect to k and\ns, where s is an upper bound on the number of non-zeros in the sparse code for\nany training data point.\n",
          "  Principal component analysis (PCA) is a widely used technique for data\nanalysis and dimension reduction with numerous applications in science and\nengineering. However, the standard PCA suffers from the fact that the principal\ncomponents (PCs) are usually linear combinations of all the original variables,\nand it is thus often difficult to interpret the PCs. To alleviate this\ndrawback, various sparse PCA approaches were proposed in literature [15, 6, 17,\n28, 8, 25, 18, 7, 16]. Despite success in achieving sparsity, some important\nproperties enjoyed by the standard PCA are lost in these methods such as\nuncorrelation of PCs and orthogonality of loading vectors. Also, the total\nexplained variance that they attempt to maximize can be too optimistic. In this\npaper we propose a new formulation for sparse PCA, aiming at finding sparse and\nnearly uncorrelated PCs with orthogonal loading vectors while explaining as\nmuch of the total variance as possible. We also develop a novel augmented\nLagrangian method for solving a class of nonsmooth constrained optimization\nproblems, which is well suited for our formulation of sparse PCA. We show that\nit converges to a feasible point, and moreover under some regularity\nassumptions, it converges to a stationary point. Additionally, we propose two\nnonmonotone gradient methods for solving the augmented Lagrangian subproblems,\nand establish their global and local convergence. Finally, we compare our\nsparse PCA approach with several existing methods on synthetic, random, and\nreal data, respectively. The computational results demonstrate that the sparse\nPCs produced by our approach substantially outperform those by other methods in\nterms of total explained variance, correlation of PCs, and orthogonality of\nloading vectors.\n",
          "  This paper presents a novel L1-norm semi-supervised learning algorithm for\nrobust image analysis by giving new L1-norm formulation of Laplacian\nregularization which is the key step of graph-based semi-supervised learning.\nSince our L1-norm Laplacian regularization is defined directly over the\neigenvectors of the normalized Laplacian matrix, we successfully formulate\nsemi-supervised learning as an L1-norm linear reconstruction problem which can\nbe effectively solved with sparse coding. By working with only a small subset\nof eigenvectors, we further develop a fast sparse coding algorithm for our\nL1-norm semi-supervised learning. Due to the sparsity induced by sparse coding,\nthe proposed algorithm can deal with the noise in the data to some extent and\nthus has important applications to robust image analysis, such as noise-robust\nimage classification and noise reduction for visual and textual bag-of-words\n(BOW) models. In particular, this paper is the first attempt to obtain robust\nimage representation by sparse co-refinement of visual and textual BOW models.\nThe experimental results have shown the promising performance of the proposed\nalgorithm.\n",
          "  This article treats the problem of learning a dictionary providing sparse\nrepresentations for a given signal class, via $\\ell_1$-minimisation. The\nproblem can also be seen as factorising a $\\ddim \\times \\nsig$ matrix $Y=(y_1\n>... y_\\nsig), y_n\\in \\R^\\ddim$ of training signals into a $\\ddim \\times\n\\natoms$ dictionary matrix $\\dico$ and a $\\natoms \\times \\nsig$ coefficient\nmatrix $\\X=(x_1... x_\\nsig), x_n \\in \\R^\\natoms$, which is sparse. The exact\nquestion studied here is when a dictionary coefficient pair $(\\dico,\\X)$ can be\nrecovered as local minimum of a (nonconvex) $\\ell_1$-criterion with input\n$Y=\\dico \\X$. First, for general dictionaries and coefficient matrices,\nalgebraic conditions ensuring local identifiability are derived, which are then\nspecialised to the case when the dictionary is a basis. Finally, assuming a\nrandom Bernoulli-Gaussian sparse model on the coefficient matrix, it is shown\nthat sufficiently incoherent bases are locally identifiable with high\nprobability. The perhaps surprising result is that the typically sufficient\nnumber of training samples $\\nsig$ grows up to a logarithmic factor only\nlinearly with the signal dimension, i.e. $\\nsig \\approx C \\natoms \\log\n\\natoms$, in contrast to previous approaches requiring combinatorially many\nsamples.\n",
          "  This paper introduces an elemental building block which combines Dictionary\nLearning and Dimension Reduction (DRDL). We show how this foundational element\ncan be used to iteratively construct a Hierarchical Sparse Representation (HSR)\nof a sensory stream. We compare our approach to existing models showing the\ngenerality of our simple prescription. We then perform preliminary experiments\nusing this framework, illustrating with the example of an object recognition\ntask using standard datasets. This work introduces the very first steps towards\nan integrated framework for designing and analyzing various computational tasks\nfrom learning to attention to action. The ultimate goal is building a\nmathematically rigorous, integrated theory of intelligence.\n",
          "  We consider the data-driven dictionary learning problem. The goal is to seek\nan over-complete dictionary from which every training signal can be best\napproximated by a linear combination of only a few codewords. This task is\noften achieved by iteratively executing two operations: sparse coding and\ndictionary update. In the literature, there are two benchmark mechanisms to\nupdate a dictionary. The first approach, such as the MOD algorithm, is\ncharacterized by searching for the optimal codewords while fixing the sparse\ncoefficients. In the second approach, represented by the K-SVD method, one\ncodeword and the related sparse coefficients are simultaneously updated while\nall other codewords and coefficients remain unchanged. We propose a novel\nframework that generalizes the aforementioned two methods. The unique feature\nof our approach is that one can update an arbitrary set of codewords and the\ncorresponding sparse coefficients simultaneously: when sparse coefficients are\nfixed, the underlying optimization problem is similar to that in the MOD\nalgorithm; when only one codeword is selected for update, it can be proved that\nthe proposed algorithm is equivalent to the K-SVD method; and more importantly,\nour method allows us to update all codewords and all sparse coefficients\nsimultaneously, hence the term simultaneous codeword optimization (SimCO).\nUnder the proposed framework, we design two algorithms, namely, primitive and\nregularized SimCO. We implement these two algorithms based on a simple gradient\ndescent mechanism. Simulations are provided to demonstrate the performance of\nthe proposed algorithms, as compared with two baseline algorithms MOD and\nK-SVD. Results show that regularized SimCO is particularly appealing in terms\nof both learning performance and running speed.\n",
          "  Structured sparse coding and the related structured dictionary learning\nproblems are novel research areas in machine learning. In this paper we present\na new application of structured dictionary learning for collaborative filtering\nbased recommender systems. Our extensive numerical experiments demonstrate that\nthe presented technique outperforms its state-of-the-art competitors and has\nseveral advantages over approaches that do not put structured constraints on\nthe dictionary elements.\n",
          "  Sparse coding, which is the decomposition of a vector using only a few basis\nelements, is widely used in machine learning and image processing. The basis\nset, also called dictionary, is learned to adapt to specific data. This\napproach has proven to be very effective in many image processing tasks.\nTraditionally, the dictionary is an unstructured \"flat\" set of atoms. In this\npaper, we study structured dictionaries which are obtained from an epitome, or\na set of epitomes. The epitome is itself a small image, and the atoms are all\nthe patches of a chosen size inside this image. This considerably reduces the\nnumber of parameters to learn and provides sparse image decompositions with\nshiftinvariance properties. We propose a new formulation and an algorithm for\nlearning the structured dictionaries associated with epitomes, and illustrate\ntheir use in image denoising tasks.\n",
          "  In this paper, we study the application of sparse principal component\nanalysis (PCA) to clustering and feature selection problems. Sparse PCA seeks\nsparse factors, or linear combinations of the data variables, explaining a\nmaximum amount of variance in the data while having only a limited number of\nnonzero coefficients. PCA is often used as a simple clustering technique and\nsparse factors allow us here to interpret the clusters in terms of a reduced\nset of variables. We begin with a brief introduction and motivation on sparse\nPCA and detail our implementation of the algorithm in d'Aspremont et al.\n(2005). We then apply these results to some classic clustering and feature\nselection problems arising in biology.\n",
          "  Coded recurrent neural networks with three levels of sparsity are introduced.\nThe first level is related to the size of messages, much smaller than the\nnumber of available neurons. The second one is provided by a particular coding\nrule, acting as a local constraint in the neural activity. The third one is a\ncharacteristic of the low final connection density of the network after the\nlearning phase. Though the proposed network is very simple since it is based on\nbinary neurons and binary connections, it is able to learn a large number of\nmessages and recall them, even in presence of strong erasures. The performance\nof the network is assessed as a classifier and as an associative memory.\n",
          "  In this paper, we address the problem of discriminative dictionary learning\n(DDL), where sparse linear representation and classification are combined in a\nprobabilistic framework. As such, a single discriminative dictionary and linear\nbinary classifiers are learned jointly. By encoding sparse representation and\ndiscriminative classification models in a MAP setting, we propose a general\noptimization framework that allows for a data-driven tradeoff between faithful\nrepresentation and accurate classification. As opposed to previous work, our\nlearning methodology is capable of incorporating a diverse family of\nclassification cost functions (including those used in popular boosting\nmethods), while avoiding the need for involved optimization techniques. We show\nthat DDL can be solved by a sequence of updates that make use of well-known and\nwell-studied sparse coding and dictionary learning algorithms from the\nliterature. To validate our DDL framework, we apply it to digit classification\nand face recognition and test it on standard benchmarks.\n",
          "  Covariances from categorical variables are defined using a regular simplex\nexpression for categories. The method follows the variance definition by Gini,\nand it gives the covariance as a solution of simultaneous equations. The\ncalculated results give reasonable values for test data. A method of principal\ncomponent analysis (RS-PCA) is also proposed using regular simplex expressions,\nwhich allows easy interpretation of the principal components. The proposed\nmethods apply to variable selection problem of categorical data USCensus1990\ndata. The proposed methods give appropriate criterion for the variable\nselection problem of categorical\n",
          "  Finding a basis matrix (dictionary) by which objective signals are\nrepresented sparsely is of major relevance in various scientific and\ntechnological fields. We consider a problem to learn a dictionary from a set of\ntraining signals. We employ techniques of statistical mechanics of disordered\nsystems to evaluate the size of the training set necessary to typically succeed\nin the dictionary learning. The results indicate that the necessary size is\nmuch smaller than previously estimated, which theoretically supports and/or\nencourages the use of dictionary learning in practical situations.\n",
          "  Exploiting a priori known structural information lies at the core of many\nimage reconstruction methods that can be stated as inverse problems. The\nsynthesis model, which assumes that images can be decomposed into a linear\ncombination of very few atoms of some dictionary, is now a well established\ntool for the design of image reconstruction algorithms. An interesting\nalternative is the analysis model, where the signal is multiplied by an\nanalysis operator and the outcome is assumed to be the sparse. This approach\nhas only recently gained increasing interest. The quality of reconstruction\nmethods based on an analysis model severely depends on the right choice of the\nsuitable operator.\n  In this work, we present an algorithm for learning an analysis operator from\ntraining images. Our method is based on an $\\ell_p$-norm minimization on the\nset of full rank matrices with normalized columns. We carefully introduce the\nemployed conjugate gradient method on manifolds, and explain the underlying\ngeometry of the constraints. Moreover, we compare our approach to\nstate-of-the-art methods for image denoising, inpainting, and single image\nsuper-resolution. Our numerical results show competitive performance of our\ngeneral approach in all presented applications compared to the specialized\nstate-of-the-art techniques.\n",
          "  We present a convex formulation of dictionary learning for sparse signal\ndecomposition. Convexity is obtained by replacing the usual explicit upper\nbound on the dictionary size by a convex rank-reducing term similar to the\ntrace norm. In particular, our formulation introduces an explicit trade-off\nbetween size and sparsity of the decomposition of rectangular matrices. Using a\nlarge set of synthetic examples, we compare the estimation abilities of the\nconvex and non-convex approaches, showing that while the convex formulation has\na single local minimum, this may lead in some cases to performance which is\ninferior to the local minima of the non-convex formulation.\n",
          "  Sparse coding--that is, modelling data vectors as sparse linear combinations\nof basis elements--is widely used in machine learning, neuroscience, signal\nprocessing, and statistics. This paper focuses on the large-scale matrix\nfactorization problem that consists of learning the basis set, adapting it to\nspecific data. Variations of this problem include dictionary learning in signal\nprocessing, non-negative matrix factorization and sparse principal component\nanalysis. In this paper, we propose to address these tasks with a new online\noptimization algorithm, based on stochastic approximations, which scales up\ngracefully to large datasets with millions of training samples, and extends\nnaturally to various matrix factorization formulations, making it suitable for\na wide range of learning problems. A proof of convergence is presented, along\nwith experiments with natural images and genomic data demonstrating that it\nleads to state-of-the-art performance in terms of speed and optimization for\nboth small and large datasets.\n",
          "  The idea that many important classes of signals can be well-represented by\nlinear combinations of a small set of atoms selected from a given dictionary\nhas had dramatic impact on the theory and practice of signal processing. For\npractical problems in which an appropriate sparsifying dictionary is not known\nahead of time, a very popular and successful heuristic is to search for a\ndictionary that minimizes an appropriate sparsity surrogate over a given set of\nsample data. While this idea is appealing, the behavior of these algorithms is\nlargely a mystery; although there is a body of empirical evidence suggesting\nthey do learn very effective representations, there is little theory to\nguarantee when they will behave correctly, or when the learned dictionary can\nbe expected to generalize. In this paper, we take a step towards such a theory.\nWe show that under mild hypotheses, the dictionary learning problem is locally\nwell-posed: the desired solution is indeed a local minimum of the $\\ell^1$\nnorm. Namely, if $\\mb A \\in \\Re^{m \\times n}$ is an incoherent (and possibly\novercomplete) dictionary, and the coefficients $\\mb X \\in \\Re^{n \\times p}$\nfollow a random sparse model, then with high probability $(\\mb A,\\mb X)$ is a\nlocal minimum of the $\\ell^1$ norm over the manifold of factorizations $(\\mb\nA',\\mb X')$ satisfying $\\mb A' \\mb X' = \\mb Y$, provided the number of samples\n$p = \\Omega(n^3 k)$. For overcomplete $\\mb A$, this is the first result showing\nthat the dictionary learning problem is locally solvable. Our analysis draws on\ntools developed for the problem of completing a low-rank matrix from a small\nsubset of its entries, which allow us to overcome a number of technical\nobstacles; in particular, the absence of the restricted isometry property.\n",
          "  We consider the problem of using a factor model we call {\\em spike-and-slab\nsparse coding} (S3C) to learn features for a classification task. The S3C model\nresembles both the spike-and-slab RBM and sparse coding. Since exact inference\nin this model is intractable, we derive a structured variational inference\nprocedure and employ a variational EM training algorithm. Prior work on\napproximate inference for this model has not prioritized the ability to exploit\nparallel architectures and scale to enormous problem sizes. We present an\ninference procedure appropriate for use with GPUs which allows us to\ndramatically increase both the training set size and the amount of latent\nfactors.\n  We demonstrate that this approach improves upon the supervised learning\ncapabilities of both sparse coding and the ssRBM on the CIFAR-10 dataset. We\nevaluate our approach's potential for semi-supervised learning on subsets of\nCIFAR-10. We demonstrate state-of-the art self-taught learning performance on\nthe STL-10 dataset and use our method to win the NIPS 2011 Workshop on\nChallenges In Learning Hierarchical Models' Transfer Learning Challenge.\n",
          "  Recently, considerable research efforts have been devoted to the design of\nmethods to learn from data overcomplete dictionaries for sparse coding.\nHowever, learned dictionaries require the solution of an optimization problem\nfor coding new data. In order to overcome this drawback, we propose an\nalgorithm aimed at learning both a dictionary and its dual: a linear mapping\ndirectly performing the coding. By leveraging on proximal methods, our\nalgorithm jointly minimizes the reconstruction error of the dictionary and the\ncoding error of its dual; the sparsity of the representation is induced by an\n$\\ell_1$-based penalty on its coefficients. The results obtained on synthetic\ndata and real images show that the algorithm is capable of recovering the\nexpected dictionaries. Furthermore, on a benchmark dataset, we show that the\nimage features obtained from the dual matrix yield state-of-the-art\nclassification performance while being much less computational intensive.\n",
          "  Adaptive sparse coding methods learn a possibly overcomplete set of basis\nfunctions, such that natural image patches can be reconstructed by linearly\ncombining a small subset of these bases. The applicability of these methods to\nvisual object recognition tasks has been limited because of the prohibitive\ncost of the optimization algorithms required to compute the sparse\nrepresentation. In this work we propose a simple and efficient algorithm to\nlearn basis functions. After training, this model also provides a fast and\nsmooth approximator to the optimal representation, achieving even better\naccuracy than exact sparse coding algorithms on visual object recognition\ntasks.\n",
          "  This paper proposes a novel approach to image deblurring and digital zooming\nusing sparse local models of image appearance. These models, where small image\npatches are represented as linear combinations of a few elements drawn from\nsome large set (dictionary) of candidates, have proven well adapted to several\nimage restoration tasks. A key to their success has been to learn dictionaries\nadapted to the reconstruction of small image patches. In contrast, recent works\nhave proposed instead to learn dictionaries which are not only adapted to data\nreconstruction, but also tuned for a specific task. We introduce here such an\napproach to deblurring and digital zoom, using pairs of blurry/sharp (or\nlow-/high-resolution) images for training, as well as an effective stochastic\ngradient algorithm for solving the corresponding optimization task. Although\nthis learning problem is not convex, once the dictionaries have been learned,\nthe sharp/high-resolution image can be recovered via convex optimization at\ntest time. Experiments with synthetic and real data demonstrate the\neffectiveness of the proposed approach, leading to state-of-the-art performance\nfor non-blind image deblurring and digital zoom.\n",
          "  This study is focused on the development of the cortex-like visual object\nrecognition system. We propose a general framework, which consists of three\nhierarchical levels (modules). These modules functionally correspond to the V1,\nV4 and IT areas. Both bottom-up and top-down connections between the\nhierarchical levels V4 and IT are employed. The higher the degree of matching\nbetween the input and the preferred stimulus, the shorter the response time of\nthe neuron. Therefore information about a single stimulus is distributed in\ntime and is transmitted by the waves of spikes. The reciprocal connections and\nwaves of spikes implement predictive coding: an initial hypothesis is generated\non the basis of information delivered by the first wave of spikes and is tested\nwith the information carried by the consecutive waves. The development is\nconsidered as extraction and accumulation of features in V4 and objects in IT.\nOnce stored a feature can be disposed, if rarely activated. This cause update\nof feature repository. Consequently, objects in IT are also updated. This\nillustrates the growing process and dynamical change of topological structures\nof V4, IT and connections between these areas.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "16_sparse_dictionaries_recognition",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "16_sparse_dictionaries_recognition"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.4945359230041504,
          1.3449987173080444,
          1.3459904193878174,
          1.0564837455749512,
          1.4095287322998047,
          1.269394874572754,
          1.3426594734191895,
          1.3337619304656982,
          1.310447335243225,
          1.384933590888977,
          1.0516111850738525,
          1.4222279787063599,
          1.3029392957687378,
          1.0327023267745972,
          1.3376904726028442,
          1.2217960357666016,
          1.2606233358383179,
          1.2656468152999878,
          1.3320564031600952,
          1.3324823379516602,
          1.3460973501205444,
          1.3099392652511597,
          1.3369159698486328,
          5.909423828125,
          1.4897871017456055
         ],
         "y": [
          10.588231086730957,
          10.820111274719238,
          10.70808219909668,
          10.413517951965332,
          10.514564514160156,
          10.8186674118042,
          10.548173904418945,
          10.701958656311035,
          10.645590782165527,
          10.594331741333008,
          10.32490348815918,
          10.959588050842285,
          10.639330863952637,
          10.30038070678711,
          10.800125122070312,
          10.788928031921387,
          10.7544584274292,
          10.611250877380371,
          10.801393508911133,
          10.28067398071289,
          10.708511352539062,
          10.63027572631836,
          10.681702613830566,
          5.889402389526367,
          10.438507080078125
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Multi-task learning leverages shared information among data sets to improve\nthe learning performance of individual tasks. The paper applies this framework\nfor data where each task is a phase-shifted periodic time series. In\nparticular, we develop a novel Bayesian nonparametric model capturing a mixture\nof Gaussian processes where each task is a sum of a group-specific function and\na component capturing individual variation, in addition to each task being\nphase shifted. We develop an efficient \\textsc{em} algorithm to learn the\nparameters of the model. As a special case we obtain the Gaussian mixture model\nand \\textsc{em} algorithm for phased-shifted periodic time series. Furthermore,\nwe extend the proposed model by using a Dirichlet Process prior and thereby\nleading to an infinite mixture model that is capable of doing automatic model\nselection. A Variational Bayesian approach is developed for inference in this\nmodel. Experiments in regression, classification and class discovery\ndemonstrate the performance of the proposed models using both synthetic data\nand real-world time series data from astrophysics. Our methods are particularly\nuseful when the time series are sparsely and non-synchronously sampled.\n",
          "  Dirichlet process (DP) mixture models provide a flexible Bayesian framework\nfor density estimation. Unfortunately, their flexibility comes at a cost:\ninference in DP mixture models is computationally expensive, even when\nconjugate distributions are used. In the common case when one seeks only a\nmaximum a posteriori assignment of data points to clusters, we show that search\nalgorithms provide a practical alternative to expensive MCMC and variational\ntechniques. When a true posterior sample is desired, the solution found by\nsearch can serve as a good initializer for MCMC. Experimental results show that\nusing these techniques is it possible to apply DP mixture models to very large\ndata sets.\n",
          "  Gaussian processes (GPs) provide a probabilistic nonparametric representation\nof functions in regression, classification, and other problems. Unfortunately,\nexact learning with GPs is intractable for large datasets. A variety of\napproximate GP methods have been proposed that essentially map the large\ndataset into a small set of basis points. Among them, two state-of-the-art\nmethods are sparse pseudo-input Gaussian process (SPGP) (Snelson and\nGhahramani, 2006) and variablesigma GP (VSGP) Walder et al. (2008), which\ngeneralizes SPGP and allows each basis point to have its own length scale.\nHowever, VSGP was only derived for regression. In this paper, we propose a new\nsparse GP framework that uses expectation propagation to directly approximate\ngeneral GP likelihoods using a sparse and smooth basis. It includes both SPGP\nand VSGP for regression as special cases. Plus as an EP algorithm, it inherits\nthe ability to process data online. As a particular choice of approximating\nfamily, we blur each basis point with a Gaussian distribution that has a full\ncovariance matrix representing the data distribution around that basis point;\nas a result, we can summarize local data manifold information with a small set\nof basis points. Our experiments demonstrate that this framework outperforms\nprevious GP classification methods on benchmark datasets in terms of minimizing\ndivergence to the non-sparse GP solution as well as lower misclassification\nrate.\n",
          "  We introduce the problem of reconstructing a sequence of multidimensional\nreal vectors where some of the data are missing. This problem contains\nregression and mapping inversion as particular cases where the pattern of\nmissing data is independent of the sequence index. The problem is hard because\nit involves possibly multivalued mappings at each vector in the sequence, where\nthe missing variables can take more than one value given the present variables;\nand the set of missing variables can vary from one vector to the next. To solve\nthis problem, we propose an algorithm based on two redundancy assumptions:\nvector redundancy (the data live in a low-dimensional manifold), so that the\npresent variables constrain the missing ones; and sequence redundancy (e.g.\ncontinuity), so that consecutive vectors constrain each other. We capture the\nlow-dimensional nature of the data in a probabilistic way with a joint density\nmodel, here the generative topographic mapping, which results in a Gaussian\nmixture. Candidate reconstructions at each vector are obtained as all the modes\nof the conditional distribution of missing variables given present variables.\nThe reconstructed sequence is obtained by minimising a global constraint, here\nthe sequence length, by dynamic programming. We present experimental results\nfor a toy problem and for inverse kinematics of a robot arm.\n",
          "  We present a new latent-variable model employing a Gaussian mixture\nintegrated with a feature selection procedure (the Bernoulli part of the model)\nwhich together form a \"Latent Bernoulli-Gauss\" distribution. The model is\napplied to MAP estimation, clustering, feature selection and collaborative\nfiltering and fares favorably with the state-of-the-art latent-variable models.\n",
          "  Bayesian learning is often hampered by large computational expense. As a\npowerful generalization of popular belief propagation, expectation propagation\n(EP) efficiently approximates the exact Bayesian computation. Nevertheless, EP\ncan be sensitive to outliers and suffer from divergence for difficult cases. To\naddress this issue, we propose a new approximate inference approach, relaxed\nexpectation propagation (REP). It relaxes the moment matching requirement of\nexpectation propagation by adding a relaxation factor into the KL minimization.\nWe penalize this relaxation with a $l_1$ penalty. As a result, when two\ndistributions in the relaxed KL divergence are similar, the relaxation factor\nwill be penalized to zero and, therefore, we obtain the original moment\nmatching; In the presence of outliers, these two distributions are\nsignificantly different and the relaxation factor will be used to reduce the\ncontribution of the outlier. Based on this penalized KL minimization, REP is\nrobust to outliers and can greatly improve the posterior approximation quality\nover EP. To examine the effectiveness of REP, we apply it to Gaussian process\nclassification, a task known to be suitable to EP. Our classification results\non synthetic and UCI benchmark datasets demonstrate significant improvement of\nREP over EP and Power EP--in terms of algorithmic stability, estimation\naccuracy and predictive performance.\n",
          "  We investigate adaptive mixture methods that linearly combine outputs of $m$\nconstituent filters running in parallel to model a desired signal. We use\n\"Bregman divergences\" and obtain certain multiplicative updates to train the\nlinear combination weights under an affine constraint or without any\nconstraints. We use unnormalized relative entropy and relative entropy to\ndefine two different Bregman divergences that produce an unnormalized\nexponentiated gradient update and a normalized exponentiated gradient update on\nthe mixture weights, respectively. We then carry out the mean and the\nmean-square transient analysis of these adaptive algorithms when they are used\nto combine outputs of $m$ constituent filters. We illustrate the accuracy of\nour results and demonstrate the effectiveness of these updates for sparse\nmixture systems.\n",
          "  Many popular Bayesian nonparametric priors can be characterized in terms of\nexchangeable species sampling sequences. However, in some applications,\nexchangeability may not be appropriate. We introduce a {novel and\nprobabilistically coherent family of non-exchangeable species sampling\nsequences characterized by a tractable predictive probability function with\nweights driven by a sequence of independent Beta random variables. We compare\ntheir theoretical clustering properties with those of the Dirichlet Process and\nthe two parameters Poisson-Dirichlet process. The proposed construction\nprovides a complete characterization of the joint process, differently from\nexisting work. We then propose the use of such process as prior distribution in\na hierarchical Bayes modeling framework, and we describe a Markov Chain Monte\nCarlo sampler for posterior inference. We evaluate the performance of the prior\nand the robustness of the resulting inference in a simulation study, providing\na comparison with popular Dirichlet Processes mixtures and Hidden Markov\nModels. Finally, we develop an application to the detection of chromosomal\naberrations in breast cancer by leveraging array CGH data.\n",
          "  We introduce a Gaussian process model of functions which are additive. An\nadditive function is one which decomposes into a sum of low-dimensional\nfunctions, each depending on only a subset of the input variables. Additive GPs\ngeneralize both Generalized Additive Models, and the standard GP models which\nuse squared-exponential kernels. Hyperparameter learning in this model can be\nseen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive\nbut tractable parameterization of the kernel function, which allows efficient\nevaluation of all input interaction terms, whose number is exponential in the\ninput dimension. The additional structure discoverable by this model results in\nincreased interpretability, as well as state-of-the-art predictive power in\nregression tasks.\n",
          "  Gaussian processes (GPs) provide a nonparametric representation of functions.\nHowever, classical GP inference suffers from high computational cost and it is\ndifficult to design nonstationary GP priors in practice. In this paper, we\npropose a sparse Gaussian process model, EigenGP, based on the Karhunen-Loeve\n(KL) expansion of a GP prior. We use the Nystrom approximation to obtain data\ndependent eigenfunctions and select these eigenfunctions by evidence\nmaximization. This selection reduces the number of eigenfunctions in our model\nand provides a nonstationary covariance function. To handle nonlinear\nlikelihoods, we develop an efficient expectation propagation (EP) inference\nalgorithm, and couple it with expectation maximization for eigenfunction\nselection. Because the eigenfunctions of a Gaussian kernel are associated with\nclusters of samples - including both the labeled and unlabeled - selecting\nrelevant eigenfunctions enables EigenGP to conduct semi-supervised learning.\nOur experimental results demonstrate improved predictive performance of EigenGP\nover alternative state-of-the-art sparse GP and semisupervised learning methods\nfor regression, classification, and semisupervised classification.\n",
          "  Latent force models (LFMs) are hybrid models combining mechanistic principles\nwith non-parametric components. In this article, we shall show how LFMs can be\nequivalently formulated and solved using the state variable approach. We shall\nalso show how the Gaussian process prior used in LFMs can be equivalently\nformulated as a linear statespace model driven by a white noise process and how\ninference on the resulting model can be efficiently implemented using Kalman\nfilter and smoother. Then we shall show how the recently proposed switching LFM\ncan be reformulated using the state variable approach, and how we can construct\na probabilistic model for the switches by formulating a similar switching LFM\nas a switching linear dynamic system (SLDS). We illustrate the performance of\nthe proposed methodology in simulated scenarios and apply it to inferring the\nswitching points in GPS data collected from car movement data in urban\nenvironment.\n",
          "  Many real world problems exhibit patterns that have periodic behavior. For\nexample, in astrophysics, periodic variable stars play a pivotal role in\nunderstanding our universe. An important step when analyzing data from such\nprocesses is the problem of identifying the period: estimating the period of a\nperiodic function based on noisy observations made at irregularly spaced time\npoints. This problem is still a difficult challenge despite extensive study in\ndifferent disciplines. The paper makes several contributions toward solving\nthis problem. First, we present a nonparametric Bayesian model for period\nfinding, based on Gaussian Processes (GP), that does not make strong\nassumptions on the shape of the periodic function. As our experiments\ndemonstrate, the new model leads to significantly better results in period\nestimation when the target function is non-sinusoidal. Second, we develop a new\nalgorithm for parameter optimization for GP which is useful when the likelihood\nfunction is very sensitive to the setting of the hyper-parameters with numerous\nlocal minima, as in the case of period estimation. The algorithm combines\ngradient optimization with grid search and incorporates several mechanisms to\novercome the high complexity of inference with GP. Third, we develop a novel\napproach for using domain knowledge, in the form of a probabilistic generative\nmodel, and incorporate it into the period estimation algorithm. Experimental\nresults on astrophysics data validate our approach showing significant\nimprovement over the state of the art in this domain.\n",
          "  Given data drawn from a mixture of multivariate Gaussians, a basic problem is\nto accurately estimate the mixture parameters. We give an algorithm for this\nproblem that has a running time, and data requirement polynomial in the\ndimension and the inverse of the desired accuracy, with provably minimal\nassumptions on the Gaussians. As simple consequences of our learning algorithm,\nwe can perform near-optimal clustering of the sample points and density\nestimation for mixtures of k Gaussians, efficiently. The building blocks of our\nalgorithm are based on the work Kalai et al. [STOC 2010] that gives an\nefficient algorithm for learning mixtures of two Gaussians by considering a\nseries of projections down to one dimension, and applying the method of moments\nto each univariate projection. A major technical hurdle in Kalai et al. is\nshowing that one can efficiently learn univariate mixtures of two Gaussians. In\ncontrast, because pathological scenarios can arise when considering univariate\nprojections of mixtures of more than two Gaussians, the bulk of the work in\nthis paper concerns how to leverage an algorithm for learning univariate\nmixtures (of many Gaussians) to yield an efficient algorithm for learning in\nhigh dimensions. Our algorithm employs hierarchical clustering and rescaling,\ntogether with delicate methods for backtracking and recovering from failures\nthat can occur in our univariate algorithm. Finally, while the running time and\ndata requirements of our algorithm depend exponentially on the number of\nGaussians in the mixture, we prove that such a dependence is necessary.\n",
          "  We describe $k$-MLE, a fast and efficient local search algorithm for learning\nfinite statistical mixtures of exponential families such as Gaussian mixture\nmodels. Mixture models are traditionally learned using the\nexpectation-maximization (EM) soft clustering technique that monotonically\nincreases the incomplete (expected complete) likelihood. Given prescribed\nmixture weights, the hard clustering $k$-MLE algorithm iteratively assigns data\nto the most likely weighted component and update the component models using\nMaximum Likelihood Estimators (MLEs). Using the duality between exponential\nfamilies and Bregman divergences, we prove that the local convergence of the\ncomplete likelihood of $k$-MLE follows directly from the convergence of a dual\nadditively weighted Bregman hard clustering. The inner loop of $k$-MLE can be\nimplemented using any $k$-means heuristic like the celebrated Lloyd's batched\nor Hartigan's greedy swap updates. We then show how to update the mixture\nweights by minimizing a cross-entropy criterion that implies to update weights\nby taking the relative proportion of cluster points, and reiterate the mixture\nparameter update and mixture weight update processes until convergence. Hard EM\nis interpreted as a special case of $k$-MLE when both the component update and\nthe weight update are performed successively in the inner loop. To initialize\n$k$-MLE, we propose $k$-MLE++, a careful initialization of $k$-MLE guaranteeing\nprobabilistically a global bound on the best possible complete likelihood.\n",
          "  Gaussian processes (GPs) provide a probabilistic nonparametric representation\nof functions in regression, classification, and other problems. Unfortunately,\nexact learning with GPs is intractable for large datasets. A variety of\napproximate GP methods have been proposed that essentially map the large\ndataset into a small set of basis points. The most advanced of these, the\nvariable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have\nits own length scale. However, VSGP was only derived for regression. We\ndescribe how VSGP can be applied to classification and other problems, by\nderiving it as an expectation propagation algorithm. In this view, sparse GP\napproximations correspond to a KL-projection of the true posterior onto a\ncompact exponential family of GPs. VSGP constitutes one such family, and we\nshow how to enlarge this family to get additional accuracy. In particular, we\nshow that endowing each basis point with its own full covariance matrix\nprovides a significant increase in approximation power.\n",
          "  Mixture models are a fundamental tool in applied statistics and machine\nlearning for treating data taken from multiple subpopulations. The current\npractice for estimating the parameters of such models relies on local search\nheuristics (e.g., the EM algorithm) which are prone to failure, and existing\nconsistent methods are unfavorable due to their high computational and sample\ncomplexity which typically scale exponentially with the number of mixture\ncomponents. This work develops an efficient method of moments approach to\nparameter estimation for a broad class of high-dimensional mixture models with\nmany components, including multi-view mixtures of Gaussians (such as mixtures\nof axis-aligned Gaussians) and hidden Markov models. The new method leads to\nrigorous unsupervised learning results for mixture models that were not\nachieved by previous works; and, because of its simplicity, it offers a viable\nalternative to EM for practical deployment.\n",
          "  In this paper, we present two classes of Bayesian approaches to the\ntwo-sample problem. Our first class of methods extends the Bayesian t-test to\ninclude all parametric models in the exponential family and their conjugate\npriors. Our second class of methods uses Dirichlet process mixtures (DPM) of\nsuch conjugate-exponential distributions as flexible nonparametric priors over\nthe unknown distributions.\n",
          "  We propose a nonparametric Bayesian factor regression model that accounts for\nuncertainty in the number of factors, and the relationship between factors. To\naccomplish this, we propose a sparse variant of the Indian Buffet Process and\ncouple this with a hierarchical model over factors, based on Kingman's\ncoalescent. We apply this model to two problems (factor analysis and factor\nregression) in gene-expression data analysis.\n",
          "  Biological data objects often have both of the following features: (i) they\nare functions rather than single numbers or vectors, and (ii) they are\ncorrelated due to phylogenetic relationships. In this paper we give a flexible\nstatistical model for such data, by combining assumptions from phylogenetics\nwith Gaussian processes. We describe its use as a nonparametric Bayesian prior\ndistribution, both for prediction (placing posterior distributions on ancestral\nfunctions) and model selection (comparing rates of evolution across a\nphylogeny, or identifying the most likely phylogenies consistent with the\nobserved data). Our work is integrative, extending the popular phylogenetic\nBrownian Motion and Ornstein-Uhlenbeck models to functional data and Bayesian\ninference, and extending Gaussian Process regression to phylogenies. We provide\na brief illustration of the application of our method.\n",
          "  In this work we introduce a mixture of GPs to address the data association\nproblem, i.e. to label a group of observations according to the sources that\ngenerated them. Unlike several previously proposed GP mixtures, the novel\nmixture has the distinct characteristic of using no gating function to\ndetermine the association of samples and mixture components. Instead, all the\nGPs in the mixture are global and samples are clustered following\n\"trajectories\" across input space. We use a non-standard variational Bayesian\nalgorithm to efficiently recover sample labels and learn the hyperparameters.\nWe show how multi-object tracking problems can be disambiguated and also\nexplore the characteristics of the model in traditional regression settings.\n",
          "  Bayesian models offer great flexibility for clustering\napplications---Bayesian nonparametrics can be used for modeling infinite\nmixtures, and hierarchical Bayesian models can be utilized for sharing clusters\nacross multiple data sets. For the most part, such flexibility is lacking in\nclassical clustering methods such as k-means. In this paper, we revisit the\nk-means clustering algorithm from a Bayesian nonparametric viewpoint. Inspired\nby the asymptotic connection between k-means and mixtures of Gaussians, we show\nthat a Gibbs sampling algorithm for the Dirichlet process mixture approaches a\nhard clustering algorithm in the limit, and further that the resulting\nalgorithm monotonically minimizes an elegant underlying k-means-like clustering\nobjective that includes a penalty for the number of clusters. We generalize\nthis analysis to the case of clustering multiple data sets through a similar\nasymptotic argument with the hierarchical Dirichlet process. We also discuss\nfurther extensions that highlight the benefits of our analysis: i) a spectral\nrelaxation involving thresholded eigenvectors, and ii) a normalized cut graph\nclustering algorithm that does not fix the number of clusters in the graph.\n",
          "  Gaussian processes (GP) are attractive building blocks for many probabilistic\nmodels. Their drawbacks, however, are the rapidly increasing inference time and\nmemory requirement alongside increasing data. The problem can be alleviated\nwith compactly supported (CS) covariance functions, which produce sparse\ncovariance matrices that are fast in computations and cheap to store. CS\nfunctions have previously been used in GP regression but here the focus is in a\nclassification problem. This brings new challenges since the posterior\ninference has to be done approximately. We utilize the expectation propagation\nalgorithm and show how its standard implementation has to be modified to obtain\ncomputational benefits from the sparse covariance matrices. We study four CS\ncovariance functions and show that they may lead to substantial speed up in the\ninference time compared to globally supported functions.\n",
          "  In a variety of disciplines such as social sciences, psychology, medicine and\neconomics, the recorded data are considered to be noisy measurements of latent\nvariables connected by some causal structure. This corresponds to a family of\ngraphical models known as the structural equation model with latent variables.\nWhile linear non-Gaussian variants have been well-studied, inference in\nnonparametric structural equation models is still underdeveloped. We introduce\na sparse Gaussian process parameterization that defines a non-linear structure\nconnecting latent variables, unlike common formulations of Gaussian process\nlatent variable models. The sparse parameterization is given a full Bayesian\ntreatment without compromising Markov chain Monte Carlo efficiency. We compare\nthe stability of the sampling procedure and the predictive ability of the model\nagainst the current practice.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "17_gaussian_classification_nonparametric",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "17_gaussian_classification_nonparametric"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.604827404022217,
          3.5656673908233643,
          3.8140125274658203,
          2.950345277786255,
          3.082632303237915,
          3.8069026470184326,
          3.2275471687316895,
          3.6241061687469482,
          3.823068380355835,
          3.7543435096740723,
          3.422997236251831,
          3.405311107635498,
          2.9801394939422607,
          3.1120357513427734,
          3.7932965755462646,
          3.0554041862487793,
          3.6244680881500244,
          3.584773540496826,
          3.708408832550049,
          3.9377481937408447,
          3.579585313796997,
          3.7799477577209473,
          3.526615619659424,
          3.511486530303955
         ],
         "y": [
          5.029185771942139,
          4.979910373687744,
          5.156203269958496,
          6.660881042480469,
          6.5710625648498535,
          5.176533222198486,
          6.643791198730469,
          5.012611389160156,
          5.1451096534729,
          5.11983585357666,
          5.077993869781494,
          5.09343147277832,
          6.732566833496094,
          6.596445560455322,
          5.135724067687988,
          6.576484680175781,
          5.03496789932251,
          5.027790546417236,
          5.140673637390137,
          5.560977935791016,
          4.991033554077148,
          5.137677192687988,
          5.0380539894104,
          5.506041049957275
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  If learning methods are to scale to the massive sizes of modern datasets, it\nis essential for the field of machine learning to embrace parallel and\ndistributed computing. Inspired by the recent development of matrix\nfactorization methods with rich theory but poor computational complexity and by\nthe relative ease of mapping matrices onto distributed architectures, we\nintroduce a scalable divide-and-conquer framework for noisy matrix\nfactorization. We present a thorough theoretical analysis of this framework in\nwhich we characterize the statistical errors introduced by the \"divide\" step\nand control their magnitude in the \"conquer\" step, so that the overall\nalgorithm enjoys high-probability estimation guarantees comparable to those of\nits base algorithm. We also present experiments in collaborative filtering and\nvideo background modeling that demonstrate the near-linear to superlinear\nspeed-ups attainable with this approach.\n",
          "  We present a general approach for collaborative filtering (CF) using spectral\nregularization to learn linear operators from \"users\" to the \"objects\" they\nrate. Recent low-rank type matrix completion approaches to CF are shown to be\nspecial cases. However, unlike existing regularization based CF methods, our\napproach can be used to also incorporate information such as attributes of the\nusers or the objects -- a limitation of existing regularization based CF\nmethods. We then provide novel representer theorems that we use to develop new\nestimation methods. We provide learning algorithms based on low-rank\ndecompositions, and test them on a standard CF dataset. The experiments\nindicate the advantages of generalizing the existing regularization based CF\nmethods to incorporate related information about users and objects. Finally, we\nshow that certain multi-task learning methods can be also seen as special cases\nof our proposed approach.\n",
          "  Predicting user affinity to items is an important problem in applications\nlike content optimization, computational advertising, and many more. While\nbilinear random effect models (matrix factorization) provide state-of-the-art\nperformance when minimizing RMSE through a Gaussian response model on explicit\nratings data, applying it to imbalanced binary response data presents\nadditional challenges that we carefully study in this paper. Data in many\napplications usually consist of users' implicit response that are often binary\n-- clicking an item or not; the goal is to predict click rates, which is often\ncombined with other measures to calculate utilities to rank items at runtime of\nthe recommender systems. Because of the implicit nature, such data are usually\nmuch larger than explicit rating data and often have an imbalanced distribution\nwith a small fraction of click events, making accurate click rate prediction\ndifficult. In this paper, we address two problems. First, we show previous\ntechniques to estimate bilinear random effect models with binary data are less\naccurate compared to our new approach based on adaptive rejection sampling,\nespecially for imbalanced response. Second, we develop a parallel bilinear\nrandom effect model fitting framework using Map-Reduce paradigm that scales to\nmassive datasets. Our parallel algorithm is based on a \"divide and conquer\"\nstrategy coupled with an ensemble approach. Through experiments on the\nbenchmark MovieLens data, a small Yahoo! Front Page data set, and a large\nYahoo! Front Page data set that contains 8M users and 1B binary observations,\nwe show that careful handling of binary response as well as identifiability\nissues are needed to achieve good performance for click rate prediction, and\nthat the proposed adaptive rejection sampler and the partitioning as well as\nensemble techniques significantly improve model performance.\n",
          "  Recommendation systems are emerging as an important business application with\nsignificant economic impact. Currently popular systems include Amazon's book\nrecommendations, Netflix's movie recommendations, and Pandora's music\nrecommendations. In this paper we address the problem of estimating\nprobabilities associated with recommendation system data using non-parametric\nkernel smoothing. In our estimation we interpret missing items as randomly\ncensored observations and obtain efficient computation schemes using\ncombinatorial properties of generating functions. We demonstrate our approach\nwith several case studies involving real world movie recommendation data. The\nresults are comparable with state-of-the-art techniques while also providing\nprobabilistic preference estimates outside the scope of traditional recommender\nsystems.\n",
          "  The recent crisis and the following flight to simplicity put most derivative\nbusinesses around the world under considerable pressure. We argue that the\ntraditional modeling techniques must be extended to include product design. We\npropose a quantitative framework for creating products which meet the challenge\nof being optimal from the investors point of view while remaining relatively\nsimple and transparent.\n",
          "  A collaborative filtering system recommends to users products that similar\nusers like. Collaborative filtering systems influence purchase decisions, and\nhence have become targets of manipulation by unscrupulous vendors. We provide\ntheoretical and empirical results demonstrating that while common nearest\nneighbor algorithms, which are widely used in commercial systems, can be highly\nsusceptible to manipulation, two classes of collaborative filtering algorithms\nwhich we refer to as linear and asymptotically linear are relatively robust.\nThese results provide guidance for the design of future collaborative filtering\nsystems.\n",
          "  Probabilistic matrix factorization (PMF) is a powerful method for modeling\ndata associated with pairwise relationships, finding use in collaborative\nfiltering, computational biology, and document analysis, among other areas. In\nmany domains, there is additional information that can assist in prediction.\nFor example, when modeling movie ratings, we might know when the rating\noccurred, where the user lives, or what actors appear in the movie. It is\ndifficult, however, to incorporate this side information into the PMF model. We\npropose a framework for incorporating side information by coupling together\nmultiple PMF problems via Gaussian process priors. We replace scalar latent\nfeatures with functions that vary over the space of side information. The GP\npriors on these functions require them to vary smoothly and share information.\nWe successfully use this new method to predict the scores of professional\nbasketball games, where side information about the venue and date of the game\nare relevant for the outcome.\n",
          "  Relational learning can be used to augment one data source with other\ncorrelated sources of information, to improve predictive accuracy. We frame a\nlarge class of relational learning problems as matrix factorization problems,\nand propose a hierarchical Bayesian model. Training our Bayesian model using\nrandom-walk Metropolis-Hastings is impractically slow, and so we develop a\nblock Metropolis-Hastings sampler which uses the gradient and Hessian of the\nlikelihood to dynamically tune the proposal. We demonstrate that a predictive\nmodel of brain response to stimuli can be improved by augmenting it with side\ninformation about the stimuli.\n",
          "  Albeit, the implicit feedback based recommendation problem - when only the\nuser history is available but there are no ratings - is the most typical\nsetting in real-world applications, it is much less researched than the\nexplicit feedback case. State-of-the-art algorithms that are efficient on the\nexplicit case cannot be straightforwardly transformed to the implicit case if\nscalability should be maintained. There are few if any implicit feedback\nbenchmark datasets, therefore new ideas are usually experimented on explicit\nbenchmarks. In this paper, we propose a generic context-aware implicit feedback\nrecommender algorithm, coined iTALS. iTALS apply a fast, ALS-based tensor\nfactorization learning method that scales linearly with the number of non-zero\nelements in the tensor. The method also allows us to incorporate diverse\ncontext information into the model while maintaining its computational\nefficiency. In particular, we present two such context-aware implementation\nvariants of iTALS. The first incorporates seasonality and enables to\ndistinguish user behavior in different time intervals. The other views the user\nhistory as sequential information and has the ability to recognize usage\npattern typical to certain group of items, e.g. to automatically tell apart\nproduct types or categories that are typically purchased repetitively\n(collectibles, grocery goods) or once (household appliances). Experiments\nperformed on three implicit datasets (two proprietary ones and an implicit\nvariant of the Netflix dataset) show that by integrating context-aware\ninformation with our factorization framework into the state-of-the-art implicit\nrecommender algorithm the recommendation quality improves significantly.\n",
          "  This paper introduces a novel message-passing (MP) framework for the\ncollaborative filtering (CF) problem associated with recommender systems. We\nmodel the movie-rating prediction problem popularized by the Netflix Prize,\nusing a probabilistic factor graph model and study the model by deriving\ngeneralization error bounds in terms of the training error. Based on the model,\nwe develop a new MP algorithm, termed IMP, for learning the model. To show\nsuperiority of the IMP algorithm, we compare it with the closely related\nexpectation-maximization (EM) based algorithm and a number of other matrix\ncompletion algorithms. Our simulation results on Netflix data show that, while\nthe methods perform similarly with large amounts of data, the IMP algorithm is\nsuperior for small amounts of data. This improves the cold-start problem of the\nCF systems in practice. Another advantage of the IMP algorithm is that it can\nbe analyzed using the technique of density evolution (DE) that was originally\ndeveloped for MP decoding of error-correcting codes.\n",
          "  User profiling is a useful primitive for constructing personalised services,\nsuch as content recommendation. In the present paper we investigate the\nfeasibility of user profiling in a distributed setting, with no central\nauthority and only local information exchanges between users. We compute a\nprofile vector for each user (i.e., a low-dimensional vector that characterises\nher taste) via spectral transformation of observed user-produced ratings for\nitems. Our two main contributions follow: i) We consider a low-rank\nprobabilistic model of user taste. More specifically, we consider that users\nand items are partitioned in a constant number of classes, such that users and\nitems within the same class are statistically identical. We prove that without\nprior knowledge of the compositions of the classes, based solely on few random\nobserved ratings (namely $O(N\\log N)$ such ratings for $N$ users), we can\npredict user preference with high probability for unrated items by running a\nlocal vote among users with similar profile vectors. In addition, we provide\nempirical evaluations characterising the way in which spectral profiling\nperformance depends on the dimension of the profile space. Such evaluations are\nperformed on a data set of real user ratings provided by Netflix. ii) We\ndevelop distributed algorithms which provably achieve an embedding of users\ninto a low-dimensional space, based on spectral transformation. These involve\nsimple message passing among users, and provably converge to the desired\nembedding. Our method essentially relies on a novel combination of gossiping\nand the algorithm proposed by Oja and Karhunen.\n",
          "  Recommender systems apply data mining techniques and prediction algorithms to\npredict users' interest on information, products and services among the\ntremendous amount of available items. The vast growth of information on the\nInternet as well as number of visitors to websites add some key challenges to\nrecommender systems. These are: producing accurate recommendation, handling\nmany recommendations efficiently and coping with the vast growth of number of\nparticipants in the system. Therefore, new recommender system technologies are\nneeded that can quickly produce high quality recommendations even for huge data\nsets.\n  To address these issues we have explored several collaborative filtering\ntechniques such as the item based approach, which identify relationship between\nitems and indirectly compute recommendations for users based on these\nrelationships. The user based approach was also studied, it identifies\nrelationships between users of similar tastes and computes recommendations\nbased on these relationships.\n  In this paper, we introduce the topic of recommender system. It provides ways\nto evaluate efficiency, scalability and accuracy of recommender system. The\npaper also analyzes different algorithms of user based and item based\ntechniques for recommendation generation. Moreover, a simple experiment was\nconducted using a data mining application -Weka- to apply data mining\nalgorithms to recommender system. We conclude by proposing our approach that\nmight enhance the quality of recommender systems.\n",
          "  Matrix factorization from a small number of observed entries has recently\ngarnered much attention as the key ingredient of successful recommendation\nsystems. One unresolved problem in this area is how to adapt current methods to\nhandle changing user preferences over time. Recent proposals to address this\nissue are heuristic in nature and do not fully exploit the time-dependent\nstructure of the problem. As a principled and general temporal formulation, we\npropose a dynamical state space model of matrix factorization. Our proposal\nbuilds upon probabilistic matrix factorization, a Bayesian model with Gaussian\npriors. We utilize results in state tracking, such as the Kalman filter, to\nprovide accurate recommendations in the presence of both process and\nmeasurement noise. We show how system parameters can be learned via\nexpectation-maximization and provide comparisons to current published\ntechniques.\n",
          "  In this paper, we propose a spreading activation approach for collaborative\nfiltering (SA-CF). By using the opinion spreading process, the similarity\nbetween any users can be obtained. The algorithm has remarkably higher accuracy\nthan the standard collaborative filtering (CF) using Pearson correlation.\nFurthermore, we introduce a free parameter $\\beta$ to regulate the\ncontributions of objects to user-user correlations. The numerical results\nindicate that decreasing the influence of popular objects can further improve\nthe algorithmic accuracy and personality. We argue that a better algorithm\nshould simultaneously require less computation and generate higher accuracy.\nAccordingly, we further propose an algorithm involving only the top-$N$ similar\nneighbors for each target user, which has both less computational complexity\nand higher algorithmic accuracy.\n",
          "  User preferences for items can be inferred from either explicit feedback,\nsuch as item ratings, or implicit feedback, such as rental histories. Research\nin collaborative filtering has concentrated on explicit feedback, resulting in\nthe development of accurate and scalable models. However, since explicit\nfeedback is often difficult to collect it is important to develop effective\nmodels that take advantage of the more widely available implicit feedback. We\nintroduce a probabilistic approach to collaborative filtering with implicit\nfeedback based on modelling the user's item selection process. In the interests\nof scalability, we restrict our attention to tree-structured distributions over\nitems and develop a principled and efficient algorithm for learning item trees\nfrom data. We also identify a problem with a widely used protocol for\nevaluating implicit feedback models and propose a way of addressing it using a\nsmall quantity of explicit feedback data.\n",
          "  In this paper we introduce a generic model for multiplicative algorithms\nwhich is suitable for the MapReduce parallel programming paradigm. We implement\nthree typical machine learning algorithms to demonstrate how similarity\ncomparison, gradient descent, power method and other classic learning\ntechniques fit this model well. Two versions of large-scale matrix\nmultiplication are discussed in this paper, and different methods are developed\nfor both cases with regard to their unique computational characteristics and\nproblem settings. In contrast to earlier research, we focus on fundamental\nlinear algebra techniques that establish a generic approach for a range of\nalgorithms, rather than specific ways of scaling up algorithms one at a time.\nExperiments show promising results when evaluated on both speedup and accuracy.\nCompared with a standard implementation with computational complexity $O(m^3)$\nin the worst case, the large-scale matrix multiplication experiments prove our\ndesign is considerably more efficient and maintains a good speedup as the\nnumber of cores increases. Algorithm-specific experiments also produce\nencouraging results on runtime performance.\n",
          "  This paper describes the solution method taken by LeBuSiShu team for track1\nin ACM KDD CUP 2011 contest (resulting in the 5th place). We identified two\nmain challenges: the unique item taxonomy characteristics as well as the large\ndata set size.To handle the item taxonomy, we present a novel method called\nMatrix Factorization Item Taxonomy Regularization (MFITR). MFITR obtained the\n2nd best prediction result out of more then ten implemented algorithms. For\nrapidly computing multiple solutions of various algorithms, we have implemented\nan open source parallel collaborative filtering library on top of the GraphLab\nmachine learning framework. We report some preliminary performance results\nobtained using the BlackLight supercomputer.\n",
          "  Traditionally, recommender systems for the Web deal with applications that\nhave two dimensions, users and items. Based on access logs that relate these\ndimensions, a recommendation model can be built and used to identify a set of N\nitems that will be of interest to a certain user. In this paper we propose a\nmethod to complement the information in the access logs with contextual\ninformation without changing the recommendation algorithm. The method consists\nin representing context as virtual items. We empirically test this method with\ntwo top-N recommender systems, an item-based collaborative filtering technique\nand association rules, on three data sets. The results show that our method is\nable to take advantage of the context (new dimensions) when it is informative.\n",
          "  A new message-passing (MP) method is considered for the matrix completion\nproblem associated with recommender systems. We attack the problem using a\n(generative) factor graph model that is related to a probabilistic low-rank\nmatrix factorization. Based on the model, we propose a new algorithm, termed\nIMP, for the recovery of a data matrix from incomplete observations. The\nalgorithm is based on a clustering followed by inference via MP (IMP). The\nalgorithm is compared with a number of other matrix completion algorithms on\nreal collaborative filtering (e.g., Netflix) data matrices. Our results show\nthat, while many methods perform similarly with a large number of revealed\nentries, the IMP algorithm outperforms all others when the fraction of observed\nentries is small. This is helpful because it reduces the well-known cold-start\nproblem associated with collaborative filtering (CF) systems in practice.\n",
          "  A client-server architecture to simultaneously solve multiple learning tasks\nfrom distributed datasets is described. In such architecture, each client is\nassociated with an individual learning task and the associated dataset of\nexamples. The goal of the architecture is to perform information fusion from\nmultiple datasets while preserving privacy of individual data. The role of the\nserver is to collect data in real-time from the clients and codify the\ninformation in a common database. The information coded in this database can be\nused by all the clients to solve their individual learning task, so that each\nclient can exploit the informative content of all the datasets without actually\nhaving access to private data of others. The proposed algorithmic framework,\nbased on regularization theory and kernel methods, uses a suitable class of\nmixed effect kernels. The new method is illustrated through a simulated music\nrecommendation system.\n",
          "  In dyadic prediction, labels must be predicted for pairs (dyads) whose\nmembers possess unique identifiers and, sometimes, additional features called\nside-information. Special cases of this problem include collaborative filtering\nand link prediction. We present the first model for dyadic prediction that\nsatisfies several important desiderata: (i) labels may be ordinal or nominal,\n(ii) side-information can be easily exploited if present, (iii) with or without\nside-information, latent features are inferred for dyad members, (iv) it is\nresistant to sample-selection bias, (v) it can learn well-calibrated\nprobabilities, and (vi) it can scale to very large datasets. To our knowledge,\nno existing method satisfies all the above criteria. In particular, many\nmethods assume that the labels are ordinal and ignore side-information when it\nis present. Experimental results show that the new method is competitive with\nstate-of-the-art methods for the special cases of collaborative filtering and\nlink prediction, and that it makes accurate predictions on nominal data.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "18_recommender_factorization_recommendations",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "18_recommender_factorization_recommendations"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -0.023552604019641876,
          -0.034764986485242844,
          -0.25382956862449646,
          -0.27283668518066406,
          2.4547119140625,
          -0.25366920232772827,
          -0.20978525280952454,
          -0.2260860651731491,
          -0.26604294776916504,
          -0.155032217502594,
          -0.2654252052307129,
          -0.2738684117794037,
          -0.17710036039352417,
          -0.26699644327163696,
          -0.2676493227481842,
          4.750596046447754,
          -0.10878650844097137,
          -0.2837984561920166,
          -0.09468042850494385,
          5.338998794555664,
          -0.2633829116821289,
          0.42128658294677734
         ],
         "y": [
          11.139541625976562,
          11.106963157653809,
          11.138678550720215,
          11.193642616271973,
          10.543174743652344,
          11.18415641784668,
          11.041467666625977,
          11.023113250732422,
          11.131560325622559,
          11.079862594604492,
          11.168134689331055,
          11.188983917236328,
          11.050712585449219,
          11.205243110656738,
          11.15630054473877,
          9.345595359802246,
          11.136198997497559,
          11.18409252166748,
          11.09532642364502,
          9.815098762512207,
          11.065630912780762,
          10.952070236206055
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  We introduce a natural generalization of submodular set cover and exact\nactive learning with a finite hypothesis class (query learning). We call this\nnew problem interactive submodular set cover. Applications include advertising\nin social networks with hidden information. We give an approximation guarantee\nfor a novel greedy algorithm and give a hardness of approximation result which\nmatches up to constant factors. We also discuss negative results for simpler\napproaches and present encouraging early experimental results.\n",
          "  Supervised learning deals with the inference of a distribution over an output\nor label space $\\CY$ conditioned on points in an observation space $\\CX$, given\na training dataset $D$ of pairs in $\\CX \\times \\CY$. However, in a lot of\napplications of interest, acquisition of large amounts of observations is easy,\nwhile the process of generating labels is time-consuming or costly. One way to\ndeal with this problem is {\\em active} learning, where points to be labelled\nare selected with the aim of creating a model with better performance than that\nof an model trained on an equal number of randomly sampled points. In this\npaper, we instead propose to deal with the labelling cost directly: The\nlearning goal is defined as the minimisation of a cost which is a function of\nthe expected model performance and the total cost of the labels used. This\nallows the development of general strategies and specific algorithms for (a)\noptimal stopping, where the expected cost dictates whether label acquisition\nshould continue (b) empirical evaluation, where the cost is used as a\nperformance metric for a given combination of inference, stopping and sampling\nmethods. Though the main focus of the paper is optimal stopping, we also aim to\nprovide the background for further developments and discussion in the related\nfield of active learning.\n",
          "  We present a new active learning algorithm based on nonparametric estimators\nof the regression function. Our investigation provides probabilistic bounds for\nthe rates of convergence of the generalization error achievable by proposed\nmethod over a broad class of underlying distributions. We also prove minimax\nlower bounds which show that the obtained rates are almost tight.\n",
          "  The problem of active diagnosis arises in several applications such as\ndisease diagnosis, and fault diagnosis in computer networks, where the goal is\nto rapidly identify the binary states of a set of objects (e.g., faulty or\nworking) by sequentially selecting, and observing, (noisy) responses to binary\nvalued queries. Current algorithms in this area rely on loopy belief\npropagation for active query selection. These algorithms have an exponential\ntime complexity, making them slow and even intractable in large networks. We\npropose a rank-based greedy algorithm that sequentially chooses queries such\nthat the area under the ROC curve of the rank-based output is maximized. The\nAUC criterion allows us to make a simplifying assumption that significantly\nreduces the complexity of active query selection (from exponential to near\nquadratic), with little or no compromise on the performance quality.\n",
          "  The sample complexity of active learning under the realizability assumption\nhas been well-studied. The realizability assumption, however, rarely holds in\npractice. In this paper, we theoretically characterize the sample complexity of\nactive learning in the non-realizable case under multi-view setting. We prove\nthat, with unbounded Tsybakov noise, the sample complexity of multi-view active\nlearning can be $\\widetilde{O}(\\log\\frac{1}{\\epsilon})$, contrasting to\nsingle-view setting where the polynomial improvement is the best possible\nachievement. We also prove that in general multi-view setting the sample\ncomplexity of active learning with unbounded Tsybakov noise is\n$\\widetilde{O}(\\frac{1}{\\epsilon})$, where the order of $1/\\epsilon$ is\nindependent of the parameter in Tsybakov noise, contrasting to previous\npolynomial bounds where the order of $1/\\epsilon$ is related to the parameter\nin Tsybakov noise.\n",
          "  We present and analyze an agnostic active learning algorithm that works\nwithout keeping a version space. This is unlike all previous approaches where a\nrestricted set of candidate hypotheses is maintained throughout learning, and\nonly hypotheses from this set are ever returned. By avoiding this version space\napproach, our algorithm sheds the computational burden and brittleness\nassociated with maintaining version spaces, yet still allows for substantial\nimprovements over supervised learning for classification.\n",
          "  Active Learning Method (ALM) is a soft computing method which is used for\nmodeling and control, based on fuzzy logic. Although ALM has shown that it acts\nwell in dynamic environments, its operators cannot support it very well in\ncomplex situations due to losing data. Thus ALM can find better membership\nfunctions if more appropriate operators be chosen for it. This paper\nsubstituted two new operators instead of ALM original ones; which consequently\nrenewed finding membership functions in a way superior to conventional ALM.\nThis new method is called Extended Active Learning Method (EALM).\n",
          "  Active learners alleviate the burden of labeling large amounts of data by\ndetecting and asking the user to label only the most informative examples in\nthe domain. We focus here on active learning for multi-view domains, in which\nthere are several disjoint subsets of features (views), each of which is\nsufficient to learn the target concept. In this paper we make several\ncontributions. First, we introduce Co-Testing, which is the first approach to\nmulti-view active learning. Second, we extend the multi-view learning framework\nby also exploiting weak views, which are adequate only for learning a concept\nthat is more general/specific than the target concept. Finally, we empirically\nshow that Co-Testing outperforms existing active learners on a variety of real\nworld domains such as wrapper induction, Web page classification, advertisement\nremoval, and discourse tree parsing.\n",
          "  We consider the problem of estimating the conditional probability of a label\nin time $O(\\log n)$, where $n$ is the number of possible labels. We analyze a\nnatural reduction of this problem to a set of binary regression problems\norganized in a tree structure, proving a regret bound that scales with the\ndepth of the tree. Motivated by this analysis, we propose the first online\nalgorithm which provably constructs a logarithmic depth tree on the set of\nlabels to solve this problem. We test the algorithm empirically, showing that\nit works succesfully on a dataset with roughly $10^6$ labels.\n",
          "  In this paper we address the problem of pool based active learning, and\nprovide an algorithm, called UPAL, that works by minimizing the unbiased\nestimator of the risk of a hypothesis in a given hypothesis space. For the\nspace of linear classifiers and the squared loss we show that UPAL is\nequivalent to an exponentially weighted average forecaster. Exploiting some\nrecent results regarding the spectra of random matrices allows us to establish\nconsistency of UPAL when the true hypothesis is a linear hypothesis. Empirical\ncomparison with an active learner implementation in Vowpal Wabbit, and a\npreviously proposed pool based active learner implementation show good\nempirical performance and better scalability.\n",
          "  In this paper we propose and study a generalization of the standard\nactive-learning model where a more general type of query, class conditional\nquery, is allowed. Such queries have been quite useful in applications, but\nhave been lacking theoretical understanding. In this work, we characterize the\npower of such queries under two well-known noise models. We give nearly tight\nupper and lower bounds on the number of queries needed to learn both for the\ngeneral agnostic setting and for the bounded noise model. We further show that\nour methods can be made adaptive to the (unknown) noise rate, with only\nnegligible loss in query complexity.\n",
          "  We derive and analyze a new, efficient, pool-based active learning algorithm\nfor halfspaces, called ALuMA. Most previous algorithms show exponential\nimprovement in the label complexity assuming that the distribution over the\ninstance space is close to uniform. This assumption rarely holds in practical\napplications. Instead, we study the label complexity under a large-margin\nassumption -- a much more realistic condition, as evident by the success of\nmargin-based algorithms such as SVM. Our algorithm is computationally efficient\nand comes with formal guarantees on its label complexity. It also naturally\nextends to the non-separable case and to non-linear kernels. Experiments\nillustrate the clear advantage of ALuMA over other active learning algorithms.\n",
          "  The major challenge in designing a discriminative learning algorithm for\npredicting structured data is to address the computational issues arising from\nthe exponential size of the output space. Existing algorithms make different\nassumptions to ensure efficient, polynomial time estimation of model\nparameters. For several combinatorial structures, including cycles, partially\nordered sets, permutations and other graph classes, these assumptions do not\nhold. In this thesis, we address the problem of designing learning algorithms\nfor predicting combinatorial structures by introducing two new assumptions: (i)\nThe first assumption is that a particular counting problem can be solved\nefficiently. The consequence is a generalisation of the classical ridge\nregression for structured prediction. (ii) The second assumption is that a\nparticular sampling problem can be solved efficiently. The consequence is a new\ntechnique for designing and analysing probabilistic structured prediction\nmodels. These results can be applied to solve several complex learning problems\nincluding but not limited to multi-label classification, multi-category\nhierarchical classification, and label ranking.\n",
          "  We present a practical and statistically consistent scheme for actively\nlearning binary classifiers under general loss functions. Our algorithm uses\nimportance weighting to correct sampling bias, and by controlling the variance,\nwe are able to give rigorous label complexity bounds for the learning process.\nExperiments on passively labeled data show that this approach reduces the label\ncomplexity required to achieve good predictive performance on many learning\nproblems.\n",
          "  This book presents a methodology and philosophy of empirical science based on\nlarge scale lossless data compression. In this view a theory is scientific if\nit can be used to build a data compression program, and it is valuable if it\ncan compress a standard benchmark database to a small size, taking into account\nthe length of the compressor itself. This methodology therefore includes an\nOccam principle as well as a solution to the problem of demarcation. Because of\nthe fundamental difficulty of lossless compression, this type of research must\nbe empirical in nature: compression can only be achieved by discovering and\ncharacterizing empirical regularities in the data. Because of this, the\nphilosophy provides a way to reformulate fields such as computer vision and\ncomputational linguistics as empirical sciences: the former by attempting to\ncompress databases of natural images, the latter by attempting to compress\nlarge text databases. The book argues that the rigor and objectivity of the\ncompression principle should set the stage for systematic progress in these\nfields. The argument is especially strong in the context of computer vision,\nwhich is plagued by chronic problems of evaluation.\n  The book also considers the field of machine learning. Here the traditional\napproach requires that the models proposed to solve learning problems be\nextremely simple, in order to avoid overfitting. However, the world may contain\nintrinsically complex phenomena, which would require complex models to\nunderstand. The compression philosophy can justify complex models because of\nthe large quantity of data being modeled (if the target database is 100 Gb, it\nis easy to justify a 10 Mb model). The complex models and abstractions learned\non the basis of the raw data (images, language, etc) can then be reused to\nsolve any specific learning problem, such as face recognition or machine\ntranslation.\n",
          "  We study the theoretical advantages of active learning over passive learning.\nSpecifically, we prove that, in noise-free classifier learning for VC classes,\nany passive learning algorithm can be transformed into an active learning\nalgorithm with asymptotically strictly superior label complexity for all\nnontrivial target functions and distributions. We further provide a general\ncharacterization of the magnitudes of these improvements in terms of a novel\ngeneralization of the disagreement coefficient. We also extend these results to\nactive learning in the presence of label noise, and find that even under broad\nclasses of noise distributions, we can typically guarantee strict improvements\nover the known results for passive learning.\n",
          "  We analyze the expected cost of a greedy active learning algorithm. Our\nanalysis extends previous work to a more general setting in which different\nqueries have different costs. Moreover, queries may have more than two possible\nresponses and the distribution over hypotheses may be non uniform. Specific\napplications include active learning with label costs, active learning for\nmulticlass and partial label queries, and batch mode active learning. We also\ndiscuss an approximate version of interest when there are very many queries.\n",
          "  The disagreement coefficient of Hanneke has become a central data independent\ninvariant in proving active learning rates. It has been shown in various ways\nthat a concept class with low complexity together with a bound on the\ndisagreement coefficient at an optimal solution allows active learning rates\nthat are superior to passive learning ones.\n  We present a different tool for pool based active learning which follows from\nthe existence of a certain uniform version of low disagreement coefficient, but\nis not equivalent to it. In fact, we present two fundamental active learning\nproblems of significant interest for which our approach allows nontrivial\nactive learning bounds. However, any general purpose method relying on the\ndisagreement coefficient bounds only fails to guarantee any useful bounds for\nthese problems.\n  The tool we use is based on the learner's ability to compute an estimator of\nthe difference between the loss of any hypotheses and some fixed \"pivotal\"\nhypothesis to within an absolute error of at most $\\eps$ times the\n",
          "  We consider active, semi-supervised learning in an offline transductive\nsetting. We show that a previously proposed error bound for active learning on\nundirected weighted graphs can be generalized by replacing graph cut with an\narbitrary symmetric submodular function. Arbitrary non-symmetric submodular\nfunctions can be used via symmetrization. Different choices of submodular\nfunctions give different versions of the error bound that are appropriate for\ndifferent kinds of problems. Moreover, the bound is deterministic and holds for\nadversarially chosen labels. We show exactly minimizing this error bound is\nNP-complete. However, we also introduce for any submodular function an\nassociated active semi-supervised learning method that approximately minimizes\nthe corresponding error bound. We show that the error bound is tight in the\nsense that there is no other bound of the same form which is better. Our\ntheoretical results are supported by experiments on real data.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "19_learning_supervised_learner",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "19_learning_supervised_learner"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.771905899047852,
          4.577261924743652,
          4.718321323394775,
          4.748538494110107,
          4.684213161468506,
          4.707027435302734,
          4.717548370361328,
          4.709861755371094,
          2.639915704727173,
          4.696847915649414,
          4.729189395904541,
          4.660451412200928,
          2.4310495853424072,
          4.52166223526001,
          2.9644861221313477,
          4.689171314239502,
          4.700770854949951,
          4.663527011871338,
          4.6273064613342285,
          4.366265773773193
         ],
         "y": [
          6.962264537811279,
          7.040657997131348,
          6.923381328582764,
          6.943681716918945,
          6.947760581970215,
          6.919076919555664,
          6.873606204986572,
          6.925004482269287,
          7.625182628631592,
          6.901239395141602,
          6.927152633666992,
          6.941273212432861,
          7.519081115722656,
          7.051313400268555,
          7.772457599639893,
          6.938472270965576,
          6.9077534675598145,
          6.923975944519043,
          6.972362518310547,
          7.053457736968994
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Images can be segmented by first using a classifier to predict an affinity\ngraph that reflects the degree to which image pixels must be grouped together\nand then partitioning the graph to yield a segmentation. Machine learning has\nbeen applied to the affinity classifier to produce affinity graphs that are\ngood in the sense of minimizing edge misclassification rates. However, this\nerror measure is only indirectly related to the quality of segmentations\nproduced by ultimately partitioning the affinity graph. We present the first\nmachine learning algorithm for training a classifier to produce affinity graphs\nthat are good in the sense of producing segmentations that directly minimize\nthe Rand index, a well known segmentation performance measure. The Rand index\nmeasures segmentation performance by quantifying the classification of the\nconnectivity of image pixel pairs after segmentation. By using the simple graph\npartitioning algorithm of finding the connected components of the thresholded\naffinity graph, we are able to train an affinity classifier to directly\nminimize the Rand index of segmentations resulting from the graph partitioning.\nOur learning algorithm corresponds to the learning of maximin affinities\nbetween image pixel pairs, which are predictive of the pixel-pair connectivity.\n",
          "  Deep Boltzmann machines are in principle powerful models for extracting the\nhierarchical structure of data. Unfortunately, attempts to train layers jointly\n(without greedy layer-wise pretraining) have been largely unsuccessful. We\npropose a modification of the learning algorithm that initially recenters the\noutput of the activation functions to zero. This modification leads to a better\nconditioned Hessian and thus makes learning easier. We test the algorithm on\nreal data and demonstrate that our suggestion, the centered deep Boltzmann\nmachine, learns a hierarchy of increasingly abstract representations and a\nbetter generative model of data.\n",
          "  We speed up marginal inference by ignoring factors that do not significantly\ncontribute to overall accuracy. In order to pick a suitable subset of factors\nto ignore, we propose three schemes: minimizing the number of model factors\nunder a bound on the KL divergence between pruned and full models; minimizing\nthe KL divergence under a bound on factor count; and minimizing the weighted\nsum of KL divergence and factor count. All three problems are solved using an\napproximation of the KL divergence than can be calculated in terms of marginals\ncomputed on a simple seed graph. Applied to synthetic image denoising and to\nthree different types of NLP parsing models, this technique performs marginal\ninference up to 11 times faster than loopy BP, with graph sizes reduced up to\n98%-at comparable error in marginals and parsing accuracy. We also show that\nminimizing the weighted sum of divergence and size is substantially faster than\nminimizing either of the other objectives based on the approximation to\ndivergence presented here.\n",
          "  Statistical models of natural stimuli provide an important tool for\nresearchers in the fields of machine learning and computational neuroscience. A\ncanonical way to quantitatively assess and compare the performance of\nstatistical models is given by the likelihood. One class of statistical models\nwhich has recently gained increasing popularity and has been applied to a\nvariety of complex data are deep belief networks. Analyses of these models,\nhowever, have been typically limited to qualitative analyses based on samples\ndue to the computationally intractable nature of the model likelihood.\nMotivated by these circumstances, the present article provides a consistent\nestimator for the likelihood that is both computationally tractable and simple\nto apply in practice. Using this estimator, a deep belief network which has\nbeen suggested for the modeling of natural image patches is quantitatively\ninvestigated and compared to other models of natural image patches. Contrary to\nearlier claims based on qualitative results, the results presented in this\narticle provide evidence that the model under investigation is not a\nparticularly good model for natural images\n",
          "  Standard maximum likelihood estimation cannot be applied to discrete\nenergy-based models in the general case because the computation of exact model\nprobabilities is intractable. Recent research has seen the proposal of several\nnew estimators designed specifically to overcome this intractability, but\nvirtually nothing is known about their theoretical properties. In this paper,\nwe present a generalized estimator that unifies many of the classical and\nrecently proposed estimators. We use results from the standard asymptotic\ntheory for M-estimators to derive a generic expression for the asymptotic\ncovariance matrix of our generalized estimator. We apply these results to study\nthe relative statistical efficiency of classical pseudolikelihood and the\nrecently-proposed ratio matching estimator.\n",
          "  We consider supervised learning problems where the features are embedded in a\ngraph, such as gene expressions in a gene network. In this context, it is of\nmuch interest to automatically select a subgraph with few connected components;\nby exploiting prior knowledge, one can indeed improve the prediction\nperformance or obtain results that are easier to interpret. Regularization or\npenalty functions for selecting features in graphs have recently been proposed,\nbut they raise new algorithmic challenges. For example, they typically require\nsolving a combinatorially hard selection problem among all connected subgraphs.\nIn this paper, we propose computationally feasible strategies to select a\nsparse and well-connected subset of features sitting on a directed acyclic\ngraph (DAG). We introduce structured sparsity penalties over paths on a DAG\ncalled \"path coding\" penalties. Unlike existing regularization functions that\nmodel long-range interactions between features in a graph, path coding\npenalties are tractable. The penalties and their proximal operators involve\npath selection problems, which we efficiently solve by leveraging network flow\noptimization. We experimentally show on synthetic, image, and genomic data that\nour approach is scalable and leads to more connected subgraphs than other\nregularization functions for graphs.\n",
          "  We consider the problem of classification when inputs correspond to sets of\nvectors. This setting occurs in many problems such as the classification of\npieces of mail containing several pages, of web sites with several sections or\nof images that have been pre-segmented into smaller regions. We propose\ngeneralizations of the restricted Boltzmann machine (RBM) that are appropriate\nin this context and explore how to incorporate different assumptions about the\nrelationship between the input sets and the target class within the RBM. In\nexperiments on standard multiple-instance learning datasets, we demonstrate the\ncompetitiveness of approaches based on RBMs and apply the proposed variants to\nthe problem of incoming mail classification.\n",
          "  Scene parsing, or semantic segmentation, consists in labeling each pixel in\nan image with the category of the object it belongs to. It is a challenging\ntask that involves the simultaneous detection, segmentation and recognition of\nall the objects in the image.\n  The scene parsing method proposed here starts by computing a tree of segments\nfrom a graph of pixel dissimilarities. Simultaneously, a set of dense feature\nvectors is computed which encodes regions of multiple sizes centered on each\npixel. The feature extractor is a multiscale convolutional network trained from\nraw pixels. The feature vectors associated with the segments covered by each\nnode in the tree are aggregated and fed to a classifier which produces an\nestimate of the distribution of object categories contained in the segment. A\nsubset of tree nodes that cover the image are then selected so as to maximize\nthe average \"purity\" of the class distributions, hence maximizing the overall\nlikelihood that each segment will contain a single object. The convolutional\nnetwork feature extractor is trained end-to-end from raw pixels, alleviating\nthe need for engineered features. After training, the system is parameter free.\n  The system yields record accuracies on the Stanford Background Dataset (8\nclasses), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170\nclasses) while being an order of magnitude faster than competing approaches,\nproducing a 320 \\times 240 image labeling in less than 1 second.\n",
          "  Current statistical models for structured prediction make simplifying\nassumptions about the underlying output graph structure, such as assuming a\nlow-order Markov chain, because exact inference becomes intractable as the\ntree-width of the underlying graph increases. Approximate inference algorithms,\non the other hand, force one to trade off representational power with\ncomputational efficiency. In this paper, we propose two new types of\nprobabilistic graphical models, large margin Boltzmann machines (LMBMs) and\nlarge margin sigmoid belief networks (LMSBNs), for structured prediction.\nLMSBNs in particular allow a very fast inference algorithm for arbitrary graph\nstructures that runs in polynomial time with a high probability. This\nprobability is data-distribution dependent and is maximized in learning. The\nnew approach overcomes the representation-efficiency trade-off in previous\nmodels and allows fast structured prediction with complicated graph structures.\nWe present results from applying a fully connected model to multi-label scene\nclassification and demonstrate that the proposed approach can yield significant\nperformance gains over current state-of-the-art methods.\n",
          "  The key limiting factor in graphical model inference and learning is the\ncomplexity of the partition function. We thus ask the question: what are\ngeneral conditions under which the partition function is tractable? The answer\nleads to a new kind of deep architecture, which we call sum-product networks\n(SPNs). SPNs are directed acyclic graphs with variables as leaves, sums and\nproducts as internal nodes, and weighted edges. We show that if an SPN is\ncomplete and consistent it represents the partition function and all marginals\nof some graphical model, and give semantics to its nodes. Essentially all\ntractable graphical models can be cast as SPNs, but SPNs are also strictly more\ngeneral. We then propose learning algorithms for SPNs, based on backpropagation\nand EM. Experiments show that inference and learning with SPNs can be both\nfaster and more accurate than with standard deep networks. For example, SPNs\nperform image completion better than state-of-the-art deep networks for this\ntask. SPNs also have intriguing potential connections to the architecture of\nthe cortex.\n",
          "  We show that the Bregman divergence provides a rich framework to estimate\nunnormalized statistical models for continuous or discrete random variables,\nthat is, models which do not integrate or sum to one, respectively. We prove\nthat recent estimation methods such as noise-contrastive estimation, ratio\nmatching, and score matching belong to the proposed framework, and explain\ntheir interconnection based on supervised learning. Further, we discuss the\nrole of boosting in unsupervised learning.\n",
          "  Fitting probabilistic models to data is often difficult, due to the general\nintractability of the partition function and its derivatives. Here we propose a\nnew parameter estimation technique that does not require computing an\nintractable normalization factor or sampling from the equilibrium distribution\nof the model. This is achieved by establishing dynamics that would transform\nthe observed data distribution into the model distribution, and then setting as\nthe objective the minimization of the KL divergence between the data\ndistribution and the distribution produced by running the dynamics for an\ninfinitesimal time. Score matching, minimum velocity learning, and certain\nforms of contrastive divergence are shown to be special cases of this learning\ntechnique. We demonstrate parameter estimation in Ising models, deep belief\nnetworks and an independent component analysis model of natural scenes. In the\nIsing model case, current state of the art techniques are outperformed by at\nleast an order of magnitude in learning time, with lower error in recovered\ncoupling parameters.\n",
          "  We propose an extension of the Restricted Boltzmann Machine (RBM) that allows\nthe joint shape and appearance of foreground objects in cluttered images to be\nmodeled independently of the background. We present a learning scheme that\nlearns this representation directly from cluttered images with only very weak\nsupervision. The model generates plausible samples and performs\nforeground-background segmentation. We demonstrate that representing foreground\nobjects independently of the background can be beneficial in recognition tasks.\n",
          "  Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic\nmodels that have recently been applied to a wide range of problems, including\ncollaborative filtering, classification, and modeling motion capture data.\nWhile much progress has been made in training non-conditional RBMs, these\nalgorithms are not applicable to conditional models and there has been almost\nno work on training and generating predictions from conditional RBMs for\nstructured output problems. We first argue that standard Contrastive\nDivergence-based learning may not be suitable for training CRBMs. We then\nidentify two distinct types of structured output prediction problems and\npropose an improved learning algorithm for each. The first problem type is one\nwhere the output space has arbitrary structure but the set of likely output\nconfigurations is relatively small, such as in multi-label classification. The\nsecond problem is one where the output space is arbitrarily structured but\nwhere the output space variability is much greater, such as in image denoising\nor pixel labeling. We show that the new learning algorithms can work much\nbetter than Contrastive Divergence on both types of problems.\n",
          "  The deep Boltzmann machine (DBM) has been an important development in the\nquest for powerful \"deep\" probabilistic models. To date, simultaneous or joint\ntraining of all layers of the DBM has been largely unsuccessful with existing\ntraining methods. We introduce a simple regularization scheme that encourages\nthe weight vectors associated with each hidden unit to have similar norms. We\ndemonstrate that this regularization can be easily combined with standard\nstochastic maximum likelihood to yield an effective training strategy for the\nsimultaneous training of all layers of the deep Boltzmann machine.\n",
          "  The restricted Boltzmann machine (RBM) is a flexible tool for modeling\ncomplex data, however there have been significant computational difficulties in\nusing RBMs to model high-dimensional multinomial observations. In natural\nlanguage processing applications, words are naturally modeled by K-ary discrete\ndistributions, where K is determined by the vocabulary size and can easily be\nin the hundreds of thousands. The conventional approach to training RBMs on\nword observations is limited because it requires sampling the states of K-way\nsoftmax visible units during block Gibbs updates, an operation that takes time\nlinear in K. In this work, we address this issue by employing a more general\nclass of Markov chain Monte Carlo operators on the visible units, yielding\nupdates with computational complexity independent of K. We demonstrate the\nsuccess of our approach by training RBMs on hundreds of millions of word\nn-grams using larger vocabularies than previously feasible and using the\nlearned features to improve performance on chunking and sentiment\nclassification tasks, achieving state-of-the-art results on the latter.\n",
          "  We present a novel algorithm for segmentation of natural images that\nharnesses the principle of minimum description length (MDL). Our method is\nbased on observations that a homogeneously textured region of a natural image\ncan be well modeled by a Gaussian distribution and the region boundary can be\neffectively coded by an adaptive chain code. The optimal segmentation of an\nimage is the one that gives the shortest coding length for encoding all\ntextures and boundaries in the image, and is obtained via an agglomerative\nclustering process applied to a hierarchy of decreasing window sizes as\nmulti-scale texture features. The optimal segmentation also provides an\naccurate estimate of the overall coding length and hence the true entropy of\nthe image. We test our algorithm on the publicly available Berkeley\nSegmentation Dataset. It achieves state-of-the-art segmentation results\ncompared to other existing methods.\n",
          "  Maximum likelihood estimators are often of limited practical use due to the\nintensive computation they require. We propose a family of alternative\nestimators that maximize a stochastic variation of the composite likelihood\nfunction. Each of the estimators resolve the computation-accuracy tradeoff\ndifferently, and taken together they span a continuous spectrum of\ncomputation-accuracy tradeoff resolutions. We prove the consistency of the\nestimators, provide formulas for their asymptotic variance, statistical\nrobustness, and computational complexity. We discuss experimental results in\nthe context of Boltzmann machines and conditional random fields. The\ntheoretical and experimental studies demonstrate the effectiveness of the\nestimators when the computational resources are insufficient. They also\ndemonstrate that in some cases reduced computational complexity is associated\nwith robustness thereby increasing statistical accuracy.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "20_segmentations_segmentation_classification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "20_segmentations_segmentation_classification"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.6318402290344238,
          2.380737781524658,
          2.309206962585449,
          2.5067644119262695,
          3.4101531505584717,
          1.9250879287719727,
          2.3760838508605957,
          0.6947075128555298,
          2.376525640487671,
          2.338930130004883,
          2.58328914642334,
          2.576885223388672,
          2.4235646724700928,
          2.427126884460449,
          2.416861057281494,
          2.2633702754974365,
          0.6453503370285034,
          2.603687047958374,
          2.1605653762817383
         ],
         "y": [
          8.677027702331543,
          6.506129264831543,
          6.506651878356934,
          6.433801174163818,
          6.452496528625488,
          10.168133735656738,
          6.517174243927002,
          8.719686508178711,
          6.5260725021362305,
          6.466676712036133,
          6.578733444213867,
          6.407896995544434,
          6.484621047973633,
          6.50510311126709,
          6.501830577850342,
          6.520679473876953,
          8.651923179626465,
          6.501737117767334,
          7.062576770782471
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Last year, in 2008, I gave a talk titled {\\it Quantum Calisthenics}. This\nyear I am going to tell you about how the work I described then has spun off\ninto a most unlikely direction. What I am going to talk about is how one maps\nthe problem of finding clusters in a given data set into a problem in quantum\nmechanics. I will then use the tricks I described to let quantum evolution lets\nthe clusters come together on their own.\n",
          "  The paper shows that ranking information units by quantum probability differs\nfrom ranking them by classical probability provided the same data used for\nparameter estimation. As probability of detection (also known as recall or\npower) and probability of false alarm (also known as fallout or size) measure\nthe quality of ranking, we point out and show that ranking by quantum\nprobability yields higher probability of detection than ranking by classical\nprobability provided a given probability of false alarm and the same parameter\nestimation data. As quantum probability provided more effective detectors than\nclassical probability within other domains that data management, we conjecture\nthat, the system that can implement subspace-based detectors shall be more\neffective than a system which implements a set-based detectors, the\neffectiveness being calculated as expected recall estimated over the\nprobability of detection and expected fallout estimated over the probability of\nfalse alarm.\n",
          "  We develop an approach to machine learning and anomaly detection via quantum\nadiabatic evolution. In the training phase we identify an optimal set of weak\nclassifiers, to form a single strong classifier. In the testing phase we\nadiabatically evolve one or more strong classifiers on a superposition of\ninputs in order to find certain anomalous elements in the classification space.\nBoth the training and testing phases are executed via quantum adiabatic\nevolution. We apply and illustrate this approach in detail to the problem of\nsoftware verification and validation.\n",
          "  In this article we develop quantum algorithms for learning and testing\njuntas, i.e. Boolean functions which depend only on an unknown set of k out of\nn input variables. Our aim is to develop efficient algorithms:\n  - whose sample complexity has no dependence on n, the dimension of the domain\nthe Boolean functions are defined over;\n  - with no access to any classical or quantum membership (\"black-box\")\nqueries. Instead, our algorithms use only classical examples generated\nuniformly at random and fixed quantum superpositions of such classical\nexamples;\n  - which require only a few quantum examples but possibly many classical\nrandom examples (which are considered quite \"cheap\" relative to quantum\nexamples).\n  Our quantum algorithms are based on a subroutine FS which enables sampling\naccording to the Fourier spectrum of f; the FS subroutine was used in earlier\nwork of Bshouty and Jackson on quantum learning. Our results are as follows:\n  - We give an algorithm for testing k-juntas to accuracy $\\epsilon$ that uses\n$O(k/\\epsilon)$ quantum examples. This improves on the number of examples used\nby the best known classical algorithm.\n  - We establish the following lower bound: any FS-based k-junta testing\nalgorithm requires $\\Omega(\\sqrt{k})$ queries.\n  - We give an algorithm for learning $k$-juntas to accuracy $\\epsilon$ that\nuses $O(\\epsilon^{-1} k\\log k)$ quantum examples and $O(2^k \\log(1/\\epsilon))$\nrandom examples. We show that this learning algorithms is close to optimal by\ngiving a related lower bound.\n",
          "  The key approaches for machine learning, especially learning in unknown\nprobabilistic environments are new representations and computation mechanisms.\nIn this paper, a novel quantum reinforcement learning (QRL) method is proposed\nby combining quantum theory and reinforcement learning (RL). Inspired by the\nstate superposition principle and quantum parallelism, a framework of value\nupdating algorithm is introduced. The state (action) in traditional RL is\nidentified as the eigen state (eigen action) in QRL. The state (action) set can\nbe represented with a quantum superposition state and the eigen state (eigen\naction) can be obtained by randomly observing the simulated quantum state\naccording to the collapse postulate of quantum measurement. The probability of\nthe eigen action is determined by the probability amplitude, which is\nparallelly updated according to rewards. Some related characteristics of QRL\nsuch as convergence, optimality and balancing between exploration and\nexploitation are also analyzed, which shows that this approach makes a good\ntradeoff between exploration and exploitation using the probability amplitude\nand can speed up learning through the quantum parallelism. To evaluate the\nperformance and practicability of QRL, several simulated experiments are given\nand the results demonstrate the effectiveness and superiority of QRL algorithm\nfor some complex problems. The present work is also an effective exploration on\nthe application of quantum computation to artificial intelligence.\n",
          "  For a class of quantized open chaotic systems satisfying a natural dynamical\nassumption, we show that the study of the resolvent, and hence of scattering\nand resonances, can be reduced to the study of a family of open quantum maps,\nthat is of finite dimensional operators obtained by quantizing the Poincar\\'e\nmap associated with the flow near the set of trapped trajectories.\n",
          "  We define a new model of quantum learning that we call Predictive Quantum\n(PQ). This is a quantum analogue of PAC, where during the testing phase the\nstudent is only required to answer a polynomial number of testing queries.\n  We demonstrate a relational concept class that is efficiently learnable in\nPQ, while in any \"reasonable\" classical model exponential amount of training\ndata would be required. This is the first unconditional separation between\nquantum and classical learning.\n  We show that our separation is the best possible in several ways; in\nparticular, there is no analogous result for a functional class, as well as for\nseveral weaker versions of quantum learning. In order to demonstrate tightness\nof our separation we consider a special case of one-way communication that we\ncall single-input mode, where Bob receives no input. Somewhat surprisingly,\nthis setting becomes nontrivial when relational communication tasks are\nconsidered. In particular, any problem with two-sided input can be transformed\ninto a single-input relational problem of equal classical one-way cost. We show\nthat the situation is different in the quantum case, where the same\ntransformation can make the communication complexity exponentially larger. This\nhappens if and only if the original problem has exponential gap between quantum\nand classical one-way communication costs. We believe that these auxiliary\nresults might be of independent interest.\n",
          "  Enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum game with the problem of data\nclustering, and then develop a quantum-game-based clustering algorithm, in\nwhich data points in a dataset are considered as players who can make decisions\nand implement quantum strategies in quantum games. After each round of a\nquantum game, each player's expected payoff is calculated. Later, he uses a\nlink-removing-and-rewiring (LRR) function to change his neighbors and adjust\nthe strength of links connecting to them in order to maximize his payoff.\nFurther, algorithms are discussed and analyzed in two cases of strategies, two\npayoff matrixes and two LRR functions. Consequently, the simulation results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms have fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n",
          "  In a previous publication we proposed discrete global optimization as a\nmethod to train a strong binary classifier constructed as a thresholded sum\nover weak classifiers. Our motivation was to cast the training of a classifier\ninto a format amenable to solution by the quantum adiabatic algorithm. Applying\nadiabatic quantum computing (AQC) promises to yield solutions that are superior\nto those which can be achieved with classical heuristic solvers. Interestingly\nwe found that by using heuristic solvers to obtain approximate solutions we\ncould already gain an advantage over the standard method AdaBoost. In this\ncommunication we generalize the baseline method to large scale classifier\ntraining. By large scale we mean that either the cardinality of the dictionary\nof candidate weak classifiers or the number of weak learners used in the strong\nclassifier exceed the number of variables that can be handled effectively in a\nsingle global optimization. For such situations we propose an iterative and\npiecewise approach in which a subset of weak classifiers is selected in each\niteration via global optimization. The strong classifier is then constructed by\nconcatenating the subsets of weak classifiers. We show in numerical studies\nthat the generalized method again successfully competes with AdaBoost. We also\nprovide theoretical arguments as to why the proposed optimization method, which\ndoes not only minimize the empirical loss but also adds L0-norm regularization,\nis superior to versions of boosting that only minimize the empirical loss. By\nconducting a Quantum Monte Carlo simulation we gather evidence that the quantum\nadiabatic algorithm is able to handle a generic training problem efficiently.\n",
          "  This paper studies quantum annealing (QA) for clustering, which can be seen\nas an extension of simulated annealing (SA). We derive a QA algorithm for\nclustering and propose an annealing schedule, which is crucial in practice.\nExperiments show the proposed QA algorithm finds better clustering assignments\nthan SA. Furthermore, QA is as easy as SA to implement.\n",
          "  In this paper, we introduce elements of probabilistic model that is suitable\nfor modeling of learning algorithms in biologically plausible artificial neural\nnetworks framework. Model is based on two of the main concepts in quantum\nphysics - a density matrix and the Born rule. As an example, we will show that\nproposed probabilistic interpretation is suitable for modeling of on-line\nlearning algorithms for PSA, which are preferably realized by a parallel\nhardware based on very simple computational units. Proposed concept (model) can\nbe used in the context of improving algorithm convergence speed, learning\nfactor choice, or input signal scale robustness. We are going to see how the\nBorn rule and the Hebbian learning rule are connected\n",
          "  This paper presents studies on a deterministic annealing algorithm based on\nquantum annealing for variational Bayes (QAVB) inference, which can be seen as\nan extension of the simulated annealing for variational Bayes (SAVB) inference.\nQAVB is as easy as SAVB to implement. Experiments revealed QAVB finds a better\nlocal optimum than SAVB in terms of the variational free energy in latent\nDirichlet allocation (LDA).\n",
          "  We examine the complexity of learning the distributions produced by\nfinite-state quantum sources. We show how prior techniques for learning hidden\nMarkov models can be adapted to the quantum generator model to find that the\nanalogous state of affairs holds: information-theoretically, a polynomial\nnumber of samples suffice to approximately identify the distribution, but\ncomputationally, the problem is as hard as learning parities with noise, a\nnotorious open question in computational learning theory.\n",
          "  Quantum classification is defined as the task of predicting the associated\nclass of an unknown quantum state drawn from an ensemble of pure states given a\nfinite number of copies of this state. By recasting the state discrimination\nproblem within the framework of Machine Learning (ML), we can use the notion of\nlearning reduction coming from classical ML to solve different variants of the\nclassification task, such as the weighted binary and the multiclass versions.\n",
          "  The enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum random walk (QRW) with the\nproblem of data clustering, and develop two clustering algorithms based on the\none dimensional QRW. Then, the probability distributions on the positions\ninduced by QRW in these algorithms are investigated, which also indicates the\npossibility of obtaining better results. Consequently, the experimental results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms are of fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n",
          "  According to the probability ranking principle, the document set with the\nhighest values of probability of relevance optimizes information retrieval\neffectiveness given the probabilities are estimated as accurately as possible.\nThe key point of this principle is the separation of the document set into two\nsubsets with a given level of fallout and with the highest recall. If subsets\nof set measures are replaced by subspaces and space measures, we obtain an\nalternative theory stemming from Quantum Theory. That theory is named after\nvector probability because vectors represent event like sets do in classical\nprobability. The paper shows that the separation into vector subspaces is more\neffective than the separation into subsets with the same available evidence.\nThe result is proved mathematically and verified experimentally. In general,\nthe paper suggests that quantum theory is not only a source of rhetoric\ninspiration, but is a sufficient condition to improve retrieval effectiveness\nin a principled way.\n",
          "  As a mathematical model of associative memories, the Hopfield model was now\nwell-established and a lot of studies to reveal the pattern-recalling process\nhave been done from various different approaches. As well-known, a single\nneuron is itself an uncertain, noisy unit with a finite unnegligible error in\nthe input-output relation. To model the situation artificially, a kind of 'heat\nbath' that surrounds neurons is introduced. The heat bath, which is a source of\nnoise, is specified by the 'temperature'. Several studies concerning the\npattern-recalling processes of the Hopfield model governed by the\nGlauber-dynamics at finite temperature were already reported. However, we might\nextend the 'thermal noise' to the quantum-mechanical variant. In this paper, in\nterms of the stochastic process of quantum-mechanical Markov chain Monte Carlo\nmethod (the quantum MCMC), we analytically derive macroscopically deterministic\nequations of order parameters such as 'overlap' in a quantum-mechanical variant\nof the Hopfield neural networks (let us call \"quantum Hopfield model\" or\n\"quantum Hopfield networks\"). For the case in which non-extensive number $p$ of\npatterns are embedded via asymmetric Hebbian connections, namely, $p/N \\to 0$\nfor the number of neuron $N \\to \\infty$ ('far from saturation'), we evaluate\nthe recalling processes for one of the built-in patterns under the influence of\nquantum-mechanical noise.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "21_quantum_superposition_qavb",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "21_quantum_superposition_qavb"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.107583522796631,
          5.1002397537231445,
          5.159613132476807,
          5.140204429626465,
          5.3185648918151855,
          5.13608455657959,
          5.138736248016357,
          5.114212989807129,
          5.168176174163818,
          5.084039211273193,
          5.167954921722412,
          4.681221961975098,
          5.129964351654053,
          5.160093307495117,
          5.108944892883301,
          5.090972900390625,
          5.139481544494629,
          5.114475250244141
         ],
         "y": [
          5.069413661956787,
          5.158043384552002,
          5.110754489898682,
          5.098791122436523,
          5.155641555786133,
          5.094659328460693,
          5.108047962188721,
          5.079610824584961,
          5.079720973968506,
          5.06339168548584,
          5.304354667663574,
          5.050447940826416,
          5.111918926239014,
          5.099216938018799,
          5.079771518707275,
          5.180713653564453,
          5.3051066398620605,
          5.1264472007751465
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This paper introduces a privacy-aware Bayesian approach that combines\nensembles of classifiers and clusterers to perform semi-supervised and\ntransductive learning. We consider scenarios where instances and their\nclassification/clustering results are distributed across different data sites\nand have sharing restrictions. As a special case, the privacy aware computation\nof the model when instances of the target data are distributed across different\ndata sites, is also discussed. Experimental results show that the proposed\napproach can provide good classification accuracies while adhering to the\ndata/model sharing constraints.\n",
          "  We consider the problem of PAC-learning from distributed data and analyze\nfundamental communication complexity questions involved. We provide general\nupper and lower bounds on the amount of communication needed to learn well,\nshowing that in addition to VC-dimension and covering number, quantities such\nas the teaching-dimension and mistake-bound of a class play an important role.\nWe also present tight results for a number of common concept classes including\nconjunctions, parity functions, and decision lists. For linear separators, we\nshow that for non-concentrated distributions, we can use a version of the\nPerceptron algorithm to learn with much less communication than the number of\nupdates given by the usual margin bound. We also show how boosting can be\nperformed in a generic manner in the distributed setting to achieve\ncommunication with only logarithmic dependence on 1/epsilon for any concept\nclass, and demonstrate how recent work on agnostic learning from\nclass-conditional queries can be used to achieve low communication in agnostic\nsettings as well. We additionally present an analysis of privacy, considering\nboth differential privacy and a notion of distributional privacy that is\nespecially appealing in this context.\n",
          "  Several recent studies in privacy-preserving learning have considered the\ntrade-off between utility or risk and the level of differential privacy\nguaranteed by mechanisms for statistical query processing. In this paper we\nstudy this trade-off in private Support Vector Machine (SVM) learning. We\npresent two efficient mechanisms, one for the case of finite-dimensional\nfeature mappings and one for potentially infinite-dimensional feature mappings\nwith translation-invariant kernels. For the case of translation-invariant\nkernels, the proposed mechanism minimizes regularized empirical risk in a\nrandom Reproducing Kernel Hilbert Space whose kernel uniformly approximates the\ndesired kernel with high probability. This technique, borrowed from large-scale\nlearning, allows the mechanism to respond with a finite encoding of the\nclassifier, even when the function class is of infinite VC dimension.\nDifferential privacy is established using a proof technique from algorithmic\nstability. Utility--the mechanism's response function is pointwise\nepsilon-close to non-private SVM with probability 1-delta--is proven by\nappealing to the smoothness of regularized empirical risk minimization with\nrespect to small perturbations to the feature mapping. We conclude with a lower\nbound on the optimal differential privacy of the SVM. This negative result\nstates that for any delta, no mechanism can be simultaneously\n(epsilon,delta)-useful and beta-differentially private for small epsilon and\nsmall beta.\n",
          "  This work considers computationally efficient privacy-preserving data\nrelease. We study the task of analyzing a database containing sensitive\ninformation about individual participants. Given a set of statistical queries\non the data, we want to release approximate answers to the queries while also\nguaranteeing differential privacy---protecting each participant's sensitive\ndata.\n  Our focus is on computationally efficient data release algorithms; we seek\nalgorithms whose running time is polynomial, or at least sub-exponential, in\nthe data dimensionality. Our primary contribution is a computationally\nefficient reduction from differentially private data release for a class of\ncounting queries, to learning thresholded sums of predicates from a related\nclass.\n  We instantiate this general reduction with a variety of algorithms for\nlearning thresholds. These instantiations yield several new results for\ndifferentially private data release. As two examples, taking {0,1}^d to be the\ndata domain (of dimension d), we obtain differentially private algorithms for:\n  (*) Releasing all k-way conjunctions. For any given k, the resulting data\nrelease algorithm has bounded error as long as the database is of size at least\nd^{O(\\sqrt{k\\log(k\\log d)})}. The running time is polynomial in the database\nsize.\n  (*) Releasing a (1-\\gamma)-fraction of all parity queries. For any \\gamma\n\\geq \\poly(1/d), the algorithm has bounded error as long as the database is of\nsize at least \\poly(d). The running time is polynomial in the database size.\n  Several other instantiations yield further results for privacy-preserving\ndata release. Of the two results highlighted above, the first learning\nalgorithm uses techniques for representing thresholded sums of predicates as\nlow-degree polynomial threshold functions. The second learning algorithm is\nbased on Jackson's Harmonic Sieve algorithm [Jackson 1997].\n",
          "  We revisit the problem of accurately answering large classes of statistical\nqueries while preserving differential privacy. Previous approaches to this\nproblem have either been very general but have not had run-time polynomial in\nthe size of the database, have applied only to very limited classes of queries,\nor have relaxed the notion of worst-case error guarantees. In this paper we\nconsider the large class of sparse queries, which take non-zero values on only\npolynomially many universe elements. We give efficient query release algorithms\nfor this class, in both the interactive and the non-interactive setting. Our\nalgorithms also achieve better accuracy bounds than previous general techniques\ndo when applied to sparse queries: our bounds are independent of the universe\nsize. In fact, even the runtime of our interactive mechanism is independent of\nthe universe size, and so can be implemented in the \"infinite universe\" model\nin which no finite universe need be specified by the data curator.\n",
          "  Learning problems form an important category of computational tasks that\ngeneralizes many of the computations researchers apply to large real-life data\nsets. We ask: what concept classes can be learned privately, namely, by an\nalgorithm whose output does not depend too heavily on any one input or specific\ntraining example? More precisely, we investigate learning algorithms that\nsatisfy differential privacy, a notion that provides strong confidentiality\nguarantees in contexts where aggregate information is released about a database\ncontaining sensitive information about individuals. We demonstrate that,\nignoring computational constraints, it is possible to privately agnostically\nlearn any concept class using a sample size approximately logarithmic in the\ncardinality of the concept class. Therefore, almost anything learnable is\nlearnable privately: specifically, if a concept class is learnable by a\n(non-private) algorithm with polynomial sample complexity and output size, then\nit can be learned privately using a polynomial number of samples. We also\npresent a computationally efficient private PAC learner for the class of parity\nfunctions. Local (or randomized response) algorithms are a practical class of\nprivate algorithms that have received extensive investigation. We provide a\nprecise characterization of local private learning algorithms. We show that a\nconcept class is learnable by a local algorithm if and only if it is learnable\nin the statistical query (SQ) model. Finally, we present a separation between\nthe power of interactive and noninteractive local learning algorithms.\n",
          "  Privacy-preserving machine learning algorithms are crucial for the\nincreasingly common setting in which personal data, such as medical or\nfinancial records, are analyzed. We provide general techniques to produce\nprivacy-preserving approximations of classifiers learned via (regularized)\nempirical risk minimization (ERM). These algorithms are private under the\n$\\epsilon$-differential privacy definition due to Dwork et al. (2006). First we\napply the output perturbation ideas of Dwork et al. (2006), to ERM\nclassification. Then we propose a new method, objective perturbation, for\nprivacy-preserving machine learning algorithm design. This method entails\nperturbing the objective function before optimizing over classifiers. If the\nloss and regularizer satisfy certain convexity and differentiability criteria,\nwe prove theoretical results showing that our algorithms preserve privacy, and\nprovide generalization bounds for linear and nonlinear kernels. We further\npresent a privacy-preserving technique for tuning the parameters in general\nmachine learning algorithms, thereby providing end-to-end privacy guarantees\nfor the training process. We apply these results to produce privacy-preserving\nanalogues of regularized logistic regression and support vector machines. We\nobtain encouraging results from evaluating their performance on real\ndemographic and benchmark data sets. Our results show that both theoretically\nand empirically, objective perturbation is superior to the previous\nstate-of-the-art, output perturbation, in managing the inherent tradeoff\nbetween privacy and learning performance.\n",
          "  Differential privacy is a framework for privately releasing summaries of a\ndatabase. Previous work has focused mainly on methods for which the output is a\nfinite dimensional vector, or an element of some discrete set. We develop\nmethods for releasing functions while preserving differential privacy.\nSpecifically, we show that adding an appropriate Gaussian process to the\nfunction of interest yields differential privacy. When the functions lie in the\nsame RKHS as the Gaussian process, then the correct noise level is established\nby measuring the \"sensitivity\" of the function in the RKHS norm. As examples we\nconsider kernel density estimation, kernel support vector machines, and\nfunctions in reproducing kernel Hilbert spaces.\n",
          "  As increasing amounts of sensitive personal information is aggregated into\ndata repositories, it has become important to develop mechanisms for processing\nthe data without revealing information about individual data instances. The\ndifferential privacy model provides a framework for the development and\ntheoretical analysis of such mechanisms. In this paper, we propose an algorithm\nfor learning a discriminatively trained multi-class Gaussian classifier that\nsatisfies differential privacy using a large margin loss function with a\nperturbed regularization term. We present a theoretical upper bound on the\nexcess risk of the classifier introduced by the perturbation.\n",
          "  Suppose we would like to know all answers to a set of statistical queries C\non a data set up to small error, but we can only access the data itself using\nstatistical queries. A trivial solution is to exhaustively ask all queries in\nC. Can we do any better?\n  + We show that the number of statistical queries necessary and sufficient for\nthis task is---up to polynomial factors---equal to the agnostic learning\ncomplexity of C in Kearns' statistical query (SQ) model. This gives a complete\nanswer to the question when running time is not a concern.\n  + We then show that the problem can be solved efficiently (allowing arbitrary\nerror on a small fraction of queries) whenever the answers to C can be\ndescribed by a submodular function. This includes many natural concept classes,\nsuch as graph cuts and Boolean disjunctions and conjunctions.\n  While interesting from a learning theoretic point of view, our main\napplications are in privacy-preserving data analysis:\n  Here, our second result leads to the first algorithm that efficiently\nreleases differentially private answers to of all Boolean conjunctions with 1%\naverage error. This presents significant progress on a key open problem in\nprivacy-preserving data analysis.\n  Our first result on the other hand gives unconditional lower bounds on any\ndifferentially private algorithm that admits a (potentially\nnon-privacy-preserving) implementation using only statistical queries. Not only\nour algorithms, but also most known private algorithms can be implemented using\nonly statistical queries, and hence are constrained by these lower bounds. Our\nresult therefore isolates the complexity of agnostic learning in the SQ-model\nas a new barrier in the design of differentially private algorithms.\n",
          "  We consider privacy preserving decision tree induction via ID3 in the case\nwhere the training data is horizontally or vertically distributed. Furthermore,\nwe consider the same problem in the case where the data is both horizontally\nand vertically distributed, a situation we refer to as grid partitioned data.\nWe give an algorithm for privacy preserving ID3 over horizontally partitioned\ndata involving more than two parties. For grid partitioned data, we discuss two\ndifferent evaluation methods for preserving privacy ID3, namely, first merging\nhorizontally and developing vertically or first merging vertically and next\ndeveloping horizontally. Next to introducing privacy preserving data mining\nover grid-partitioned data, the main contribution of this paper is that we\nshow, by means of a complexity analysis that the former evaluation method is\nthe more efficient.\n",
          "  We propose a relaxed privacy definition called {\\em random differential\nprivacy} (RDP). Differential privacy requires that adding any new observation\nto a database will have small effect on the output of the data-release\nprocedure. Random differential privacy requires that adding a {\\em randomly\ndrawn new observation} to a database will have small effect on the output. We\nshow an analog of the composition property of differentially private procedures\nwhich applies to our new definition. We show how to release an RDP histogram\nand we show that RDP histograms are much more accurate than histograms obtained\nusing ordinary differential privacy. We finally show an analog of the global\nsensitivity framework for the release of functions under our privacy\ndefinition.\n",
          "  This report explores the use of machine learning techniques to accurately\npredict travel times in city streets and highways using floating car data\n(location information of user vehicles on a road network). The aim of this\nreport is twofold, first we present a general architecture of solving this\nproblem, then present and evaluate few techniques on real floating car data\ngathered over a month on a 5 Km highway in New Delhi.\n",
          "  In this paper we demonstrate that, ignoring computational constraints, it is\npossible to privately release synthetic databases that are useful for large\nclasses of queries -- much larger in size than the database itself.\nSpecifically, we give a mechanism that privately releases synthetic data for a\nclass of queries over a discrete domain with error that grows as a function of\nthe size of the smallest net approximately representing the answers to that\nclass of queries. We show that this in particular implies a mechanism for\ncounting queries that gives error guarantees that grow only with the\nVC-dimension of the class of queries, which itself grows only logarithmically\nwith the size of the query class.\n  We also show that it is not possible to privately release even simple classes\nof queries (such as intervals and their generalizations) over continuous\ndomains. Despite this, we give a privacy-preserving polynomial time algorithm\nthat releases information useful for all halfspace queries, given a slight\nrelaxation of the utility guarantee. This algorithm does not release synthetic\ndata, but instead another data structure capable of representing an answer for\neach query. We also give an efficient algorithm for releasing synthetic data\nfor the class of interval queries and axis-aligned rectangles of constant\ndimension.\n  Finally, inspired by learning theory, we introduce a new notion of data\nprivacy, which we call distributional privacy, and show that it is strictly\nstronger than the prevailing privacy notion, differential privacy.\n",
          "  Machine Learning is usually defined as a subfield of AI, which is busy with\ninformation extraction from raw data sets. Despite of its common acceptance and\nwidespread recognition, this definition is wrong and groundless. Meaningful\ninformation does not belong to the data that bear it. It belongs to the\nobservers of the data and it is a shared agreement and a convention among them.\nTherefore, this private information cannot be extracted from the data by any\nmeans. Therefore, all further attempts of Machine Learning apologists to\njustify their funny business are inappropriate.\n",
          "  We consider a group of Bayesian agents who try to estimate a state of the\nworld $\\theta$ through interaction on a social network. Each agent $v$\ninitially receives a private measurement of $\\theta$: a number $S_v$ picked\nfrom a Gaussian distribution with mean $\\theta$ and standard deviation one.\nThen, in each discrete time iteration, each reveals its estimate of $\\theta$ to\nits neighbors, and, observing its neighbors' actions, updates its belief using\nBayes' Law.\n  This process aggregates information efficiently, in the sense that all the\nagents converge to the belief that they would have, had they access to all the\nprivate measurements. We show that this process is computationally efficient,\nso that each agent's calculation can be easily carried out. We also show that\non any graph the process converges after at most $2N \\cdot D$ steps, where $N$\nis the number of agents and $D$ is the diameter of the network. Finally, we\nshow that on trees and on distance transitive-graphs the process converges\nafter $D$ steps, and that it preserves privacy, so that agents learn very\nlittle about the private signal of most other agents, despite the efficient\naggregation of information. Our results extend those in an unpublished\nmanuscript of the first and last authors.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "22_privacy_private_privately",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "22_privacy_private_privately"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.411976337432861,
          5.379655838012695,
          5.417001247406006,
          5.417040824890137,
          5.426506996154785,
          5.4274492263793945,
          5.405948162078857,
          5.4391984939575195,
          5.4051337242126465,
          5.4158501625061035,
          5.397084712982178,
          5.427029132843018,
          5.764550685882568,
          5.423022747039795,
          5.386979579925537,
          5.483024597167969,
          5.439215660095215
         ],
         "y": [
          9.795238494873047,
          9.730360984802246,
          9.813847541809082,
          9.844667434692383,
          9.844254493713379,
          9.74429988861084,
          9.811988830566406,
          9.879155158996582,
          9.847940444946289,
          9.817691802978516,
          9.772472381591797,
          9.859853744506836,
          9.165003776550293,
          9.85003662109375,
          9.721002578735352,
          9.469734191894531,
          9.747971534729004
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Boosting combines weak learners into a predictor with low empirical risk. Its\ndual constructs a high entropy distribution upon which weak learners and\ntraining labels are uncorrelated. This manuscript studies this primal-dual\nrelationship under a broad family of losses, including the exponential loss of\nAdaBoost and the logistic loss, revealing:\n  - Weak learnability aids the whole loss family: for any {\\epsilon}>0,\nO(ln(1/{\\epsilon})) iterations suffice to produce a predictor with empirical\nrisk {\\epsilon}-close to the infimum;\n  - The circumstances granting the existence of an empirical risk minimizer may\nbe characterized in terms of the primal and dual problems, yielding a new proof\nof the known rate O(ln(1/{\\epsilon}));\n  - Arbitrary instances may be decomposed into the above two, granting rate\nO(1/{\\epsilon}), with a matching lower bound provided for the logistic loss.\n",
          "  In practical applications, machine learning algorithms are often needed to\nlearn classifiers that optimize domain specific performance measures.\nPreviously, the research has focused on learning the needed classifier in\nisolation, yet learning nonlinear classifier for nonlinear and nonsmooth\nperformance measures is still hard. In this paper, rather than learning the\nneeded classifier by optimizing specific performance measure directly, we\ncircumvent this problem by proposing a novel two-step approach called as CAPO,\nnamely to first train nonlinear auxiliary classifiers with existing learning\nmethods, and then to adapt auxiliary classifiers for specific performance\nmeasures. In the first step, auxiliary classifiers can be obtained efficiently\nby taking off-the-shelf learning algorithms. For the second step, we show that\nthe classifier adaptation problem can be reduced to a quadratic program\nproblem, which is similar to linear SVMperf and can be efficiently solved. By\nexploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear\nclassifier which optimizes a large variety of performance measures including\nall the performance measure based on the contingency table and AUC, whilst\nkeeping high computational efficiency. Empirical studies show that CAPO is\neffective and of high computational efficiency, and even it is more efficient\nthan linear SVMperf.\n",
          "  Due to myriads of classes, designing accurate and efficient classifiers\nbecomes very challenging for multi-class classification. Recent research has\nshown that class structure learning can greatly facilitate multi-class\nlearning. In this paper, we propose a novel method to learn the class structure\nfor multi-class classification problems. The class structure is assumed to be a\nbinary hierarchical tree. To learn such a tree, we propose a maximum separating\nmargin method to determine the child nodes of any internal node. The proposed\nmethod ensures that two classgroups represented by any two sibling nodes are\nmost separable. In the experiments, we evaluate the accuracy and efficiency of\nthe proposed method over other multi-class classification methods on real world\nlarge-scale problems. The results show that the proposed method outperforms\nbenchmark methods in terms of accuracy for most datasets and performs\ncomparably with other class structure learning methods in terms of efficiency\nfor all datasets.\n",
          "  In this paper, we derive a novel probabilistic model of boosting as a Product\nof Experts. We re-derive the boosting algorithm as a greedy incremental model\nselection procedure which ensures that addition of new experts to the ensemble\ndoes not decrease the likelihood of the data. These learning rules lead to a\ngeneric boosting algorithm - POE- Boost which turns out to be similar to the\nAdaBoost algorithm under certain assumptions on the expert probabilities. The\npaper then extends the POEBoost algorithm to POEBoost.CS which handles\nhypothesis that produce probabilistic predictions. This new algorithm is shown\nto have better generalization performance compared to other state of the art\nalgorithms.\n",
          "  Boosting has attracted much research attention in the past decade. The\nsuccess of boosting algorithms may be interpreted in terms of the margin\ntheory. Recently it has been shown that generalization error of classifiers can\nbe obtained by explicitly taking the margin distribution of the training data\ninto account. Most of the current boosting algorithms in practice usually\noptimizes a convex loss function and do not make use of the margin\ndistribution. In this work we design a new boosting algorithm, termed\nmargin-distribution boosting (MDBoost), which directly maximizes the average\nmargin and minimizes the margin variance simultaneously. This way the margin\ndistribution is optimized. A totally-corrective optimization algorithm based on\ncolumn generation is proposed to implement MDBoost. Experiments on UCI datasets\nshow that MDBoost outperforms AdaBoost and LPBoost in most cases.\n",
          "  An approach to the acceleration of parametric weak classifier boosting is\nproposed. Weak classifier is called parametric if it has fixed number of\nparameters and, so, can be represented as a point into multidimensional space.\nGenetic algorithm is used instead of exhaustive search to learn parameters of\nsuch classifier. Proposed approach also takes cases when effective algorithm\nfor learning some of the classifier parameters exists into account. Experiments\nconfirm that such an approach can dramatically decrease classifier training\ntime while keeping both training and test errors small.\n",
          "  Multiclass prediction is the problem of classifying an object into a relevant\ntarget class. We consider the problem of learning a multiclass predictor that\nuses only few features, and in particular, the number of used features should\nincrease sub-linearly with the number of possible classes. This implies that\nfeatures should be shared by several classes. We describe and analyze the\nShareBoost algorithm for learning a multiclass predictor that uses few shared\nfeatures. We prove that ShareBoost efficiently finds a predictor that uses few\nshared features (if such a predictor exists) and that it has a small\ngeneralization error. We also describe how to use ShareBoost for learning a\nnon-linear predictor that has a fast evaluation time. In a series of\nexperiments with natural data sets we demonstrate the benefits of ShareBoost\nand evaluate its success relatively to other state-of-the-art approaches.\n",
          "  Logitboost is an influential boosting algorithm for classification. In this\npaper, we develop robust logitboost to provide an explicit formulation of\ntree-split criterion for building weak learners (regression trees) for\nlogitboost. This formulation leads to a numerically stable implementation of\nlogitboost. We then propose abc-logitboost for multi-class classification, by\ncombining robust logitboost with the prior work of abc-boost. Previously,\nabc-boost was implemented as abc-mart using the mart algorithm. Our extensive\nexperiments on multi-class classification compare four algorithms: mart,\nabcmart, (robust) logitboost, and abc-logitboost, and demonstrate the\nsuperiority of abc-logitboost. Comparisons with other learning methods\nincluding SVM and deep learning are also available through prior publications.\n",
          "  Abc-boost is a new line of boosting algorithms for multi-class\nclassification, by utilizing the commonly used sum-to-zero constraint. To\nimplement abc-boost, a base class must be identified at each boosting step.\nPrior studies used a very expensive procedure based on exhaustive search for\ndetermining the base class at each boosting step. Good testing performances of\nabc-boost (implemented as abc-mart and abc-logitboost) on a variety of datasets\nwere reported.\n  For large datasets, however, the exhaustive search strategy adopted in prior\nabc-boost algorithms can be too prohibitive. To overcome this serious\nlimitation, this paper suggests a heuristic by introducing Gaps when computing\nthe base class during training. That is, we update the choice of the base class\nonly for every $G$ boosting steps (i.e., G=1 in prior studies). We test this\nidea on large datasets (Covertype and Poker) as well as datasets of moderate\nsizes. Our preliminary results are very encouraging. On the large datasets,\neven with G=100 (or larger), there is essentially no loss of test accuracy. On\nthe moderate datasets, no obvious loss of test accuracy is observed when G<=\n20~50. Therefore, aided by this heuristic, it is promising that abc-boost will\nbe a practical tool for accurate multi-class classification.\n",
          "  This empirical study is mainly devoted to comparing four tree-based boosting\nalgorithms: mart, abc-mart, robust logitboost, and abc-logitboost, for\nmulti-class classification on a variety of publicly available datasets. Some of\nthose datasets have been thoroughly tested in prior studies using a broad range\nof classification algorithms including SVM, neural nets, and deep learning.\n  In terms of the empirical classification errors, our experiment results\ndemonstrate:\n  1. Abc-mart considerably improves mart. 2. Abc-logitboost considerably\nimproves (robust) logitboost. 3. Robust) logitboost} considerably improves mart\non most datasets. 4. Abc-logitboost considerably improves abc-mart on most\ndatasets. 5. These four boosting algorithms (especially abc-logitboost)\noutperform SVM on many datasets. 6. Compared to the best deep learning methods,\nthese four boosting algorithms (especially abc-logitboost) are competitive.\n",
          "  We develop the concept of ABC-Boost (Adaptive Base Class Boost) for\nmulti-class classification and present ABC-MART, a concrete implementation of\nABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has\nbeen very successful in large-scale applications. For binary classification,\nABC-MART recovers MART. For multi-class classification, ABC-MART considerably\nimproves MART, as evaluated on several public data sets.\n",
          "  Boosting is a popular way to derive powerful learners from simpler hypothesis\nclasses. Following previous work (Mason et al., 1999; Friedman, 2000) on\ngeneral boosting frameworks, we analyze gradient-based descent algorithms for\nboosting with respect to any convex objective and introduce a new measure of\nweak learner performance into this setting which generalizes existing work. We\npresent the weak to strong learning guarantees for the existing gradient\nboosting work for strongly-smooth, strongly-convex objectives under this new\nmeasure of performance, and also demonstrate that this work fails for\nnon-smooth objectives. To address this issue, we present new algorithms which\nextend this boosting approach to arbitrary convex loss functions and give\ncorresponding weak to strong convergence results. In addition, we demonstrate\nexperimental results that support our analysis and demonstrate the need for the\nnew algorithms we present.\n",
          "  In this work, we propose a new optimization framework for multiclass boosting\nlearning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two\nsuccessful multiclass boosting algorithms, which can use binary weak learners.\nWe explicitly derive these two algorithms' Lagrange dual problems based on\ntheir regularized loss functions. We show that the Lagrange dual formulations\nenable us to design totally-corrective multiclass algorithms by using the\nprimal-dual optimization technique. Experiments on benchmark data sets suggest\nthat our multiclass boosting can achieve a comparable generalization capability\nwith state-of-the-art, but the convergence speed is much faster than stage-wise\ngradient descent boosting. In other words, the new totally corrective\nalgorithms can maximize the margin more aggressively.\n",
          "  Margin theory provides one of the most popular explanations to the success of\n\\texttt{AdaBoost}, where the central point lies in the recognition that\n\\textit{margin} is the key for characterizing the performance of\n\\texttt{AdaBoost}. This theory has been very influential, e.g., it has been\nused to argue that \\texttt{AdaBoost} usually does not overfit since it tends to\nenlarge the margin even after the training error reaches zero. Previously the\n\\textit{minimum margin bound} was established for \\texttt{AdaBoost}, however,\n\\cite{Breiman1999} pointed out that maximizing the minimum margin does not\nnecessarily lead to a better generalization. Later, \\cite{Reyzin:Schapire2006}\nemphasized that the margin distribution rather than minimum margin is crucial\nto the performance of \\texttt{AdaBoost}. In this paper, we first present the\n\\textit{$k$th margin bound} and further study on its relationship to previous\nwork such as the minimum margin bound and Emargin bound. Then, we improve the\nprevious empirical Bernstein bounds\n\\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such\nfindings, we defend the margin-based explanation against Breiman's doubts by\nproving a new generalization error bound that considers exactly the same\nfactors as \\cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than\n\\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as\naverage margin and variance, we present a generalization error bound that is\nheavily related to the whole margin distribution. We also provide margin\ndistribution bounds for generalization error of voting classifiers in finite\nVC-dimension space.\n",
          "  We develop abc-logitboost, based on the prior work on abc-boost and robust\nlogitboost. Our extensive experiments on a variety of datasets demonstrate the\nconsiderable improvement of abc-logitboost over logitboost and abc-mart.\n",
          "  We study boosting algorithms from a new perspective. We show that the\nLagrange dual problems of AdaBoost, LogitBoost and soft-margin LPBoost with\ngeneralized hinge loss are all entropy maximization problems. By looking at the\ndual problems of these boosting algorithms, we show that the success of\nboosting algorithms can be understood in terms of maintaining a better margin\ndistribution by maximizing margins and at the same time controlling the margin\nvariance.We also theoretically prove that, approximately, AdaBoost maximizes\nthe average margin, instead of the minimum margin. The duality formulation also\nenables us to develop column generation based optimization algorithms, which\nare totally corrective. We show that they exhibit almost identical\nclassification results to that of standard stage-wise additive boosting\nalgorithms but with much faster convergence rates. Therefore fewer weak\nclassifiers are needed to build the ensemble using our proposed optimization\ntechnique.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "23_boosting_classifiers_boost",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "23_boosting_classifiers_boost"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.690074920654297,
          3.7244575023651123,
          3.640420913696289,
          3.68580961227417,
          3.677854061126709,
          3.6370058059692383,
          3.583883285522461,
          3.655531883239746,
          3.6511425971984863,
          3.6293272972106934,
          3.645308256149292,
          3.831167459487915,
          3.6726162433624268,
          3.694732666015625,
          3.6618425846099854,
          3.7002358436584473,
          3.6738381385803223
         ],
         "y": [
          9.729487419128418,
          9.771719932556152,
          9.872097969055176,
          9.871213912963867,
          9.882770538330078,
          9.859515190124512,
          9.829638481140137,
          9.916972160339355,
          9.915599822998047,
          9.942193031311035,
          9.90522575378418,
          9.721756935119629,
          9.869732856750488,
          9.759332656860352,
          9.937169075012207,
          9.856160163879395,
          9.85253620147705
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  In this paper, a novel framework based on trace norm minimization for audio\nsegment is proposed. In this framework, both the feature extraction and\nclassification are obtained by solving corresponding convex optimization\nproblem with trace norm regularization. For feature extraction, robust\nprinciple component analysis (robust PCA) via minimization a combination of the\nnuclear norm and the $\\ell_1$-norm is used to extract low-rank features which\nare robust to white noise and gross corruption for audio segments. These\nlow-rank features are fed to a linear classifier where the weight and bias are\nlearned by solving similar trace norm constrained problems. For this\nclassifier, most methods find the weight and bias in batch-mode learning, which\nmakes them inefficient for large-scale problems. In this paper, we propose an\nonline framework using accelerated proximal gradient method. This framework has\na main advantage in memory cost. In addition, as a result of the regularization\nformulation of matrix classification, the Lipschitz constant was given\nexplicitly, and hence the step size estimation of general proximal gradient\nmethod was omitted in our approach. Experiments on real data sets for\nlaugh/non-laugh and applause/non-applause classification indicate that this\nnovel framework is effective and noise robust.\n",
          "  Facial Action Coding System consists of 44 action units (AUs) and more than\n7000 combinations. Hidden Markov models (HMMs) classifier has been used\nsuccessfully to recognize facial action units (AUs) and expressions due to its\nability to deal with AU dynamics. However, a separate HMM is necessary for each\nsingle AU and each AU combination. Since combinations of AU numbering in\nthousands, a more efficient method will be needed. In this paper an accurate\nreal-time sequence-based system for representation and recognition of facial\nAUs is presented. Our system has the following characteristics: 1) employing a\nmixture of HMMs and neural network, we develop a novel accurate classifier,\nwhich can deal with AU dynamics, recognize subtle changes, and it is also\nrobust to intensity variations, 2) although we use an HMM for each single AU\nonly, by employing a neural network we can recognize each single and\ncombination AU, and 3) using both geometric and appearance-based features, and\napplying efficient dimension reduction techniques, our system is robust to\nillumination changes and it can represent the temporal information involved in\nformation of the facial expressions. Extensive experiments on Cohn-Kanade\ndatabase show the superiority of the proposed method, in comparison with other\nclassifiers. Keywords: classifier design and evaluation, data fusion, facial\naction units (AUs), hidden Markov models (HMMs), neural network (NN).\n",
          "  In this project, we have developed a sign language tutor that lets users\nlearn isolated signs by watching recorded videos and by trying the same signs.\nThe system records the user's video and analyses it. If the sign is recognized,\nboth verbal and animated feedback is given to the user. The system is able to\nrecognize complex signs that involve both hand gestures and head movements and\nexpressions. Our performance tests yield a 99% recognition rate on signs\ninvolving only manual gestures and 85% recognition rate on signs that involve\nboth manual and non manual components, such as head movement and facial\nexpressions.\n",
          "  In this paper, a novel method for representation and recognition of the\nfacial expressions in two-dimensional image sequences is presented. We apply a\nvariation of two-dimensional heteroscedastic linear discriminant analysis\n(2DHLDA) algorithm, as an efficient dimensionality reduction technique, to\nGabor representation of the input sequence. 2DHLDA is an extension of the\ntwo-dimensional linear discriminant analysis (2DLDA) approach and it removes\nthe equal within-class covariance. By applying 2DHLDA in two directions, we\neliminate the correlations between both image columns and image rows. Then, we\nperform a one-dimensional LDA on the new features. This combined method can\nalleviate the small sample size problem and instability encountered by HLDA.\nAlso, employing both geometric and appearance features and using an ensemble\nlearning scheme based on data fusion, we create a classifier which can\nefficiently classify the facial expressions. The proposed method is robust to\nillumination changes and it can properly represent temporal information as well\nas subtle changes in facial muscles. We provide experiments on Cohn-Kanade\ndatabase that show the superiority of the proposed method. KEYWORDS:\ntwo-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace\nlearning, facial expression analysis, Gabor wavelets, ensemble learning.\n",
          "  We present promising results for real-time vehicle visual detection, obtained\nwith adaBoost using new original ?keypoints presence features?. These\nweak-classifiers produce a boolean response based on presence or absence in the\ntested image of a ?keypoint? (~ a SURF interest point) with a descriptor\nsufficiently similar (i.e. within a given distance) to a reference descriptor\ncharacterizing the feature. A first experiment was conducted on a public image\ndataset containing lateral-viewed cars, yielding 95% recall with 95% precision\non test set. Moreover, analysis of the positions of adaBoost-selected keypoints\nshow that they correspond to a specific part of the object category (such as\n?wheel? or ?side skirt?) and thus have a ?semantic? meaning.\n",
          "  Identity verification of authentic persons by their multiview faces is a real\nvalued problem in machine vision. Multiview faces are having difficulties due\nto non-linear representation in the feature space. This paper illustrates the\nusability of the generalization of LDA in the form of canonical covariate for\nface recognition to multiview faces. In the proposed work, the Gabor filter\nbank is used to extract facial features that characterized by spatial\nfrequency, spatial locality and orientation. Gabor face representation captures\nsubstantial amount of variations of the face instances that often occurs due to\nillumination, pose and facial expression changes. Convolution of Gabor filter\nbank to face images of rotated profile views produce Gabor faces with high\ndimensional features vectors. Canonical covariate is then used to Gabor faces\nto reduce the high dimensional feature spaces into low dimensional subspaces.\nFinally, support vector machines are trained with canonical sub-spaces that\ncontain reduced set of features and perform recognition task. The proposed\nsystem is evaluated with UMIST face database. The experiment results\ndemonstrate the efficiency and robustness of the proposed system with high\nrecognition rates.\n",
          "  In this work, we first show that feature selection methods other than\nboosting can also be used for training an efficient object detector. In\nparticular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)\n\\cite{Moghaddam2007Fast} for its conceptual simplicity and computational\nefficiency; and slightly better detection performance is achieved compared with\n\\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted\nGreedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a\ndetection cascade. BGSLDA exploits the sample re-weighting property of boosting\nand the class-separability criterion of GSLDA.\n",
          "  This paper shows how to improve the real-time object detection in complex\nrobotics applications, by exploring new visual features as AdaBoost weak\nclassifiers. These new features are symmetric Haar filters (enforcing global\nhorizontal and vertical symmetry) and N-connexity control points. Experimental\nevaluation on a car database show that the latter appear to provide the best\nresults for the vehicle-detection problem.\n",
          "  Applications such as face recognition that deal with high-dimensional data\nneed a mapping technique that introduces representation of low-dimensional\nfeatures with enhanced discriminatory power and a proper classifier, able to\nclassify those complex features. Most of traditional Linear Discriminant\nAnalysis suffer from the disadvantage that their optimality criteria are not\ndirectly related to the classification ability of the obtained feature\nrepresentation. Moreover, their classification accuracy is affected by the\n\"small sample size\" problem which is often encountered in FR tasks. In this\nshort paper, we combine nonlinear kernel based mapping of data called KDDA with\nSupport Vector machine classifier to deal with both of the shortcomings in an\nefficient and cost effective manner. The proposed here method is compared, in\nterms of classification accuracy, to other commonly used FR methods on UMIST\nface database. Results indicate that the performance of the proposed method is\noverall superior to those of traditional FR approaches, such as the Eigenfaces,\nFisherfaces, and D-LDA methods and traditional linear classifiers.\n",
          "  We present promising results for visual object categorization, obtained with\nadaBoost using new original ?keypoints-based features?. These weak-classifiers\nproduce a boolean response based on presence or absence in the tested image of\na ?keypoint? (a kind of SURF interest point) with a descriptor sufficiently\nsimilar (i.e. within a given distance) to a reference descriptor characterizing\nthe feature. A first experiment was conducted on a public image dataset\ncontaining lateral-viewed cars, yielding 95% recall with 95% precision on test\nset. Preliminary tests on a small subset of a pedestrians database also gives\npromising 97% recall with 92 % precision, which shows the generality of our new\nfamily of features. Moreover, analysis of the positions of adaBoost-selected\nkeypoints show that they correspond to a specific part of the object category\n(such as ?wheel? or ?side skirt? in the case of lateral-cars) and thus have a\n?semantic? meaning. We also made a first test on video for detecting vehicles\nfrom adaBoostselected keypoints filtered in real-time from all detected\nkeypoints.\n",
          "  In this paper a novel efficient method for representation of facial action\nunits by encoding an image sequence as a fourth-order tensor is presented. The\nmultilinear tensor-based extension of the biased discriminant analysis (BDA)\nalgorithm, called multilinear biased discriminant analysis (MBDA), is first\nproposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms,\nas the dimensionality reduction techniques, to Gabor representations and the\ngeometric features of the input image sequence respectively. The proposed\nscheme can deal with the asymmetry between positive and negative samples as\nwell as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade\ndatabase show the superiority of the proposed method for representation of the\nsubtle changes and the temporal information involved in formation of the facial\nexpressions. As an accurate tool, this representation can be applied to many\nareas such as recognition of spontaneous and deliberate facial expressions,\nmulti modal/media human computer interaction and lie detection efforts.\n",
          "  The repeatability and efficiency of a corner detector determines how likely\nit is to be useful in a real-world application. The repeatability is importand\nbecause the same scene viewed from different positions should yield features\nwhich correspond to the same real-world 3D locations [Schmid et al 2000]. The\nefficiency is important because this determines whether the detector combined\nwith further processing can operate at frame rate.\n  Three advances are described in this paper. First, we present a new heuristic\nfor feature detection, and using machine learning we derive a feature detector\nfrom this which can fully process live PAL video using less than 5% of the\navailable processing time. By comparison, most other detectors cannot even\noperate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize\nthe detector, allowing it to be optimized for repeatability, with little loss\nof efficiency. Third, we carry out a rigorous comparison of corner detectors\nbased on the above repeatability criterion applied to 3D scenes. We show that\ndespite being principally constructed for speed, on these stringent tests, our\nheuristic detector significantly outperforms existing feature detectors.\nFinally, the comparison demonstrates that using machine learning produces\nsignificant improvements in repeatability, yielding a detector that is both\nvery fast and very high quality.\n",
          "  This paper proposes a method of gesture recognition with a focus on important\nactions for distinguishing similar gestures. The method generates a partial\naction sequence by using optical flow images, expresses the sequence in the\neigenspace, and checks the feature vector sequence by applying an optimum\npath-searching method of weighted graph to focus the important actions. Also\npresented are the results of an experiment on the recognition of similar sign\nlanguage words.\n",
          "  Recently, Adaboost has been widely used to improve the accuracy of any given\nlearning algorithm. In this paper we focus on designing an algorithm to employ\ncombination of Adaboost with Support Vector Machine as weak component\nclassifiers to be used in Face Detection Task. To obtain a set of effective\nSVM-weaklearner Classifier, this algorithm adaptively adjusts the kernel\nparameter in SVM instead of using a fixed one. Proposed combination outperforms\nin generalization in comparison with SVM on imbalanced classification problem.\nThe proposed here method is compared, in terms of classification accuracy, to\nother commonly used Adaboost methods, such as Decision Trees and Neural\nNetworks, on CMU+MIT face database. Results indicate that the performance of\nthe proposed method is overall superior to previous Adaboost approaches.\n",
          "  We present in this paper a study on the ability and the benefits of using a\nkeystroke dynamics authentication method for collaborative systems.\nAuthentication is a challenging issue in order to guarantee the security of use\nof collaborative systems during the access control step. Many solutions exist\nin the state of the art such as the use of one time passwords or smart-cards.\nWe focus in this paper on biometric based solutions that do not necessitate any\nadditional sensor. Keystroke dynamics is an interesting solution as it uses\nonly the keyboard and is invisible for users. Many methods have been published\nin this field. We make a comparative study of many of them considering the\noperational constraints of use for collaborative systems.\n",
          "  In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is\nproposed which is an extension to the original 2DPCA. We state that the\ncovariance matrix of 2DPCA is equivalent to the average of the main diagonal of\nthe covariance matrix of PCA. This implies that 2DPCA eliminates some\ncovariance information that can be useful for recognition. E2DPCA instead of\njust using the main diagonal considers a radius of r diagonals around it and\nexpands the averaging so as to include the covariance information within those\ndiagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance\nof 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control\nthe trade-offs between recognition accuracy and energy compression (fewer\ncoefficients), and between training and recognition complexity. Experiments on\nORL face database show improvement in both recognition accuracy and recognition\ntime over the original 2DPCA.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "24_recognition_classifiers_classifier",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "24_recognition_classifiers_classifier"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.3978429138660431,
          0.45379701256752014,
          0.5238991975784302,
          0.4349209666252136,
          0.5787941217422485,
          0.47079309821128845,
          0.704231321811676,
          0.5974273085594177,
          0.5117856860160828,
          0.6060417294502258,
          0.44000381231307983,
          0.5825260281562805,
          0.5380752086639404,
          0.5483118295669556,
          4.730892181396484,
          0.43681973218917847,
          0.7847601175308228
         ],
         "y": [
          10.577211380004883,
          9.138999938964844,
          8.842212677001953,
          9.195642471313477,
          8.83304214477539,
          9.139233589172363,
          8.988808631896973,
          8.857587814331055,
          9.119854927062988,
          8.82310962677002,
          9.17406177520752,
          8.828227996826172,
          8.99233341217041,
          8.909096717834473,
          10.024365425109863,
          9.186836242675781,
          9.164414405822754
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  In many real world problems, optimization decisions have to be made with\nlimited information. The decision maker may have no a priori or posteriori data\nabout the often nonconvex objective function except from on a limited number of\npoints that are obtained over time through costly observations. This paper\npresents an optimization framework that takes into account the information\ncollection (observation), estimation (regression), and optimization\n(maximization) aspects in a holistic and structured manner. Explicitly\nquantifying the information acquired at each optimization step using the\nentropy measure from information theory, the (nonconvex) objective function to\nbe optimized (maximized) is modeled and estimated by adopting a Bayesian\napproach and using Gaussian processes as a state-of-the-art regression method.\nThe resulting iterative scheme allows the decision maker to solve the problem\nby expressing preferences for each aspect quantitatively and concurrently.\n",
          "  The decentralized particle filter (DPF) was proposed recently to increase the\nlevel of parallelism of particle filtering. Given a decomposition of the state\nspace into two nested sets of variables, the DPF uses a particle filter to\nsample the first set and then conditions on this sample to generate a set of\nsamples for the second set of variables. The DPF can be understood as a variant\nof the popular Rao-Blackwellized particle filter (RBPF), where the second step\nis carried out using Monte Carlo approximations instead of analytical\ninference. As a result, the range of applications of the DPF is broader than\nthe one for the RBPF. In this paper, we improve the DPF in two ways. First, we\nderive a Monte Carlo approximation of the optimal proposal distribution and,\nconsequently, design and implement a more efficient look-ahead DPF. Although\nthe decentralized filters were initially designed to capitalize on parallel\nimplementation, we show that the look-ahead DPF can outperform the standard\nparticle filter even on a single machine. Second, we propose the use of bandit\nalgorithms to automatically configure the state space decomposition of the DPF.\n",
          "  The ultimate goal of optimization is to find the minimizer of a target\nfunction.However, typical criteria for active optimization often ignore the\nuncertainty about the minimizer. We propose a novel criterion for global\noptimization and an associated sequential active learning strategy using\nGaussian processes.Our criterion is the reduction of uncertainty in the\nposterior distribution of the function minimizer. It can also flexibly\nincorporate multiple global minimizers. We implement a tractable approximation\nof the criterion and demonstrate that it obtains the global minimizer\naccurately compared to conventional Bayesian optimization criteria.\n",
          "  Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm\nthat avoids the random walk behavior and sensitivity to correlated parameters\nthat plague many MCMC methods by taking a series of steps informed by\nfirst-order gradient information. These features allow it to converge to\nhigh-dimensional target distributions much more quickly than simpler methods\nsuch as random walk Metropolis or Gibbs sampling. However, HMC's performance is\nhighly sensitive to two user-specified parameters: a step size {\\epsilon} and a\ndesired number of steps L. In particular, if L is too small then the algorithm\nexhibits undesirable random walk behavior, while if L is too large the\nalgorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an\nextension to HMC that eliminates the need to set a number of steps L. NUTS uses\na recursive algorithm to build a set of likely candidate points that spans a\nwide swath of the target distribution, stopping automatically when it starts to\ndouble back and retrace its steps. Empirically, NUTS perform at least as\nefficiently as and sometimes more efficiently than a well tuned standard HMC\nmethod, without requiring user intervention or costly tuning runs. We also\nderive a method for adapting the step size parameter {\\epsilon} on the fly\nbased on primal-dual averaging. NUTS can thus be used with no hand-tuning at\nall. NUTS is also suitable for applications such as BUGS-style automatic\ninference engines that require efficient \"turnkey\" sampling algorithms.\n",
          "  Bayesian Optimization aims at optimizing an unknown non-convex/concave\nfunction that is costly to evaluate. We are interested in application scenarios\nwhere concurrent function evaluations are possible. Under such a setting, BO\ncould choose to either sequentially evaluate the function, one input at a time\nand wait for the output of the function before making the next selection, or\nevaluate the function at a batch of multiple inputs at once. These two\ndifferent settings are commonly referred to as the sequential and batch\nsettings of Bayesian Optimization. In general, the sequential setting leads to\nbetter optimization performance as each function evaluation is selected with\nmore information, whereas the batch setting has an advantage in terms of the\ntotal experimental time (the number of iterations). In this work, our goal is\nto combine the strength of both settings. Specifically, we systematically\nanalyze Bayesian optimization using Gaussian process as the posterior estimator\nand provide a hybrid algorithm that, based on the current state, dynamically\nswitches between a sequential policy and a batch policy with variable batch\nsizes. We provide theoretical justification for our algorithm and present\nexperimental results on eight benchmark BO problems. The results show that our\nmethod achieves substantial speedup (up to %78) compared to a pure sequential\npolicy, without suffering any significant performance loss.\n",
          "  This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.\n",
          "  An automated technique has recently been proposed to transfer learning in the\nhierarchical Bayesian optimization algorithm (hBOA) based on distance-based\nstatistics. The technique enables practitioners to improve hBOA efficiency by\ncollecting statistics from probabilistic models obtained in previous hBOA runs\nand using the obtained statistics to bias future hBOA runs on similar problems.\nThe purpose of this paper is threefold: (1) test the technique on several\nclasses of NP-complete problems, including MAXSAT, spin glasses and minimum\nvertex cover; (2) demonstrate that the technique is effective even when\nprevious runs were done on problems of different size; (3) provide empirical\nevidence that combining transfer learning with other efficiency enhancement\ntechniques can often yield nearly multiplicative speedups.\n",
          "  Let $\\FF$ be a set of real-valued functions on a set $\\XX$ and let $S:\\FF \\to\n\\GG$ be an arbitrary mapping. We consider the problem of making inference about\n$S(f)$, with $f\\in\\FF$ unknown, from a finite set of pointwise evaluations of\n$f$. We are mainly interested in the problems of approximation and\noptimization. In this article, we make a brief review of results concerning\naverage error bounds of Bayesian search methods that use a random process prior\nabout $f$.\n",
          "  Bayesian optimization with Gaussian processes has become an increasingly\npopular tool in the machine learning community. It is efficient and can be used\nwhen very little is known about the objective function, making it popular in\nexpensive black-box optimization scenarios. It uses Bayesian methods to sample\nthe objective efficiently using an acquisition function which incorporates the\nmodel's estimate of the objective and the uncertainty at any given point.\nHowever, there are several different parameterized acquisition functions in the\nliterature, and it is often unclear which one to use. Instead of using a single\nacquisition function, we adopt a portfolio of acquisition functions governed by\nan online multi-armed bandit strategy. We propose several portfolio strategies,\nthe best of which we call GP-Hedge, and show that this method outperforms the\nbest individual acquisition function. We also provide a theoretical bound on\nthe algorithm's performance.\n",
          "  We present a tutorial on Bayesian optimization, a method of finding the\nmaximum of expensive cost functions. Bayesian optimization employs the Bayesian\ntechnique of setting a prior over the objective function and combining it with\nevidence to get a posterior function. This permits a utility-based selection of\nthe next observation to make on the objective function, which must take into\naccount both exploration (sampling from areas of high uncertainty) and\nexploitation (sampling areas likely to offer improvement over the current best\nobservation). We also present two detailed extensions of Bayesian optimization,\nwith experiments---active user modelling with preferences, and hierarchical\nreinforcement learning---and a discussion of the pros and cons of Bayesian\noptimization based on our experiences.\n",
          "  In many real world problems, control decisions have to be made with limited\ninformation. The controller may have no a priori (or even posteriori) data on\nthe nonlinear system, except from a limited number of points that are obtained\nover time. This is either due to high cost of observation or the highly\nnon-stationary nature of the system. The resulting conflict between information\ncollection (identification, exploration) and control (optimization,\nexploitation) necessitates an active learning approach for iteratively\nselecting the control actions which concurrently provide the data points for\nsystem identification. This paper presents a dual control approach where the\ninformation acquired at each control step is quantified using the entropy\nmeasure from information theory and serves as the training input to a\nstate-of-the-art Gaussian process regression (Bayesian learning) method. The\nexplicit quantification of the information obtained from each data point allows\nfor iterative optimization of both identification and control objectives. The\napproach developed is illustrated with two examples: control of logistic map as\na chaotic system and position control of a cart with inverted pendulum.\n",
          "  We consider the problem of optimizing a real-valued continuous function $f$\nusing a Bayesian approach, where the evaluations of $f$ are chosen sequentially\nby combining prior information about $f$, which is described by a random\nprocess model, and past evaluation results. The main difficulty with this\napproach is to be able to compute the posterior distributions of quantities of\ninterest which are used to choose evaluation points. In this article, we decide\nto use a Sequential Monte Carlo (SMC) approach.\n",
          "  Bayesian optimization (BO) algorithms try to optimize an unknown function\nthat is expensive to evaluate using minimum number of evaluations/experiments.\nMost of the proposed algorithms in BO are sequential, where only one experiment\nis selected at each iteration. This method can be time inefficient when each\nexperiment takes a long time and more than one experiment can be ran\nconcurrently. On the other hand, requesting a fix-sized batch of experiments at\neach iteration causes performance inefficiency in BO compared to the sequential\npolicies. In this paper, we present an algorithm that asks a batch of\nexperiments at each time step t where the batch size p_t is dynamically\ndetermined in each step. Our algorithm is based on the observation that the\nsequence of experiments selected by the sequential policy can sometimes be\nalmost independent from each other. Our algorithm identifies such scenarios and\nrequest those experiments at the same time without degrading the performance.\nWe evaluate our proposed method using the Expected Improvement policy and the\nresults show substantial speedup with little impact on the performance in eight\nreal and synthetic benchmarks.\n",
          "  The scientific method relies on the iterated processes of inference and\ninquiry. The inference phase consists of selecting the most probable models\nbased on the available data; whereas the inquiry phase consists of using what\nis known about the models to select the most relevant experiment. Optimizing\ninquiry involves searching the parameterized space of experiments to select the\nexperiment that promises, on average, to be maximally informative. In the case\nwhere it is important to learn about each of the model parameters, the\nrelevance of an experiment is quantified by Shannon entropy of the distribution\nof experimental outcomes predicted by a probable set of models. If the set of\npotential experiments is described by many parameters, we must search this\nhigh-dimensional entropy space. Brute force search methods will be slow and\ncomputationally expensive. We present an entropy-based search algorithm, called\nnested entropy sampling, to select the most informative experiment for\nefficient experimental design. This algorithm is inspired by Skilling's nested\nsampling algorithm used in inference and borrows the concept of a rising\nthreshold while a set of experiment samples are maintained. We demonstrate that\nthis algorithm not only selects highly relevant experiments, but also is more\nefficient than brute force search. Such entropic search techniques promise to\ngreatly benefit autonomous experimental design.\n",
          "  The problem of optimizing unknown costly-to-evaluate functions has been\nstudied for a long time in the context of Bayesian Optimization. Algorithms in\nthis field aim to find the optimizer of the function by asking only a few\nfunction evaluations at locations carefully selected based on a posterior\nmodel. In this paper, we assume the unknown function is Lipschitz continuous.\nLeveraging the Lipschitz property, we propose an algorithm with a distinct\nexploration phase followed by an exploitation phase. The exploration phase aims\nto select samples that shrink the search space as much as possible. The\nexploitation phase then focuses on the reduced search space and selects samples\nclosest to the optimizer. Considering the Expected Improvement (EI) as a\nbaseline, we empirically show that the proposed algorithm significantly\noutperforms EI.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "25_optimizing_optimizer_optimization",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "25_optimizing_optimizer_optimization"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.870360374450684,
          5.785421848297119,
          5.62811279296875,
          5.8385186195373535,
          5.862607479095459,
          5.757737159729004,
          5.873133182525635,
          5.911705017089844,
          5.996664047241211,
          5.907702922821045,
          6.047971725463867,
          5.852331638336182,
          5.809177875518799,
          5.694760322570801,
          5.839358329772949,
          5.845037937164307
         ],
         "y": [
          6.592898368835449,
          6.726591110229492,
          6.615250587463379,
          6.824734210968018,
          6.729942798614502,
          6.873385429382324,
          6.722469806671143,
          6.785924434661865,
          6.828400611877441,
          6.71359920501709,
          6.423325538635254,
          6.717774391174316,
          6.73556661605835,
          6.749999046325684,
          6.755796909332275,
          6.719710826873779
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  The LETOR website contains three information retrieval datasets used as a\nbenchmark for testing machine learning ideas for ranking. Algorithms\nparticipating in the challenge are required to assign score values to search\nresults for a collection of queries, and are measured using standard IR ranking\nmeasures (NDCG, precision, MAP) that depend only the relative score-induced\norder of the results. Similarly to many of the ideas proposed in the\nparticipating algorithms, we train a linear classifier. In contrast with other\nparticipating algorithms, we define an additional free variable (intercept, or\nbenchmark) for each query. This allows expressing the fact that results for\ndifferent queries are incomparable for the purpose of determining relevance.\nThe cost of this idea is the addition of relatively few nuisance parameters.\nOur approach is simple, and we used a standard logistic regression library to\ntest it. The results beat the reported participating algorithms. Hence, it\nseems promising to combine our approach with other more complex ideas.\n",
          "  There are many applications in which it is desirable to order rather than\nclassify instances. Here we consider the problem of learning how to order\ninstances given feedback in the form of preference judgments, i.e., statements\nto the effect that one instance should be ranked ahead of another. We outline a\ntwo-stage approach in which one first learns by conventional means a binary\npreference function indicating whether it is advisable to rank one instance\nbefore another. Here we consider an on-line algorithm for learning preference\nfunctions that is based on Freund and Schapire's 'Hedge' algorithm. In the\nsecond stage, new instances are ordered so as to maximize agreement with the\nlearned preference function. We show that the problem of finding the ordering\nthat agrees best with a learned preference function is NP-complete.\nNevertheless, we describe simple greedy algorithms that are guaranteed to find\na good approximation. Finally, we show how metasearch can be formulated as an\nordering problem, and present experimental results on learning a combination of\n'search experts', each of which is a domain-specific query expansion strategy\nfor a web search engine.\n",
          "  We present a family of pairwise tournaments reducing $k$-class classification\nto binary classification. These reductions are provably robust against a\nconstant fraction of binary errors. The results improve on the PECOC\nconstruction \\cite{SECOC} with an exponential improvement in computation, from\n$O(k)$ to $O(\\log_2 k)$, and the removal of a square root in the regret\ndependence, matching the best possible computation and regret up to a constant.\n",
          "  This paper describes an efficient reduction of the learning problem of\nranking to binary classification. The reduction guarantees an average pairwise\nmisranking regret of at most that of the binary classifier regret, improving a\nrecent result of Balcan et al which only guarantees a factor of 2. Moreover,\nour reduction applies to a broader class of ranking loss functions, admits a\nsimpler proof, and the expected running time complexity of our algorithm in\nterms of number of calls to a classifier or preference function is improved\nfrom $\\Omega(n^2)$ to $O(n \\log n)$. In addition, when the top $k$ ranked\nelements only are required ($k \\ll n$), as in many applications in information\nextraction or search engines, the time complexity of our algorithm can be\nfurther reduced to $O(k \\log k + n)$. Our reduction and algorithm are thus\npractical for realistic applications where the number of points to rank exceeds\nseveral thousands. Much of our results also extend beyond the bipartite case\npreviously studied.\n  Our rediction is a randomized one. To complement our result, we also derive\nlower bounds on any deterministic reduction from binary (preference)\nclassification to ranking, implying that our use of a randomized reduction is\nessentially necessary for the guarantees we provide.\n",
          "  Traditional machine-learned ranking systems for web search are often trained\nto capture stationary relevance of documents to queries, which has limited\nability to track non-stationary user intention in a timely manner. In recency\nsearch, for instance, the relevance of documents to a query on breaking news\noften changes significantly over time, requiring effective adaptation to user\nintention. In this paper, we focus on recency search and study a number of\nalgorithms to improve ranking results by leveraging user click feedback. Our\ncontributions are three-fold. First, we use real search sessions collected in a\nrandom exploration bucket for \\emph{reliable} offline evaluation of these\nalgorithms, which provides an unbiased comparison across algorithms without\nonline bucket tests. Second, we propose a re-ranking approach to improve search\nresults for recency queries using user clicks. Third, our empirical comparison\nof a dozen algorithms on real-life search data suggests importance of a few\nalgorithmic choices in these applications, including generalization across\ndifferent query-document pairs, specialization to popular queries, and\nreal-time adaptation of user clicks.\n",
          "  Representing distributions over permutations can be a daunting task due to\nthe fact that the number of permutations of $n$ objects scales factorially in\n$n$. One recent way that has been used to reduce storage complexity has been to\nexploit probabilistic independence, but as we argue, full independence\nassumptions impose strong sparsity constraints on distributions and are\nunsuitable for modeling rankings. We identify a novel class of independence\nstructures, called \\emph{riffled independence}, encompassing a more expressive\nfamily of distributions while retaining many of the properties necessary for\nperforming efficient inference and reducing sample complexity. In riffled\nindependence, one draws two permutations independently, then performs the\n\\emph{riffle shuffle}, common in card games, to combine the two permutations to\nform a single permutation. Within the context of ranking, riffled independence\ncorresponds to ranking disjoint sets of objects independently, then\ninterleaving those rankings. In this paper, we provide a formal introduction to\nriffled independence and present algorithms for using riffled independence\nwithin Fourier-theoretic frameworks which have been explored by a number of\nrecent papers. Additionally, we propose an automated method for discovering\nsets of items which are riffle independent from a training set of rankings. We\nshow that our clustering-like algorithms can be used to discover meaningful\nlatent coalitions from real preference ranking datasets and to learn the\nstructure of hierarchically decomposable models based on riffled independence.\n",
          "  The Probability Ranking Principle states that the document set with the\nhighest values of probability of relevance optimizes information retrieval\neffectiveness given the probabilities are estimated as accurately as possible.\nThe key point of the principle is the separation of the document set into two\nsubsets with a given level of fallout and with the highest recall. The paper\nintroduces the separation between two vector subspaces and shows that the\nseparation yields a more effective performance than the optimal separation into\nsubsets with the same available evidence, the performance being measured with\nrecall and fallout. The result is proved mathematically and exemplified\nexperimentally.\n",
          "  In this paper we analyze judgement aggregation problems in which a group of\nagents independently votes on a set of complex propositions that has some\ninterdependency constraint between them(e.g., transitivity when describing\npreferences). We consider the issue of judgement aggregation from the\nperspective of approximation. That is, we generalize the previous results by\nstudying approximate judgement aggregation. We relax the main two constraints\nassumed in the current literature, Consistency and Independence and consider\nmechanisms that only approximately satisfy these constraints, that is, satisfy\nthem up to a small portion of the inputs. The main question we raise is whether\nthe relaxation of these notions significantly alters the class of satisfying\naggregation mechanisms. The recent works for preference aggregation of Kalai,\nMossel, and Keller fit into this framework. The main result of this paper is\nthat, as in the case of preference aggregation, in the case of a subclass of a\nnatural class of aggregation problems termed `truth-functional agendas', the\nset of satisfying aggregation mechanisms does not extend non-trivially when\nrelaxing the constraints. Our proof techniques involve Boolean Fourier\ntransform and analysis of voter influences for voting protocols. The question\nwe raise for Approximate Aggregation can be stated in terms of Property\nTesting. For instance, as a corollary from our result we get a generalization\nof the classic result for property testing of linearity of Boolean functions.\n  An updated version (RePEc:huj:dispap:dp574R) is available at\nhttp://www.ratio.huji.ac.il/dp_files/dp574R.pdf\n",
          "  Given a set of alternatives to be ranked, and some pairwise comparison data,\nranking is a least squares computation on a graph. The vertices are the\nalternatives, and the edge values comprise the comparison data. The basic idea\nis very simple and old: come up with values on vertices such that their\ndifferences match the given edge data. Since an exact match will usually be\nimpossible, one settles for matching in a least squares sense. This formulation\nwas first described by Leake in 1976 for rankingfootball teams and appears as\nan example in Professor Gilbert Strang's classic linear algebra textbook. If\none is willing to look into the residual a little further, then the problem\nreally comes alive, as shown effectively by the remarkable recent paper of\nJiang et al. With or without this twist, the humble least squares problem on\ngraphs has far-reaching connections with many current areas ofresearch. These\nconnections are to theoretical computer science (spectral graph theory, and\nmultilevel methods for graph Laplacian systems); numerical analysis (algebraic\nmultigrid, and finite element exterior calculus); other mathematics (Hodge\ndecomposition, and random clique complexes); and applications (arbitrage, and\nranking of sports teams). Not all of these connections are explored in this\npaper, but many are. The underlying ideas are easy to explain, requiring only\nthe four fundamental subspaces from elementary linear algebra. One of our aims\nis to explain these basic ideas and connections, to get researchers in many\nfields interested in this topic. Another aim is to use our numerical\nexperiments for guidance on selecting methods and exposing the need for further\ndevelopment.\n",
          "  We consider the predictive problem of supervised ranking, where the task is\nto rank sets of candidate items returned in response to queries. Although there\nexist statistical procedures that come with guarantees of consistency in this\nsetting, these procedures require that individuals provide a complete ranking\nof all items, which is rarely feasible in practice. Instead, individuals\nroutinely provide partial preference information, such as pairwise comparisons\nof items, and more practical approaches to ranking have aimed at modeling this\npartial preference data directly. As we show, however, such an approach raises\nserious theoretical challenges. Indeed, we demonstrate that many commonly used\nsurrogate losses for pairwise comparison data do not yield consistency;\nsurprisingly, we show inconsistency even in low-noise settings. With these\nnegative results as motivation, we present a new approach to supervised ranking\nbased on aggregation of partial preferences, and we develop $U$-statistic-based\nempirical risk minimization procedures. We present an asymptotic analysis of\nthese new procedures, showing that they yield consistency results that parallel\nthose available for classification. We complement our theoretical results with\nan experiment studying the new procedures in a large-scale web-ranking task.\n",
          "  This paper examines the problem of ranking a collection of objects using\npairwise comparisons (rankings of two objects). In general, the ranking of $n$\nobjects can be identified by standard sorting methods using $n log_2 n$\npairwise comparisons. We are interested in natural situations in which\nrelationships among the objects may allow for ranking using far fewer pairwise\ncomparisons. Specifically, we assume that the objects can be embedded into a\n$d$-dimensional Euclidean space and that the rankings reflect their relative\ndistances from a common reference point in $R^d$. We show that under this\nassumption the number of possible rankings grows like $n^{2d}$ and demonstrate\nan algorithm that can identify a randomly selected ranking using just slightly\nmore than $d log n$ adaptively selected pairwise comparisons, on average. If\ninstead the comparisons are chosen at random, then almost all pairwise\ncomparisons must be made in order to identify any ranking. In addition, we\npropose a robust, error-tolerant algorithm that only requires that the pairwise\ncomparisons are probably correct. Experimental studies with synthetic and real\ndatasets support the conclusions of our theoretical analysis.\n",
          "  It is of increasing importance to develop learning methods for ranking. In\ncontrast to many learning objectives, however, the ranking problem presents\ndifficulties due to the fact that the space of permutations is not smooth. In\nthis paper, we examine the class of rank-linear objective functions, which\nincludes popular metrics such as precision and discounted cumulative gain. In\nparticular, we observe that expectations of these gains are completely\ncharacterized by the marginals of the corresponding distribution over\npermutation matrices. Thus, the expectations of rank-linear objectives can\nalways be described through locations in the Birkhoff polytope, i.e.,\ndoubly-stochastic matrices (DSMs). We propose a technique for learning\nDSM-based ranking functions using an iterative projection operator known as\nSinkhorn normalization. Gradients of this operator can be computed via\nbackpropagation, resulting in an algorithm we call Sinkhorn propagation, or\nSinkProp. This approach can be combined with a wide range of gradient-based\napproaches to rank learning. We demonstrate the utility of SinkProp on several\ninformation retrieval data sets.\n",
          "  Most learning to rank research has assumed that the utility of different\ndocuments is independent, which results in learned ranking functions that\nreturn redundant results. The few approaches that avoid this have rather\nunsatisfyingly lacked theoretical foundations, or do not scale. We present a\nlearning-to-rank formulation that optimizes the fraction of satisfied users,\nwith several scalable algorithms that explicitly takes document similarity and\nranking context into account. Our formulation is a non-trivial common\ngeneralization of two multi-armed bandit models from the literature: \"ranked\nbandits\" (Radlinski et al., ICML 2008) and \"Lipschitz bandits\" (Kleinberg et\nal., STOC 2008). We present theoretical justifications for this approach, as\nwell as a near-optimal algorithm. Our evaluation adds optimizations that\nimprove empirical performance, and shows that our algorithms learn orders of\nmagnitude more quickly than previous approaches.\n",
          "  We propose a new online learning model for learning with preference feedback.\nThe model is especially suited for applications like web search and recommender\nsystems, where preference data is readily available from implicit user feedback\n(e.g. clicks). In particular, at each time step a potentially structured object\n(e.g. a ranking) is presented to the user in response to a context (e.g.\nquery), providing him or her with some unobserved amount of utility. As\nfeedback the algorithm receives an improved object that would have provided\nhigher utility. We propose a learning algorithm with provable regret bounds for\nthis online learning setting and demonstrate its effectiveness on a web-search\napplication. The new learning model also applies to many other interactive\nlearning problems and admits several interesting extensions.\n",
          "  Search engines today present results that are often oblivious to abrupt\nshifts in intent. For example, the query `independence day' usually refers to a\nUS holiday, but the intent of this query abruptly changed during the release of\na major film by that name. While no studies exactly quantify the magnitude of\nintent-shifting traffic, studies suggest that news events, seasonal topics, pop\nculture, etc account for 50% of all search queries. This paper shows that the\nsignals a search engine receives can be used to both determine that a shift in\nintent has happened, as well as find a result that is now more relevant. We\npresent a meta-algorithm that marries a classifier with a bandit algorithm to\nachieve regret that depends logarithmically on the number of query impressions,\nunder certain assumptions. We provide strong evidence that this regret is close\nto the best achievable. Finally, via a series of experiments, we demonstrate\nthat our algorithm outperforms prior approaches, particularly as the amount of\nintent-shifting traffic increases.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "26_ranking_rankings_ranked",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "26_ranking_rankings_ranked"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.854522705078125,
          5.882863521575928,
          5.730886936187744,
          5.79575252532959,
          6.0114545822143555,
          5.731719017028809,
          5.8192548751831055,
          5.788817882537842,
          5.668906211853027,
          5.79074764251709,
          5.693554401397705,
          5.783138275146484,
          5.983285427093506,
          5.987175941467285,
          6.100775718688965,
          5.84152364730835
         ],
         "y": [
          7.717871189117432,
          7.789455890655518,
          7.900020599365234,
          7.795391082763672,
          7.828886032104492,
          7.735511779785156,
          7.631513595581055,
          7.717285633087158,
          7.794827461242676,
          7.763814926147461,
          7.776857376098633,
          7.811523914337158,
          7.72700834274292,
          7.805413246154785,
          7.893370151519775,
          7.779250144958496
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Directed acyclic graphs (DAGs) are a popular framework to express\nmultivariate probability distributions. Acyclic directed mixed graphs (ADMGs)\nare generalizations of DAGs that can succinctly capture much richer sets of\nconditional independencies, and are especially useful in modeling the effects\nof latent variables implicitly. Unfortunately there are currently no good\nparameterizations of general ADMGs. In this paper, we apply recent work on\ncumulative distribution networks and copulas to propose one one general\nconstruction for ADMG models. We consider a simple parameter estimation\napproach, and report some encouraging experimental results.\n",
          "  We present some nonparametric methods for graphical modeling. In the discrete\ncase, where the data are binary or drawn from a finite alphabet, Markov random\nfields are already essentially nonparametric, since the cliques can take only a\nfinite number of values. Continuous data are different. The Gaussian graphical\nmodel is the standard parametric model for continuous data, but it makes\ndistributional assumptions that are often unrealistic. We discuss two\napproaches to building more flexible graphical models. One allows arbitrary\ngraphs and a nonparametric extension of the Gaussian; the other uses kernel\ndensity estimation and restricts the graphs to trees and forests. Examples of\nboth methods are presented. We also discuss possible future research directions\nfor nonparametric graphical modeling.\n",
          "  Probabilistic inference in graphical models is the task of computing marginal\nand conditional densities of interest from a factorized representation of a\njoint probability distribution. Inference algorithms such as variable\nelimination and belief propagation take advantage of constraints embedded in\nthis factorization to compute such densities efficiently. In this paper, we\npropose an algorithm which computes interventional distributions in latent\nvariable causal models represented by acyclic directed mixed graphs(ADMGs). To\ncompute these distributions efficiently, we take advantage of a recursive\nfactorization which generalizes the usual Markov factorization for DAGs and the\nmore recent factorization for ADMGs. Our algorithm can be viewed as a\ngeneralization of variable elimination to the mixed graph case. We show our\nalgorithm is exponential in the mixed graph generalization of treewidth.\n",
          "  Probabilistic graphical models (PGMs) have become a popular tool for\ncomputational analysis of biological data in a variety of domains. But, what\nexactly are they and how do they work? How can we use PGMs to discover patterns\nthat are biologically relevant? And to what extent can PGMs help us formulate\nnew hypotheses that are testable at the bench? This note sketches out some\nanswers and illustrates the main ideas behind the statistical approach to\nbiological pattern discovery.\n",
          "  We consider learning continuous probabilistic graphical models in the face of\nmissing data. For non-Gaussian models, learning the parameters and structure of\nsuch models depends on our ability to perform efficient inference, and can be\nprohibitive even for relatively modest domains. Recently, we introduced the\nCopula Bayesian Network (CBN) density model - a flexible framework that\ncaptures complex high-dimensional dependency structures while offering direct\ncontrol over the univariate marginals, leading to improved generalization. In\nthis work we show that the CBN model also offers significant computational\nadvantages when training data is partially observed. Concretely, we leverage on\nthe specialized form of the model to derive a computationally amenable learning\nobjective that is a lower bound on the log-likelihood function. Importantly,\nour energy-like bound circumvents the need for costly inference of an auxiliary\ndistribution, thus facilitating practical learning of highdimensional\ndensities. We demonstrate the effectiveness of our approach for learning the\nstructure and parameters of a CBN model for two reallife continuous domains.\n",
          "  We analyse the potential of Gibbs Random Fields for shape prior modelling. We\nshow that the expressive power of second order GRFs is already sufficient to\nexpress simple shapes and spatial relations between them simultaneously. This\nallows to model and recognise complex shapes as spatial compositions of simpler\nparts.\n",
          "  Probabilistic graphical models combine the graph theory and probability\ntheory to give a multivariate statistical modeling. They provide a unified\ndescription of uncertainty using probability and complexity using the graphical\nmodel. Especially, graphical models provide the following several useful\nproperties:\n  - Graphical models provide a simple and intuitive interpretation of the\nstructures of probabilistic models. On the other hand, they can be used to\ndesign and motivate new models.\n  - Graphical models provide additional insights into the properties of the\nmodel, including the conditional independence properties.\n  - Complex computations which are required to perform inference and learning\nin sophisticated models can be expressed in terms of graphical manipulations,\nin which the underlying mathematical expressions are carried along implicitly.\n  The graphical models have been applied to a large number of fields, including\nbioinformatics, social science, control theory, image processing, marketing\nanalysis, among others. However, structure learning for graphical models\nremains an open challenge, since one must cope with a combinatorial search over\nthe space of all possible structures.\n  In this paper, we present a comprehensive survey of the existing structure\nlearning algorithms.\n",
          "  Structure learning of Gaussian graphical models is an extensively studied\nproblem in the classical multivariate setting where the sample size n is larger\nthan the number of random variables p, as well as in the more challenging\nsetting when p>>n. However, analogous approaches for learning the structure of\ngraphical models with mixed discrete and continuous variables when p>>n remain\nlargely unexplored. Here we describe a statistical learning procedure for this\nproblem based on limited-order correlations and assess its performance with\nsynthetic and real data.\n",
          "  Dependence strucuture estimation is one of the important problems in machine\nlearning domain and has many applications in different scientific areas. In\nthis paper, a theoretical framework for such estimation based on copula and\ncopula entropy -- the probabilistic theory of representation and measurement of\nstatistical dependence, is proposed. Graphical models are considered as a\nspecial case of the copula framework. A method of the framework for estimating\nmaximum spanning copula is proposed. Due to copula, the method is irrelevant to\nthe properties of individual variables, insensitive to outlier and able to deal\nwith non-Gaussianity. Experiments on both simulated data and real dataset\ndemonstrated the effectiveness of the proposed method.\n",
          "  We present a new Markov chain Monte Carlo method for estimating posterior\nprobabilities of structural features in Bayesian networks. The method draws\nsamples from the posterior distribution of partial orders on the nodes; for\neach sampled partial order, the conditional probabilities of interest are\ncomputed exactly. We give both analytical and empirical results that suggest\nthe superiority of the new method compared to previous methods, which sample\neither directed acyclic graphs or linear orders on the nodes.\n",
          "  We show that the log-likelihood of several probabilistic graphical models is\nLipschitz continuous with respect to the lp-norm of the parameters. We discuss\nseveral implications of Lipschitz parametrization. We present an upper bound of\nthe Kullback-Leibler divergence that allows understanding methods that penalize\nthe lp-norm of differences of parameters as the minimization of that upper\nbound. The expected log-likelihood is lower bounded by the negative lp-norm,\nwhich allows understanding the generalization ability of probabilistic models.\nThe exponential of the negative lp-norm is involved in the lower bound of the\nBayes error rate, which shows that it is reasonable to use parameters as\nfeatures in algorithms that rely on metric spaces (e.g. classification,\ndimensionality reduction, clustering). Our results do not rely on specific\nalgorithms for learning the structure or parameters. We show preliminary\nresults for activity recognition and temporal segmentation.\n",
          "  We consider unsupervised estimation of mixtures of discrete graphical models,\nwhere the class variable corresponding to the mixture components is hidden and\neach mixture component over the observed variables can have a potentially\ndifferent Markov graph structure and parameters. We propose a novel approach\nfor estimating the mixture components, and our output is a tree-mixture model\nwhich serves as a good approximation to the underlying graphical model mixture.\nOur method is efficient when the union graph, which is the union of the Markov\ngraphs of the mixture components, has sparse vertex separators between any pair\nof observed variables. This includes tree mixtures and mixtures of bounded\ndegree graphs. For such models, we prove that our method correctly recovers the\nunion graph structure and the tree structures corresponding to\nmaximum-likelihood tree approximations of the mixture components. The sample\nand computational complexities of our method scale as $\\poly(p, r)$, for an\n$r$-component mixture of $p$-variate graphical models. We further extend our\nresults to the case when the union graph has sparse local separators between\nany pair of observed variables, such as mixtures of locally tree-like graphs,\nand the mixture components are in the regime of correlation decay.\n",
          "  Heavy-tailed distributions naturally occur in many real life problems.\nUnfortunately, it is typically not possible to compute inference in closed-form\nin graphical models which involve such heavy-tailed distributions.\n  In this work, we propose a novel simple linear graphical model for\nindependent latent random variables, called linear characteristic model (LCM),\ndefined in the characteristic function domain. Using stable distributions, a\nheavy-tailed family of distributions which is a generalization of Cauchy,\nL\\'evy and Gaussian distributions, we show for the first time, how to compute\nboth exact and approximate inference in such a linear multivariate graphical\nmodel. LCMs are not limited to stable distributions, in fact LCMs are always\ndefined for any random variables (discrete, continuous or a mixture of both).\n  We provide a realistic problem from the field of computer networks to\ndemonstrate the applicability of our construction. Other potential application\nis iterative decoding of linear channels with non-Gaussian noise.\n",
          "  This work considers the problem of learning the structure of multivariate\nlinear tree models, which include a variety of directed tree graphical models\nwith continuous, discrete, and mixed latent variables such as linear-Gaussian\nmodels, hidden Markov models, Gaussian mixture models, and Markov evolutionary\ntrees. The setting is one where we only have samples from certain observed\nvariables in the tree, and our goal is to estimate the tree structure (i.e.,\nthe graph of how the underlying hidden variables are connected to each other\nand to the observed variables). We propose the Spectral Recursive Grouping\nalgorithm, an efficient and simple bottom-up procedure for recovering the tree\nstructure from independent samples of the observed variables. Our finite sample\nsize bounds for exact recovery of the tree structure reveal certain natural\ndependencies on underlying statistical and structural properties of the\nunderlying joint distribution. Furthermore, our sample complexity guarantees\nhave no explicit dependence on the dimensionality of the observed variables,\nmaking the algorithm applicable to many high-dimensional settings. At the heart\nof our algorithm is a spectral quartet test for determining the relative\ntopology of a quartet of variables from second-order statistics.\n",
          "  In undirected graphical models, learning the graph structure and learning the\nfunctions that relate the predictive variables (features) to the responses\ngiven the structure are two topics that have been widely investigated in\nmachine learning and statistics. Learning graphical models in two stages will\nhave problems because graph structure may change after considering the\nfeatures. The main contribution of this paper is the proposed method that\nlearns the graph structure and functions on the graph at the same time. General\ngraphical models with binary outcomes conditioned on predictive variables are\nproved to be equivalent to multivariate Bernoulli model. The reparameterization\nof the potential functions in graphical model by conditional log odds ratios in\nmultivariate Bernoulli model offers advantage in the representation of the\nconditional independence structure in the model. Additionally, we impose a\nstructure penalty on groups of conditional log odds ratios to learn the graph\nstructure. These groups of functions are designed with overlaps to enforce\nhierarchical function selection. In this way, we are able to shrink higher\norder interactions to obtain a sparse graph structure. Simulation studies show\nthat the method is able to recover the graph structure. The analysis of county\ndata from Census Bureau gives interesting relations between unemployment rate,\ncrime and others discovered by the model.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "27_graphs_probabilistic_models",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "27_graphs_probabilistic_models"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.666890859603882,
          2.6478865146636963,
          2.5606884956359863,
          2.5442676544189453,
          2.73045015335083,
          2.6137170791625977,
          2.6592841148376465,
          2.5971031188964844,
          2.6596546173095703,
          2.932774066925049,
          2.7367191314697266,
          2.5262913703918457,
          2.648937940597534,
          2.557659387588501,
          2.5920472145080566,
          2.644958019256592
         ],
         "y": [
          5.07190465927124,
          5.154736042022705,
          5.001327991485596,
          5.175924301147461,
          5.133289813995361,
          5.3205885887146,
          5.181026935577393,
          5.15471887588501,
          5.077853202819824,
          5.258572101593018,
          5.230452537536621,
          5.342244625091553,
          5.160089015960693,
          5.335419654846191,
          5.15747594833374,
          5.183708190917969
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Suppose the signal x is realized by driving a k-sparse signal u through an\narbitrary unknown stable discrete-linear time invariant system H. These types\nof processes arise naturally in Reflection Seismology. In this paper we are\ninterested in several problems: (a) Blind-Deconvolution: Can we recover both\nthe filter $H$ and the sparse signal $u$ from noisy measurements? (b)\nCompressive Sensing: Is x compressible in the conventional sense of compressed\nsensing? Namely, can x, u and H be reconstructed from a sparse set of\nmeasurements. We develop novel L1 minimization methods to solve both cases and\nestablish sufficient conditions for exact recovery for the case when the\nunknown system H is auto-regressive (i.e. all pole) of a known order. In the\ncompressed sensing/sampling setting it turns out that both H and x can be\nreconstructed from O(k log(n)) measurements under certain technical conditions\non the support structure of u. Our main idea is to pass x through a linear time\ninvariant system G and collect O(k log(n)) sequential measurements. The filter\nG is chosen suitably, namely, its associated Toeplitz matrix satisfies the RIP\nproperty. We develop a novel LP optimization algorithm and show that both the\nunknown filter H and the sparse input u can be reliably estimated.\n",
          "  We consider a system of m linear equations in n variables Ax=b where A is a\ngiven m x n matrix and b is a given m-vector known to be equal to Ax' for some\nunknown solution x' that is integer and k-sparse: x' in {0,1}^n and exactly k\nentries of x' are 1. We give necessary and sufficient conditions for recovering\nthe solution x exactly using an LP relaxation that minimizes l1 norm of x. When\nA is drawn from a distribution that has exchangeable columns, we show an\ninteresting connection between the recovery probability and a well known\nproblem in geometry, namely the k-set problem. To the best of our knowledge,\nthis connection appears to be new in the compressive sensing literature. We\nempirically show that for large n if the elements of A are drawn i.i.d. from\nthe normal distribution then the performance of the recovery LP exhibits a\nphase transition, i.e., for each k there exists a value m' of m such that the\nrecovery always succeeds if m > m' and always fails if m < m'. Using the\nempirical data we conjecture that m' = nH(k/n)/2 where H(x) = -(x)log_2(x) -\n(1-x)log_2(1-x) is the binary entropy function.\n",
          "  In this paper we present a linear programming solution for sign pattern\nrecovery of a sparse signal from noisy random projections of the signal. We\nconsider two types of noise models, input noise, where noise enters before the\nrandom projection; and output noise, where noise enters after the random\nprojection. Sign pattern recovery involves the estimation of sign pattern of a\nsparse signal. Our idea is to pretend that no noise exists and solve the\nnoiseless $\\ell_1$ problem, namely, $\\min \\|\\beta\\|_1 ~ s.t. ~ y=G \\beta$ and\nquantizing the resulting solution. We show that the quantized solution\nperfectly reconstructs the sign pattern of a sufficiently sparse signal.\nSpecifically, we show that the sign pattern of an arbitrary k-sparse,\nn-dimensional signal $x$ can be recovered with $SNR=\\Omega(\\log n)$ and\nmeasurements scaling as $m= \\Omega(k \\log{n/k})$ for all sparsity levels $k$\nsatisfying $0< k \\leq \\alpha n$, where $\\alpha$ is a sufficiently small\npositive constant. Surprisingly, this bound matches the optimal\n\\emph{Max-Likelihood} performance bounds in terms of $SNR$, required number of\nmeasurements, and admissible sparsity level in an order-wise sense. In contrast\nto our results, previous results based on LASSO and Max-Correlation techniques\neither assume significantly larger $SNR$, sublinear sparsity levels or\nrestrictive assumptions on signal sets. Our proof technique is based on noisy\nperturbation of the noiseless $\\ell_1$ problem, in that, we estimate the\nmaximum admissible noise level before sign pattern recovery fails.\n",
          "  Approximate message passing algorithms proved to be extremely effective in\nreconstructing sparse signals from a small number of incoherent linear\nmeasurements. Extensive numerical experiments further showed that their\ndynamics is accurately tracked by a simple one-dimensional iteration termed\nstate evolution. In this paper we provide the first rigorous foundation to\nstate evolution. We prove that indeed it holds asymptotically in the large\nsystem limit for sensing matrices with independent and identically distributed\ngaussian entries.\n  While our focus is on message passing algorithms for compressed sensing, the\nanalysis extends beyond this setting, to a general class of algorithms on dense\ngraphs. In this context, state evolution plays the role that density evolution\nhas for sparse graphs.\n  The proof technique is fundamentally different from the standard approach to\ndensity evolution, in that it copes with large number of short loops in the\nunderlying factor graph. It relies instead on a conditioning technique recently\ndeveloped by Erwin Bolthausen in the context of spin glass theory.\n",
          "  One of the key challenges in sensor networks is the extraction of information\nby fusing data from a multitude of distinct, but possibly unreliable sensors.\nRecovering information from the maximum number of dependable sensors while\nspecifying the unreliable ones is critical for robust sensing. This sensing\ntask is formulated here as that of finding the maximum number of feasible\nsubsystems of linear equations, and proved to be NP-hard. Useful links are\nestablished with compressive sampling, which aims at recovering vectors that\nare sparse. In contrast, the signals here are not sparse, but give rise to\nsparse residuals. Capitalizing on this form of sparsity, four sensing schemes\nwith complementary strengths are developed. The first scheme is a convex\nrelaxation of the original problem expressed as a second-order cone program\n(SOCP). It is shown that when the involved sensing matrices are Gaussian and\nthe reliable measurements are sufficiently many, the SOCP can recover the\noptimal solution with overwhelming probability. The second scheme is obtained\nby replacing the initial objective function with a concave one. The third and\nfourth schemes are tailored for noisy sensor data. The noisy case is cast as a\ncombinatorial problem that is subsequently surrogated by a (weighted) SOCP.\nInterestingly, the derived cost functions fall into the framework of robust\nmultivariate linear regression, while an efficient block-coordinate descent\nalgorithm is developed for their minimization. The robust sensing capabilities\nof all schemes are verified by simulated tests.\n",
          "  Recovering intrinsic data structure from corrupted observations plays an\nimportant role in various tasks in the communities of machine learning and\nsignal processing. In this paper, we propose a novel model, named log-sum\nheuristic recovery (LHR), to learn the essential low-rank structure from\ncorrupted data. Different from traditional approaches, which directly utilize\n$\\ell_1$ norm to measure the sparseness, LHR introduces a more reasonable\nlog-sum measurement to enhance the sparsity in both the intrinsic low-rank\nstructure and in the sparse corruptions. Although the proposed LHR optimization\nis no longer convex, it still can be effectively solved by a\nmajorization-minimization (MM) type algorithm, with which the non-convex\nobjective function is iteratively replaced by its convex surrogate and LHR\nfinally falls into the general framework of reweighed approaches. We prove that\nthe MM-type algorithm can converge to a stationary point after successive\niteration. We test the performance of our proposed model by applying it to\nsolve two typical problems: robust principal component analysis (RPCA) and\nlow-rank representation (LRR).\n  For RPCA, we compare LHR with the benchmark Principal Component Pursuit (PCP)\nmethod from both the perspectives of simulations and practical applications.\nFor LRR, we apply LHR to compute the low-rank representation matrix for motion\nsegmentation and stock clustering. Experimental results on low rank structure\nlearning demonstrate that the proposed Log-sum based model performs much better\nthan the $\\ell_1$-based method on for data with higher rank and with denser\ncorruptions.\n",
          "  Standard compressive sensing results state that to exactly recover an s\nsparse signal in R^p, one requires O(s. log(p)) measurements. While this bound\nis extremely useful in practice, often real world signals are not only sparse,\nbut also exhibit structure in the sparsity pattern. We focus on\ngroup-structured patterns in this paper. Under this model, groups of signal\ncoefficients are active (or inactive) together. The groups are predefined, but\nthe particular set of groups that are active (i.e., in the signal support) must\nbe learned from measurements. We show that exploiting knowledge of groups can\nfurther reduce the number of measurements required for exact signal recovery,\nand derive universal bounds for the number of measurements needed. The bound is\nuniversal in the sense that it only depends on the number of groups under\nconsideration, and not the particulars of the groups (e.g., compositions,\nsizes, extents, overlaps, etc.). Experiments show that our result holds for a\nvariety of overlapping group configurations.\n",
          "  This article considers constrained $\\ell_1$ minimization methods for the\nrecovery of high dimensional sparse signals in three settings: noiseless,\nbounded error and Gaussian noise. A unified and elementary treatment is given\nin these noise settings for two $\\ell_1$ minimization methods: the Dantzig\nselector and $\\ell_1$ minimization with an $\\ell_2$ constraint. The results of\nthis paper improve the existing results in the literature by weakening the\nconditions and tightening the error bounds. The improvement on the conditions\nshows that signals with larger support can be recovered accurately. This paper\nalso establishes connections between restricted isometry property and the\nmutual incoherence property. Some results of Candes, Romberg and Tao (2006) and\nDonoho, Elad, and Temlyakov (2006) are extended.\n",
          "  In this paper, we derive Hybrid, Bayesian and Marginalized Cram\\'{e}r-Rao\nlower bounds (HCRB, BCRB and MCRB) for the single and multiple measurement\nvector Sparse Bayesian Learning (SBL) problem of estimating compressible\nvectors and their prior distribution parameters. We assume the unknown vector\nto be drawn from a compressible Student-t prior distribution. We derive CRBs\nthat encompass the deterministic or random nature of the unknown parameters of\nthe prior distribution and the regression noise variance. We extend the MCRB to\nthe case where the compressible vector is distributed according to a general\ncompressible prior distribution, of which the generalized Pareto distribution\nis a special case. We use the derived bounds to uncover the relationship\nbetween the compressibility and Mean Square Error (MSE) in the estimates.\nFurther, we illustrate the tightness and utility of the bounds through\nsimulations, by comparing them with the MSE performance of two popular\nSBL-based estimators. It is found that the MCRB is generally the tightest among\nthe bounds derived and that the MSE performance of the Expectation-Maximization\n(EM) algorithm coincides with the MCRB for the compressible vector. Through\nsimulations, we demonstrate the dependence of the MSE performance of SBL based\nestimators on the compressibility of the vector for several values of the\nnumber of observations and at different signal powers.\n",
          "  We consider the problem of reconstructing a discrete-time signal (sequence)\nwith continuous-valued components corrupted by a known memoryless channel. When\nperformance is measured using a per-symbol loss function satisfying mild\nregularity conditions, we develop a sequence of denoisers that, although\nindependent of the distribution of the underlying `clean' sequence, is\nuniversally optimal in the limit of large sequence length. This sequence of\ndenoisers is universal in the sense of performing as well as any sliding window\ndenoising scheme which may be optimized for the underlying clean signal. Our\nresults are initially developed in a ``semi-stochastic'' setting, where the\nnoiseless signal is an unknown individual sequence, and the only source of\nrandomness is due to the channel noise. It is subsequently shown that in the\nfully stochastic setting, where the noiseless sequence is a stationary\nstochastic process, our schemes universally attain optimum performance. The\nproposed schemes draw from nonparametric density estimation techniques and are\npractically implementable. We demonstrate efficacy of the proposed schemes in\ndenoising gray-scale images in the conventional additive white Gaussian noise\nsetting, with additional promising results for less conventional noise\ndistributions.\n",
          "  A novel framework of compressed sensing, namely statistical compressed\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution, and achieving accurate reconstruction on\naverage, is introduced. SCS based on Gaussian models is investigated in depth.\nFor signals that follow a single Gaussian model, with Gaussian or Bernoulli\nsensing matrices of O(k) measurements, considerably smaller than the O(k\nlog(N/k)) required by conventional CS based on sparse models, where N is the\nsignal dimension, and with an optimal decoder implemented via linear filtering,\nsignificantly faster than the pursuit decoders applied in conventional CS, the\nerror of SCS is shown tightly upper bounded by a constant times the best k-term\napproximation error, with overwhelming probability. The failure probability is\nalso significantly smaller than that of conventional sparsity-oriented CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the best k-term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For Gaussian mixture models (GMMs), that assume multiple Gaussian\ndistributions and that each signal follows one of them with an unknown index, a\npiecewise linear estimator is introduced to decode SCS. The accuracy of model\nselection, at the heart of the piecewise linear decoder, is analyzed in terms\nof the properties of the Gaussian distributions and the number of sensing\nmeasurements. A maximum a posteriori expectation-maximization algorithm that\niteratively estimates the Gaussian models parameters, the signals model\nselection, and decodes the signals, is presented for GMM-based SCS. In real\nimage sensing applications, GMM-based SCS is shown to lead to improved results\ncompared to conventional CS, at a considerably lower computational cost.\n",
          "  We develop two approaches for analyzing the approximation error bound for the\nNystr\\\"{o}m method, one based on the concentration inequality of integral\noperator, and one based on the compressive sensing theory. We show that the\napproximation error, measured in the spectral norm, can be improved from\n$O(N/\\sqrt{m})$ to $O(N/m^{1 - \\rho})$ in the case of large eigengap, where $N$\nis the total number of data points, $m$ is the number of sampled data points,\nand $\\rho \\in (0, 1/2)$ is a positive constant that characterizes the eigengap.\nWhen the eigenvalues of the kernel matrix follow a $p$-power law, our analysis\nbased on compressive sensing theory further improves the bound to $O(N/m^{p -\n1})$ under an incoherence assumption, which explains why the Nystr\\\"{o}m method\nworks well for kernel matrix with skewed eigenvalues. We present a kernel\nclassification approach based on the Nystr\\\"{o}m method and derive its\ngeneralization performance using the improved bound. We show that when the\neigenvalues of kernel matrix follow a $p$-power law, we can reduce the number\nof support vectors to $N^{2p/(p^2 - 1)}$, a number less than $N$ when $p >\n1+\\sqrt{2}$, without seriously sacrificing its generalization performance.\n",
          "  In this paper, we consider the problem of sparse recovery from nonlinear\nmeasurements, which has applications in state estimation and bad data detection\nfor power networks. An iterative mixed $\\ell_1$ and $\\ell_2$ convex program is\nused to estimate the true state by locally linearizing the nonlinear\nmeasurements. When the measurements are linear, through using the almost\nEuclidean property for a linear subspace, we derive a new performance bound for\nthe state estimation error under sparse bad data and additive observation\nnoise. As a byproduct, in this paper we provide sharp bounds on the almost\nEuclidean property of a linear subspace, using the \"escape-through-the-mesh\"\ntheorem from geometric functional analysis. When the measurements are\nnonlinear, we give conditions under which the solution of the iterative\nalgorithm converges to the true state even though the locally linearized\nmeasurements may not be the actual nonlinear measurements. We numerically\nevaluate our iterative convex programming approach to perform bad data\ndetections in nonlinear electrical power networks problems. We are able to use\nsemidefinite programming to verify the conditions for convergence of the\nproposed iterative sparse recovery algorithms from nonlinear measurements.\n",
          "  Recently, it has been proved in Babadi et al. that in noisy compressed\nsensing, a joint typical estimator can asymptotically achieve the Cramer-Rao\nlower bound of the problem.To prove this result, this paper used a lemma,which\nis provided in Akcakaya et al,that comprises the main building block of the\nproof. This lemma is based on the assumption of Gaussianity of the measurement\nmatrix and its randomness in the domain of noise. In this correspondence, we\ngeneralize the results obtained in Babadi et al by dropping the Gaussianity\nassumption on the measurement matrix. In fact, by considering the measurement\nmatrix as a deterministic matrix in our analysis, we find a theorem similar to\nthe main theorem of Babadi et al for a family of randomly generated (but\ndeterministic in the noise domain) measurement matrices that satisfy a\ngeneralized condition known as The Concentration of Measures Inequality. By\nthis, we finally show that under our generalized assumptions, the Cramer-Rao\nbound of the estimation is achievable by using the typical estimator introduced\nin Babadi et al.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "28_compressive_sparse_compressed",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "28_compressive_sparse_compressed"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          0.9307610988616943,
          0.8929820656776428,
          0.9824729561805725,
          0.910767138004303,
          0.9517262578010559,
          0.7692571878433228,
          0.9833366870880127,
          1.0304011106491089,
          1.0366779565811157,
          1.0096088647842407,
          0.9637595415115356,
          0.8796718120574951,
          0.8882030248641968,
          0.910437822341919,
          0.9385759234428406
         ],
         "y": [
          11.292208671569824,
          11.232379913330078,
          11.242273330688477,
          11.27791690826416,
          11.271734237670898,
          10.998734474182129,
          11.239723205566406,
          11.185935020446777,
          11.255722999572754,
          11.288187980651855,
          11.348087310791016,
          11.211709022521973,
          11.224706649780273,
          11.280677795410156,
          11.239286422729492
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This work addresses the following question: Under what assumptions on the\ndata generating process can one infer the causal graph from the joint\ndistribution? The approach taken by conditional independence-based causal\ndiscovery methods is based on two assumptions: the Markov condition and\nfaithfulness. It has been shown that under these assumptions the causal graph\ncan be identified up to Markov equivalence (some arrows remain undirected)\nusing methods like the PC algorithm. In this work we propose an alternative by\ndefining Identifiable Functional Model Classes (IFMOCs). As our main theorem we\nprove that if the data generating process belongs to an IFMOC, one can identify\nthe complete causal graph. To the best of our knowledge this is the first\nidentifiability result of this kind that is not limited to linear functional\nrelationships. We discuss how the IFMOC assumption and the Markov and\nfaithfulness assumptions relate to each other and explain why we believe that\nthe IFMOC assumption can be tested more easily on given data. We further\nprovide a practical algorithm that recovers the causal graph from finitely many\ndata; experiments on simulated data support the theoretical findings.\n",
          "  We describe a method that infers whether statistical dependences between two\nobserved variables X and Y are due to a \"direct\" causal link or only due to a\nconnecting causal path that contains an unobserved variable of low complexity,\ne.g., a binary variable. This problem is motivated by statistical genetics.\nGiven a genetic marker that is correlated with a phenotype of interest, we want\nto detect whether this marker is causal or it only correlates with a causal\none. Our method is based on the analysis of the location of the conditional\ndistributions P(Y|x) in the simplex of all distributions of Y. We report\nencouraging results on semi-empirical data.\n",
          "  Conditional independence testing is an important problem, especially in\nBayesian network learning and causal discovery. Due to the curse of\ndimensionality, testing for conditional independence of continuous variables is\nparticularly challenging. We propose a Kernel-based Conditional Independence\ntest (KCI-test), by constructing an appropriate test statistic and deriving its\nasymptotic distribution under the null hypothesis of conditional independence.\nThe proposed method is computationally efficient and easy to implement.\nExperimental results show that it outperforms other methods, especially when\nthe conditioning set is large or the sample size is not very large, in which\ncase other methods encounter difficulties.\n",
          "  Identifying and understanding modular organizations is centrally important in\nthe study of complex systems. Several approaches to this problem have been\nadvanced, many framed in information-theoretic terms. Our treatment starts from\nthe complementary point of view of statistical modeling and prediction of\ndynamical systems. It is known that for finite amounts of training data,\nsimpler models can have greater predictive power than more complex ones. We use\nthe trade-off between model simplicity and predictive accuracy to generate\noptimal multiscale decompositions of dynamical networks into weakly-coupled,\nsimple modules. State-dependent and causal versions of our method are also\nproposed.\n",
          "  Given R groups of numerical variables X1, ... XR, we assume that each group\nis the result of one underlying latent variable, and that all latent variables\nare bound together through a linear equation system. Moreover, we assume that\nsome explanatory latent variables may interact pairwise in one or more\nequations. We basically consider PLS Path Modelling's algorithm to estimate\nboth latent variables and the model's coefficients. New \"external\" estimation\nschemes are proposed that draw latent variables towards strong group structures\nin a more flexible way. New \"internal\" estimation schemes are proposed to\nenable PLSPM to make good use of variable group complementarity and to deal\nwith interactions. Application examples are given.\n",
          "  Discovering causal relations among observed variables in a given data set is\na main topic in studies of statistics and artificial intelligence. Recently,\nsome techniques to discover an identifiable causal structure have been explored\nbased on non-Gaussianity of the observed data distribution. However, most of\nthese are limited to continuous data. In this paper, we present a novel causal\nmodel for binary data and propose a new approach to derive an identifiable\ncausal structure governing the data based on skew Bernoulli distributions of\nexternal noise. Experimental evaluation shows excellent performance for both\nartificial and real world data sets.\n",
          "  We consider the problem of learning causal information between random\nvariables in directed acyclic graphs (DAGs) when allowing arbitrarily many\nlatent and selection variables. The FCI (Fast Causal Inference) algorithm has\nbeen explicitly designed to infer conditional independence and causal\ninformation in such settings. However, FCI is computationally infeasible for\nlarge graphs. We therefore propose the new RFCI algorithm, which is much faster\nthan FCI. In some situations the output of RFCI is slightly less informative,\nin particular with respect to conditional independence information. However, we\nprove that any causal information in the output of RFCI is correct in the\nasymptotic limit. We also define a class of graphs on which the outputs of FCI\nand RFCI are identical. We prove consistency of FCI and RFCI in sparse\nhigh-dimensional settings, and demonstrate in simulations that the estimation\nperformances of the algorithms are very similar. All software is implemented in\nthe R-package pcalg.\n",
          "  We introduce an approach to inferring the causal architecture of stochastic\ndynamical systems that extends rate distortion theory to use causal\nshielding---a natural principle of learning. We study two distinct cases of\ncausal inference: optimal causal filtering and optimal causal estimation.\n  Filtering corresponds to the ideal case in which the probability distribution\nof measurement sequences is known, giving a principled method to approximate a\nsystem's causal structure at a desired level of representation. We show that,\nin the limit in which a model complexity constraint is relaxed, filtering finds\nthe exact causal architecture of a stochastic dynamical system, known as the\ncausal-state partition. From this, one can estimate the amount of historical\ninformation the process stores. More generally, causal filtering finds a graded\nmodel-complexity hierarchy of approximations to the causal architecture. Abrupt\nchanges in the hierarchy, as a function of approximation, capture distinct\nscales of structural organization.\n  For nonideal cases with finite data, we show how the correct number of\nunderlying causal states can be found by optimal causal estimation. A\npreviously derived model complexity control term allows us to correct for the\neffect of statistical fluctuations in probability estimates and thereby avoid\nover-fitting.\n",
          "  Probabilistic graphical models are a fundamental tool in statistics, machine\nlearning, signal processing, and control. When such a model is defined on a\ndirected acyclic graph (DAG), one can assign a partial ordering to the events\noccurring in the corresponding stochastic system. Based on the work of Judea\nPearl and others, these DAG-based \"causal factorizations\" of joint probability\nmeasures have been used for characterization and inference of functional\ndependencies (causal links). This mostly expository paper focuses on several\nconnections between Pearl's formalism (and in particular his notion of\n\"intervention\") and information-theoretic notions of causality and feedback\n(such as causal conditioning, directed stochastic kernels, and directed\ninformation). As an application, we show how conditional directed information\ncan be used to develop an information-theoretic version of Pearl's \"back-door\"\ncriterion for identifiability of causal effects from passive observations. This\nsuggests that the back-door criterion can be thought of as a causal analog of\nstatistical sufficiency.\n",
          "  Over the past two decades, several consistent procedures have been designed\nto infer causal conclusions from observational data. We prove that if the true\ncausal network might be an arbitrary, linear Gaussian network or a discrete\nBayes network, then every unambiguous causal conclusion produced by a\nconsistent method from non-experimental data is subject to reversal as the\nsample size increases any finite number of times. That result, called the\ncausal flipping theorem, extends prior results to the effect that causal\ndiscovery cannot be reliable on a given sample size. We argue that since\nrepeated flipping of causal conclusions is unavoidable in principle for\nconsistent methods, the best possible discovery methods are consistent methods\nthat retract their earlier conclusions no more than necessary. A series of\nsimulations of various methods across a wide range of sample sizes illustrates\nconcretely both the theorem and the principle of comparing methods in terms of\nretractions.\n",
          "  Discovering latent representations of the observed world has become\nincreasingly more relevant in data analysis. Much of the effort concentrates on\nbuilding latent variables which can be used in prediction problems, such as\nclassification and regression. A related goal of learning latent structure from\ndata is that of identifying which hidden common causes generate the\nobservations, such as in applications that require predicting the effect of\npolicies. This will be the main problem tackled in our contribution: given a\ndataset of indicators assumed to be generated by unknown and unmeasured common\ncauses, we wish to discover which hidden common causes are those, and how they\ngenerate our data. This is possible under the assumption that observed\nvariables are linear functions of the latent causes with additive noise.\nPrevious results in the literature present solutions for the case where each\nobserved variable is a noisy function of a single latent variable. We show how\nto extend the existing results for some cases where observed variables measure\nmore than one latent variable.\n",
          "  We propose a method that infers whether linear relations between two\nhigh-dimensional variables X and Y are due to a causal influence from X to Y or\nfrom Y to X. The earlier proposed so-called Trace Method is extended to the\nregime where the dimension of the observed variables exceeds the sample size.\nBased on previous work, we postulate conditions that characterize a causal\nrelation between X and Y. Moreover, we describe a statistical test and argue\nthat both causal directions are typically rejected if there is a common cause.\nA full theoretical analysis is presented for the deterministic case but our\napproach seems to be valid for the noisy case, too, for which we additionally\npresent an approach based on a sparsity constraint. The discussed method yields\npromising results for both simulated and real world data.\n",
          "  We consider two variables that are related to each other by an invertible\nfunction. While it has previously been shown that the dependence structure of\nthe noise can provide hints to determine which of the two variables is the\ncause, we presently show that even in the deterministic (noise-free) case,\nthere are asymmetries that can be exploited for causal inference. Our method is\nbased on the idea that if the function and the probability density of the cause\nare chosen independently, then the distribution of the effect will, in a\ncertain sense, depend on the function. We provide a theoretical analysis of\nthis method, showing that it also works in the low noise regime, and link it to\ninformation geometry. We report strong empirical results on various real-world\ndata sets from different domains.\n",
          "  Given a set of experiments in which varying subsets of observed variables are\nsubject to intervention, we consider the problem of identifiability of causal\nmodels exhibiting latent confounding. While identifiability is trivial when\neach experiment intervenes on a large number of variables, the situation is\nmore complicated when only one or a few variables are subject to intervention\nper experiment. For linear causal models with latent variables Hyttinen et al.\n(2010) gave precise conditions for when such data are sufficient to identify\nthe full model. While their result cannot be extended to discrete-valued\nvariables with arbitrary cause-effect relationships, we show that a similar\nresult can be obtained for the class of causal models whose conditional\nprobability distributions are restricted to a `noisy-OR' parameterization. We\nfurther show that identification is preserved under an extension of the model\nthat allows for negative influences, and present learning algorithms that we\ntest for accuracy, scalability and robustness.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "29_causal_inference_discovering",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "29_causal_inference_discovering"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.565471887588501,
          2.578187942504883,
          2.5986390113830566,
          2.4382717609405518,
          3.222269296646118,
          2.570314407348633,
          2.5595099925994873,
          2.4604992866516113,
          2.5567522048950195,
          2.5726895332336426,
          3.186978578567505,
          2.5760066509246826,
          2.5469534397125244,
          2.588639974594116,
          2.6443703174591064
         ],
         "y": [
          4.629918098449707,
          4.604628086090088,
          4.68392276763916,
          4.85273551940918,
          5.063355922698975,
          4.599724292755127,
          4.710745811462402,
          4.741552829742432,
          4.641536235809326,
          4.6074442863464355,
          5.053536415100098,
          4.5945611000061035,
          4.633333206176758,
          4.620820999145508,
          4.716987133026123
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  There is much interest in the Hierarchical Dirichlet Process Hidden Markov\nModel (HDP-HMM) as a natural Bayesian nonparametric extension of the\ntraditional HMM. However, in many settings the HDP-HMM's strict Markovian\nconstraints are undesirable, particularly if we wish to learn or encode\nnon-geometric state durations. We can extend the HDP-HMM to capture such\nstructure by drawing upon explicit-duration semi-Markovianity, which has been\ndeveloped in the parametric setting to allow construction of highly\ninterpretable models that admit natural prior information on state durations.\nIn this paper we introduce the explicitduration HDP-HSMM and develop posterior\nsampling algorithms for efficient inference in both the direct-assignment and\nweak-limit approximation settings. We demonstrate the utility of the model and\nour inference methods on synthetic data as well as experiments on a speaker\ndiarization problem and an example of learning the patterns in Morse code.\n",
          "  This paper presents a method of choosing number of states of a HMM based on\nnumber of critical points of the motion capture data. The choice of Hidden\nMarkov Models(HMM) parameters is crucial for recognizer's performance as it is\nthe first step of the training and cannot be corrected automatically within\nHMM. In this article we define predictor of number of states based on number of\ncritical points of the sequence and test its effectiveness against sample data.\n",
          "  Inferring the sequence of states from observations is one of the most\nfundamental problems in Hidden Markov Models. In statistical physics language,\nthis problem is equivalent to computing the marginals of a one-dimensional\nmodel with a random external field. While this task can be accomplished through\ntransfer matrix methods, it becomes quickly intractable when the underlying\nstate space is large.\n  This paper develops several low-complexity approximate algorithms to address\nthis inference problem when the state space becomes large. The new algorithms\nare based on various mean-field approximations of the transfer matrix. Their\nperformances are studied in detail on a simple realistic model for DNA\npyrosequencing.\n",
          "  Hidden Markov Models (HMMs) can be accurately approximated using\nco-occurrence frequencies of pairs and triples of observations by using a fast\nspectral method in contrast to the usual slow methods like EM or Gibbs\nsampling. We provide a new spectral method which significantly reduces the\nnumber of model parameters that need to be estimated, and generates a sample\ncomplexity that does not depend on the size of the observation vocabulary. We\npresent an elementary proof giving bounds on the relative accuracy of\nprobability estimates from our model. (Correlaries show our bounds can be\nweakened to provide either L1 bounds or KL bounds which provide easier direct\ncomparisons to previous work.) Our theorem uses conditions that are checkable\nfrom the data, instead of putting conditions on the unobservable Markov\ntransition matrix.\n",
          "  We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization\nof HMMs that can model smooth state evolution as in Linear Dynamical Systems\n(LDSs) as well as non-log-concave predictive distributions as in\ncontinuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n\ndiscrete observations, with a transition matrix of rank k <= m. This implies\nthe dynamics evolve in a k-dimensional subspace, while the shape of the set of\npredictive distributions is determined by m. Latent state belief is represented\nwith a k-dimensional state vector and inference is carried out entirely in R^k,\nmaking RR-HMMs as computationally efficient as k-state HMMs yet more\nexpressive. To learn RR-HMMs, we relax the assumptions of a recently proposed\nspectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it\nto learn k-dimensional observable representations of rank-k RR-HMMs. The\nalgorithm is consistent and free of local optima, and we extend its performance\nguarantees to cover the RR-HMM case. We show how this algorithm can be used in\nconjunction with a kernel density estimator to efficiently model\nhigh-dimensional multivariate continuous data. We also relax the assumption\nthat single observations are sufficient to disambiguate state, and extend the\nalgorithm accordingly. Experiments on synthetic data and a toy video, as well\nas on a difficult robot vision modeling problem, yield accurate models that\ncompare favorably with standard alternatives in simulation quality and\nprediction capability.\n",
          "  Hidden Markov Models (HMMs) are one of the most fundamental and widely used\nstatistical tools for modeling discrete time series. In general, learning HMMs\nfrom data is computationally hard (under cryptographic assumptions), and\npractitioners typically resort to search heuristics which suffer from the usual\nlocal optima issues. We prove that under a natural separation condition (bounds\non the smallest singular value of the HMM parameters), there is an efficient\nand provably correct algorithm for learning HMMs. The sample complexity of the\nalgorithm does not explicitly depend on the number of distinct (discrete)\nobservations---it implicitly depends on this quantity through spectral\nproperties of the underlying HMM. This makes the algorithm particularly\napplicable to settings with a large number of observations, such as those in\nnatural language processing where the space of observation is sometimes the\nwords in a language. The algorithm is also simple, employing only a singular\nvalue decomposition and matrix multiplications.\n",
          "  Motivated by the unceasing interest in hidden Markov models (HMMs), this\npaper re-examines hidden path inference in these models, using primarily a\nrisk-based framework. While the most common maximum a posteriori (MAP), or\nViterbi, path estimator and the minimum error, or Posterior Decoder (PD), have\nlong been around, other path estimators, or decoders, have been either only\nhinted at or applied more recently and in dedicated applications generally\nunfamiliar to the statistical learning community. Over a decade ago, however, a\nfamily of algorithmically defined decoders aiming to hybridize the two standard\nones was proposed (Brushe et al., 1998). The present paper gives a careful\nanalysis of this hybridization approach, identifies several problems and issues\nwith it and other previously proposed approaches, and proposes practical\nresolutions of those. Furthermore, simple modifications of the classical\ncriteria for hidden path recognition are shown to lead to a new class of\ndecoders. Dynamic programming algorithms to compute these decoders in the usual\nforward-backward manner are presented. A particularly interesting subclass of\nsuch estimators can be also viewed as hybrids of the MAP and PD estimators.\nSimilar to previously proposed MAP-PD hybrids, the new class is parameterized\nby a small number of tunable parameters. Unlike their algorithmic predecessors,\nthe new risk-based decoders are more clearly interpretable, and, most\nimportantly, work \"out of the box\" in practice, which is demonstrated on some\nreal bioinformatics tasks and data. Some further generalizations and\napplications are discussed in conclusion.\n",
          "  Background: Hidden Markov models are widely employed by numerous\nbioinformatics programs used today. Applications range widely from comparative\ngene prediction to time-series analyses of micro-array data. The parameters of\nthe underlying models need to be adjusted for specific data sets, for example\nthe genome of a particular species, in order to maximize the prediction\naccuracy. Computationally efficient algorithms for parameter training are thus\nkey to maximizing the usability of a wide range of bioinformatics applications.\n  Results: We introduce two computationally efficient training algorithms, one\nfor Viterbi training and one for stochastic expectation maximization (EM)\ntraining, which render the memory requirements independent of the sequence\nlength. Unlike the existing algorithms for Viterbi and stochastic EM training\nwhich require a two-step procedure, our two new algorithms require only one\nstep and scan the input sequence in only one direction. We also implement these\ntwo new algorithms and the already published linear-memory algorithm for EM\ntraining into the hidden Markov model compiler HMM-Converter and examine their\nrespective practical merits for three small example models.\n  Conclusions: Bioinformatics applications employing hidden Markov models can\nuse the two algorithms in order to make Viterbi training and stochastic EM\ntraining more computationally efficient. Using these algorithms, parameter\ntraining can thus be attempted for more complex models and longer training\nsequences. The two new algorithms have the added advantage of being easier to\nimplement than the corresponding default algorithms for Viterbi training and\nstochastic EM training.\n",
          "  The Baum-Welsh algorithm together with its derivatives and variations has\nbeen the main technique for learning Hidden Markov Models (HMM) from\nobservational data. We present an HMM learning algorithm based on the\nnon-negative matrix factorization (NMF) of higher order Markovian statistics\nthat is structurally different from the Baum-Welsh and its associated\napproaches. The described algorithm supports estimation of the number of\nrecurrent states of an HMM and iterates the non-negative matrix factorization\n(NMF) algorithm to improve the learned HMM parameters. Numerical examples are\nprovided as well.\n",
          "  A simple linear algebraic explanation of the algorithm in \"A Spectral\nAlgorithm for Learning Hidden Markov Models\" (COLT 2009). Most of the content\nis in Figure 2; the text just makes everything precise in four nearly-trivial\nclaims.\n",
          "  This paper proposes a new estimation algorithm for the parameters of an HMM\nas to best account for the observed data. In this model, in addition to the\nobservation sequence, we have \\emph{partial} and \\emph{noisy} access to the\nhidden state sequence as side information. This access can be seen as \"partial\nlabeling\" of the hidden states. Furthermore, we model possible mislabeling in\nthe side information in a joint framework and derive the corresponding EM\nupdates accordingly. In our simulations, we observe that using this side\ninformation, we considerably improve the state recognition performance, up to\n70%, with respect to the \"achievable margin\" defined by the baseline\nalgorithms. Moreover, our algorithm is shown to be robust to the training\nconditions.\n",
          "  In this letter we borrow from the inference techniques developed for\nunbounded state-cardinality (nonparametric) variants of the HMM and use them to\ndevelop a tuning-parameter free, black-box inference procedure for\nExplicit-state-duration hidden Markov models (EDHMM). EDHMMs are HMMs that have\nlatent states consisting of both discrete state-indicator and discrete\nstate-duration random variables. In contrast to the implicit geometric state\nduration distribution possessed by the standard HMM, EDHMMs allow the direct\nparameterisation and estimation of per-state duration distributions. As most\nduration distributions are defined over the positive integers, truncation or\nother approximations are usually required to perform EDHMM inference.\n",
          "  The ability to predict the intentions of people based solely on their visual\nactions is a skill only performed by humans and animals. The intelligence of\ncurrent computer algorithms has not reached this level of complexity, but there\nare several research efforts that are working towards it. With the number of\nclassification algorithms available, it is hard to determine which algorithm\nworks best for a particular situation. In classification of visual human intent\ndata, Hidden Markov Models (HMM), and their variants, are leading candidates.\n  The inability of HMMs to provide a probability in the observation to\nobservation linkages is a big downfall in this classification technique. If a\nperson is visually identifying an action of another person, they monitor\npatterns in the observations. By estimating the next observation, people have\nthe ability to summarize the actions, and thus determine, with pretty good\naccuracy, the intention of the person performing the action. These visual cues\nand linkages are important in creating intelligent algorithms for determining\nhuman actions based on visual observations.\n  The Evidence Feed Forward Hidden Markov Model is a newly developed algorithm\nwhich provides observation to observation linkages. The following research\naddresses the theory behind Evidence Feed Forward HMMs, provides mathematical\nproofs of their learning of these parameters to optimize the likelihood of\nobservations with a Evidence Feed Forwards HMM, which is important in all\ncomputational intelligence algorithm, and gives comparative examples with\nstandard HMMs in classification of both visual action data and measurement\ndata; thus providing a strong base for Evidence Feed Forward HMMs in\nclassification of many types of problems.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "30_markov_markovian_bioinformatics",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "30_markov_markovian_bioinformatics"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.696355104446411,
          3.7391741275787354,
          3.7075791358947754,
          3.73272705078125,
          3.719949245452881,
          3.7080109119415283,
          3.7216198444366455,
          3.7001476287841797,
          3.731151819229126,
          3.7078142166137695,
          3.7238845825195312,
          3.699741840362549,
          3.769449472427368,
          3.719815731048584
         ],
         "y": [
          4.0406670570373535,
          4.0414509773254395,
          4.018588066101074,
          3.9878950119018555,
          4.01975154876709,
          3.992841958999634,
          4.016674041748047,
          3.994206666946411,
          3.997873544692993,
          3.987189531326294,
          4.015243053436279,
          4.0097880363464355,
          4.062225341796875,
          4.014184474945068
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  Two ubiquitous aspects of large-scale data analysis are that the data often\nhave heavy-tailed properties and that diffusion-based or spectral-based methods\nare often used to identify and extract structure of interest. Perhaps\nsurprisingly, popular distribution-independent methods such as those based on\nthe VC dimension fail to provide nontrivial results for even simple learning\nproblems such as binary classification in these two settings. In this paper, we\ndevelop distribution-dependent learning methods that can be used to provide\ndimension-independent sample complexity bounds for the binary classification\nproblem in these two popular settings. In particular, we provide bounds on the\nsample complexity of maximum margin classifiers when the magnitude of the\nentries in the feature vector decays according to a power law and also when\nlearning is performed with the so-called Diffusion Maps kernel. Both of these\nresults rely on bounding the annealed entropy of gap-tolerant classifiers in a\nHilbert space. We provide such a bound, and we demonstrate that our proof\ntechnique generalizes to the case when the margin is measured with respect to\nmore general Banach space norms. The latter result is of potential interest in\ncases where modeling the relationship between data elements as a dot product in\na Hilbert space is too restrictive.\n",
          "  In this paper, we examine the CE method in the broad context of Monte Carlo\nOptimization (MCO) and Parametric Learning (PL), a type of machine learning. A\nwell-known overarching principle used to improve the performance of many PL\nalgorithms is the bias-variance tradeoff. This tradeoff has been used to\nimprove PL algorithms ranging from Monte Carlo estimation of integrals, to\nlinear estimation, to general statistical estimation. Moreover, as described\nby, MCO is very closely related to PL. Owing to this similarity, the\nbias-variance tradeoff affects MCO performance, just as it does PL performance.\n  In this article, we exploit the bias-variance tradeoff to enhance the\nperformance of MCO algorithms. We use the technique of cross-validation, a\ntechnique based on the bias-variance tradeoff, to significantly improve the\nperformance of the Cross Entropy (CE) method, which is an MCO algorithm. In\nprevious work we have confirmed that other PL techniques improve the perfomance\nof other MCO algorithms. We conclude that the many techniques pioneered in PL\ncould be investigated as ways to improve MCO algorithms in general, and the CE\nmethod in particular.\n",
          "  We derive generalization bounds for learning algorithms based on their\nrobustness: the property that if a testing sample is \"similar\" to a training\nsample, then the testing error is close to the training error. This provides a\nnovel approach, different from the complexity or stability arguments, to study\ngeneralization of learning algorithms. We further show that a weak notion of\nrobustness is both sufficient and necessary for generalizability, which implies\nthat robustness is a fundamental property for learning algorithms to work.\n",
          "  We obtain a tight distribution-specific characterization of the sample\ncomplexity of large-margin classification with L2 regularization: We introduce\nthe margin-adapted dimension, which is a simple function of the second order\nstatistics of the data distribution, and show distribution-specific upper and\nlower bounds on the sample complexity, both governed by the margin-adapted\ndimension of the data distribution. The upper bounds are universal, and the\nlower bounds hold for the rich family of sub-Gaussian distributions with\nindependent features. We conclude that this new quantity tightly characterizes\nthe true sample complexity of large-margin classification. To prove the lower\nbound, we develop several new tools of independent interest. These include new\nconnections between shattering and hardness of learning, new properties of\nshattering with linear classifiers, and a new lower bound on the smallest\neigenvalue of a random Gram matrix generated by sub-Gaussian variables. Our\nresults can be used to quantitatively compare large margin learning to other\nlearning rules, and to improve the effectiveness of methods that use sample\ncomplexity bounds, such as active learning.\n",
          "  We define a novel, basic, unsupervised learning problem - learning the lowest\ndensity homogeneous hyperplane separator of an unknown probability\ndistribution. This task is relevant to several problems in machine learning,\nsuch as semi-supervised learning and clustering stability. We investigate the\nquestion of existence of a universally consistent algorithm for this problem.\nWe propose two natural learning paradigms and prove that, on input unlabeled\nrandom samples generated by any member of a rich family of distributions, they\nare guaranteed to converge to the optimal separator for that distribution. We\ncomplement this result by showing that no learning algorithm for our task can\nachieve uniform learning rates (that are independent of the data generating\ndistribution).\n",
          "  An empirical investigation of the interaction of sample size and\ndiscretization - in this case the entropy-based method CAIM (Class-Attribute\nInterdependence Maximization) - was undertaken to evaluate the impact and\npotential bias introduced into data mining performance metrics due to variation\nin sample size as it impacts the discretization process. Of particular interest\nwas the effect of discretizing within cross-validation folds averse to outside\ndiscretization folds. Previous publications have suggested that discretizing\nexternally can bias performance results; however, a thorough review of the\nliterature found no empirical evidence to support such an assertion. This\ninvestigation involved construction of over 117,000 models on seven distinct\ndatasets from the UCI (University of California-Irvine) Machine Learning\nLibrary and multiple modeling methods across a variety of configurations of\nsample size and discretization, with each unique \"setup\" being independently\nreplicated ten times. The analysis revealed a significant optimistic bias as\nsample sizes decreased and discretization was employed. The study also revealed\nthat there may be a relationship between the interaction that produces such\nbias and the numbers and types of predictor attributes, extending the \"curse of\ndimensionality\" concept from feature selection into the discretization realm.\nDirections for further exploration are laid out, as well some general\nguidelines about the proper application of discretization in light of these\nresults.\n",
          "  We obtain a tight distribution-specific characterization of the sample\ncomplexity of large-margin classification with L_2 regularization: We introduce\nthe \\gamma-adapted-dimension, which is a simple function of the spectrum of a\ndistribution's covariance matrix, and show distribution-specific upper and\nlower bounds on the sample complexity, both governed by the\n\\gamma-adapted-dimension of the source distribution. We conclude that this new\nquantity tightly characterizes the true sample complexity of large-margin\nclassification. The bounds hold for a rich family of sub-Gaussian\ndistributions.\n",
          "  This work is motivated by the problem of image mis-registration in remote\nsensing and we are interested in determining the resulting loss in the accuracy\nof pattern classification. A statistical formulation is given where we propose\nto use data contamination to model and understand the phenomenon of image\nmis-registration. This model is widely applicable to many other types of errors\nas well, for example, measurement errors and gross errors etc. The impact of\ndata contamination on classification is studied under a statistical learning\ntheoretical framework. A closed-form asymptotic bound is established for the\nresulting loss in classification accuracy, which is less than\n$\\epsilon/(1-\\epsilon)$ for data contamination of an amount of $\\epsilon$. Our\nbound is sharper than similar bounds in the domain adaptation literature and,\nunlike such bounds, it applies to classifiers with an infinite\nVapnik-Chervonekis (VC) dimension. Extensive simulations have been conducted on\nboth synthetic and real datasets under various types of data contamination,\nincluding label flipping, feature swapping and the replacement of feature\nvalues with data generated from a random source such as a Gaussian or Cauchy\ndistribution. Our simulation results show that the bound we derive is fairly\ntight.\n",
          "  In this paper, we correct an upper bound, presented in~\\cite{hs-11}, on the\ngeneralisation error of classifiers learned through multiple kernel learning.\nThe bound in~\\cite{hs-11} uses Rademacher complexity and has an\\emph{additive}\ndependence on the logarithm of the number of kernels and the margin achieved by\nthe classifier. However, there are some errors in parts of the proof which are\ncorrected in this paper. Unfortunately, the final result turns out to be a risk\nbound which has a \\emph{multiplicative} dependence on the logarithm of the\nnumber of kernels and the margin achieved by the classifier.\n",
          "  Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).\n",
          "  Bounds on the risk play a crucial role in statistical learning theory. They\nusually involve as capacity measure of the model studied the VC dimension or\none of its extensions. In classification, such \"VC dimensions\" exist for models\ntaking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations\nappropriate for the missing case, the one of models with values in R^Q. This\nprovides us with a new guaranteed risk for M-SVMs which appears superior to the\nexisting one.\n",
          "  This paper presents a theoretical analysis of sample selection bias\ncorrection. The sample bias correction technique commonly used in machine\nlearning consists of reweighting the cost of an error on each training point of\na biased sample to more closely reflect the unbiased distribution. This relies\non weights derived by various estimation techniques based on finite samples. We\nanalyze the effect of an error in that estimation on the accuracy of the\nhypothesis returned by the learning algorithm for two estimation techniques: a\ncluster-based estimation technique and kernel mean matching. We also report the\nresults of sample bias correction experiments with several data sets using\nthese techniques. Our analysis is based on the novel concept of distributional\nstability which generalizes the existing concept of point-based stability. Much\nof our work and proof techniques can be used to analyze other importance\nweighting techniques and their effect on accuracy when using a distributionally\nstable algorithm.\n",
          "  In this paper, we provide new theoretical results on the generalization\nproperties of learning algorithms for multiclass classification problems. The\noriginality of our work is that we propose to use the confusion matrix of a\nclassifier as a measure of its quality; our contribution is in the line of work\nwhich attempts to set up and study the statistical properties of new evaluation\nmeasures such as, e.g. ROC curves. In the confusion-based learning framework we\npropose, we claim that a targetted objective is to minimize the size of the\nconfusion matrix C, measured through its operator norm ||C||. We derive\ngeneralization bounds on the (size of the) confusion matrix in an extended\nframework of uniform stability, adapted to the case of matrix valued loss.\nPivotal to our study is a very recent matrix concentration inequality that\ngeneralizes McDiarmid's inequality. As an illustration of the relevance of our\ntheoretical results, we show how two SVM learning procedures can be proved to\nbe confusion-friendly. To the best of our knowledge, the present paper is the\nfirst that focuses on the confusion matrix from a theoretical point of view.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "31_classifiers_classification_generalization",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "31_classifiers_classification_generalization"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.3759806156158447,
          3.526517152786255,
          3.793734073638916,
          3.3321046829223633,
          3.5427651405334473,
          3.391636848449707,
          3.4159932136535645,
          3.190422773361206,
          3.2176477909088135,
          3.3820481300354004,
          3.22247052192688,
          3.602271795272827,
          3.1176204681396484,
          3.3931703567504883
         ],
         "y": [
          8.386931419372559,
          8.542553901672363,
          8.798649787902832,
          8.376450538635254,
          8.412195205688477,
          8.451004028320312,
          8.33368968963623,
          8.51842212677002,
          8.496811866760254,
          8.352659225463867,
          8.456278800964355,
          8.51791763305664,
          8.573213577270508,
          8.478212356567383
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "  This article applies Machine Learning techniques to solve Intrusion Detection\nproblems within computer networks. Due to complex and dynamic nature of\ncomputer networks and hacking techniques, detecting malicious activities\nremains a challenging task for security experts, that is, currently available\ndefense systems suffer from low detection capability and high number of false\nalarms. To overcome such performance limitations, we propose a novel Machine\nLearning algorithm, namely Boosted Subspace Probabilistic Neural Network\n(BSPNN), which integrates an adaptive boosting technique and a semi parametric\nneural network to obtain good tradeoff between accuracy and generality. As the\nresult, learning bias and generalization variance can be significantly\nminimized. Substantial experiments on KDD 99 intrusion benchmark indicate that\nour model outperforms other state of the art learning algorithms, with\nsignificantly improved detection accuracy, minimal false alarms and relatively\nsmall computational complexity.\n",
          "  Motivated by authentication, intrusion and spam detection applications we\nconsider single-class classification (SCC) as a two-person game between the\nlearner and an adversary. In this game the learner has a sample from a target\ndistribution and the goal is to construct a classifier capable of\ndistinguishing observations from the target distribution from observations\nemitted from an unknown other distribution. The ideal SCC classifier must\nguarantee a given tolerance for the false-positive error (false alarm rate)\nwhile minimizing the false negative error (intruder pass rate). Viewing SCC as\na two-person zero-sum game we identify both deterministic and randomized\noptimal classification strategies for different game variants. We demonstrate\nthat randomized classification can provide a significant advantage. In the\ndeterministic setting we show how to reduce SCC to two-class classification\nwhere in the two-class problem the other class is a synthetically generated\ndistribution. We provide an efficient and practical algorithm for constructing\nand solving the two class problem. The algorithm distinguishes low density\nregions of the target distribution and is shown to be consistent.\n",
          "  In this paper we present methods for attacking and defending $k$-gram\nstatistical analysis techniques that are used, for example, in network traffic\nanalysis and covert channel detection. The main new result is our demonstration\nof how to use a behavior's or process' $k$-order statistics to build a\nstochastic process that has those same $k$-order stationary statistics but\npossesses different, deliberately designed, $(k+1)$-order statistics if\ndesired. Such a model realizes a \"complexification\" of the process or behavior\nwhich a defender can use to monitor whether an attacker is shaping the\nbehavior. By deliberately introducing designed $(k+1)$-order behaviors, the\ndefender can check to see if those behaviors are present in the data. We also\ndevelop constructs for source codes that respect the $k$-order statistics of a\nprocess while encoding covert information. One fundamental consequence of these\nresults is that certain types of behavior analyses techniques come down to an\n{\\em arms race} in the sense that the advantage goes to the party that has more\ncomputing resources applied to the problem.\n",
          "  Security protocols often use randomization to achieve probabilistic\nnon-determinism. This non-determinism, in turn, is used in obfuscating the\ndependence of observable values on secret data. Since the correctness of\nsecurity protocols is very important, formal analysis of security protocols has\nbeen widely studied in literature. Randomized security protocols have also been\nanalyzed using formal techniques such as process-calculi and probabilistic\nmodel checking. In this paper, we consider the problem of validating\nimplementations of randomized protocols. Unlike previous approaches which treat\nthe protocol as a white-box, our approach tries to verify an implementation\nprovided as a black box. Our goal is to infer the secrecy guarantees provided\nby a security protocol through statistical techniques. We learn the\nprobabilistic dependency of the observable outputs on secret inputs using\nBayesian network. This is then used to approximate the leakage of secret. In\norder to evaluate the accuracy of our statistical approach, we compare our\ntechnique with the probabilistic model checking technique on two examples:\ncrowds protocol and dining crypotgrapher's protocol.\n",
          "  User authentication and intrusion detection differ from standard\nclassification problems in that while we have data generated from legitimate\nusers, impostor or intrusion data is scarce or non-existent. We review existing\ntechniques for dealing with this problem and propose a novel alternative based\non a principled statistical decision-making view point. We examine the\ntechnique on a toy problem and validate it on complex real-world data from an\nRFID based access control system. The results indicate that it can\nsignificantly outperform the classical world model approach. The method could\nbe more generally useful in other decision-making scenarios where there is a\nlack of adversary data.\n",
          "  Web applications suffer from cross-site scripting (XSS) attacks that\nresulting from incomplete or incorrect input sanitization. Learning the\nstructure of attack vectors could enrich the variety of manifestations in\ngenerated XSS attacks. In this study, we focus on generating more threatening\nXSS attacks for the state-of-the-art detection approaches that can find\npotential XSS vulnerabilities in Web applications, and propose a mechanism for\nstructural learning of attack vectors with the aim of generating mutated XSS\nattacks in a fully automatic way. Mutated XSS attack generation depends on the\nanalysis of attack vectors and the structural learning mechanism. For the\nkernel of the learning mechanism, we use a Hidden Markov model (HMM) as the\nstructure of the attack vector model to capture the implicit manner of the\nattack vector, and this manner is benefited from the syntax meanings that are\nlabeled by the proposed tokenizing mechanism. Bayes theorem is used to\ndetermine the number of hidden states in the model for generalizing the\nstructure model. The paper has the contributions as following: (1)\nautomatically learn the structure of attack vectors from practical data\nanalysis to modeling a structure model of attack vectors, (2) mimic the manners\nand the elements of attack vectors to extend the ability of testing tool for\nidentifying XSS vulnerabilities, (3) be helpful to verify the flaws of\nblacklist sanitization procedures of Web applications. We evaluated the\nproposed mechanism by Burp Intruder with a dataset collected from public XSS\narchives. The results show that mutated XSS attack generation can identify\npotential vulnerabilities.\n",
          "  Mobile ad hoc networking (MANET) has become an exciting and important\ntechnology in recent years because of the rapid proliferation of wireless\ndevices. MANETs are highly vulnerable to attacks due to the open medium,\ndynamically changing network topology and lack of centralized monitoring point.\nIt is important to search new architecture and mechanisms to protect the\nwireless networks and mobile computing application. IDS analyze the network\nactivities by means of audit data and use patterns of well-known attacks or\nnormal profile to detect potential attacks. There are two methods to analyze:\nmisuse detection and anomaly detection. Misuse detection is not effective\nagainst unknown attacks and therefore, anomaly detection method is used. In\nthis approach, the audit data is collected from each mobile node after\nsimulating the attack and compared with the normal behavior of the system. If\nthere is any deviation from normal behavior then the event is considered as an\nattack. Some of the features of collected audit data may be redundant or\ncontribute little to the detection process. So it is essential to select the\nimportant features to increase the detection rate. This paper focuses on\nimplementing two feature selection methods namely, markov blanket discovery and\ngenetic algorithm. In genetic algorithm, bayesian network is constructed over\nthe collected features and fitness function is calculated. Based on the fitness\nvalue the features are selected. Markov blanket discovery also uses bayesian\nnetwork and the features are selected depending on the minimum description\nlength. During the evaluation phase, the performances of both approaches are\ncompared based on detection rate and false alarm rate.\n",
          "  The main function of IDS (Intrusion Detection System) is to protect the\nsystem, analyze and predict the behaviors of users. Then these behaviors will\nbe considered an attack or a normal behavior. Though IDS has been developed for\nmany years, the large number of return alert messages makes managers maintain\nsystem inefficiently. In this paper, we use RST (Rough Set Theory) and SVM\n(Support Vector Machine) to detect intrusions. First, RST is used to preprocess\nthe data and reduce the dimensions. Next, the features were selected by RST\nwill be sent to SVM model to learn and test respectively. The method is\neffective to decrease the space density of data. The experiments will compare\nthe results with different methods and show RST and SVM schema could improve\nthe false positive rate and accuracy.\n",
          "  In this paper, we have proposed an architecture of active learning SVMs with\nrelevance feedback (RF)for classifying e-mail. This architecture combines both\nactive learning strategies where instead of using a randomly selected training\nset, the learner has access to a pool of unlabeled instances and can request\nthe labels of some number of them and relevance feedback where if any mail\nmisclassified then the next set of support vectors will be different from the\npresent set otherwise the next set will not change. Our proposed architecture\nwill ensure that a legitimate e-mail will not be dropped in the event of\noverflowing mailbox. The proposed architecture also exhibits dynamic updating\ncharacteristics making life as difficult for the spammer as possible.\n",
          "  In this paper we discuss the techniques involved in the design of the famous\nstatistical spam filters that include Naive Bayes, Term Frequency-Inverse\nDocument Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes\nAdditive Regression Tree. We compare these techniques with each other in terms\nof accuracy, recall, precision, etc. Further, we discuss the effectiveness and\nlimitations of statistical filters in filtering out various types of spam from\nlegitimate e-mails.\n",
          "  Email is a private medium of communication, and the inherent privacy\nconstraints form a major obstacle in developing effective spam filtering\nmethods which require access to a large amount of email data belonging to\nmultiple users. To mitigate this problem, we envision a privacy preserving spam\nfiltering system, where the server is able to train and evaluate a logistic\nregression based spam classifier on the combined email data of all users\nwithout being able to observe any emails using primitives such as homomorphic\nencryption and randomization. We analyze the protocols for correctness and\nsecurity, and perform experiments of a prototype system on a large scale spam\nfiltering task.\n  State of the art spam filters often use character n-grams as features which\nresult in large sparse data representation, which is not feasible to be used\ndirectly with our training and evaluation protocols. We explore various data\nindependent dimensionality reduction which decrease the running time of the\nprotocol making it feasible to use in practice while achieving high accuracy.\n",
          "  Phishing is an increasingly sophisticated method to steal personal user\ninformation using sites that pretend to be legitimate. In this paper, we take\nthe following steps to identify phishing URLs. First, we carefully select\nlexical features of the URLs that are resistant to obfuscation techniques used\nby attackers. Second, we evaluate the classification accuracy when using only\nlexical features, both automatically and hand-selected, vs. when using\nadditional features. We show that lexical features are sufficient for all\npractical purposes. Third, we thoroughly compare several classification\nalgorithms, and we propose to use an online method (AROW) that is able to\novercome noisy training data. Based on the insights gained from our analysis,\nwe propose PhishDef, a phishing detection system that uses only URL names and\ncombines the above three elements. PhishDef is a highly accurate method (when\ncompared to state-of-the-art approaches over real datasets), lightweight (thus\nappropriate for online and client-side deployment), proactive (based on online\nclassification rather than blacklists), and resilient to training data\ninaccuracies (thus enabling the use of large noisy training data).\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "32_attacks_security_intrusion",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "32_attacks_security_intrusion"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.733790397644043,
          4.773988246917725,
          4.903153896331787,
          5.011364936828613,
          4.754296779632568,
          4.855020999908447,
          4.71613883972168,
          4.765439033508301,
          4.913529396057129,
          4.890219688415527,
          4.9948883056640625,
          4.944761753082275,
          4.854715824127197
         ],
         "y": [
          10.011801719665527,
          9.937090873718262,
          9.957059860229492,
          9.948379516601562,
          10.01317024230957,
          9.977489471435547,
          10.02038288116455,
          10.01545238494873,
          9.978137016296387,
          10.001321792602539,
          9.92519760131836,
          9.960176467895508,
          9.978804588317871
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -1.3898915588855743,
          "y": 8.21970575451851,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 4.129584082961082,
          "xshift": 10,
          "y": 13.050300407409669
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 4.129584082961082,
          "x1": 4.129584082961082,
          "y0": 3.38911110162735,
          "y1": 13.050300407409669
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -1.3898915588855743,
          "x1": 9.649059724807739,
          "y0": 8.21970575451851,
          "y1": 8.21970575451851
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "kernels | kernel | regularization | classification | supervised",
           132
          ],
          [
           1,
           "reinforcement | learning | planning | reward | adaptive",
           83
          ],
          [
           2,
           "clusterings | clustering | cluster | clusters | clustered",
           77
          ],
          [
           3,
           "classifiers | classifier | classification | ensembles | features",
           64
          ],
          [
           4,
           "bandit | bandits | optimal | strategy | reward",
           54
          ],
          [
           5,
           "learnability | learnable | learning | algorithms | complexity",
           52
          ],
          [
           6,
           "bandit | reward | optimal | rewards | allocation",
           45
          ],
          [
           7,
           "corpus | classification | semantic | labeling | semantics",
           43
          ],
          [
           8,
           "optimal | learning | learnability | optimization | prediction",
           40
          ],
          [
           9,
           "lasso | regularization | regularized | sparse | penalized",
           32
          ],
          [
           10,
           "supervised | labeling | classification | labeled | classifiers",
           30
          ],
          [
           11,
           "matrix | matrices | minimization | rank | completion",
           29
          ],
          [
           12,
           "topics | topic | corpus | dirichlet | topical",
           29
          ],
          [
           13,
           "models | propagation | markov | bethe | belief",
           28
          ],
          [
           14,
           "classifier | classification | classify | categorization | classified",
           25
          ],
          [
           15,
           "prediction | forecasting | forecasts | forecast | expert",
           24
          ],
          [
           16,
           "sparse | dictionaries | recognition | learning | classification",
           24
          ],
          [
           17,
           "gaussian | classification | nonparametric | sparse | gaussians",
           23
          ],
          [
           18,
           "recommender | factorization | recommendations | recommendation | ratings",
           21
          ],
          [
           19,
           "learning | supervised | learner | generalization | complexity",
           19
          ],
          [
           20,
           "segmentations | segmentation | classification | networks | classifier",
           18
          ],
          [
           21,
           "quantum | superposition | qavb | qrw | learning",
           17
          ],
          [
           22,
           "privacy | private | privately | queries | regularized",
           16
          ],
          [
           23,
           "boosting | classifiers | boost | classifier | logitboost",
           16
          ],
          [
           24,
           "recognition | classifiers | classifier | recognize | facial",
           16
          ],
          [
           25,
           "optimizing | optimizer | optimization | bayesian | sampling",
           15
          ],
          [
           26,
           "ranking | rankings | ranked | retrieval | rank",
           15
          ],
          [
           27,
           "graphs | probabilistic | models | graphical | inference",
           15
          ],
          [
           28,
           "compressive | sparse | compressed | minimization | sensing",
           14
          ],
          [
           29,
           "causal | inference | discovering | models | discovery",
           14
          ],
          [
           30,
           "markov | markovian | bioinformatics | decoders | classification",
           13
          ],
          [
           31,
           "classifiers | classification | generalization | complexity | learning",
           13
          ],
          [
           32,
           "attacks | security | intrusion | phishing | detection",
           12
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>%{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           132,
           83,
           77,
           64,
           54,
           52,
           45,
           43,
           40,
           32,
           30,
           29,
           29,
           28,
           25,
           24,
           24,
           23,
           21,
           19,
           18,
           17,
           16,
           16,
           16,
           15,
           15,
           15,
           14,
           14,
           13,
           13,
           12
          ],
          "sizemode": "area",
          "sizeref": 0.0825,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          7.876577377319336,
          1.2471712827682495,
          7.4959282875061035,
          10.938883781433105,
          1.6268352270126343,
          6.3345561027526855,
          1.7819218635559082,
          11.976978302001953,
          7.9788007736206055,
          0.7937366962432861,
          10.933606147766113,
          1.4455307722091675,
          11.905622482299805,
          -4.106480121612549,
          12.187232971191406,
          2.03985333442688,
          1.0544416904449463,
          -3.6573562622070312,
          0.958245038986206,
          11.178548812866211,
          7.978271007537842,
          6.514671802520752,
          6.172297477722168,
          11.045584678649902,
          7.780386924743652,
          1.0808465480804443,
          1.2464065551757812,
          -4.285697937011719,
          1.152251124382019,
          -4.431565761566162,
          -3.700453519821167,
          6.980509281158447,
          10.838874816894531
         ],
         "xaxis": "x",
         "y": [
          8.45212459564209,
          16.802608489990234,
          8.370665550231934,
          4.353513717651367,
          17.129878997802734,
          10.008606910705566,
          17.234506607055664,
          3.389085292816162,
          8.816429138183594,
          -0.5926142930984497,
          3.704071521759033,
          0.05849483609199524,
          3.496971368789673,
          6.985641002655029,
          3.215806484222412,
          16.811174392700195,
          -0.3324900269508362,
          7.434990882873535,
          17.879541397094727,
          3.755657196044922,
          8.211599349975586,
          9.82954216003418,
          10.168200492858887,
          4.302281856536865,
          8.688740730285645,
          16.66469955444336,
          17.5939884185791,
          6.806675910949707,
          -0.23488663136959076,
          6.659750938415527,
          7.39162540435791,
          9.35561752319336,
          4.534060001373291
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -5.096300625801087,
          "y": 9.93998308479786,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 4.459508645534515,
          "xshift": 10,
          "y": 20.561472606658935
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 4.459508645534515,
          "x1": 4.459508645534515,
          "y0": -0.6815064370632171,
          "y1": 20.561472606658935
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -5.096300625801087,
          "x1": 14.015317916870117,
          "y0": 9.93998308479786,
          "y1": 9.93998308479786
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 10",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 11",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 12",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 13",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 14",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 15",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 16",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 17",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 18",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 19",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 20",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 21",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 22",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 23",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 24",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 25",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 26",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 27",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 28",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 29",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 30",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 31",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 32",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -5.096300625801087,
          14.015317916870117
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -0.6815064370632171,
          20.561472606658935
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_kernels_kernel_regulariza...",
          "1_reinforcement_learning_pl...",
          "2_clusterings_clustering_cl...",
          "3_classifiers_classifier_cl...",
          "4_bandit_bandits_optimal",
          "5_learnability_learnable_le...",
          "6_bandit_reward_optimal",
          "7_corpus_classification_sem...",
          "8_optimal_learning_learnabi...",
          "9_lasso_regularization_regu...",
          "10_supervised_labeling_clas...",
          "11_matrix_matrices_minimiza...",
          "12_topics_topic_corpus",
          "13_models_propagation_markov",
          "14_classifier_classificatio...",
          "15_prediction_forecasting_f...",
          "16_sparse_dictionaries_reco...",
          "17_gaussian_classification_...",
          "18_recommender_factorizatio...",
          "19_learning_supervised_lear...",
          "20_segmentations_segmentati...",
          "21_quantum_superposition_qavb",
          "22_privacy_private_privately",
          "23_boosting_classifiers_boost",
          "24_recognition_classifiers_...",
          "25_optimizing_optimizer_opt...",
          "26_ranking_rankings_ranked",
          "27_graphs_probabilistic_mod...",
          "28_compressive_sparse_compr...",
          "29_causal_inference_discove...",
          "30_markov_markovian_bioinfo...",
          "31_classifiers_classificati...",
          "32_attacks_security_intrusion"
         ],
         "xaxis": "x",
         "y": [
          "0_kernels_kernel_regulariza...",
          "1_reinforcement_learning_pl...",
          "2_clusterings_clustering_cl...",
          "3_classifiers_classifier_cl...",
          "4_bandit_bandits_optimal",
          "5_learnability_learnable_le...",
          "6_bandit_reward_optimal",
          "7_corpus_classification_sem...",
          "8_optimal_learning_learnabi...",
          "9_lasso_regularization_regu...",
          "10_supervised_labeling_clas...",
          "11_matrix_matrices_minimiza...",
          "12_topics_topic_corpus",
          "13_models_propagation_markov",
          "14_classifier_classificatio...",
          "15_prediction_forecasting_f...",
          "16_sparse_dictionaries_reco...",
          "17_gaussian_classification_...",
          "18_recommender_factorizatio...",
          "19_learning_supervised_lear...",
          "20_segmentations_segmentati...",
          "21_quantum_superposition_qavb",
          "22_privacy_private_privately",
          "23_boosting_classifiers_boost",
          "24_recognition_classifiers_...",
          "25_optimizing_optimizer_opt...",
          "26_ranking_rankings_ranked",
          "27_graphs_probabilistic_mod...",
          "28_compressive_sparse_compr...",
          "29_causal_inference_discove...",
          "30_markov_markovian_bioinfo...",
          "31_classifiers_classificati...",
          "32_attacks_security_intrusion"
         ],
         "yaxis": "y",
         "z": [
          [
           0.9999997615814209,
           0.4441104531288147,
           0.6227008104324341,
           0.7303847074508667,
           0.40491390228271484,
           0.6528028249740601,
           0.333207905292511,
           0.5413642525672913,
           0.6979585289955139,
           0.7131158709526062,
           0.7723244428634644,
           0.6541033387184143,
           0.5583704113960266,
           0.5606973171234131,
           0.4540274739265442,
           0.4897024929523468,
           0.7189590930938721,
           0.6493089199066162,
           0.5795429944992065,
           0.6758174896240234,
           0.6892598867416382,
           0.430219829082489,
           0.5628739595413208,
           0.6493223905563354,
           0.6391125321388245,
           0.5153776407241821,
           0.5365343689918518,
           0.5655852556228638,
           0.5510386228561401,
           0.5045416355133057,
           0.5459491610527039,
           0.8089891672134399,
           0.5027819871902466
          ],
          [
           0.4441104531288147,
           0.9999998211860657,
           0.25205862522125244,
           0.3904728293418884,
           0.7572393417358398,
           0.5301339626312256,
           0.708463191986084,
           0.4564487338066101,
           0.5816234350204468,
           0.31751126050949097,
           0.4512830078601837,
           0.28475984930992126,
           0.356829434633255,
           0.4821966886520386,
           0.23892149329185486,
           0.6796590089797974,
           0.3697623610496521,
           0.45852580666542053,
           0.39472299814224243,
           0.5349606871604919,
           0.40727201104164124,
           0.4848475456237793,
           0.37997618317604065,
           0.4195862114429474,
           0.2621801197528839,
           0.7046858072280884,
           0.47542330622673035,
           0.3861274719238281,
           0.3415735363960266,
           0.4002729654312134,
           0.5151503682136536,
           0.4560896158218384,
           0.32455798983573914
          ],
          [
           0.6227008104324341,
           0.25205862522125244,
           1.0000001192092896,
           0.5567450523376465,
           0.2534219026565552,
           0.5124902129173279,
           0.2881484031677246,
           0.4398309290409088,
           0.46319490671157837,
           0.5305029153823853,
           0.5124742984771729,
           0.5833893418312073,
           0.5254675149917603,
           0.5409222841262817,
           0.5035549998283386,
           0.2975148558616638,
           0.530281126499176,
           0.5789567232131958,
           0.4779145121574402,
           0.4474841356277466,
           0.5261977910995483,
           0.406516969203949,
           0.45715218782424927,
           0.430248498916626,
           0.4122799038887024,
           0.37855255603790283,
           0.40393704175949097,
           0.507114589214325,
           0.43654394149780273,
           0.3740093410015106,
           0.4192863404750824,
           0.5373622179031372,
           0.39361846446990967
          ],
          [
           0.7303847074508667,
           0.3904728293418884,
           0.5567450523376465,
           0.9999999403953552,
           0.3047364354133606,
           0.532935380935669,
           0.2707933783531189,
           0.5245956778526306,
           0.5109199285507202,
           0.520413875579834,
           0.737872838973999,
           0.41731002926826477,
           0.4709685444831848,
           0.37089160084724426,
           0.6347345113754272,
           0.507427453994751,
           0.5731107592582703,
           0.47068214416503906,
           0.45982885360717773,
           0.613418459892273,
           0.5692979097366333,
           0.37206193804740906,
           0.4947488307952881,
           0.7357611060142517,
           0.6299939155578613,
           0.4613927900791168,
           0.5039664506912231,
           0.4038955271244049,
           0.34235185384750366,
           0.3710598945617676,
           0.4191981852054596,
           0.7284296751022339,
           0.6004992723464966
          ],
          [
           0.40491390228271484,
           0.7572393417358398,
           0.2534219026565552,
           0.3047364354133606,
           1,
           0.6092536449432373,
           0.7345340251922607,
           0.3251810073852539,
           0.6964792013168335,
           0.3852148652076721,
           0.43567216396331787,
           0.3405708372592926,
           0.28029972314834595,
           0.5218051671981812,
           0.16306617856025696,
           0.7200620770454407,
           0.3318633437156677,
           0.38290321826934814,
           0.41875767707824707,
           0.5442032814025879,
           0.34683236479759216,
           0.4007663130760193,
           0.39059093594551086,
           0.4382549524307251,
           0.17926345765590668,
           0.6896995306015015,
           0.6522272825241089,
           0.3415020704269409,
           0.41122257709503174,
           0.3569128215312958,
           0.3740389943122864,
           0.48887646198272705,
           0.3274345397949219
          ],
          [
           0.6528028249740601,
           0.5301339626312256,
           0.5124902129173279,
           0.532935380935669,
           0.6092536449432373,
           1,
           0.5199568271636963,
           0.474636435508728,
           0.6657612323760986,
           0.5253399610519409,
           0.6279035806655884,
           0.4617559313774109,
           0.4100695252418518,
           0.7406938076019287,
           0.35649311542510986,
           0.6056001782417297,
           0.5587201118469238,
           0.5127307176589966,
           0.4095308780670166,
           0.6794583201408386,
           0.5745803117752075,
           0.5493065118789673,
           0.6636784076690674,
           0.5506263375282288,
           0.32799032330513,
           0.5457520484924316,
           0.5762031078338623,
           0.5598453283309937,
           0.5913210511207581,
           0.5708718299865723,
           0.5073995590209961,
           0.7910655736923218,
           0.4701378047466278
          ],
          [
           0.333207905292511,
           0.708463191986084,
           0.2881484031677246,
           0.2707933783531189,
           0.7345340251922607,
           0.5199568271636963,
           1,
           0.23409631848335266,
           0.5858835577964783,
           0.28859463334083557,
           0.308000385761261,
           0.31386062502861023,
           0.24177804589271545,
           0.4879072308540344,
           0.13386553525924683,
           0.5812472105026245,
           0.3223458528518677,
           0.3352452218532562,
           0.37899550795555115,
           0.4219854474067688,
           0.27236175537109375,
           0.4009535610675812,
           0.35999375581741333,
           0.3206707835197449,
           0.13006505370140076,
           0.5489509105682373,
           0.42820852994918823,
           0.30081114172935486,
           0.43037596344947815,
           0.3057647943496704,
           0.3982470631599426,
           0.4089283347129822,
           0.32767564058303833
          ],
          [
           0.5413642525672913,
           0.4564487338066101,
           0.4398309290409088,
           0.5245956778526306,
           0.3251810073852539,
           0.474636435508728,
           0.23409631848335266,
           1.0000001192092896,
           0.39412063360214233,
           0.3452489376068115,
           0.6914170980453491,
           0.2821517884731293,
           0.6876827478408813,
           0.39732080698013306,
           0.654100775718689,
           0.39077743887901306,
           0.4659668803215027,
           0.43426692485809326,
           0.4872225522994995,
           0.5639474391937256,
           0.5685495734214783,
           0.3405183255672455,
           0.44927075505256653,
           0.49518993496894836,
           0.4146602153778076,
           0.4120335280895233,
           0.5673850178718567,
           0.4945676922798157,
           0.18581269681453705,
           0.44121605157852173,
           0.45549750328063965,
           0.4654386639595032,
           0.4386741816997528
          ],
          [
           0.6979585289955139,
           0.5816234350204468,
           0.46319490671157837,
           0.5109199285507202,
           0.6964792013168335,
           0.6657612323760986,
           0.5858835577964783,
           0.39412063360214233,
           1.0000001192092896,
           0.6829214096069336,
           0.5916969776153564,
           0.575555145740509,
           0.41460248827934265,
           0.5845832824707031,
           0.2384529858827591,
           0.6724997758865356,
           0.5923498868942261,
           0.529597818851471,
           0.5140681862831116,
           0.630475640296936,
           0.552405834197998,
           0.3826289772987366,
           0.5593616962432861,
           0.6225098371505737,
           0.3625897169113159,
           0.6366111040115356,
           0.5647392272949219,
           0.3973754346370697,
           0.5746142864227295,
           0.4220426678657532,
           0.474209725856781,
           0.6795907020568848,
           0.39480113983154297
          ],
          [
           0.7131158709526062,
           0.31751126050949097,
           0.5305029153823853,
           0.520413875579834,
           0.3852148652076721,
           0.5253399610519409,
           0.28859463334083557,
           0.3452489376068115,
           0.6829214096069336,
           0.9999996423721313,
           0.5547968149185181,
           0.6837397813796997,
           0.4048139452934265,
           0.5242505073547363,
           0.27277877926826477,
           0.3763430714607239,
           0.7709770202636719,
           0.5831880569458008,
           0.5191010236740112,
           0.5174780488014221,
           0.5562171936035156,
           0.26708897948265076,
           0.4409523606300354,
           0.5153131484985352,
           0.4193272292613983,
           0.46659812331199646,
           0.414948046207428,
           0.47532713413238525,
           0.6613473892211914,
           0.4555418789386749,
           0.3901122808456421,
           0.6052711009979248,
           0.33452901244163513
          ],
          [
           0.7723244428634644,
           0.4512830078601837,
           0.5124742984771729,
           0.737872838973999,
           0.43567216396331787,
           0.6279035806655884,
           0.308000385761261,
           0.6914170980453491,
           0.5916969776153564,
           0.5547968149185181,
           1,
           0.4069257378578186,
           0.6059030294418335,
           0.5038890838623047,
           0.5805619955062866,
           0.5017310380935669,
           0.5721035003662109,
           0.5834799408912659,
           0.5598488450050354,
           0.7606419324874878,
           0.688235878944397,
           0.3855046033859253,
           0.5798263549804688,
           0.7001528739929199,
           0.5172804594039917,
           0.5322300791740417,
           0.6021707057952881,
           0.5798251032829285,
           0.35803478956222534,
           0.5626604557037354,
           0.5040881633758545,
           0.7524995803833008,
           0.5494532585144043
          ],
          [
           0.6541033387184143,
           0.28475984930992126,
           0.5833893418312073,
           0.41731002926826477,
           0.3405708372592926,
           0.4617559313774109,
           0.31386062502861023,
           0.2821517884731293,
           0.575555145740509,
           0.6837397813796997,
           0.4069257378578186,
           1,
           0.4331331253051758,
           0.5244125723838806,
           0.2736908793449402,
           0.3618324398994446,
           0.6698726415634155,
           0.49629920721054077,
           0.6185399293899536,
           0.4232996106147766,
           0.41238319873809814,
           0.3126593828201294,
           0.3562520742416382,
           0.37035423517227173,
           0.4018125534057617,
           0.40834158658981323,
           0.48727136850357056,
           0.37645047903060913,
           0.7008169889450073,
           0.36862635612487793,
           0.4525220990180969,
           0.512771725654602,
           0.2726842761039734
          ],
          [
           0.5583704113960266,
           0.356829434633255,
           0.5254675149917603,
           0.4709685444831848,
           0.28029972314834595,
           0.4100695252418518,
           0.24177804589271545,
           0.6876827478408813,
           0.41460248827934265,
           0.4048139452934265,
           0.6059030294418335,
           0.4331331253051758,
           1,
           0.48248833417892456,
           0.6017934083938599,
           0.39059141278266907,
           0.46412116289138794,
           0.6405555009841919,
           0.6093034744262695,
           0.4879695773124695,
           0.5579671263694763,
           0.35514217615127563,
           0.39131659269332886,
           0.4465893507003784,
           0.3907780051231384,
           0.4282548129558563,
           0.5062544941902161,
           0.5862572193145752,
           0.27218878269195557,
           0.5009785294532776,
           0.546633243560791,
           0.4434375762939453,
           0.47128939628601074
          ],
          [
           0.5606973171234131,
           0.4821966886520386,
           0.5409222841262817,
           0.37089160084724426,
           0.5218051671981812,
           0.7406938076019287,
           0.4879072308540344,
           0.39732080698013306,
           0.5845832824707031,
           0.5242505073547363,
           0.5038890838623047,
           0.5244125723838806,
           0.48248833417892456,
           0.9999998807907104,
           0.24400237202644348,
           0.49193453788757324,
           0.4866783022880554,
           0.6298273801803589,
           0.48100546002388,
           0.528294563293457,
           0.6486258506774902,
           0.4866897463798523,
           0.510785698890686,
           0.38332316279411316,
           0.25639739632606506,
           0.5603029727935791,
           0.44002765417099,
           0.7613275051116943,
           0.5847132205963135,
           0.5793404579162598,
           0.589750349521637,
           0.5777676701545715,
           0.32060790061950684
          ],
          [
           0.4540274739265442,
           0.23892149329185486,
           0.5035549998283386,
           0.6347345113754272,
           0.16306617856025696,
           0.35649311542510986,
           0.13386553525924683,
           0.654100775718689,
           0.2384529858827591,
           0.27277877926826477,
           0.5805619955062866,
           0.2736908793449402,
           0.6017934083938599,
           0.24400237202644348,
           0.9999997615814209,
           0.3214019536972046,
           0.3511906862258911,
           0.32563960552215576,
           0.5175548791885376,
           0.4874316155910492,
           0.3045843243598938,
           0.27194470167160034,
           0.4044935703277588,
           0.49538445472717285,
           0.3892456591129303,
           0.2720768451690674,
           0.5131351351737976,
           0.34040015935897827,
           0.0883803442120552,
           0.30191361904144287,
           0.2718331813812256,
           0.4471045732498169,
           0.5279200077056885
          ],
          [
           0.4897024929523468,
           0.6796590089797974,
           0.2975148558616638,
           0.507427453994751,
           0.7200620770454407,
           0.6056001782417297,
           0.5812472105026245,
           0.39077743887901306,
           0.6724997758865356,
           0.3763430714607239,
           0.5017310380935669,
           0.3618324398994446,
           0.39059141278266907,
           0.49193453788757324,
           0.3214019536972046,
           0.9999998807907104,
           0.32041633129119873,
           0.421525239944458,
           0.48462051153182983,
           0.5444730520248413,
           0.42348599433898926,
           0.4292142391204834,
           0.4807082712650299,
           0.5525387525558472,
           0.2107555866241455,
           0.5953110456466675,
           0.5788476467132568,
           0.35637837648391724,
           0.3496992886066437,
           0.4321677088737488,
           0.472206175327301,
           0.5501937866210938,
           0.405961275100708
          ],
          [
           0.7189590930938721,
           0.3697623610496521,
           0.530281126499176,
           0.5731107592582703,
           0.3318633437156677,
           0.5587201118469238,
           0.3223458528518677,
           0.4659668803215027,
           0.5923498868942261,
           0.7709770202636719,
           0.5721035003662109,
           0.6698726415634155,
           0.46412116289138794,
           0.4866783022880554,
           0.3511906862258911,
           0.32041633129119873,
           1.000000238418579,
           0.5488637089729309,
           0.5141513347625732,
           0.5314576625823975,
           0.6161230802536011,
           0.3505231738090515,
           0.42201364040374756,
           0.483532190322876,
           0.5780977010726929,
           0.40559059381484985,
           0.40924549102783203,
           0.4628583788871765,
           0.7198028564453125,
           0.421636700630188,
           0.4551580250263214,
           0.6025217771530151,
           0.3523007929325104
          ],
          [
           0.6493089199066162,
           0.45852580666542053,
           0.5789567232131958,
           0.47068214416503906,
           0.38290321826934814,
           0.5127307176589966,
           0.3352452218532562,
           0.43426692485809326,
           0.529597818851471,
           0.5831880569458008,
           0.5834799408912659,
           0.49629920721054077,
           0.6405555009841919,
           0.6298273801803589,
           0.32563960552215576,
           0.421525239944458,
           0.5488637089729309,
           1.000000238418579,
           0.5664167404174805,
           0.4775235056877136,
           0.6307965517044067,
           0.3993101716041565,
           0.43065544962882996,
           0.414977490901947,
           0.38579660654067993,
           0.6909060478210449,
           0.3768436908721924,
           0.7186263799667358,
           0.49072369933128357,
           0.5912742614746094,
           0.6203473806381226,
           0.5404119491577148,
           0.3892233967781067
          ],
          [
           0.5795429944992065,
           0.39472299814224243,
           0.4779145121574402,
           0.45982885360717773,
           0.41875767707824707,
           0.4095308780670166,
           0.37899550795555115,
           0.4872225522994995,
           0.5140681862831116,
           0.5191010236740112,
           0.5598488450050354,
           0.6185399293899536,
           0.6093034744262695,
           0.48100546002388,
           0.5175548791885376,
           0.48462051153182983,
           0.5141513347625732,
           0.5664167404174805,
           1,
           0.48462536931037903,
           0.47605520486831665,
           0.32078859210014343,
           0.471017062664032,
           0.45350074768066406,
           0.34903353452682495,
           0.47582268714904785,
           0.6497721672058105,
           0.49514222145080566,
           0.35232362151145935,
           0.46134474873542786,
           0.4207994341850281,
           0.44679611921310425,
           0.41359174251556396
          ],
          [
           0.6758174896240234,
           0.5349606871604919,
           0.4474841356277466,
           0.613418459892273,
           0.5442032814025879,
           0.6794583201408386,
           0.4219854474067688,
           0.5639474391937256,
           0.630475640296936,
           0.5174780488014221,
           0.7606419324874878,
           0.4232996106147766,
           0.4879695773124695,
           0.528294563293457,
           0.4874316155910492,
           0.5444730520248413,
           0.5314576625823975,
           0.4775235056877136,
           0.48462536931037903,
           0.9999998807907104,
           0.5676555633544922,
           0.41177454590797424,
           0.5400810837745667,
           0.6317735910415649,
           0.43365103006362915,
           0.5492974519729614,
           0.5822268724441528,
           0.47975409030914307,
           0.4259255528450012,
           0.48497772216796875,
           0.47567039728164673,
           0.7254304885864258,
           0.4791933000087738
          ],
          [
           0.6892598867416382,
           0.40727201104164124,
           0.5261977910995483,
           0.5692979097366333,
           0.34683236479759216,
           0.5745803117752075,
           0.27236175537109375,
           0.5685495734214783,
           0.552405834197998,
           0.5562171936035156,
           0.688235878944397,
           0.41238319873809814,
           0.5579671263694763,
           0.6486258506774902,
           0.3045843243598938,
           0.42348599433898926,
           0.6161230802536011,
           0.6307965517044067,
           0.47605520486831665,
           0.5676555633544922,
           1,
           0.39105457067489624,
           0.477225124835968,
           0.5461912155151367,
           0.511380672454834,
           0.467800498008728,
           0.39870506525039673,
           0.6645091772079468,
           0.4197813868522644,
           0.46021920442581177,
           0.5675032138824463,
           0.6190464496612549,
           0.35641902685165405
          ],
          [
           0.430219829082489,
           0.4848475456237793,
           0.406516969203949,
           0.37206193804740906,
           0.4007663130760193,
           0.5493065118789673,
           0.4009535610675812,
           0.3405183255672455,
           0.3826289772987366,
           0.26708897948265076,
           0.3855046033859253,
           0.3126593828201294,
           0.35514217615127563,
           0.4866897463798523,
           0.27194470167160034,
           0.4292142391204834,
           0.3505231738090515,
           0.3993101716041565,
           0.32078859210014343,
           0.41177454590797424,
           0.39105457067489624,
           1,
           0.41634392738342285,
           0.3277122974395752,
           0.22421163320541382,
           0.48026949167251587,
           0.3984191417694092,
           0.36070266366004944,
           0.3525763750076294,
           0.35609400272369385,
           0.48236966133117676,
           0.4245980978012085,
           0.35555118322372437
          ],
          [
           0.5628739595413208,
           0.37997618317604065,
           0.45715218782424927,
           0.4947488307952881,
           0.39059093594551086,
           0.6636784076690674,
           0.35999375581741333,
           0.44927075505256653,
           0.5593616962432861,
           0.4409523606300354,
           0.5798263549804688,
           0.3562520742416382,
           0.39131659269332886,
           0.510785698890686,
           0.4044935703277588,
           0.4807082712650299,
           0.42201364040374756,
           0.43065544962882996,
           0.471017062664032,
           0.5400810837745667,
           0.477225124835968,
           0.41634392738342285,
           0.9999999403953552,
           0.4891195595264435,
           0.30562853813171387,
           0.4144776463508606,
           0.4987563490867615,
           0.42153361439704895,
           0.40140679478645325,
           0.4484361410140991,
           0.4222263693809509,
           0.5964224338531494,
           0.5950772762298584
          ],
          [
           0.6493223905563354,
           0.4195862114429474,
           0.430248498916626,
           0.7357611060142517,
           0.4382549524307251,
           0.5506263375282288,
           0.3206707835197449,
           0.49518993496894836,
           0.6225098371505737,
           0.5153131484985352,
           0.7001528739929199,
           0.37035423517227173,
           0.4465893507003784,
           0.38332316279411316,
           0.49538445472717285,
           0.5525387525558472,
           0.483532190322876,
           0.414977490901947,
           0.45350074768066406,
           0.6317735910415649,
           0.5461912155151367,
           0.3277122974395752,
           0.4891195595264435,
           1,
           0.5594130754470825,
           0.4499581754207611,
           0.5345416069030762,
           0.35710543394088745,
           0.358623743057251,
           0.31291109323501587,
           0.4237538278102875,
           0.6804134845733643,
           0.5318213701248169
          ],
          [
           0.6391125321388245,
           0.2621801197528839,
           0.4122799038887024,
           0.6299939155578613,
           0.17926345765590668,
           0.32799032330513,
           0.13006505370140076,
           0.4146602153778076,
           0.3625897169113159,
           0.4193272292613983,
           0.5172804594039917,
           0.4018125534057617,
           0.3907780051231384,
           0.25639739632606506,
           0.3892456591129303,
           0.2107555866241455,
           0.5780977010726929,
           0.38579660654067993,
           0.34903353452682495,
           0.43365103006362915,
           0.511380672454834,
           0.22421163320541382,
           0.30562853813171387,
           0.5594130754470825,
           1,
           0.24632421135902405,
           0.31012845039367676,
           0.309531033039093,
           0.31026706099510193,
           0.19179964065551758,
           0.448036253452301,
           0.4984613358974457,
           0.4102034270763397
          ],
          [
           0.5153776407241821,
           0.7046858072280884,
           0.37855255603790283,
           0.4613927900791168,
           0.6896995306015015,
           0.5457520484924316,
           0.5489509105682373,
           0.4120335280895233,
           0.6366111040115356,
           0.46659812331199646,
           0.5322300791740417,
           0.40834158658981323,
           0.4282548129558563,
           0.5603029727935791,
           0.2720768451690674,
           0.5953110456466675,
           0.40559059381484985,
           0.6909060478210449,
           0.47582268714904785,
           0.5492974519729614,
           0.467800498008728,
           0.48026949167251587,
           0.4144776463508606,
           0.4499581754207611,
           0.24632421135902405,
           1.0000004768371582,
           0.5166028141975403,
           0.48651322722435,
           0.42841678857803345,
           0.4487396776676178,
           0.49813681840896606,
           0.5246498584747314,
           0.3949865698814392
          ],
          [
           0.5365343689918518,
           0.47542330622673035,
           0.40393704175949097,
           0.5039664506912231,
           0.6522272825241089,
           0.5762031078338623,
           0.42820852994918823,
           0.5673850178718567,
           0.5647392272949219,
           0.414948046207428,
           0.6021707057952881,
           0.48727136850357056,
           0.5062544941902161,
           0.44002765417099,
           0.5131351351737976,
           0.5788476467132568,
           0.40924549102783203,
           0.3768436908721924,
           0.6497721672058105,
           0.5822268724441528,
           0.39870506525039673,
           0.3984191417694092,
           0.4987563490867615,
           0.5345416069030762,
           0.31012845039367676,
           0.5166028141975403,
           1.0000001192092896,
           0.3946681022644043,
           0.2889000177383423,
           0.3912891447544098,
           0.3355146646499634,
           0.5314868092536926,
           0.45518171787261963
          ],
          [
           0.5655852556228638,
           0.3861274719238281,
           0.507114589214325,
           0.4038955271244049,
           0.3415020704269409,
           0.5598453283309937,
           0.30081114172935486,
           0.4945676922798157,
           0.3973754346370697,
           0.47532713413238525,
           0.5798251032829285,
           0.37645047903060913,
           0.5862572193145752,
           0.7613275051116943,
           0.34040015935897827,
           0.35637837648391724,
           0.4628583788871765,
           0.7186263799667358,
           0.49514222145080566,
           0.47975409030914307,
           0.6645091772079468,
           0.36070266366004944,
           0.42153361439704895,
           0.35710543394088745,
           0.309531033039093,
           0.48651322722435,
           0.3946681022644043,
           1.0000001192092896,
           0.36895090341567993,
           0.6913110017776489,
           0.5337074995040894,
           0.5118363499641418,
           0.34740257263183594
          ],
          [
           0.5510386228561401,
           0.3415735363960266,
           0.43654394149780273,
           0.34235185384750366,
           0.41122257709503174,
           0.5913210511207581,
           0.43037596344947815,
           0.18581269681453705,
           0.5746142864227295,
           0.6613473892211914,
           0.35803478956222534,
           0.7008169889450073,
           0.27218878269195557,
           0.5847132205963135,
           0.0883803442120552,
           0.3496992886066437,
           0.7198028564453125,
           0.49072369933128357,
           0.35232362151145935,
           0.4259255528450012,
           0.4197813868522644,
           0.3525763750076294,
           0.40140679478645325,
           0.358623743057251,
           0.31026706099510193,
           0.42841678857803345,
           0.2889000177383423,
           0.36895090341567993,
           0.9999995827674866,
           0.3882989287376404,
           0.4483764171600342,
           0.5253013372421265,
           0.262723833322525
          ],
          [
           0.5045416355133057,
           0.4002729654312134,
           0.3740093410015106,
           0.3710598945617676,
           0.3569128215312958,
           0.5708718299865723,
           0.3057647943496704,
           0.44121605157852173,
           0.4220426678657532,
           0.4555418789386749,
           0.5626604557037354,
           0.36862635612487793,
           0.5009785294532776,
           0.5793404579162598,
           0.30191361904144287,
           0.4321677088737488,
           0.421636700630188,
           0.5912742614746094,
           0.46134474873542786,
           0.48497772216796875,
           0.46021920442581177,
           0.35609400272369385,
           0.4484361410140991,
           0.31291109323501587,
           0.19179964065551758,
           0.4487396776676178,
           0.3912891447544098,
           0.6913110017776489,
           0.3882989287376404,
           0.9999998807907104,
           0.4300602376461029,
           0.5007820129394531,
           0.36551040410995483
          ],
          [
           0.5459491610527039,
           0.5151503682136536,
           0.4192863404750824,
           0.4191981852054596,
           0.3740389943122864,
           0.5073995590209961,
           0.3982470631599426,
           0.45549750328063965,
           0.474209725856781,
           0.3901122808456421,
           0.5040881633758545,
           0.4525220990180969,
           0.546633243560791,
           0.589750349521637,
           0.2718331813812256,
           0.472206175327301,
           0.4551580250263214,
           0.6203473806381226,
           0.4207994341850281,
           0.47567039728164673,
           0.5675032138824463,
           0.48236966133117676,
           0.4222263693809509,
           0.4237538278102875,
           0.448036253452301,
           0.49813681840896606,
           0.3355146646499634,
           0.5337074995040894,
           0.4483764171600342,
           0.4300602376461029,
           1,
           0.4980979263782501,
           0.40386614203453064
          ],
          [
           0.8089891672134399,
           0.4560896158218384,
           0.5373622179031372,
           0.7284296751022339,
           0.48887646198272705,
           0.7910655736923218,
           0.4089283347129822,
           0.4654386639595032,
           0.6795907020568848,
           0.6052711009979248,
           0.7524995803833008,
           0.512771725654602,
           0.4434375762939453,
           0.5777676701545715,
           0.4471045732498169,
           0.5501937866210938,
           0.6025217771530151,
           0.5404119491577148,
           0.44679611921310425,
           0.7254304885864258,
           0.6190464496612549,
           0.4245980978012085,
           0.5964224338531494,
           0.6804134845733643,
           0.4984613358974457,
           0.5246498584747314,
           0.5314868092536926,
           0.5118363499641418,
           0.5253013372421265,
           0.5007820129394531,
           0.4980979263782501,
           1,
           0.5139815211296082
          ],
          [
           0.5027819871902466,
           0.32455798983573914,
           0.39361846446990967,
           0.6004992723464966,
           0.3274345397949219,
           0.4701378047466278,
           0.32767564058303833,
           0.4386741816997528,
           0.39480113983154297,
           0.33452901244163513,
           0.5494532585144043,
           0.2726842761039734,
           0.47128939628601074,
           0.32060790061950684,
           0.5279200077056885,
           0.405961275100708,
           0.3523007929325104,
           0.3892233967781067,
           0.41359174251556396,
           0.4791933000087738,
           0.35641902685165405,
           0.35555118322372437,
           0.5950772762298584,
           0.5318213701248169,
           0.4102034270763397,
           0.3949865698814392,
           0.45518171787261963,
           0.34740257263183594,
           0.262723833322525,
           0.36551040410995483,
           0.40386614203453064,
           0.5139815211296082,
           1
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix</b>",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#C8D2D7",
          "line": {
           "color": "#6E8484",
           "width": 1
          }
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.92489765290502,
          0.840413849124035,
          0.9702244834197739,
          0.6681666153411807,
          0.9944806846699777,
          0.720024356744281,
          0.6043292562969377,
          0.49905873419047897,
          0.34580524045829053,
          0.972868825037662,
          0.42816061956754425,
          0.707232152255365,
          0.9932051878992504,
          0.38366258565453903,
          0.9736899308432277,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7754499545240354
         ],
         "y": [
          "<b>Topic 0</b>: kernels_kernel_regulariz...",
          "<b>Topic 1</b>: reinforcement_learning_p...",
          "<b>Topic 2</b>: clusterings_clustering_c...",
          "<b>Topic 4</b>: bandit_bandits_optimal_s...",
          "<b>Topic 6</b>: bandit_reward_optimal_re...",
          "<b>Topic 7</b>: corpus_classification_se...",
          "<b>Topic 9</b>: lasso_regularization_reg...",
          "<b>Topic 14</b>: classifier_classificati...",
          "<b>Topic 15</b>: prediction_forecasting_...",
          "<b>Topic 16</b>: sparse_dictionaries_rec...",
          "<b>Topic 18</b>: recommender_factorizati...",
          "<b>Topic 19</b>: learning_supervised_lea...",
          "<b>Topic 20</b>: segmentations_segmentat...",
          "<b>Topic 21</b>: quantum_superposition_q...",
          "<b>Topic 24</b>: recognition_classifiers...",
          "<b>Topic 25</b>: optimizing_optimizer_op...",
          "<b>Topic 26</b>: ranking_rankings_ranked...",
          "<b>Topic 27</b>: graphs_probabilistic_mo...",
          "<b>Topic 28</b>: compressive_sparse_comp...",
          "<b>Topic 30</b>: markov_markovian_bioinf...",
          "<b>Topic 31</b>: classifiers_classificat...",
          "<b>Topic 32</b>: attacks_security_intrus..."
         ]
        }
       ],
       "layout": {
        "height": 600,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Topic Probability Distribution</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Probability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_distribution(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
